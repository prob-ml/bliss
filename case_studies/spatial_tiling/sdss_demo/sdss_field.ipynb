{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from os import environ\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from bliss.main import predict\n",
    "from bliss.catalog import TileCatalog, FullCatalog\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "ckpt = \"/home/regier/bliss/tests/data/base_config_trained_encoder.pt\"\n",
    "with initialize(config_path=\".\", version_base=None):\n",
    "    cfg0 = compose(\"config\", {\n",
    "        f\"train.pretrained_weights={ckpt}\",\n",
    "        f\"predict.weight_save_path={ckpt}\",\n",
    "        \"cached_simulator.splits=0:80/80:90/99:100\",\n",
    "        \"cached_simulator.num_workers=0\",\n",
    "    })\n",
    "\n",
    "cfg_c4 = OmegaConf.merge(cfg0, {\"encoder\": {\n",
    "    \"use_checkerboard\": True,\n",
    "    \"n_sampler_colors\": 4\n",
    "}})\n",
    "cfg_c2 = OmegaConf.merge(cfg0, {\"encoder\": {\n",
    "    \"use_checkerboard\": True,\n",
    "    \"n_sampler_colors\": 2,\n",
    "}})\n",
    "cfg_c1 = OmegaConf.merge(cfg0, {\"encoder\": {\n",
    "    \"use_checkerboard\": False,\n",
    "}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and view the SDSS field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss = instantiate(cfg0.surveys.sdss, load_image_data=True)\n",
    "sdss.prepare_data()\n",
    "sdss_frame, = sdss.predict_dataloader()\n",
    "obs_image = sdss_frame[\"images\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = make_lupton_rgb(obs_image[3], obs_image[2], obs_image[1], Q=0, stretch=0.1)\n",
    "plt.imshow(rgb, origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and view SDSS predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bliss.surveys.sdss import PhotoFullCatalog\n",
    "from pathlib import Path\n",
    "\n",
    "rcf = cfg0.surveys.sdss.fields[0]\n",
    "\n",
    "run, camcol, field = rcf[\"run\"], rcf[\"camcol\"], rcf[\"fields\"][0]\n",
    "po_fn = f\"photoObj-{run:06d}-{camcol}-{field:04d}.fits\"\n",
    "po_path = Path(cfg0.paths.sdss) / str(run) / str(camcol) / str(field) / po_fn\n",
    "\n",
    "sdss_wcs = sdss[0][\"wcs\"][2]\n",
    "photo_cat = PhotoFullCatalog.from_file(po_path, sdss_wcs, *obs_image[2].shape)\n",
    "photo_cat[\"n_sources\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and view DECaLS predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bliss.surveys.des import TractorFullCatalog\n",
    "\n",
    "sdss_wcs = sdss[0][\"wcs\"][2]\n",
    "decals_path = Path(cfg0.paths.des) / \"336\" / \"3366m010\" / \"tractor-3366m010.fits\"\n",
    "decals_cat = TractorFullCatalog.from_file(decals_path, sdss_wcs, 1488, 2048)\n",
    "decals_cat[\"n_sources\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make and plot predictions with BLISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated() / 1e9  # show current memory usage in GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = instantiate(cfg0.train.encoder).cuda()\n",
    "enc_state_dict = torch.load(cfg0.train.pretrained_weights)\n",
    "if cfg0.train.pretrained_weights.endswith(\".ckpt\"):\n",
    "    enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "encoder.load_state_dict(enc_state_dict)\n",
    "encoder.eval()\n",
    "\n",
    "batch = {\n",
    "    \"images\": obs_image[:, :, :].unsqueeze(0).cuda(),\n",
    "    \"psf_params\": sdss_frame[\"psf_params\"].cuda(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bliss.catalog import convert_mag_to_nmgy\n",
    "\n",
    "bliss_tile_cat = encoder.sample(batch, use_mode=True)\n",
    "bliss_flux_filter_cat = bliss_tile_cat.filter_by_flux(convert_mag_to_nmgy(23))\n",
    "bliss_cat = bliss_flux_filter_cat.to_full_catalog(4).to(\"cpu\")\n",
    "bliss_cat[\"n_sources\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three-way performance scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_cat_box = photo_cat.filter_by_ploc_box(torch.zeros(2), 1488)\n",
    "decals_cat_box = decals_cat.filter_by_ploc_box(torch.zeros(2), 1488)\n",
    "bliss_cat_box = bliss_cat.filter_by_ploc_box(torch.zeros(2), 1488)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bliss.encoder.metrics import CatalogMatcher\n",
    "\n",
    "# Create a CatalogMatcher object\n",
    "matcher = CatalogMatcher()\n",
    "\n",
    "# Match the catalogs based on their positions\n",
    "match_gt_pred = matcher.match_catalogs(decals_cat_box, bliss_cat_box)\n",
    "match_gt_comp = matcher.match_catalogs(decals_cat_box, photo_cat_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matcher.match_catalogs(bliss_cat_box, photo_cat_box)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP:\n",
    "# both\n",
    "# neither\n",
    "\n",
    "# gt only\n",
    "# comp only\n",
    "# FP: pred only\n",
    "# FP: gt only\n",
    "\n",
    "matches = {\n",
    "    # in gt and pred or comp\n",
    "    \"gt_all\": set(match_gt_pred[0]).union(match_gt_comp[0]),\n",
    "    # in pred and gt, not in comp\n",
    "    \"gt_pred_only\": set(match_gt_pred[0]).difference(match_gt_comp[0]),\n",
    "    # in comp and gt, not in pred\n",
    "    \"gt_comp_only\": set(gt_comp_matches).difference(gt_pred_matches),\n",
    "    # in pred, not in gt\n",
    "    \"pred_only\": set(range(pred_cat[\"n_sources\"].item())).difference(pred_gt_matches),\n",
    "    # in comp, not in gt\n",
    "    \"comp_only\": set(range(comp_cat[\"n_sources\"].item())).difference(comp_gt_matches),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_cat_box[\"n_sources\"], bliss_cat_box[\"n_sources\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
