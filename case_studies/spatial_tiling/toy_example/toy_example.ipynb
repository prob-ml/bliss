{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Data Example\n",
    "\n",
    "Demonstrates that\n",
    "1) the independent tiling posterior approximation becomes increasingly bad as a star approaches a tile border\n",
    "2) the checkerboard tiling posterior approximation remains reasonable regardless of star position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages and pick a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "from bliss.catalog import TileCatalog\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the encoder with pre-trained weights. (This encoder was trained with 20% of tiles contain sources, which is quite high for one-star data, but the incorrect rate shouldn't detract from this example.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "with initialize(config_path=\".\", version_base=None):\n",
    "    overrides = {\n",
    "        \"predict.weight_save_path=/home/regier/bliss_output/jul25_toy_example_10_percent/version_0/checkpoints/best_encoder.ckpt\",\n",
    "        \"decoder.with_noise=true\",\n",
    "        \"decoder.with_dither=false\",\n",
    "        \"encoder.predict_mode_not_samples=false\",\n",
    "        \"train.trainer.logger=false\",\n",
    "        \"train.trainer.max_epochs=0\",\n",
    "        \"+train.trainer.num_sanity_val_steps=0\",\n",
    "        \"cached_simulator.num_workers=0\",\n",
    "        \"cached_simulator.splits=0:80/0:90/99:100\",\n",
    "    }\n",
    "    cfg = compose(\"config\", overrides)\n",
    "\n",
    "decoder = instantiate(cfg.decoder)\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "trainer = instantiate(cfg.train.trainer)\n",
    "\n",
    "data_source = instantiate(cfg.train.data_source)\n",
    "data_source.setup(\"fit\")\n",
    "data_source.setup(\"test\")\n",
    "\n",
    "encoder = instantiate(cfg.encoder).cuda()\n",
    "encoder.eval()\n",
    "state_dict = torch.load(cfg.predict.weight_save_path)[\"state_dict\"]\n",
    "encoder.load_state_dict(state_dict);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One star “moving” across tile border boundaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a batch synethic catalogs of one bright star at three positions: 0, 0.667, and 0.133 pixels from the border. (The first position is perfectly ambiguous, the second is somewhat ambiguous, the third is unambiguous.)\n",
    "\n",
    "The nice thing about this setting is the lack of ambiguity in the (exact) posterior: there should be about one star detected. But is there with each of these posterior approximations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_loc_shift_data(pixel_shift, flux=10.0, n=100, add_galaxy=False):\n",
    "    # 5.0 nmgy = 20.75 magnitude\n",
    "    # n_sources = x[\"tile_catalog\"][\"n_sources\"].unsqueeze(0).repeat(n, 1, 1)\n",
    "    n_sources = torch.zeros(n, 20, 20)\n",
    "    ht = int(pixel_shift // 4)\n",
    "    hp = pixel_shift % 4\n",
    "    n_sources[:, ht, 10] = 1\n",
    "\n",
    "    locs = torch.ones((n, 20, 20, 1, 2)) * 0.5\n",
    "    locs[:, ht, 10, 0, 0] = hp * 0.25\n",
    "    locs[:, 10, 9, 0, :] = 0.5\n",
    "\n",
    "    if add_galaxy:\n",
    "        n_sources[:, 10, 9] = 1\n",
    "    \n",
    "    source_type = torch.zeros(n, 20, 20, 1, 1)\n",
    "    source_type[:, ht, 10] = 0\n",
    "    source_type[:, 10, 9] = 1\n",
    "\n",
    "    galaxy_params = torch.ones(n, 20, 20, 1, 6) * 0.5\n",
    "    galaxy_params[:, 10, 9, 0, [3,5]] = 10.0\n",
    "\n",
    "    star_fluxes = torch.zeros(n, 20, 20, 1, 5)\n",
    "    star_fluxes[:, ht, 10] = flux\n",
    "\n",
    "    galaxy_fluxes = torch.zeros(n, 20, 20, 1, 5)\n",
    "    galaxy_fluxes[:, 10, 9] = 400.0\n",
    "\n",
    "    true_catalog_dict = {\n",
    "        \"n_sources\": n_sources,\n",
    "        \"source_type\": source_type,\n",
    "        \"locs\": locs,\n",
    "        \"star_fluxes\": star_fluxes, \n",
    "        \"galaxy_fluxes\": galaxy_fluxes,\n",
    "        \"galaxy_params\": galaxy_params,\n",
    "    }\n",
    "    true_catalog = TileCatalog(true_catalog_dict)\n",
    "\n",
    "    images, psf_params = decoder.render_images(true_catalog)\n",
    "\n",
    "    # one band (without using CachedDataset + OneBandTransform for simplicity)\n",
    "    true_catalog[\"star_fluxes\"] = true_catalog[\"star_fluxes\"][..., 2:3]\n",
    "    true_catalog[\"galaxy_fluxes\"] = true_catalog[\"galaxy_fluxes\"][..., 2:3]\n",
    "\n",
    "    batch = {\n",
    "        \"images\": images[:, 2:3].cuda(),\n",
    "        \"psf_params\": psf_params[:, 2:3].cuda(),\n",
    "        \"tile_catalog\": true_catalog,\n",
    "    }\n",
    "\n",
    "    return true_catalog, batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate one image for each catalog"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the r-band of sample images, one with each center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_catalog, batch = gen_loc_shift_data(40, flux=10.0, n=10)\n",
    "\n",
    "i = 0\n",
    "plt.set_cmap('viridis')\n",
    "plt.imshow(batch[\"images\"][i, 0].cpu().numpy())\n",
    "plt.grid(color='white', linewidth=1, linestyle='dotted')\n",
    "plt.xticks(np.arange(20) * 4 + 3.5);\n",
    "plt.yticks(np.arange(20) * 4 + 3.5);\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels([]);\n",
    "ax.set_yticklabels([]);\n",
    "ax.tick_params(axis='both', which='both', length=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc1 = (true_catalog[\"locs\"][i, 10, 10, 0] + 10 - 8) * 4 - 0.5\n",
    "loc1 = loc1.cpu().numpy()\n",
    "\n",
    "plt.imshow(batch[\"images\"][i, 0, 32:48, 32:48].cpu().numpy())\n",
    "plt.grid(color='white', linewidth=1, linestyle='dotted')\n",
    "plt.xticks(np.arange(4) * 4 + 3.5)\n",
    "plt.yticks(np.arange(4) * 4 + 3.5)\n",
    "#plt.plot(loc1[1], loc1[0], 'ro', markersize=7)\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear the GPU memory so we don't run out in case we re-run this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder.cuda()\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated() / 1e9  # show current memory usage in GB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkerboard Tiling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict two catalogs: one the mode of the variational distribution and the other a sample of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.use_checkerboard = True\n",
    "\n",
    "encoder.predict_mode_not_samples = True\n",
    "mode_cat = encoder.predict_step(batch, 0, 0)\n",
    "\n",
    "encoder.predict_mode_not_samples = False\n",
    "sample_cat = encoder.predict_step(batch, 0, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tthe source should be found in tile [10,10], moving in the first dimension\n",
    "from 0 to 0.5. We restrict our attention to a 2 tiles per image to avoid spurious detections,\n",
    "which are inevitable in a large enough image due to Gaussian noise.\n",
    "\n",
    "For all three locations, all 20 replicates show 1 source in the variational distribution mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_cat[\"n_sources\"][:, 9:11, 10].sum([1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample cat isn't as consistent, but there's clear dependence on the location (border vs interior). The twos are low-flux detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cat[\"n_sources\"][:, 9:11, 10].sum([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cat2 = sample_cat.filter_by_flux(min_flux=5.0, band=0)\n",
    "sample_cat2[\"n_sources\"][:, 9:11, 10].sum([1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent Tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.use_checkerboard = False\n",
    "\n",
    "encoder.predict_mode_not_samples = True\n",
    "mode_cat = encoder.predict_step(batch, 0, 0)\n",
    "\n",
    "encoder.predict_mode_not_samples = False\n",
    "sample_cat = encoder.predict_step(batch, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_cat[\"n_sources\"][:, 9:11, 10].sum([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_cat2 = mode_cat.filter_by_flux(min_flux=5.0, band=0)\n",
    "mode_cat2[\"n_sources\"][:, 9:11, 10].sum([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cat[\"n_sources\"][:, 9:11, 10].sum([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_cat2 = sample_cat.filter_by_flux(min_flux=5.0, band=0)\n",
    "sample_cat2[\"n_sources\"][:, 9:11, 10].sum([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated() / 1e9  # show current memory usage in GB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All-pixel-shifts comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "pixel_shifts = (0.0, 0.03, 0.05, 0.08, 0.1, 0.13, 0.2, 0.3, 0.8, 1.5)\n",
    "pixel_shifts = np.array(pixel_shifts)\n",
    "ps2 = np.flip(4 - pixel_shifts)\n",
    "pixel_shifts = np.concatenate([pixel_shifts, ps2])\n",
    "pixel_shifts = np.concatenate([pixel_shifts, pixel_shifts + 4, pixel_shifts + 8])\n",
    "pixel_shifts += 32\n",
    "pixel_shifts\n",
    "\n",
    "encoder.predict_mode_not_samples=False\n",
    "\n",
    "def all_pixel_shifts(flux):\n",
    "    accuracy = [[], []]\n",
    "\n",
    "    for pixel_shift in pixel_shifts:\n",
    "        true_catalog, batch = gen_loc_shift_data(pixel_shift, flux=flux)\n",
    "        for use_cb in range(0, 2):\n",
    "            encoder.use_checkerboard = use_cb\n",
    "            acc = 0\n",
    "            for i in range(10):\n",
    "                sample_cat = encoder.predict_step(batch, 0, 0)\n",
    "                sample_cat2 = sample_cat.filter_by_flux(flux / 2, band=0)\n",
    "                ht = int((pixel_shift - 2) // 4)\n",
    "                acc += (sample_cat2[\"n_sources\"][:, ht:(ht+2), 10].sum([1]) == 1).sum().item()\n",
    "            accuracy[use_cb].append(acc / 1000)\n",
    "            print(f\"{use_cb}, {pixel_shift}: {acc}\")\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "accuracy_bright = all_pixel_shifts(6.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(accuracy):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_context(\"paper\", font_scale=1.5)\n",
    "    plt.plot(pixel_shifts, accuracy[0], '-', label=\"Independent\")\n",
    "    plt.plot(pixel_shifts, accuracy[1], '-', label=\"Checkerboard\")\n",
    "    plt.xlabel(\"Star vertical position (pixels)\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim(0.5, 1.01)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_accuracy(accuracy_bright);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faint Star\n",
    "\n",
    "An ambiguous detection (~80% detection prob) at the border and at the center.\n",
    "\n",
    "First, we generate a true catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_faint = all_pixel_shifts(1.3)\n",
    "plot_accuracy(accuracy_faint);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A blended star and galaxy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we render the images and backgrounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_catalog, batch = gen_loc_shift_data(40.0, add_galaxy=False, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "loc1 = (true_catalog[\"locs\"][i, 10, 10, 0] + 10 - 8) * 4 - 0.5\n",
    "\n",
    "plt.imshow(batch[\"images\"][i, 0, 32:48, 32:48].cpu().numpy(), cmap='viridis')\n",
    "plt.grid(color='white', linewidth=1, linestyle='dotted')\n",
    "plt.xticks(np.arange(4) * 4 + 3.5)\n",
    "plt.yticks(np.arange(4) * 4 + 3.5)\n",
    "plt.plot(loc1[1], loc1[0], 'ro', markersize=7)\n",
    "plt.plot(5.5, 9.5, 'ro', markersize=7)\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate in-distribution performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.use_checkerboard = True\n",
    "encoder.n_sampler_colors = 4\n",
    "encoder.mode_metrics.reset()\n",
    "\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "\n",
    "class NllCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.nlls = []\n",
    "        self.precisions = []\n",
    "        self.recalls = []\n",
    "        self.f1s = []\n",
    "\n",
    "    def on_predict_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        nlls = pl_module.compute_sampler_nll(batch).sum([1,2])\n",
    "        self.nlls.append(nlls)\n",
    "\n",
    "        pl_module.update_metrics(batch, batch_idx)\n",
    "        m = pl_module.mode_metrics[\"detection_performance\"].compute()\n",
    "        self.precisions.append(m[\"detection_precision\"].item())\n",
    "        self.recalls.append(m[\"detection_recall\"].item())\n",
    "        self.f1s.append(m[\"detection_f1\"].item())\n",
    "        pl_module.mode_metrics.reset()\n",
    "    \n",
    "    def report(self):\n",
    "        nlls = torch.cat(self.nlls)\n",
    "\n",
    "        nll_sd = nlls.std().item() / np.sqrt(nlls.size(0))\n",
    "        print(f\"Mean NLL: {nlls.mean().item():.2f} ({nll_sd:.2f})\")\n",
    "\n",
    "        precision_sd = np.std(self.precisions) / np.sqrt(len(self.precisions))\n",
    "        print(f\"Mean precision: {np.mean(self.precisions):.4f} ({precision_sd:.4f})\")\n",
    "\n",
    "        recall_sd = np.std(self.recalls) / np.sqrt(len(self.recalls))\n",
    "        print(f\"Mean recall: {np.mean(self.recalls):.4f} ({recall_sd:.4f})\")\n",
    "\n",
    "        f1_sd = np.std(self.f1s) / np.sqrt(len(self.f1s))\n",
    "        print(f\"Mean F1: {np.mean(self.f1s):.4f} ({f1_sd:.4f})\")\n",
    "\n",
    "nll_callback = NllCallback()\n",
    "trainer = instantiate(cfg.train.trainer, callbacks=[nll_callback])\n",
    "trainer.predict(encoder, dataloaders=[data_source.test_dataloader()], return_predictions=False)\n",
    "nll_callback.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.use_checkerboard = True\n",
    "encoder.n_sampler_colors = 2\n",
    "\n",
    "nll_callback = NllCallback()\n",
    "trainer = instantiate(cfg.train.trainer, callbacks=[nll_callback])\n",
    "trainer.predict(encoder, dataloaders=[data_source.test_dataloader()], return_predictions=False)\n",
    "nll_callback.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.use_checkerboard = False\n",
    "\n",
    "nll_callback = NllCallback()\n",
    "trainer = instantiate(cfg.train.trainer, callbacks=[nll_callback])\n",
    "trainer.predict(encoder, dataloaders=[data_source.test_dataloader()], return_predictions=False)\n",
    "nll_callback.report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
