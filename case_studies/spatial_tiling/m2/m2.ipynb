{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from bliss.main import predict\n",
    "from bliss.catalog import TileCatalog, FullCatalog\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "ckpt = \"/home/regier/bliss_output/aug17_sample100percent/version_0/checkpoints/best_encoder.ckpt\"\n",
    "with initialize(config_path=\".\", version_base=None):\n",
    "    cfg0 = compose(\"config\", {\n",
    "        f\"train.pretrained_weights={ckpt}\",\n",
    "        f\"predict.weight_save_path={ckpt}\",\n",
    "        \"cached_simulator.splits=0:80/80:90/97:98\",\n",
    "        \"cached_simulator.num_workers=0\",\n",
    "    })\n",
    "\n",
    "cfg_c4 = OmegaConf.merge(cfg0, {\"encoder\": {\n",
    "    \"use_checkerboard\": True,\n",
    "    \"n_sampler_colors\": 4\n",
    "}})\n",
    "cfg_c2 = OmegaConf.merge(cfg0, {\"encoder\": {\n",
    "    \"use_checkerboard\": True,\n",
    "    \"n_sampler_colors\": 2,\n",
    "}})\n",
    "cfg_c1 = OmegaConf.merge(cfg0, {\"encoder\": {\n",
    "    \"use_checkerboard\": False,\n",
    "}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SDSS image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = fits.open('/home/regier/bliss/tests/data/sdss/2583/2/136/frame-r-002583-2-0136.fits')\n",
    "w = WCS(f[0].header)\n",
    "\n",
    "# lower-left corner of the 100x100-pixel study area is at pixel (310, 630)\n",
    "w.pixel_to_world(310, 630)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(f[0].data, origin='lower', cmap='Greys_r')\n",
    "print(\"Behold, the M2 globular cluster!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logimage = np.log(f[0].data - f[0].data.min() + 1)\n",
    "plt.imshow(logimage, origin='lower', cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "plt.imshow(logimage, origin='lower', cmap='Greys_r')\n",
    "rect = Rectangle((310, 630), 100, 100, linewidth=2, edgecolor='r', facecolor='none')\n",
    "_ = plt.gca().add_patch(rect)\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = f[0].data[630:730, 310:410]\n",
    "\n",
    "arcsinh_median = np.arcsinh((original - np.median(original)))\n",
    "\n",
    "clipped = original.clip(max=np.quantile(original, 0.98))\n",
    "arcsinh_clipped = np.arcsinh((clipped - np.median(clipped)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "images = [original, arcsinh_median, arcsinh_clipped]\n",
    "titles = ['original', 'arcsinc', 'arcsinc with clipping']\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    ax = axs[i]\n",
    "    ax.imshow(img, origin='lower', cmap='Greys_r')\n",
    "    ax.set_title(titles[i])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and view HST predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget https://archive.stsci.edu/pub/hlsp/acsggct/ngc7089/hlsp_acsggct_hst_acs-wfc_ngc7089_r.rdviq.cal.adj.zpt\n",
    "hubble_cat_file = \"/home/regier/hlsp_acsggct_hst_acs-wfc_ngc7089_r.rdviq.cal.adj.zpt\"\n",
    "hubble_cat = np.loadtxt(hubble_cat_file, skiprows=3, usecols=(9,21,22))\n",
    "\n",
    "hst_r_mag_all = torch.from_numpy(hubble_cat[:, 0])\n",
    "ra = torch.from_numpy(hubble_cat[:, 1])\n",
    "dec = torch.from_numpy(hubble_cat[:, 2])\n",
    "\n",
    "plocs_all = FullCatalog.plocs_from_ra_dec(ra, dec, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_bounds = (plocs_all[:, 1] > 310) & (plocs_all[:, 1] < 410)\n",
    "in_bounds &= (plocs_all[:, 0] > 630) & (plocs_all[:, 0] < 730)\n",
    "in_bounds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hst_r_mag = hst_r_mag_all[in_bounds]\n",
    "plocs = plocs_all[in_bounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plocs_square = plocs - torch.tensor([630, 310])\n",
    "\n",
    "from bliss.catalog import convert_mag_to_nmgy, convert_nmgy_to_mag\n",
    "hst_r_nmgy = convert_mag_to_nmgy(hst_r_mag)\n",
    "\n",
    "# these magnitudes are about 15% off: the hubble fw606 band filter curve\n",
    "#  isn't exactly the sdss r band filter curve\n",
    "sdss_r_nmgy = hst_r_nmgy * 1.15\n",
    "sdss_r_mag = convert_nmgy_to_mag(sdss_r_nmgy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"plocs\": plocs_square.unsqueeze(0),\n",
    "    \"star_fluxes\": sdss_r_nmgy.unsqueeze(0).unsqueeze(2),\n",
    "    \"galaxy_fluxes\": sdss_r_nmgy.unsqueeze(0).unsqueeze(2) * 0.0,\n",
    "    \"n_sources\": torch.tensor(plocs.shape[0]).unsqueeze(0),\n",
    "    \"source_type\": torch.zeros(plocs.shape[0]).unsqueeze(0).unsqueeze(2).long(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cat_all = FullCatalog(100, 100, d)\n",
    "true_cat_all[\"n_sources\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tile_cat_all = true_cat_all.to_tile_catalog(2, 11)\n",
    "true_tile_cat_all[\"n_sources\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_bright = sdss_r_mag < 22.565\n",
    "is_bright.sum(), convert_mag_to_nmgy(22.565)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target number of sources in 1114\n",
    "cutoff_mag_1114 = 22.130\n",
    "(sdss_r_mag < cutoff_mag_1114).sum()\n",
    "cutoff_nmgy_1114 = convert_mag_to_nmgy(cutoff_mag_1114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"plocs\": plocs_square[is_bright].unsqueeze(0),\n",
    "    \"star_fluxes\": sdss_r_nmgy[is_bright].unsqueeze(0).unsqueeze(2).expand([-1, -1, 5]),\n",
    "    \"galaxy_fluxes\": sdss_r_nmgy[is_bright].unsqueeze(0).unsqueeze(2).expand([-1, -1, 5]) * 0.0,\n",
    "    \"n_sources\": torch.tensor(plocs[is_bright].shape[0]).unsqueeze(0),\n",
    "    \"source_type\": torch.zeros(plocs[is_bright].shape[0]).unsqueeze(0).unsqueeze(2).long(),\n",
    "}\n",
    "true_cat = FullCatalog(100, 100, d)\n",
    "true_cat[\"n_sources\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tile_cat = true_cat.to_tile_catalog(2, 5)\n",
    "true_tile_cat[\"n_sources\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "cutoffs = [20, 22.065, 24]\n",
    "\n",
    "for i, cutoff in enumerate(cutoffs):\n",
    "    is_bright = sdss_r_mag < cutoff\n",
    "    plocs_square_bright = plocs_square[is_bright]\n",
    "    ax = axs[i]\n",
    "    ax.imshow(arcsinh_clipped, origin='lower', cmap='Greys_r')\n",
    "    ax.scatter(plocs_square_bright[:, 1], plocs_square_bright[:, 0], s=5, c='r')\n",
    "    ax.set_title(f\"magnitude < {cutoff}\")\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLISS performance on M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m2_dp(cfg):\n",
    "    preds = predict(cfg.predict)\n",
    "    bliss_cat, = preds.values()  # singleton dict\n",
    "    bliss_cat = bliss_cat.symmetric_crop(3).to_full_catalog(cfg.encoder.tile_slen)\n",
    "\n",
    "    matcher = instantiate(cfg.encoder.matcher)\n",
    "    mode_metrics = instantiate(cfg.encoder.mode_metrics)\n",
    "\n",
    "    matching = matcher.match_catalogs(true_cat, bliss_cat)\n",
    "    return mode_metrics(true_cat, bliss_cat, matching)\n",
    "\n",
    "c4_dp_real = m2_dp(cfg_c4)\n",
    "c2_dp_real = m2_dp(cfg_c2)\n",
    "c1_dp_real = m2_dp(cfg_c1)\n",
    "\n",
    "metrics = [c4_dp_real, c2_dp_real, c1_dp_real]\n",
    "for m in metrics:\n",
    "    p = m[\"detection_precision\"].item()\n",
    "    r = m[\"detection_recall\"].item()\n",
    "    f = m[\"detection_f1\"].item()\n",
    "    print(f\"precision: {p:.4}  recall: {r:.4}  f1: {f:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = instantiate(cfg0.surveys.sdss, load_image_data=True)\n",
    "dataset.prepare_data()\n",
    "sdss_frame, = dataset.predict_dataloader()\n",
    "obs_image_padded = sdss_frame[\"images\"][:, 2:3, 624:736, 304:416]\n",
    "obs_image_cropped = obs_image_padded[0, 0, 6:-6, 6:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {\n",
    "    \"images\": obs_image_padded.expand(50, -1, -1, -1).cuda(),\n",
    "}\n",
    "\n",
    "def m2_credible_intervals_new(cfg):\n",
    "    cfg_sample = OmegaConf.merge(cfg, {\"encoder\": {\"predict_mode_not_samples\": False}})\n",
    "\n",
    "    encoder = instantiate(cfg_sample.train.encoder).cuda()\n",
    "    enc_state_dict = torch.load(cfg_sample.train.pretrained_weights)\n",
    "    enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "    encoder.load_state_dict(enc_state_dict)\n",
    "    encoder.eval()\n",
    "\n",
    "    counts = []\n",
    "    for i in range(20):\n",
    "        sample_cat = encoder.predict_step(batch, 0)\n",
    "        sample_cat = sample_cat.symmetric_crop(3)\n",
    "        bliss_sources = (sample_cat.on_fluxes(\"nmgy\") > cutoff_nmgy_1114).sum([1,2,3,4])\n",
    "        counts.append(bliss_sources)\n",
    "\n",
    "    cs = torch.cat(counts).float()\n",
    "    return (cs.quantile(0.05).item(), cs.mean().item(), cs.quantile(0.95).item())\n",
    "\n",
    "c4_ci_real = m2_credible_intervals_new(cfg_c4)\n",
    "c2_ci_real = m2_credible_intervals_new(cfg_c2)\n",
    "c1_ci_real = m2_credible_intervals_new(cfg_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ci in [c4_ci_real, c2_ci_real, c1_ci_real]:\n",
    "    print(ci)\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLISS performance on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NllCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.nlls = []\n",
    "        self.precisions = []\n",
    "        self.recalls = []\n",
    "        self.f1s = []\n",
    "\n",
    "    def on_predict_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        nlls = pl_module.compute_sampler_nll(batch).sum([1,2])\n",
    "        self.nlls.append(nlls)\n",
    "\n",
    "        pl_module.update_metrics(batch, batch_idx)\n",
    "        m = pl_module.mode_metrics[\"detection_performance\"].compute()\n",
    "        self.precisions.append(m[\"detection_precision\"].item())\n",
    "        self.recalls.append(m[\"detection_recall\"].item())\n",
    "        self.f1s.append(m[\"detection_f1\"].item())\n",
    "        pl_module.mode_metrics.reset()\n",
    "\n",
    "    def report(self):\n",
    "        nlls = torch.cat(self.nlls)\n",
    "\n",
    "        nll_sd = nlls.std().item() / np.sqrt(nlls.size(0))\n",
    "        print(f\"Mean NLL: {nlls.mean().item():.2f} ({nll_sd:.2f})\")\n",
    "\n",
    "        precision_sd = np.std(self.precisions) / np.sqrt(len(self.precisions))\n",
    "        print(f\"Mean precision: {np.mean(self.precisions):.4f} ({precision_sd:.4f})\")\n",
    "\n",
    "        recall_sd = np.std(self.recalls) / np.sqrt(len(self.recalls))\n",
    "        print(f\"Mean recall: {np.mean(self.recalls):.4f} ({recall_sd:.4f})\")\n",
    "\n",
    "        f1_sd = np.std(self.f1s) / np.sqrt(len(self.f1s))\n",
    "        print(f\"Mean F1: {np.mean(self.f1s):.4f} ({f1_sd:.4f})\")\n",
    "\n",
    "\n",
    "data_module = instantiate(cfg0.train.data_source)\n",
    "data_module.setup(\"fit\")\n",
    "data_module.setup(\"test\")\n",
    "test_dl = data_module.test_dataloader()\n",
    "\n",
    "for cfg in [cfg_c4, cfg_c2, cfg_c1]:\n",
    "    encoder = instantiate(cfg.train.encoder)\n",
    "    enc_state_dict = torch.load(cfg.train.pretrained_weights)\n",
    "    if cfg.train.pretrained_weights.endswith(\".ckpt\"):\n",
    "        enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "    encoder.load_state_dict(enc_state_dict)\n",
    "\n",
    "    nll_cb = NllCallback()\n",
    "    trainer = instantiate(cfg.predict.trainer, callbacks=[nll_cb])\n",
    "    trainer.predict(encoder, dataloaders=[test_dl], return_predictions=False)\n",
    "    nll_cb.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_metric(cfg):\n",
    "    cfg.train.data_source.nontrain_transforms[2]['min_flux'] = 1.5\n",
    "    data_module = instantiate(cfg.train.data_source)\n",
    "    data_module.setup(\"fit\")\n",
    "    data_module.setup(\"test\")\n",
    "\n",
    "    encoder = instantiate(cfg.train.encoder)\n",
    "    enc_state_dict = torch.load(cfg.train.pretrained_weights)\n",
    "    if cfg.train.pretrained_weights.endswith(\".ckpt\"):\n",
    "        enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "    encoder.load_state_dict(enc_state_dict)\n",
    "\n",
    "    trainer = instantiate(cfg0.predict.trainer)\n",
    "    x = trainer.test(encoder, datamodule=data_module)\n",
    "\n",
    "    # could use x instead here instead, but need to output bins\n",
    "    # as a vector\n",
    "    dp = encoder.mode_metrics[\"detection_performance\"]\n",
    "    two_pt = encoder.sample_metrics[\"two_point\"]\n",
    "\n",
    "    return dp.compute(), two_pt.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "c4_dp_synthetic, c4_two_pt_synthetic = synthetic_metric(cfg_c4)\n",
    "c2_dp_synthetic, c2_two_pt_synthetic = synthetic_metric(cfg_c2)\n",
    "c1_dp_synthetic, c1_two_pt_synthetic = synthetic_metric(cfg_c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess the two-point correlation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings from spotchecking sources of nonzero two-point correlation above:\n",
    "* two pairs of sources with modes within 1e-4: catty corner, need 4 color checkerboard\n",
    "* one pair of sources with modes within 1e-2: consecutive columns in a row, near a corner; one source a second detect; need conditioning info to second detect\n",
    "* one pair of sources with sampled modes within 0.1: a double detect solidly within a tile; high uncertainty about whether second exists (it doesn't); first correctly identified; second detected source hovers around the pixel (of 4) containing the source; need conditioning info for the second detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radii = [float(r) for r in c4_two_pt_synthetic.keys()]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(radii, c1_two_pt_synthetic.values(), marker=\"s\", label=\"1-color checkerboard\")\n",
    "plt.plot(radii, c2_two_pt_synthetic.values(), label=\"2-color checkerboard\", marker=\"s\")\n",
    "plt.plot(radii, c4_two_pt_synthetic.values(), label=\"4-color checkerboard\", marker=\"s\")\n",
    "plt.axhline(y=0, color='black', linestyle='dotted', label='ideal')\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Distance (pixels)\")\n",
    "plt.ylabel(\"Two-point correlation\")\n",
    "plt.xticks([0.1, 0.3, 1, 3], labels=[\"0.1\", \"0.3\", \"1\", \"3\"])\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.residual_sources = []\n",
    "\n",
    "    def on_predict_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        bliss_cat = outputs\n",
    "        bliss_cat = bliss_cat.symmetric_crop(3)\n",
    "        bliss_sources = (bliss_cat.on_fluxes(\"nmgy\") > cutoff_nmgy_1114).sum([1,2,3,4])\n",
    "        true_fluxes = TileCatalog(batch[\"tile_catalog\"]).symmetric_crop(3).on_fluxes(\"nmgy\")\n",
    "        true_sources =  (true_fluxes > cutoff_nmgy_1114).sum([1,2,3,4])\n",
    "        residual_sources = true_sources - bliss_sources \n",
    "        self.residual_sources.append(residual_sources)\n",
    "\n",
    "    def report(self):\n",
    "        counts = torch.cat(self.residual_sources).float()\n",
    "        mean = counts.mean().item()\n",
    "        mean_std = counts.std().item() / np.sqrt(counts.size(0))\n",
    "        print(f\"Mean residual sources: {mean:.2f} ({mean_std:.2f})\")\n",
    "\n",
    "def synthetic_calibration(cfg):\n",
    "    cfg_sample = OmegaConf.merge(cfg, {\"encoder\": {\"predict_mode_not_samples\": False}})\n",
    "\n",
    "    data_module = instantiate(cfg.train.data_source)\n",
    "    data_module.setup(\"test\")\n",
    "    test_dl = data_module.test_dataloader()\n",
    "\n",
    "    encoder = instantiate(cfg_sample.train.encoder)\n",
    "    enc_state_dict = torch.load(cfg_sample.train.pretrained_weights)\n",
    "    if cfg_sample.train.pretrained_weights.endswith(\".ckpt\"):\n",
    "        enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "    encoder.load_state_dict(enc_state_dict)\n",
    "\n",
    "    ci_cb = CiCallback()\n",
    "    trainer = instantiate(cfg.predict.trainer, callbacks=[ci_cb])\n",
    "    trainer.predict(encoder, dataloaders=[test_dl], return_predictions=False)\n",
    "    ci_cb.report()\n",
    "\n",
    "synthetic_calibration(cfg_c4)\n",
    "synthetic_calibration(cfg_c2)\n",
    "synthetic_calibration(cfg_c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = instantiate(cfg0.train.data_source)\n",
    "data_module.setup(\"fit\")\n",
    "data_module.setup(\"test\")\n",
    "\n",
    "encoder = instantiate(cfg0.train.encoder, predict_mode_not_samples=False)\n",
    "\n",
    "enc_state_dict = torch.load(cfg0.train.pretrained_weights)\n",
    "if cfg0.train.pretrained_weights.endswith(\".ckpt\"):\n",
    "    enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "encoder.load_state_dict(enc_state_dict)\n",
    "\n",
    "\n",
    "class DetectionHeatmapCallback(Callback):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.heatmap = torch.zeros(8, 8, device=\"cuda\")\n",
    "\n",
    "    def on_predict_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        fc = outputs.to_full_catalog(cfg0.encoder.tile_slen)\n",
    "        tile_pos = fc[\"plocs\"] % 2\n",
    "        for i, n in enumerate(fc[\"n_sources\"]):\n",
    "            indices = (tile_pos[i][:n] // 0.25).long()\n",
    "            values = torch.ones(indices.size(0), device=\"cuda\")\n",
    "            rows = indices[:, 0]\n",
    "            cols = indices[:, 1]\n",
    "            self.heatmap.index_put_((rows, cols), values, accumulate=True)\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "class NearbyHeatmapCallback(Callback):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.heatmap = torch.zeros(8, 8, device=\"cuda\")\n",
    "\n",
    "    def on_predict_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        fc = outputs.to_full_catalog(cfg0.encoder.tile_slen)\n",
    "        tile_pos = fc[\"plocs\"] % 2\n",
    "        for i, n in enumerate(fc[\"n_sources\"]):\n",
    "            indices = (tile_pos[i][:n] // 0.25).long()\n",
    "            locs_all = fc[\"plocs\"][i, :n]\n",
    "            kd_all = cKDTree(locs_all.cpu().numpy())\n",
    "            for j1, j2 in kd_all.query_pairs(0.35):\n",
    "                self.heatmap[indices[j1][0], indices[j1][1]] += 1\n",
    "                self.heatmap[indices[j2][0], indices[j2][1]] += 1\n",
    "\n",
    "dhcb = DetectionHeatmapCallback()\n",
    "nhmcb = NearbyHeatmapCallback()\n",
    "trainer = instantiate(cfg0.predict.trainer, callbacks=[dhcb, nhmcb])\n",
    "trainer.predict(encoder, dataloaders=[data_module.test_dataloader()], return_predictions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(dhcb.heatmap.cpu(), origin='lower', cmap='viridis')\n",
    "plt.colorbar();\n",
    "\n",
    "plt.xticks([-0.5, 3.5, 7.5], [0, 1, 2])\n",
    "plt.yticks([-0.5, 3.5, 7.5], [0, 1, 2]);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(nhmcb.heatmap.cpu(), origin='lower', cmap='viridis')\n",
    "plt.colorbar();\n",
    "\n",
    "plt.xticks([-0.5, 3.5, 7.5], [0, 1, 2])\n",
    "plt.yticks([-0.5, 3.5, 7.5], [0, 1, 2]);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess the model and BLISS fit visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = instantiate(cfg0.decoder, with_noise=False)\n",
    "truth_images, _psf_params = decoder.render_images(true_tile_cat_all)\n",
    "true_recon_all = truth_images[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(cfg0.predict)\n",
    "bliss_cat, = preds.values()  # singleton dict\n",
    "bliss_images, _psf_params = decoder.render_images(bliss_cat)\n",
    "bliss_recon = bliss_images[0, 2][6:-6, 6:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['SDSS image', 'HST reconstruction', 'Our reconstruction']\n",
    "\n",
    "images = [obs_image_cropped, true_recon_all, bliss_recon]\n",
    "images = [img.clip(max=obs_image_cropped.quantile(0.99)) for img in images]\n",
    "images = [np.arcsinh((img - np.median(obs_image_cropped) / 50)) for img in images]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "vmin = min(img.min() for img in images)\n",
    "vmax = max(img.max() for img in images)\n",
    "\n",
    "plt.set_cmap(\"viridis\")\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    ax = axs[i]\n",
    "    ax.imshow(img, origin='lower', vmin=vmin, vmax=vmax, cmap='Greys_r')\n",
    "    ax.set_title(titles[i])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flux Prior Elicitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob = (plocs_all[:, 1] > 210) & (plocs_all[:, 1] < 510)\n",
    "oob &= (plocs_all[:, 0] > 530) & (plocs_all[:, 0] < 830)\n",
    "oob &= ~in_bounds\n",
    "oob.sum() # some of this region (about half) is outside of our HST cat coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hst_oob = hst_r_mag_all[oob]\n",
    "hst_oob_nmgy = convert_mag_to_nmgy(hst_oob) * 1.15\n",
    "hst_oob_mag = convert_nmgy_to_mag(hst_oob_nmgy)\n",
    "training_data = hst_oob_nmgy[hst_oob_mag < 24]\n",
    "training_data.shape[0], training_data.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncpareto\n",
    "alpha, trunc, loc, scale = truncpareto.fit(training_data)\n",
    "alpha, trunc, loc, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncpareto\n",
    "\n",
    "x = np.logspace(hst_oob_nmgy.log10().min(), hst_oob_nmgy.log10().max(), num=100)\n",
    "\n",
    "_ = plt.plot(x, truncpareto.pdf(x, alpha, trunc, loc, scale), 'r-', lw=3, alpha=0.7, label='new prior')\n",
    "_ = plt.plot(x, truncpareto.pdf(x, 0.5, 1014, 0, 0.63), 'g-', lw=3, alpha=0.7, label='old prior')\n",
    "_ = plt.hist(hst_oob_nmgy, log=True, bins=100, label='star_fluxes histogram', density=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncpareto\n",
    "\n",
    "x = np.linspace(hst_oob_nmgy.log10().min(), 100, num=100)\n",
    "\n",
    "_ = plt.plot(x, truncpareto.pdf(x, 0.01, 100, 3.0, 3.0), 'g-', lw=3, alpha=0.7, label='old prior')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(x, truncpareto.pdf(x, alpha, trunc, loc, scale), 'r-', lw=3, alpha=0.7, label='new prior')\n",
    "_ = plt.plot(x, truncpareto.pdf(x, 0.5, 1014, 0, 0.63), 'g-', lw=3, alpha=0.7, label='old prior')\n",
    "plt.legend()\n",
    "plt.loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = truncpareto.rvs(alpha, trunc, loc, scale, size=1500)\n",
    "sorted(samples, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = instantiate(cfg0.prior)\n",
    "prior.sample().on_nmgy[0, :, :, :, 2].view(-1).topk(100)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate rate with oob data\n",
    "(hst_oob_mag < 24).sum() / (4 * 1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the per-tile source density\n",
    "(1114 / 50**2) / (1 - truncpareto.cdf(cutoff_nmgy_1114, alpha, trunc, loc, scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-synthetic M2 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "decoder = instantiate(cfg0.decoder, with_noise=False)\n",
    "\n",
    "#TODO: crop 6 pixels from each side (to 100x100)\n",
    "d2 = deepcopy(true_cat_all)\n",
    "d2[\"plocs\"] += 6\n",
    "true_cat_pad = FullCatalog(112, 112, d2)\n",
    "\n",
    "truth_images, _ = decoder.render_images(true_cat_pad.to_tile_catalog(2, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semisynth_image = truth_images[:, 2:3]\n",
    "plt.imshow(semisynth_image[0, 0, 6:-6, 6:-6].numpy(), origin='lower', cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {\n",
    "    \"images\": semisynth_image.cuda(),\n",
    "}\n",
    "\n",
    "def semisynth_dp(cfg):\n",
    "    cfg_sample = OmegaConf.merge(cfg, {\"encoder\": {\"predict_mode_not_samples\": True}})\n",
    "\n",
    "    encoder = instantiate(cfg_sample.train.encoder).cuda()\n",
    "    enc_state_dict = torch.load(cfg_sample.train.pretrained_weights)\n",
    "    enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "    encoder.load_state_dict(enc_state_dict)\n",
    "    encoder.eval()\n",
    "\n",
    "    bliss_cat = encoder.predict_step(batch, 0)\n",
    "\n",
    "    bliss_cat = bliss_cat.symmetric_crop(3)\n",
    "    bliss_cat = bliss_cat.to_full_catalog(cfg_sample.encoder.tile_slen)\n",
    "    true_cat_cuda = true_cat_all.to(\"cuda:0\")\n",
    "    matching = encoder.matcher.match_catalogs(true_cat_cuda, bliss_cat)\n",
    "    return encoder.mode_metrics(true_cat_cuda, bliss_cat, matching)\n",
    "\n",
    "c4_dp_semisynth = semisynth_dp(cfg_c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbc = cfg0.star_metrics.detection_performance.bin_cutoffs\n",
    "\n",
    "titles = [\"Fully Synthetic\", \"Semi-Synthetic\", \"Real\"]\n",
    "dp_metrics = [c4_dp_synthetic, c4_dp_semisynth, c4_dp_real]\n",
    "\n",
    "xlabels = [f\"[{mbc[i]}, {mbc[i+1]}]\" for i in range(len(mbc) - 1)]\n",
    "xlabels = [\"< \" + str(mbc[0])] + xlabels + [\"> \" + str(mbc[-1])]\n",
    "xlabels = xlabels[:-1]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for i, dp in enumerate(dp_metrics):\n",
    "    recall = [v.item() for k, v in dp.items() if k[:-1] == \"detection_recall_bin_\"]\n",
    "    precision = [v.item() for k, v in dp.items() if k[:-1] == \"detection_precision_bin_\"]\n",
    "    axs[0].plot(recall, marker=\"s\", label=titles[i])\n",
    "    axs[1].plot(precision, marker=\"s\", label=titles[i])\n",
    "\n",
    "axs[0].set_title(\"Recall\")\n",
    "axs[1].set_title(\"Precision\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xticks(range(len(xlabels)))\n",
    "    ax.set_xticklabels(xlabels, rotation=45)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
