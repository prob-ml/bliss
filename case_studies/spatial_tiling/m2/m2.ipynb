{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from bliss.main import predict\n",
    "from bliss.catalog import TileCatalog, FullCatalog\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# ckpt = \"/home/regier/bliss_output/sep21_minimalist/version_0/checkpoints/encoder_2_0.59.ckpt\"\n",
    "ckpt = \"/home/regier/bliss_output/20250821_m2_anyorderfalse_1xval_nometrics_minimalist/version_0/checkpoints/encoder_4.ckpt\"\n",
    "with initialize(config_path=\".\", version_base=None):\n",
    "    cfg0 = compose(\"config\", {\n",
    "        f\"train.pretrained_weights={ckpt}\",\n",
    "        f\"predict.weight_save_path={ckpt}\",\n",
    "        \"cached_simulator.splits=0:80/80:90/97:98\",\n",
    "        \"cached_simulator.num_workers=0\",\n",
    "        \"encoder.minimalist_conditioning=True\",\n",
    "        \"encoder.use_checkerboard=True\",\n",
    "        \"encoder.n_sampler_colors=4\",\n",
    "    })\n",
    "\n",
    "plot_title = \"Independent ($K=1$)\" if cfg0.encoder.n_sampler_colors == 1 else f\"Autoregressive ($K=4$)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SDSS image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = fits.open('/home/regier/bliss/tests/data/sdss/2583/2/136/frame-r-002583-2-0136.fits')\n",
    "w = WCS(f[0].header)\n",
    "\n",
    "# lower-left corner of the 100x100-pixel study area is at pixel (310, 630)\n",
    "w.pixel_to_world(310, 630)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(f[0].data, origin='lower', cmap='Greys_r')\n",
    "print(\"Behold, the M2 globular cluster!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logimage = np.log(f[0].data - f[0].data.min() + 1)\n",
    "plt.imshow(logimage, origin='lower', cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "plt.imshow(logimage, origin='lower', cmap='Greys_r')\n",
    "rect = Rectangle((310, 630), 100, 100, linewidth=2, edgecolor='r', facecolor='none')\n",
    "_ = plt.gca().add_patch(rect)\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = f[0].data[630:730, 310:410]\n",
    "\n",
    "arcsinh_median = np.arcsinh((original - np.median(original)))\n",
    "\n",
    "clipped = original.clip(max=np.quantile(original, 0.98))\n",
    "arcsinh_clipped = np.arcsinh((clipped - np.median(clipped)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "images = [original, arcsinh_median, arcsinh_clipped]\n",
    "titles = ['original', 'arcsinc', 'arcsinc with clipping']\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    ax = axs[i]\n",
    "    ax.imshow(img, origin='lower', cmap='Greys_r')\n",
    "    ax.set_title(titles[i])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and view HST predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget https://archive.stsci.edu/pub/hlsp/acsggct/ngc7089/hlsp_acsggct_hst_acs-wfc_ngc7089_r.rdviq.cal.adj.zpt\n",
    "hubble_cat_file = \"/home/regier/hlsp_acsggct_hst_acs-wfc_ngc7089_r.rdviq.cal.adj.zpt\"\n",
    "hubble_cat = np.loadtxt(hubble_cat_file, skiprows=3, usecols=(9,21,22))\n",
    "\n",
    "hst_r_mag_all = torch.from_numpy(hubble_cat[:, 0])\n",
    "ra = torch.from_numpy(hubble_cat[:, 1])\n",
    "dec = torch.from_numpy(hubble_cat[:, 2])\n",
    "\n",
    "plocs_all = FullCatalog.plocs_from_ra_dec(ra, dec, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_bounds = (plocs_all[:, 1] > 310) & (plocs_all[:, 1] < 410)\n",
    "in_bounds &= (plocs_all[:, 0] > 630) & (plocs_all[:, 0] < 730)\n",
    "in_bounds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hst_r_mag = hst_r_mag_all[in_bounds]\n",
    "plocs = plocs_all[in_bounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plocs_square = plocs - torch.tensor([630, 310])\n",
    "\n",
    "from bliss.catalog import convert_mag_to_nmgy, convert_nmgy_to_mag\n",
    "hst_r_nmgy = convert_mag_to_nmgy(hst_r_mag)\n",
    "\n",
    "# these magnitudes are about 15% off: the hubble fw606 band filter curve\n",
    "#  isn't exactly the sdss r band filter curve\n",
    "sdss_r_nmgy = hst_r_nmgy * 1.15\n",
    "sdss_r_mag = convert_nmgy_to_mag(sdss_r_nmgy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"plocs\": plocs_square.unsqueeze(0),\n",
    "    \"fluxes\": sdss_r_nmgy.unsqueeze(0).unsqueeze(2),\n",
    "    \"n_sources\": torch.tensor(plocs.shape[0]).unsqueeze(0),\n",
    "    \"source_type\": torch.zeros(plocs.shape[0]).unsqueeze(0).unsqueeze(2).long(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cat_all = FullCatalog(100, 100, d)\n",
    "true_cat_all[\"n_sources\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tile_cat_all = true_cat_all.to_tile_catalog(2, 11)\n",
    "true_tile_cat_all[\"n_sources\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_bright = sdss_r_mag < 22.565\n",
    "is_bright.sum(), convert_mag_to_nmgy(22.565)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target number of sources in 1114\n",
    "cutoff_mag_1114 = 22.130\n",
    "(sdss_r_mag < cutoff_mag_1114).sum()\n",
    "cutoff_nmgy_1114 = convert_mag_to_nmgy(cutoff_mag_1114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"plocs\": plocs_square[is_bright].unsqueeze(0),\n",
    "    \"fluxes\": sdss_r_nmgy[is_bright].unsqueeze(0).unsqueeze(2).expand([-1, -1, 5]),\n",
    "    \"n_sources\": torch.tensor(plocs[is_bright].shape[0]).unsqueeze(0),\n",
    "    \"source_type\": torch.zeros(plocs[is_bright].shape[0]).unsqueeze(0).unsqueeze(2).long(),\n",
    "}\n",
    "true_cat = FullCatalog(100, 100, d)\n",
    "true_cat[\"n_sources\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tile_cat = true_cat.to_tile_catalog(2, 5)\n",
    "true_tile_cat[\"n_sources\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "cutoffs = [20, 22.065, 24]\n",
    "\n",
    "for i, cutoff in enumerate(cutoffs):\n",
    "    is_bright = sdss_r_mag < cutoff\n",
    "    plocs_square_bright = plocs_square[is_bright]\n",
    "    ax = axs[i]\n",
    "    ax.imshow(arcsinh_clipped, origin='lower', cmap='Greys_r')\n",
    "    ax.scatter(plocs_square_bright[:, 1], plocs_square_bright[:, 0], s=5, c='r')\n",
    "    ax.set_title(f\"magnitude < {cutoff}\")\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLISS performance on M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(cfg0.predict)\n",
    "bliss_cat, = preds.values()  # singleton dict\n",
    "bliss_cat = bliss_cat.symmetric_crop(3).to_full_catalog(cfg0.encoder.tile_slen)\n",
    "\n",
    "matcher = instantiate(cfg0.encoder.matcher)\n",
    "mode_metrics = instantiate(cfg0.encoder.mode_metrics)\n",
    "\n",
    "matching = matcher.match_catalogs(true_cat, bliss_cat)\n",
    "c_dp_real = mode_metrics(true_cat, bliss_cat, matching)\n",
    "\n",
    "p = c_dp_real[\"detection_precision\"].item()\n",
    "r = c_dp_real[\"detection_recall\"].item()\n",
    "f = c_dp_real[\"detection_f1\"].item()\n",
    "print(f\"precision: {p:.4}  recall: {r:.4}  f1: {f:.4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = instantiate(cfg0.surveys.sdss, load_image_data=True)\n",
    "dataset.prepare_data()\n",
    "sdss_frame, = dataset.predict_dataloader()\n",
    "obs_image_padded = sdss_frame[\"images\"][:, 2:3, 624:736, 304:416]\n",
    "obs_image_cropped = obs_image_padded[0, 0, 6:-6, 6:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {\n",
    "    \"images\": obs_image_padded.expand(50, -1, -1, -1).cuda(),\n",
    "}\n",
    "\n",
    "cfg_sample = OmegaConf.merge(cfg0, {\"encoder\": {\"predict_mode_not_samples\": False}})\n",
    "\n",
    "encoder = instantiate(cfg_sample.train.encoder).cuda()\n",
    "enc_state_dict = torch.load(cfg_sample.train.pretrained_weights)\n",
    "enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "encoder.load_state_dict(enc_state_dict)\n",
    "encoder.eval()\n",
    "\n",
    "counts = []\n",
    "for i in range(20):\n",
    "    sample_cat = encoder.predict_step(batch, 0)\n",
    "    sample_cat = sample_cat.symmetric_crop(3)\n",
    "    bliss_sources = (sample_cat.on_fluxes > cutoff_nmgy_1114).sum([1,2,3,4])\n",
    "    counts.append(bliss_sources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = torch.cat(counts).float()\n",
    "c_ci_real = (cs.quantile(0.05).item(), cs.mean().item(), cs.quantile(0.95).item())\n",
    "print(c_ci_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLISS performance on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NllCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.nlls = []\n",
    "        self.precisions = []\n",
    "        self.recalls = []\n",
    "        self.f1s = []\n",
    "\n",
    "    def on_predict_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        nlls = pl_module.compute_sampler_nll(batch).sum([1,2])\n",
    "        self.nlls.append(nlls)\n",
    "\n",
    "        pl_module.update_metrics(batch, batch_idx)\n",
    "        m = pl_module.mode_metrics[\"detection_performance\"].compute()\n",
    "        self.precisions.append(m[\"detection_precision\"].item())\n",
    "        self.recalls.append(m[\"detection_recall\"].item())\n",
    "        self.f1s.append(m[\"detection_f1\"].item())\n",
    "        pl_module.mode_metrics.reset()\n",
    "\n",
    "    def report(self):\n",
    "        nlls = torch.cat(self.nlls)\n",
    "\n",
    "        nll_sd = nlls.std().item() / np.sqrt(nlls.size(0))\n",
    "        print(f\"Mean NLL: {nlls.mean().item():.2f} ({nll_sd:.2f})\")\n",
    "\n",
    "        precision_sd = np.std(self.precisions) / np.sqrt(len(self.precisions))\n",
    "        print(f\"Mean precision: {np.mean(self.precisions):.4f} ({precision_sd:.4f})\")\n",
    "\n",
    "        recall_sd = np.std(self.recalls) / np.sqrt(len(self.recalls))\n",
    "        print(f\"Mean recall: {np.mean(self.recalls):.4f} ({recall_sd:.4f})\")\n",
    "\n",
    "        f1_sd = np.std(self.f1s) / np.sqrt(len(self.f1s))\n",
    "        print(f\"Mean F1: {np.mean(self.f1s):.4f} ({f1_sd:.4f})\")\n",
    "\n",
    "\n",
    "data_module = instantiate(cfg0.train.data_source)\n",
    "data_module.setup(\"fit\")\n",
    "data_module.setup(\"test\")\n",
    "test_dl = data_module.test_dataloader()\n",
    "\n",
    "encoder = instantiate(cfg0.train.encoder)\n",
    "enc_state_dict = torch.load(cfg0.train.pretrained_weights)\n",
    "if cfg0.train.pretrained_weights.endswith(\".ckpt\"):\n",
    "    enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "encoder.load_state_dict(enc_state_dict)\n",
    "\n",
    "nll_cb = NllCallback()\n",
    "trainer = instantiate(cfg0.predict.trainer, callbacks=[nll_cb])\n",
    "trainer.predict(encoder, dataloaders=[test_dl], return_predictions=False)\n",
    "nll_cb.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_metric(cfg):\n",
    "    cfg = cfg.copy()\n",
    "    cfg.train.data_source.nontrain_transforms[2]['min_flux'] = 1.5\n",
    "    data_module = instantiate(cfg.train.data_source)\n",
    "    data_module.setup(\"fit\")\n",
    "    data_module.setup(\"test\")\n",
    "\n",
    "    encoder = instantiate(cfg.train.encoder)\n",
    "    enc_state_dict = torch.load(cfg.train.pretrained_weights)\n",
    "    if cfg.train.pretrained_weights.endswith(\".ckpt\"):\n",
    "        enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "    encoder.load_state_dict(enc_state_dict)\n",
    "\n",
    "    trainer = instantiate(cfg0.predict.trainer)\n",
    "    x = trainer.test(encoder, datamodule=data_module)\n",
    "\n",
    "    # could use x instead here instead, but need to output bins\n",
    "    # as a vector\n",
    "    dp = encoder.mode_metrics[\"detection_performance\"]\n",
    "    two_pt = encoder.sample_metrics[\"two_point\"]\n",
    "\n",
    "    return dp.compute(), two_pt.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_dp_synthetic, c_two_pt_synthetic = synthetic_metric(cfg0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess the two-point correlation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radii = [float(r[2:]) for r in c_two_pt_synthetic.keys()]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(radii, c_two_pt_synthetic.values(), marker=\"s\", label=f\"Rank $K$={cfg0.encoder.n_sampler_colors} checkerboard\")\n",
    "plt.axhline(y=0, color='black', linestyle='dotted', label='ideal')\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Distance (pixels)\")\n",
    "plt.ylabel(\"Two-point correlation\")\n",
    "plt.xticks([0.1, 0.3, 1, 3], labels=[\"0.1\", \"0.3\", \"1\", \"3\"])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.residual_sources = []\n",
    "\n",
    "    def on_predict_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        bliss_cat = outputs\n",
    "        bliss_cat = bliss_cat.symmetric_crop(3)\n",
    "        bliss_sources = (bliss_cat.on_fluxes > cutoff_nmgy_1114).sum([1,2,3,4])\n",
    "        true_fluxes = TileCatalog(batch[\"tile_catalog\"]).symmetric_crop(3).on_fluxes\n",
    "        true_sources =  (true_fluxes > cutoff_nmgy_1114).sum([1,2,3,4])\n",
    "        residual_sources = true_sources - bliss_sources \n",
    "        self.residual_sources.append(residual_sources)\n",
    "\n",
    "    def report(self):\n",
    "        counts = torch.cat(self.residual_sources).float()\n",
    "        mean = counts.mean().item()\n",
    "        mean_std = counts.std().item() / np.sqrt(counts.size(0))\n",
    "        print(f\"Mean residual sources: {mean:.2f} ({mean_std:.2f})\")\n",
    "\n",
    "def synthetic_calibration(cfg):\n",
    "    cfg_sample = OmegaConf.merge(cfg, {\"encoder\": {\"predict_mode_not_samples\": False}})\n",
    "\n",
    "    data_module = instantiate(cfg.train.data_source)\n",
    "    data_module.setup(\"test\")\n",
    "    test_dl = data_module.test_dataloader()\n",
    "\n",
    "    encoder = instantiate(cfg_sample.train.encoder)\n",
    "    enc_state_dict = torch.load(cfg_sample.train.pretrained_weights)\n",
    "    if cfg_sample.train.pretrained_weights.endswith(\".ckpt\"):\n",
    "        enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "    encoder.load_state_dict(enc_state_dict)\n",
    "\n",
    "    ci_cb = CiCallback()\n",
    "    trainer = instantiate(cfg.predict.trainer, callbacks=[ci_cb])\n",
    "    trainer.predict(encoder, dataloaders=[test_dl], return_predictions=False)\n",
    "    ci_cb.report()\n",
    "\n",
    "synthetic_calibration(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess the model and BLISS fit visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = instantiate(cfg0.decoder, with_noise=False)\n",
    "truth_images, _psf_params = decoder.render_images(true_tile_cat_all)\n",
    "true_recon_all = truth_images[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(cfg0.predict)\n",
    "bliss_cat, = preds.values()  # singleton dict\n",
    "bliss_cat[\"source_type\"] = torch.zeros_like(bliss_cat[\"fluxes\"], dtype=torch.long)\n",
    "bliss_images, _psf_params = decoder.render_images(bliss_cat)\n",
    "bliss_recon = bliss_images[0, 2][6:-6, 6:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['SDSS image', 'HST reconstruction', 'Our reconstruction']\n",
    "\n",
    "images = [obs_image_cropped, true_recon_all, bliss_recon]\n",
    "images = [img.clip(max=obs_image_cropped.quantile(0.99)) for img in images]\n",
    "images = [np.arcsinh((img - np.median(obs_image_cropped) / 50)) for img in images]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "vmin = min(img.min() for img in images)\n",
    "vmax = max(img.max() for img in images)\n",
    "\n",
    "plt.set_cmap(\"viridis\")\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    ax = axs[i]\n",
    "    ax.imshow(img, origin='lower', vmin=vmin, vmax=vmax, cmap='Greys_r')\n",
    "    ax.set_title(titles[i])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flux Prior Elicitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob = (plocs_all[:, 1] > 210) & (plocs_all[:, 1] < 510)\n",
    "oob &= (plocs_all[:, 0] > 530) & (plocs_all[:, 0] < 830)\n",
    "oob &= ~in_bounds\n",
    "oob.sum() # some of this region (about half) is outside of our HST cat coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hst_oob = hst_r_mag_all[oob]\n",
    "hst_oob_nmgy = convert_mag_to_nmgy(hst_oob) * 1.15\n",
    "hst_oob_mag = convert_nmgy_to_mag(hst_oob_nmgy)\n",
    "training_data = hst_oob_nmgy[hst_oob_mag < 24]\n",
    "training_data.shape[0], training_data.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncpareto\n",
    "alpha, trunc, loc, scale = truncpareto.fit(training_data)\n",
    "alpha, trunc, loc, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncpareto\n",
    "\n",
    "x = np.logspace(hst_oob_nmgy.log10().min(), hst_oob_nmgy.log10().max(), num=100)\n",
    "\n",
    "_ = plt.plot(x, truncpareto.pdf(x, alpha, trunc, loc, scale), 'r-', lw=3, alpha=0.7, label='new prior')\n",
    "_ = plt.plot(x, truncpareto.pdf(x, 0.5, 1014, 0, 0.63), 'g-', lw=3, alpha=0.7, label='old prior')\n",
    "_ = plt.hist(hst_oob_nmgy, log=True, bins=100, label='star_fluxes histogram', density=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncpareto\n",
    "\n",
    "x = np.linspace(hst_oob_nmgy.log10().min(), 100, num=100)\n",
    "\n",
    "_ = plt.plot(x, truncpareto.pdf(x, 0.01, 100, 3.0, 3.0), 'g-', lw=3, alpha=0.7, label='old prior')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(x, truncpareto.pdf(x, alpha, trunc, loc, scale), 'r-', lw=3, alpha=0.7, label='new prior')\n",
    "_ = plt.plot(x, truncpareto.pdf(x, 0.5, 1014, 0, 0.63), 'g-', lw=3, alpha=0.7, label='old prior')\n",
    "plt.legend()\n",
    "plt.loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = truncpareto.rvs(alpha, trunc, loc, scale, size=1500)\n",
    "sorted(samples, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = instantiate(cfg0.prior)\n",
    "prior.sample().on_fluxes[0, :, :, :, 2].view(-1).topk(100)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate rate with oob data\n",
    "(hst_oob_mag < 24).sum() / (4 * 1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the per-tile source density\n",
    "(1114 / 50**2) / (1 - truncpareto.cdf(cutoff_nmgy_1114, alpha, trunc, loc, scale))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-synthetic M2 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "decoder = instantiate(cfg0.decoder, with_noise=False)\n",
    "\n",
    "#TODO: crop 6 pixels from each side (to 100x100)\n",
    "d2 = deepcopy(true_cat_all)\n",
    "d2[\"plocs\"] += 6\n",
    "true_cat_pad = FullCatalog(112, 112, d2)\n",
    "\n",
    "truth_images, _ = decoder.render_images(true_cat_pad.to_tile_catalog(2, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semisynth_image = truth_images[:, 2:3]\n",
    "plt.imshow(semisynth_image[0, 0, 6:-6, 6:-6].numpy(), origin='lower', cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {\n",
    "    \"images\": semisynth_image.cuda(),\n",
    "}\n",
    "\n",
    "def semisynth_dp(cfg):\n",
    "    cfg_sample = OmegaConf.merge(cfg, {\"encoder\": {\"predict_mode_not_samples\": True}})\n",
    "\n",
    "    encoder = instantiate(cfg_sample.train.encoder).cuda()\n",
    "    enc_state_dict = torch.load(cfg_sample.train.pretrained_weights)\n",
    "    enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "    encoder.load_state_dict(enc_state_dict)\n",
    "    encoder.eval()\n",
    "\n",
    "    bliss_cat = encoder.predict_step(batch, 0)\n",
    "\n",
    "    bliss_cat = bliss_cat.symmetric_crop(3)\n",
    "    bliss_cat = bliss_cat.to_full_catalog(cfg_sample.encoder.tile_slen)\n",
    "    true_cat_cuda = true_cat_all.to(\"cuda:0\")\n",
    "    matching = encoder.matcher.match_catalogs(true_cat_cuda, bliss_cat)\n",
    "    return encoder.mode_metrics(true_cat_cuda, bliss_cat, matching)\n",
    "\n",
    "c_dp_semisynth = semisynth_dp(cfg0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbc = cfg0.star_metrics.detection_performance.base_flux_bin_cutoffs\n",
    "mbc = convert_nmgy_to_mag(torch.tensor(mbc)).tolist()\n",
    "mbc.reverse()\n",
    "\n",
    "titles = [\"Fully Synthetic\", \"Semi-Synthetic\", \"Real\"]\n",
    "dp_metrics = [c_dp_synthetic, c_dp_semisynth, c_dp_real]\n",
    "\n",
    "xlabels = [f\"[{mbc[i]:.1f}, {mbc[i+1]:.1f}]\" for i in range(len(mbc) - 1)]\n",
    "xlabels = [f\"< {mbc[0]:.1f}\"] + xlabels + [\"> \" + str(mbc[-1])]\n",
    "xlabels = xlabels[:-1]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for i, dp in enumerate(dp_metrics):\n",
    "    recall = [v.item() for k, v in dp.items() if k[:-1] == \"detection_recall_bin_\"]\n",
    "    precision = [v.item() for k, v in dp.items() if k[:-1] == \"detection_precision_bin_\"]\n",
    "    axs[0].plot(recall, marker=\"s\", label=titles[i])\n",
    "    axs[1].plot(precision, marker=\"s\", label=titles[i])\n",
    "\n",
    "axs[0].set_title(\"Recall\")\n",
    "axs[1].set_title(\"Precision\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xticks(range(len(xlabels)))\n",
    "    ax.set_xticklabels(xlabels, rotation=45)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPC confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from bliss.catalog import TileCatalog\n",
    "\n",
    "\n",
    "class VsbcCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.confusion_matrix = torch.zeros((5, 5), dtype=torch.int64)\n",
    "\n",
    "    def on_predict_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
    "        tc = TileCatalog(batch[\"tile_catalog\"])\n",
    "#        true_n_sources = batch[\"tile_catalog\"][\"n_sources\"].cpu().clamp(0, 1)\n",
    "#        sampled_n_sources = outputs[\"n_sources\"].cpu().clamp(0, 1)\n",
    "#        true_n_sources = (tc.on_fluxes > 10).sum([-2, -1])\n",
    "#        sampled_n_sources = (outputs.on_fluxes > 10).sum([-2, -1])\n",
    "        frac = 1/8\n",
    "        true_left = ((tc[\"locs\"][:, :, :, :, 0] < frac) * tc.is_on_mask).sum(-1).clamp(0, 2)\n",
    "        true_right = ((tc[\"locs\"][:, :, :, :, 0] > (1-frac)) * tc.is_on_mask).sum(-1).clamp(0, 2)\n",
    "        true_n_sources = true_left[:, 1:, :] + true_right[:, :-1, :]\n",
    "\n",
    "        sampled_left = ((outputs[\"locs\"][:, :, :, :, 0] < frac) * outputs.is_on_mask).sum(-1).clamp(0, 2)\n",
    "        sampled_right = ((outputs[\"locs\"][:, :, :, :, 0] > (1 - frac)) * outputs.is_on_mask).sum(-1).clamp(0, 2)\n",
    "        sampled_n_sources = (sampled_left[:, 1:, :] + sampled_right[:, :-1, :])\n",
    "\n",
    "#        vertical_true_sums = true_n_sources.unfold(1, 2, 1).sum(-1)\n",
    "#        vertical_sampled_sums = sampled_n_sources.unfold(1, 2, 1).sum(-1)\n",
    "#        horizontal_true_sums = vertical_true_sums.unfold(2, 2, 1).sum(-1).view(-1)\n",
    "#        horizontal_sampled_sums = vertical_sampled_sums.unfold(2, 2, 1).sum(-1).view(-1)\n",
    "#        indices = (horizontal_true_sums, horizontal_sampled_sums)\n",
    "\n",
    "        indices = (true_n_sources.view(-1), sampled_n_sources.view(-1))\n",
    "        values = torch.ones(indices[0].size(0), dtype=torch.int64)\n",
    "        self.confusion_matrix.index_put_(indices, values, accumulate=True)\n",
    "\n",
    "    def report(self):\n",
    "        print(self.confusion_matrix)\n",
    "\n",
    "vsbc_callback = VsbcCallback()\n",
    "trainer = instantiate(cfg0.train.trainer, callbacks=[vsbc_callback])\n",
    "encoder = instantiate(cfg0.train.encoder, predict_mode_not_samples = False)\n",
    "enc_state_dict = torch.load(cfg0.train.pretrained_weights)\n",
    "if cfg0.train.pretrained_weights.endswith(\".ckpt\"):\n",
    "    enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "encoder.load_state_dict(enc_state_dict)\n",
    "\n",
    "data_source = instantiate(cfg0.train.data_source)\n",
    "data_source.setup(\"test\")\n",
    "\n",
    "trainer.predict(encoder, dataloaders=[data_source.test_dataloader()], return_predictions=False)\n",
    "\n",
    "vsbc_callback.report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(counts, title=\"\"):\n",
    "    counts_list = counts.tolist()\n",
    "    annotations = [[f'{val:,}' for val in row] for row in counts_list]\n",
    "    ax = sns.heatmap(\n",
    "        (counts + 1).log(),\n",
    "        annot=annotations,\n",
    "        fmt='s',\n",
    "        cbar=False,\n",
    "        cmap='Blues',\n",
    "        annot_kws={\"fontsize\": 14},  # Adjust annotation font size here\n",
    "    )\n",
    "    ax.set_xlabel(\"Predicted source count\", fontsize=16)  # Adjust x-axis label font size here\n",
    "    ax.set_ylabel(\"Actual source count\", fontsize=16)  # Adjust y-axis label font size here\n",
    "    ax.set_title(title, pad=20, fontsize=18)  # Adjust title font size here\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    plt.show()\n",
    "    \n",
    "make_confusion_matrix(vsbc_callback.confusion_matrix, title=plot_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_factor_matrix(counts, title=\"\"):\n",
    "    counts_t = counts.transpose(0, 1)\n",
    "    diff_factor = (counts - counts_t) / torch.min(counts, counts_t)\n",
    "    annotations = [[f'{val:.1f}\\u00D7' for val in row] for row in diff_factor.tolist()]\n",
    "\n",
    "    for i in range(len(annotations)):\n",
    "        annotations[i][i] = \"\"\n",
    "        for j in range(len(annotations)):\n",
    "            if torch.min(counts[i, j], counts[j, i]) < 100:\n",
    "                annotations[i][j] = \"\"\n",
    "                diff_factor[i, j] = 0\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        (1 + diff_factor.abs()).log(),\n",
    "        annot=annotations,\n",
    "        fmt='s',\n",
    "        cbar=False,\n",
    "        cmap='YlOrRd',\n",
    "        vmin=0,\n",
    "        vmax=1.5,\n",
    "        annot_kws={\"fontsize\": 15},  # Adjust annotation font size here\n",
    "    )\n",
    "    ax.set_xlabel(\"Predicted source count\", fontsize=16)  # Adjust x-axis label font size here\n",
    "    ax.set_ylabel(\"Actual source count\", fontsize=16)  # Adjust y-axis label font size here\n",
    "    ax.set_title(title, pad=20, fontsize=18)  # Adjust title font size here\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    plt.show()\n",
    "\n",
    "make_factor_matrix(vsbc_callback.confusion_matrix, title=plot_title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
