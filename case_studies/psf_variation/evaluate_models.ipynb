{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import environ\n",
    "import torch\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\".\", version_base=None):\n",
    "    cfg = compose(\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on fields not trained on\n",
    "test_path = \"/data/scratch/aakash/test_small\"\n",
    "test_dataset = instantiate(cfg.cached_simulator, cached_data_path=test_path, splits=\"0:100/0:100/0:100\")\n",
    "trainer = instantiate(cfg.train.trainer, logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"../../output/PSF_MODELS/single_field_base/checkpoints/epoch15.ckpt\"\n",
    "UNAWARE_PATH = \"../../output/PSF_MODELS/multi_field_psf_unaware/checkpoints/epoch19.ckpt\"\n",
    "PARAMS_ONLY_PATH = \"../../output/PSF_MODELS/multi_field_psf_params_only/checkpoints/epoch15.ckpt\"\n",
    "\n",
    "base_model = instantiate(cfg.encoder, image_normalizer={\"concat_psf_params\": False})\n",
    "base_model.load_state_dict(torch.load(BASE_PATH)[\"state_dict\"])\n",
    "base_model.eval();\n",
    "\n",
    "unaware_model = instantiate(cfg.encoder, image_normalizer={\"concat_psf_params\": False})\n",
    "unaware_model.load_state_dict(torch.load(UNAWARE_PATH)[\"state_dict\"])\n",
    "unaware_model.eval();\n",
    "\n",
    "params_only_model = instantiate(cfg.encoder, image_normalizer={\"concat_psf_params\": True})\n",
    "params_only_model.load_state_dict(torch.load(PARAMS_ONLY_PATH)[\"state_dict\"])\n",
    "params_only_model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_results = trainer.test(base_model, datamodule=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSF-unaware model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unaware_results = trainer.test(unaware_model, datamodule=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat params only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_results = trainer.test(params_only_model, datamodule=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate results into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"base\": (base_model, base_results),\n",
    "    \"unaware\": (unaware_model, unaware_results),\n",
    "    \"params\": (params_only_model, params_results),\n",
    "}\n",
    "\n",
    "# Results\n",
    "keys = list(base_results[0].keys())\n",
    "data = { model_name: [results[0][key] for key in keys] for model_name, (_, results) in models.items() }\n",
    "data_flat = pd.DataFrame.from_dict(data, orient=\"index\", columns=[key.split(\"/\")[1] for key in keys]).reset_index()\n",
    "data_flat= data_flat.rename(columns={\"index\": \"model\"})\n",
    "data_melt = pd.melt(data_flat, id_vars=\"model\", value_vars=[key.split(\"/\")[1] for key in keys], var_name=\"metric\", value_name=\"value\")\n",
    "data_melt.to_csv(\"psf_model_results.csv\")\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML(data_flat.to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(data, ncols=3, title=None):\n",
    "    sns.set_style('ticks')\n",
    "    sns.set(font_scale=0.8)\n",
    "\n",
    "    hue = \"bin\" if \"bin\" in data.columns else None\n",
    "\n",
    "    g = sns.catplot(\n",
    "        data,\n",
    "        kind=\"bar\",\n",
    "        x=\"model\", y=\"value\", col=\"metric\", hue=hue,\n",
    "        sharex=False, sharey=False, col_wrap=ncols,\n",
    "        height=3, aspect=1.5,\n",
    "        palette=\"dark\", alpha=0.6,\n",
    "        legend=True\n",
    "    )\n",
    "    g.set_titles(template=\"{col_name}\")\n",
    "\n",
    "    for ax in g.axes:\n",
    "        remove_ticks = False\n",
    "        heights = []\n",
    "        for container in ax.containers:\n",
    "            heights.extend([rect.get_height() for rect in container.patches])\n",
    "        median = np.median(heights)\n",
    "\n",
    "        for container in ax.containers:\n",
    "            orig_heights = [rect.get_height() for rect in container]\n",
    "            # clip outlier heights\n",
    "            for rect in container.patches:\n",
    "                if rect.get_height() > np.abs(5 * median):\n",
    "                    rect.set_height(np.abs(5 * median))\n",
    "                    remove_ticks = True\n",
    "\n",
    "            # add labels\n",
    "            labels = ax.bar_label(container, labels=[f\"{height:.3f}\" for height in orig_heights], fontsize=6)\n",
    "\n",
    "        new_heights = []\n",
    "        for container in ax.containers:\n",
    "            new_heights.extend([rect.get_height() for rect in container.patches])\n",
    "        ax.set_ylim(min(0, min(new_heights) * 1.1 + 0.1), max(new_heights) * 1.1 + 0.1)\n",
    "\n",
    "        ax.tick_params(axis=\"x\", labelsize=6)\n",
    "\n",
    "        # remove y ticks and labels\n",
    "        if remove_ticks:\n",
    "            ax.set(yticklabels=[])\n",
    "    \n",
    "    if title:\n",
    "        fig = g.axes[-1].get_figure()\n",
    "        plt.suptitle(title)\n",
    "        fig.set_tight_layout(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_keys = [\"f1\", \"star_fluxes_r_mae\", \"gal_fluxes_r_mae\", \"disk_hlr_mae\", \"bulge_hlr_mae\"]\n",
    "data_to_plot = data_melt[np.isin(data_melt[\"metric\"], keep_keys)]\n",
    "\n",
    "data_to_plot = data_to_plot.replace({\"base\": \"Single Field\", \"unaware\": \"PSF-unaware\", \"params\": \"PSF Encoding\"})\n",
    "data_to_plot = data_to_plot.replace({\"f1\": \"F1-score\", \"galaxy_fluxes_r_mae\": \"Galaxy flux, median estimation error\", \"star_fluxes_r_mae\": \"Star flux, median estimation error\", \"disk_hlr_mae\": \"Disk half-light radius, median estimation error\", \"bulge_hlr_mae\": \"Bulge half-light radius, median estimation error\"})\n",
    "plot_results(data_to_plot, ncols=2, title=\"Results on simulated data with variable PSFs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bliss-deblender-av05Bskt-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
