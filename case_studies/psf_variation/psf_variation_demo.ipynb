{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Encoding PSF variation with BLISS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the capability of BLISS to encode and use PSF information to make more accurate predictions compared to a PSF-unaware model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import hydra\n",
    "\n",
    "from bliss.catalog import TileCatalog\n",
    "from bliss.encoder.encoder import Encoder\n",
    "from bliss.simulator.decoder import ImageDecoder\n",
    "from bliss.encoder.metrics import CatalogMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "with hydra.initialize(config_path=\".\", version_base=None):\n",
    "    cfg = hydra.compose(\"config\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare two models:\n",
    "1. A \"PSF-unaware\" model that has been trained on a single PSF (and has no information about the PSF during inference), and\n",
    "2. A \"PSF-aware\" model that has been trained on images from different PSFs, and uses the PSF parameters during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psf-unaware model (trained on single PSF)\n",
    "base_model: Encoder = hydra.utils.instantiate(\n",
    "    cfg.encoder,\n",
    "    image_normalizer={\"concat_psf_params\": False}\n",
    ")\n",
    "base_model.load_state_dict(torch.load(Path(cfg.paths.pretrained_models) / \"single_band_base.pt\"))\n",
    "base_model.eval();\n",
    "\n",
    "# psf-aware model (trained with varying PSFs)\n",
    "psf_model: Encoder = hydra.utils.instantiate(cfg.encoder)\n",
    "psf_model.load_state_dict(torch.load(Path(cfg.paths.pretrained_models) / \"psf_aware.pt\"));\n",
    "psf_model.eval();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate these models on two images. Both are generated from the same catalog; they have sources at the same locations with the same parameters, but the only difference is one has a more localized PSF than the other, which is more spread out. We can think of these as being the PSFs on a clear night vs. a cloudy night, but looking at the same region of the sky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(\"data/clear_psf.pt\", \"rb\") as f:\n",
    "    clear_data = torch.load(f)\n",
    "\n",
    "with open(\"data/cloudy_psf.pt\", \"rb\") as f:\n",
    "    cloudy_data = torch.load(f)\n",
    "\n",
    "dataloader = DataLoader(clear_data + cloudy_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the images and PSFs to see the differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct PSF images from saved params\n",
    "decoder: ImageDecoder = hydra.utils.instantiate(cfg.simulator.decoder)\n",
    "clear_psf = decoder._get_psf(clear_data[0][\"psf_params\"])\n",
    "cloudy_psf = decoder._get_psf(cloudy_data[0][\"psf_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot images and PSFs\n",
    "fig, ax = plt.subplots(2, 2, figsize=(6, 6))\n",
    "ax[0, 0].set_title(\"'Clear' PSF\", size=\"large\")\n",
    "ax[0, 1].set_title(\"'Cloudy' PSF\", size=\"large\")\n",
    "ax[0, 0].set_ylabel(\"Image\", rotation=90, size=\"large\")\n",
    "ax[1, 0].set_ylabel(\"PSF\", rotation=90, size=\"large\")\n",
    "\n",
    "ax[0, 0].imshow(clear_data[0][\"images\"][2])  # plot r band\n",
    "ax[0, 1].imshow(cloudy_data[0][\"images\"][2])\n",
    "\n",
    "ax[1, 0].imshow(clear_psf[0].original.image.array)\n",
    "ax[1, 1].imshow(cloudy_psf[0].original.image.array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the Trainer\n",
    "trainer = hydra.utils.instantiate(cfg.train.trainer, accelerator=\"cpu\", logger=None)\n",
    "\n",
    "# make predictions\n",
    "base_results = trainer.predict(base_model, dataloader)\n",
    "psf_results = trainer.predict(psf_model, dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions and true locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get true catalog and crop to account for tiles cropped by model\n",
    "true_catalog = TileCatalog(cfg.encoder.tile_slen, clear_data[0][\"tile_catalog\"])\n",
    "true_catalog = true_catalog.symmetric_crop(base_model.tiles_to_crop).to_full_catalog(cfg.encoder.tile_slen)\n",
    "true_locs = true_catalog[\"plocs\"]\n",
    "\n",
    "# get predicted locations\n",
    "px_to_crop = 0 #base_model.tiles_to_crop * base_model.tile_slen\n",
    "est_locs = [\n",
    "    [\n",
    "        base_results[0][\"est_cat\"].to_full_catalog(cfg.encoder.tile_slen)[\"plocs\"] + px_to_crop,\n",
    "        base_results[1][\"est_cat\"].to_full_catalog(cfg.encoder.tile_slen)[\"plocs\"] + px_to_crop\n",
    "    ],\n",
    "    [\n",
    "        psf_results[0][\"est_cat\"].to_full_catalog(cfg.encoder.tile_slen)[\"plocs\"] + px_to_crop,\n",
    "        psf_results[1][\"est_cat\"].to_full_catalog(cfg.encoder.tile_slen)[\"plocs\"] + px_to_crop\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot true and estimated predictions for both models and both images\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "true_plot_args = dict(color=\"r\", s=25, marker=\"X\", edgecolors=\"k\", linewidth=0.5, label=\"True\")\n",
    "est_plot_args = dict(color=\"y\", s=25, marker=\"P\", edgecolors=\"k\", linewidth=0.5, label=\"Predicted\")\n",
    "\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        image = clear_data[0][\"images\"] if col == 0 else cloudy_data[0][\"images\"]\n",
    "        image = image[2, 4:76, 4:76]\n",
    "        \n",
    "        ax[row, col].imshow(image, origin=\"lower\", extent=(0, 72, 0, 72))\n",
    "        ax[row, col].scatter(true_locs[0, :, 1], true_locs[0, :, 0], **true_plot_args)\n",
    "        ax[row, col].scatter(est_locs[row][col][0, :, 1], est_locs[row][col][0, :, 0], **est_plot_args)\n",
    "\n",
    "# add row and column labels\n",
    "ax[0, 0].set_ylabel(\"Base model\", rotation=90, size=12);\n",
    "ax[1, 0].set_ylabel(\"PSF-aware model\", rotation=90, size=12);\n",
    "ax[0, 0].set_title(\"'Clear' PSF\", size=12);\n",
    "ax[0, 1].set_title(\"'Cloudy' PSF\", size=12);\n",
    "\n",
    "# add legend\n",
    "handles, labels = ax[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncol=2, bbox_to_anchor=(0, -0.03, 1, 1), fontsize=10)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PSF-unaware model performs well on the \"clear\" image, but much more poorly on the \"cloudy\" image; it misses the brightest source altogether, and some of the other predicted sources are offset from the true location. The PSF-aware model, on the other hand, is able to deal with the difference in PSF and performs equally well on the \"cloudy\" image as the \"clear\" image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's take a look at some metrics for the PSF-unaware model compared to the PSF-aware model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = CatalogMetrics(mode=\"matching\")\n",
    "keys = [\"f1\", \"avg_distance_keep\", \"(disk|bulge)_.*_mae\", \".*_r_mae\"]\n",
    "\n",
    "results = {\n",
    "    \"psf-unaware\": { key: val for key, val in metrics(true_catalog, base_results[1][\"est_cat\"].to_full_catalog(4)).items()},\n",
    "    \"psf-aware\": { key: val for key, val in metrics(true_catalog, psf_results[1][\"est_cat\"].to_full_catalog(4)).items()}\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "df[[col for col in df.columns if any([re.match(pattern, col) for pattern in keys])]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that across a majority of the relevant metrics, the psf-aware model outperforms the psf-unaware model, demonstrating the effectiveness of using PSF information in the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bliss-deblender-av05Bskt-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
