{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "import math\n",
    "import time\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "from pytorch_lightning.utilities import move_data_to_device\n",
    "from bliss.surveys.dc2 import DC2DataModule\n",
    "from bliss.catalog import TileCatalog\n",
    "from typing import Dict, Tuple\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load config\n",
    "with initialize(config_path=\".\", version_base=None):\n",
    "    notebook_cfg = compose(\"notebook_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tile_catalog(\n",
    "        ori_full_cat,\n",
    "        tile_slen: int,\n",
    "        max_sources_per_tile: int,\n",
    "        ignore_extra_sources=False,\n",
    "        filter_oob=False,\n",
    "    ) -> TileCatalog:\n",
    "        \"\"\"Returns the TileCatalog corresponding to this FullCatalog.\n",
    "\n",
    "        Args:\n",
    "            tile_slen: The side length of the tiles.\n",
    "            max_sources_per_tile: The maximum number of sources in one tile.\n",
    "            ignore_extra_sources: If False (default), raises an error if the number of sources\n",
    "                in one tile exceeds the `max_sources_per_tile`. If True, only adds the tile\n",
    "                parameters of the first `max_sources_per_tile` sources to the new TileCatalog.\n",
    "            filter_oob: If filter_oob is true, filter out the sources outside the image. (e.g. In\n",
    "                case of data augmentation, there is a chance of some sources located outside the\n",
    "                image)\n",
    "\n",
    "        Returns:\n",
    "            TileCatalog correspond to the each source in the FullCatalog.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the number of sources in one tile exceeds `max_sources_per_tile` and\n",
    "                `ignore_extra_sources` is False.\n",
    "            KeyError: If the tile_params contain `plocs` or `n_sources`.\n",
    "        \"\"\"\n",
    "        # TODO: a FullCatalog only needs to \"know\" its height and width to convert itself to a\n",
    "        # TileCatalog. So those parameters should be passed on conversion, not initialization.\n",
    "        tile_coords = torch.div(ori_full_cat[\"plocs\"], tile_slen, rounding_mode=\"trunc\").to(torch.int)\n",
    "        n_tiles_h = math.ceil(ori_full_cat.height / tile_slen)\n",
    "        n_tiles_w = math.ceil(ori_full_cat.width / tile_slen)\n",
    "\n",
    "        # prepare tiled tensors\n",
    "        tile_cat_shape = (ori_full_cat.batch_size, n_tiles_h, n_tiles_w, max_sources_per_tile)\n",
    "        tile_locs = torch.zeros((*tile_cat_shape, 2), device=ori_full_cat.device)\n",
    "        tile_n_sources = torch.zeros(tile_cat_shape[:3], dtype=torch.int64, device=ori_full_cat.device)\n",
    "        tile_params: Dict[str, Tensor] = {}\n",
    "        for k, v in ori_full_cat.items():\n",
    "            if k in {\"plocs\", \"n_sources\"}:\n",
    "                continue\n",
    "            size = (ori_full_cat.batch_size, n_tiles_h, n_tiles_w, max_sources_per_tile, v.shape[-1])\n",
    "            tile_params[k] = torch.zeros(size, dtype=v.dtype, device=ori_full_cat.device)\n",
    "\n",
    "        tile_params[\"locs\"] = tile_locs\n",
    "\n",
    "        for ii in range(ori_full_cat.batch_size):\n",
    "            n_sources = int(ori_full_cat[\"n_sources\"][ii].item())\n",
    "            plocs_ii = ori_full_cat[\"plocs\"][ii][:n_sources]\n",
    "            filter_sources = n_sources\n",
    "            source_tile_coords = tile_coords[ii][:n_sources]\n",
    "            if filter_oob:\n",
    "                x0_mask = (plocs_ii[:, 0] > 0) & (plocs_ii[:, 0] < ori_full_cat.height)\n",
    "                x1_mask = (plocs_ii[:, 1] > 0) & (plocs_ii[:, 1] < ori_full_cat.width)\n",
    "                x_mask = x0_mask * x1_mask\n",
    "                filter_sources = x_mask.sum()\n",
    "                source_tile_coords = source_tile_coords[x_mask]\n",
    "\n",
    "            if filter_sources == 0:\n",
    "                continue\n",
    "\n",
    "            source_indices = source_tile_coords[:, 0] * n_tiles_w + source_tile_coords[\n",
    "                :, 1\n",
    "            ].unsqueeze(0)\n",
    "            tile_indices = torch.arange(n_tiles_h * n_tiles_w, device=ori_full_cat.device).unsqueeze(1)\n",
    "\n",
    "            tile_to_source_mapping = (source_indices == tile_indices).nonzero()\n",
    "            tile_source_count: Tuple[Tensor, Tensor] = tile_to_source_mapping[:, 0].unique(\n",
    "                sorted=True, return_counts=True\n",
    "            )  # first element is tile index; second element is source count\n",
    "            if tile_source_count[1].max() > max_sources_per_tile:\n",
    "                if not ignore_extra_sources:\n",
    "                    raise ValueError(  # noqa: WPS220\n",
    "                        \"# of sources per tile exceeds `max_sources_per_tile`.\"\n",
    "                    )\n",
    "\n",
    "            # get n_sources for each tile\n",
    "            tile_n_sources[ii].view(-1)[tile_source_count[0].flatten().tolist()] = torch.where(\n",
    "                tile_source_count[1] <= max_sources_per_tile,\n",
    "                tile_source_count[1],\n",
    "                max_sources_per_tile,\n",
    "            )\n",
    "\n",
    "            for k, v in tile_params.items():\n",
    "                if k == \"plocs\":\n",
    "                    raise KeyError(\"plocs should not be in tile_params\")\n",
    "                if k == \"locs\":\n",
    "                    k = \"plocs\"\n",
    "                if k == \"n_sources\":\n",
    "                    raise KeyError(\"n_sources should not be in tile_params\")\n",
    "                param_matrix = ori_full_cat[k][ii][:n_sources]\n",
    "                if filter_oob:\n",
    "                    param_matrix = param_matrix[x_mask]\n",
    "                params_on_tile = list(\n",
    "                    param_matrix[tile_to_source_mapping[:, 1]].split(\n",
    "                        tile_source_count[1].flatten().tolist()\n",
    "                    )\n",
    "                )\n",
    "                # pad first tensor to desired length\n",
    "                # the second argument of pad function is\n",
    "                # padding_left, padding_right, padding_top, padding_bottom\n",
    "                params_on_tile[0] = torch.nn.functional.pad(\n",
    "                    params_on_tile[0],\n",
    "                    (0, 0, 0, (max_sources_per_tile - params_on_tile[0].shape[0])),\n",
    "                )\n",
    "                # pad all tensors\n",
    "                params_on_tile = pad_sequence(params_on_tile, batch_first=True)\n",
    "                max_fill = min(filter_sources, max_sources_per_tile)\n",
    "                v[ii].view(-1, *v[ii].shape[2:])[\n",
    "                    tile_to_source_mapping[:, 0].unique(sorted=True).tolist(), :max_fill\n",
    "                ] = params_on_tile[:, :max_fill].to(dtype=v.dtype)\n",
    "\n",
    "            # modify tile location\n",
    "            tile_params[\"locs\"][ii] = (tile_params[\"locs\"][ii] % tile_slen) / tile_slen\n",
    "        tile_params.update({\"n_sources\": tile_n_sources})\n",
    "        return TileCatalog(tile_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tile_cat_equal(left_tile_cat, right_tile_cat):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    is_equal = True\n",
    "    for k, v in left_tile_cat.items():\n",
    "        cur_test_equal = torch.allclose(right_tile_cat[k], v, equal_nan=True)\n",
    "        if not cur_test_equal:\n",
    "            logger.warning(\"%s are different\", k)\n",
    "        is_equal &= cur_test_equal\n",
    "    return is_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup bliss encoder\n",
    "tile_slen = notebook_cfg.surveys.dc2.tile_slen\n",
    "max_sources_per_tile = notebook_cfg.surveys.dc2.max_sources_per_tile\n",
    "\n",
    "dc2: DC2DataModule = instantiate(notebook_cfg.surveys.dc2)\n",
    "dc2.setup(stage=\"validate\")\n",
    "dc2_val_dataloader = dc2.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_gpu_time = 0\n",
    "new_gpu_time = 0\n",
    "for i, batch in enumerate(dc2_val_dataloader):\n",
    "    batch_on_device = move_data_to_device(batch, device=device)\n",
    "    full_cat = TileCatalog(batch_on_device[\"tile_catalog\"]).to_full_catalog(tile_slen)\n",
    "\n",
    "    old_start_time = time.time()\n",
    "    old_tile_cat = to_tile_catalog(full_cat, tile_slen=tile_slen, max_sources_per_tile=max_sources_per_tile)\n",
    "    old_end_time = time.time()\n",
    "    print(f\"[{i}] old: {old_end_time - old_start_time: .3f}\")\n",
    "    old_gpu_time += (old_end_time - old_start_time)\n",
    "\n",
    "    new_start_time = time.time()\n",
    "    new_tile_cat = full_cat.to_tile_catalog(tile_slen=tile_slen, max_sources_per_tile=max_sources_per_tile)\n",
    "    new_end_time = time.time()\n",
    "    print(f\"[{i}] new: {new_end_time - new_start_time: .3f}\")\n",
    "    new_gpu_time += (new_end_time - new_start_time)\n",
    "\n",
    "    assert test_tile_cat_equal(old_tile_cat, new_tile_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"old_gpu_time: {old_gpu_time: .3f}\")\n",
    "print(f\"new_gpu_time: {new_gpu_time: .3f}\")\n",
    "print(f\"old/new: {old_gpu_time / new_gpu_time: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cpu_time = 0\n",
    "new_cpu_time = 0\n",
    "for i, batch in enumerate(dc2_val_dataloader):\n",
    "    batch_on_device = move_data_to_device(batch, device=\"cpu\")\n",
    "    full_cat = TileCatalog(batch_on_device[\"tile_catalog\"]).to_full_catalog(tile_slen)\n",
    "\n",
    "    old_start_time = time.time()\n",
    "    old_tile_cat = to_tile_catalog(full_cat, tile_slen=tile_slen, max_sources_per_tile=max_sources_per_tile)\n",
    "    old_end_time = time.time()\n",
    "    print(f\"[{i}] old: {old_end_time - old_start_time: .3f}\")\n",
    "    old_cpu_time += (old_end_time - old_start_time)\n",
    "\n",
    "    new_start_time = time.time()\n",
    "    new_tile_cat = full_cat.to_tile_catalog(tile_slen=tile_slen, max_sources_per_tile=max_sources_per_tile)\n",
    "    new_end_time = time.time()\n",
    "    print(f\"[{i}] new: {new_end_time - new_start_time: .3f}\")\n",
    "    new_cpu_time += (new_end_time - new_start_time)\n",
    "\n",
    "    assert test_tile_cat_equal(old_tile_cat, new_tile_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"old_cpu_time: {old_cpu_time: .3f}\")\n",
    "print(f\"new_cpu_time: {new_cpu_time: .3f}\")\n",
    "print(f\"old/new: {old_cpu_time / new_cpu_time: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image_old_time = 0\n",
    "full_image_new_time = 0\n",
    "for i in range(10):\n",
    "    full_cat = dc2.get_plotting_sample(i)[\"full_catalog\"]\n",
    "\n",
    "    old_start_time = time.time()\n",
    "    old_tile_cat = to_tile_catalog(full_cat, tile_slen, max_sources_per_tile)\n",
    "    old_end_time = time.time()\n",
    "    print(f\"[{i}] old: {old_end_time - old_start_time: .3f}\")\n",
    "    full_image_old_time += (old_end_time - old_start_time)\n",
    "\n",
    "    new_start_time = time.time()\n",
    "    new_tile_cat = full_cat.to_tile_catalog(tile_slen, max_sources_per_tile)\n",
    "    new_end_time = time.time()\n",
    "    print(f\"[{i}] new: {new_end_time - new_start_time: .3f}\")\n",
    "    full_image_new_time += (new_end_time -new_start_time)\n",
    "\n",
    "    assert test_tile_cat_equal(old_tile_cat, new_tile_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"full_image_old_time: {full_image_old_time: .3f}\")\n",
    "print(f\"full_image_new_time: {full_image_new_time: .3f}\")\n",
    "print(f\"old/new: {full_image_old_time / full_image_new_time: .3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
