{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from case_studies.dc2_cataloging.utils.load_full_cat import get_full_cat\n",
    "from case_studies.dc2_cataloging.utils.notebook_variables import NoteBookVariables\n",
    "\n",
    "output_dir = Path(\"./plot_output/detection_selector_output/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# change this model path according to your training setting\n",
    "model_path = \"../../../bliss_output/DC2_cataloging_exp/exp_08-02-1/checkpoints/best_encoder.ckpt\"\n",
    "lsst_root_dir = \"/data/scratch/dc2_nfs/\"\n",
    "\n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\".\", version_base=None):\n",
    "    notebook_cfg = compose(\"notebook_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_idx = 0\n",
    "test_image, test_image_cat, bliss_full_cat, lsst_full_cat = get_full_cat(notebook_cfg, \n",
    "                                                                        test_image_idx, \n",
    "                                                                        model_path, \n",
    "                                                                        lsst_root_dir, \n",
    "                                                                        device)\n",
    "image_lim = test_image.shape[1]\n",
    "test_image = test_image[2]  # r-band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = instantiate(notebook_cfg.encoder.matcher)\n",
    "plocs_box_len = 100\n",
    "first_legend = True\n",
    "\n",
    "for i in range(0, image_lim, plocs_box_len):\n",
    "    for j in range(0, image_lim, plocs_box_len):\n",
    "        plocs_box_origin = torch.tensor([i, j])\n",
    "\n",
    "        cur_target_full_cat = test_image_cat.filter_by_ploc_box(plocs_box_origin, plocs_box_len)\n",
    "        cur_bliss_full_cat = bliss_full_cat.filter_by_ploc_box(plocs_box_origin, plocs_box_len)\n",
    "        cur_lsst_full_cat = lsst_full_cat.filter_by_ploc_box(plocs_box_origin, plocs_box_len)\n",
    "        bliss_matching = matcher.match_catalogs(cur_target_full_cat, cur_bliss_full_cat)[0]\n",
    "        lsst_matching = matcher.match_catalogs(cur_target_full_cat, cur_lsst_full_cat)[0]\n",
    "        \n",
    "        n_bliss_matching = len(bliss_matching[1])\n",
    "        n_lsst_matching = len(lsst_matching[1])\n",
    "        n_target = cur_target_full_cat[\"plocs\"].shape[1]\n",
    "        bliss_lsst_matching_diff = abs(n_bliss_matching - n_lsst_matching) / n_target if n_target != 0 else 0\n",
    "        if bliss_lsst_matching_diff < 0.4:\n",
    "            continue\n",
    "\n",
    "        target_set = set(list(range(0, cur_target_full_cat[\"plocs\"].shape[1])))\n",
    "        bliss_match_set = set(bliss_matching[0].int().tolist())\n",
    "        lsst_match_set = set(lsst_matching[0].int().tolist())\n",
    "        missing_match = list(target_set - (bliss_match_set | lsst_match_set))\n",
    "        only_bliss_match = list(bliss_match_set - lsst_match_set)\n",
    "        only_lsst_match = list(lsst_match_set - bliss_match_set)\n",
    "        both_match = list(lsst_match_set & bliss_match_set)\n",
    "\n",
    "        bliss_error = torch.tensor(list(target_set - bliss_match_set)).view(-1, 1)\n",
    "        lsst_error = torch.tensor(list(target_set - lsst_match_set)).view(-1, 1)\n",
    "        bliss_error_indices = (bliss_error == bliss_matching[0].int()).nonzero()[:, 1]\n",
    "        lsst_error_indices = (lsst_error == lsst_matching[0].int()).nonzero()[:, 1]\n",
    "        bliss_error = torch.take_along_dim(bliss_matching[1].int(), \n",
    "                                                   indices=bliss_error_indices, \n",
    "                                                   dim=0)\n",
    "        lsst_error = torch.take_along_dim(lsst_matching[1].int(),\n",
    "                                                  indices=lsst_error_indices,\n",
    "                                                  dim=0)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=NoteBookVariables.figsize)\n",
    "        image_sub = test_image[i:(i + plocs_box_len), j:(j + plocs_box_len)]\n",
    "        ax.imshow(np.arcsinh(image_sub - 0.0073), cmap=\"viridis\")\n",
    "        ax.scatter(cur_target_full_cat[\"plocs\"][0, only_bliss_match, 1], \n",
    "                   cur_target_full_cat[\"plocs\"][0, only_bliss_match, 0], \n",
    "                   facecolors=\"none\", edgecolors=\"aqua\", \n",
    "                   alpha=1, s=130, linewidth=3, label=\"Only BLISS\")\n",
    "        ax.scatter(cur_target_full_cat[\"plocs\"][0, only_lsst_match, 1], \n",
    "                   cur_target_full_cat[\"plocs\"][0, only_lsst_match, 0], \n",
    "                   facecolors=\"none\", edgecolors=\"orange\", \n",
    "                   alpha=1, s=130, linewidth=3, label=\"Only LSST\")\n",
    "        ax.scatter(cur_target_full_cat[\"plocs\"][0, both_match, 1], \n",
    "                   cur_target_full_cat[\"plocs\"][0, both_match, 0], \n",
    "                   facecolors=\"none\", edgecolors=\"lime\", \n",
    "                   alpha=1, s=130, linewidth=3, label=\"Both\")\n",
    "        ax.scatter(cur_target_full_cat[\"plocs\"][0, missing_match, 1], \n",
    "                   cur_target_full_cat[\"plocs\"][0, missing_match, 0], \n",
    "                   facecolors=\"none\", edgecolors=\"red\", \n",
    "                   alpha=1, s=130, linewidth=3, label=\"Neither\")\n",
    "        ax.scatter(cur_bliss_full_cat[\"plocs\"][0, bliss_error, 1], \n",
    "                   cur_bliss_full_cat[\"plocs\"][0, bliss_error, 0],\n",
    "                    marker=\"X\", facecolors=\"aqua\", edgecolors=\"aqua\", \n",
    "                    alpha=1, s=100, linewidth=1, label=\"BLISS Error\")\n",
    "        ax.scatter(cur_lsst_full_cat[\"plocs\"][0, lsst_error, 1], \n",
    "                   cur_lsst_full_cat[\"plocs\"][0, lsst_error, 0],\n",
    "                    marker=\"X\", facecolors=\"orange\", edgecolors=\"orange\", \n",
    "                    alpha=1, s=100, linewidth=1, label=\"LSST Error\")\n",
    "        ax.tick_params(labelsize=NoteBookVariables.font_size)\n",
    "\n",
    "        if first_legend:\n",
    "            ax.legend(loc=\"lower right\", fontsize=NoteBookVariables.font_size)\n",
    "            first_legend = False\n",
    "        fig.savefig(output_dir / f\"image_{test_image_idx}_{i}_{j}.pdf\", bbox_inches=\"tight\", dpi=NoteBookVariables.dpi)\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
