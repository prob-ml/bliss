{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DC2 Bootstrap Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from pathlib import Path\n",
    "\n",
    "import GCRCatalogs\n",
    "import pandas as pd\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from bliss.catalog import SourceType\n",
    "from bliss.surveys.dc2 import DC2, from_wcs_header_str_to_wcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lsst_params(\n",
    "    lsst_catalog_tensors_dict, cur_image_wcs, image_lim, image_height_index, image_width_index\n",
    "):\n",
    "    lsst_ra = lsst_catalog_tensors_dict[\"ra\"]\n",
    "    lsst_dec = lsst_catalog_tensors_dict[\"dec\"]\n",
    "    lsst_pt, lsst_pr = cur_image_wcs.all_world2pix(lsst_ra, lsst_dec, 0)\n",
    "    lsst_pt = torch.from_numpy(lsst_pt)\n",
    "    lsst_pr = torch.from_numpy(lsst_pr)\n",
    "\n",
    "    lsst_plocs = torch.stack((lsst_pr, lsst_pt), dim=-1)\n",
    "    lsst_source_type = lsst_catalog_tensors_dict[\"truth_type\"]\n",
    "    lsst_flux = lsst_catalog_tensors_dict[\"flux\"]\n",
    "\n",
    "    x0_mask = (lsst_plocs[:, 0] > image_height_index * image_lim) & (\n",
    "        lsst_plocs[:, 0] < (image_height_index + 1) * image_lim\n",
    "    )\n",
    "    x1_mask = (lsst_plocs[:, 1] > image_width_index * image_lim) & (\n",
    "        lsst_plocs[:, 1] < (image_width_index + 1) * image_lim\n",
    "    )\n",
    "    lsst_x_mask = x0_mask * x1_mask\n",
    "    # filter r band\n",
    "    lsst_flux_mask = lsst_flux[:, 2] > 0\n",
    "    # filter supernova\n",
    "    lsst_source_mask = (lsst_source_type != 3).squeeze(1)\n",
    "    lsst_mask = lsst_x_mask * lsst_flux_mask * lsst_source_mask\n",
    "\n",
    "    lsst_plocs = lsst_plocs[lsst_mask, :] % image_lim\n",
    "    lsst_source_type = torch.where(\n",
    "        lsst_source_type[lsst_mask] == 2, SourceType.STAR, SourceType.GALAXY\n",
    "    )\n",
    "    lsst_flux = lsst_flux[lsst_mask, :]\n",
    "\n",
    "    return lsst_plocs, lsst_source_type, lsst_flux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lsst_fullcat_files(\n",
    "    split_results_path, split_ids, lsst_catalog_tensors_dict, output_path\n",
    "):\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    for split_id in split_ids:\n",
    "        with open(split_results_path / split_id, \"rb\") as split_result_file:\n",
    "            split_result = torch.load(split_result_file)\n",
    "        cur_image_wcs = from_wcs_header_str_to_wcs(split_result[\"wcs_header_str\"])\n",
    "        image_lim = split_result[\"images\"].shape[1]\n",
    "        assert (\n",
    "            split_result[\"images\"].shape[1] == split_result[\"images\"].shape[2]\n",
    "        ), \"image width should be equal to image height\"\n",
    "\n",
    "        cur_plocs, cur_source_type, cur_flux = get_lsst_params(\n",
    "            lsst_catalog_tensors_dict,\n",
    "            cur_image_wcs,\n",
    "            image_lim,\n",
    "            image_height_index=split_result[\"image_height_index\"],\n",
    "            image_width_index=split_result[\"image_width_index\"],\n",
    "        )\n",
    "\n",
    "        with open(output_path / (\"lsst_\" + split_id), \"wb\") as output_file:\n",
    "            output_dict = {\n",
    "                    \"plocs\": cur_plocs.clone(),\n",
    "                    \"source_type\": cur_source_type.clone(),\n",
    "                    \"flux\": cur_flux.clone(),\n",
    "                }\n",
    "            torch.save(output_dict, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"+\" * 100, flush=True)\n",
    "print(\"initialization begins\", flush=True)\n",
    "\n",
    "output_dir = Path(\"./bootstrap_output/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with initialize(config_path=\".\", version_base=None):\n",
    "    notebook_cfg = compose(\"notebook_config\")\n",
    "print(\"initialization ends\", flush=True)\n",
    "print(\"+\" * 100, flush=True)\n",
    "\n",
    "print(\"+\" * 100, flush=True)\n",
    "print(\"load dc2\", flush=True)\n",
    "dc2: DC2 = instantiate(notebook_cfg.surveys.dc2)\n",
    "dc2.prepare_data()\n",
    "dc2.setup()\n",
    "dc2_test_dataset = dc2.test_dataset\n",
    "print(\"+\" * 100, flush=True)\n",
    "\n",
    "print(\"+\" * 100, flush=True)\n",
    "print(\"load lsst catalog\", flush=True)\n",
    "GCRCatalogs.set_root_dir(\"/data/dc2/\")\n",
    "lsst_catalog_gcr = GCRCatalogs.load_catalog(\"desc_dc2_run2.2i_dr6_object_with_truth_match\")\n",
    "lsst_catalog_sub = lsst_catalog_gcr.get_quantities(\n",
    "    [\n",
    "        \"id_truth\",\n",
    "        \"objectId\",\n",
    "        \"ra\",\n",
    "        \"dec\",\n",
    "        \"truth_type\",\n",
    "        \"cModelFlux_u\",\n",
    "        \"cModelFluxErr_u\",\n",
    "        \"cModelFlux_g\",\n",
    "        \"cModelFluxErr_g\",\n",
    "        \"cModelFlux_r\",\n",
    "        \"cModelFluxErr_r\",\n",
    "        \"cModelFlux_i\",\n",
    "        \"cModelFluxErr_i\",\n",
    "        \"cModelFlux_z\",\n",
    "        \"cModelFluxErr_z\",\n",
    "        \"cModelFlux_y\",\n",
    "        \"cModelFluxErr_y\",\n",
    "    ]\n",
    ")\n",
    "lsst_catalog_df = pd.DataFrame(lsst_catalog_sub)\n",
    "lsst_flux_per_band = [\n",
    "                lsst_catalog_df[\"cModelFlux_g\"],\n",
    "                lsst_catalog_df[\"cModelFlux_i\"],\n",
    "                lsst_catalog_df[\"cModelFlux_r\"],\n",
    "                lsst_catalog_df[\"cModelFlux_u\"],\n",
    "                lsst_catalog_df[\"cModelFlux_y\"],\n",
    "                lsst_catalog_df[\"cModelFlux_z\"],\n",
    "            ]\n",
    "lsst_flux_per_band_tensor =  [\n",
    "            torch.tensor(flux.values).view(-1, 1)\n",
    "            for flux in lsst_flux_per_band\n",
    "        ]\n",
    "lsst_catalog_tensors_dict = {\n",
    "    \"truth_type\": torch.tensor(lsst_catalog_df[\"truth_type\"].values).view(-1, 1),\n",
    "    \"flux\": torch.cat(lsst_flux_per_band_tensor, dim=1),\n",
    "    \"ra\": torch.tensor(lsst_catalog_df[\"ra\"].values),\n",
    "    \"dec\": torch.tensor(lsst_catalog_df[\"dec\"].values),\n",
    "}\n",
    "print(\"+\" * 100, flush=True)\n",
    "\n",
    "print(\"+\" * 100, flush=True)\n",
    "print(\"generate lsst split results\", flush=True)\n",
    "split_results_path = Path(\n",
    "    \"/data/scratch/dc2local/run2.2i-dr6-v4/coadd-t3828-t3829/deepCoadd-results/split_results/\"\n",
    ")\n",
    "split_ids = [split_file_path.name for split_file_path in dc2_test_dataset.split_files_list]\n",
    "print(f\"there are {len(split_ids)} split_ids\", flush=True)\n",
    "lsst_split_result_dir = output_dir / \"lsst_split_results\"\n",
    "lsst_split_result_dir.mkdir(exist_ok=True)\n",
    "\n",
    "generate_lsst_fullcat_files(\n",
    "    split_results_path, split_ids, lsst_catalog_tensors_dict, lsst_split_result_dir\n",
    ")\n",
    "\n",
    "print(\"generation ends\", flush=True)\n",
    "print(\"+\" * 100, flush=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
