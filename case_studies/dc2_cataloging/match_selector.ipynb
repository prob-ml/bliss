{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from einops import rearrange\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from pytorch_lightning.utilities import move_data_to_device\n",
    "\n",
    "from bliss.catalog import FullCatalog\n",
    "from bliss.surveys.dc2 import DC2, unsqueeze_tile_dict\n",
    "from case_studies.dc2_cataloging.utils.load_lsst import get_lsst_full_cat\n",
    "\n",
    "output_dir = Path(\"./match_selector_output/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# change this model path according to your training setting\n",
    "model_path = \"../../../bliss_output/DC2_cataloging_exp/exp_06-16-2/checkpoints/best_encoder.ckpt\"\n",
    "lsst_root_dir = \"/data/scratch/dc2_nfs/\"\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\".\", version_base=None):\n",
    "    notebook_cfg = compose(\"notebook_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2: DC2 = instantiate(notebook_cfg.surveys.dc2)\n",
    "image_idx = 0\n",
    "test_sample = dc2.get_plotting_sample(image_idx)\n",
    "cur_image_wcs = test_sample[\"wcs\"]\n",
    "cur_image_true_full_cat: FullCatalog = test_sample[\"full_catalog\"]\n",
    "cur_image_match_id = test_sample[\"match_id\"]\n",
    "image_lim = test_sample[\"image\"].shape[1]\n",
    "r_band_min_flux = notebook_cfg.encoder.min_flux_for_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_full_cat = get_lsst_full_cat(lsst_root_dir=lsst_root_dir,\n",
    "                                  cur_image_wcs=cur_image_wcs,\n",
    "                                  image_lim=image_lim,\n",
    "                                  r_band_min_flux=r_band_min_flux,\n",
    "                                  device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_encoder = instantiate(notebook_cfg.encoder).to(device=device)\n",
    "pretrained_weights = torch.load(model_path, device)[\"state_dict\"]\n",
    "bliss_encoder.load_state_dict(pretrained_weights)\n",
    "bliss_encoder.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {\n",
    "    \"tile_catalog\": unsqueeze_tile_dict(test_sample[\"tile_catalog\"]),\n",
    "    \"images\": rearrange(test_sample[\"image\"], \"h w nw -> 1 h w nw\"),\n",
    "    \"background\": rearrange(test_sample[\"background\"], \"h w nw -> 1 h w nw\"),\n",
    "    \"psf_params\": rearrange(test_sample[\"psf_params\"], \"h w -> 1 h w\")\n",
    "}\n",
    "\n",
    "batch = move_data_to_device(batch, device=device)\n",
    "\n",
    "bliss_output_path = output_dir / \"bliss_output.pkl\"\n",
    "\n",
    "if not bliss_output_path.exists():\n",
    "    bliss_out_dict = bliss_encoder.predict_step(batch, None)\n",
    "\n",
    "    with open(bliss_output_path, \"wb\") as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(bliss_out_dict, outp, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(bliss_output_path, \"rb\") as inputp:\n",
    "        bliss_out_dict = pickle.load(inputp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_full_cat: FullCatalog = bliss_out_dict[\"mode_cat\"].to_full_catalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = instantiate(notebook_cfg.encoder.matcher)\n",
    "plocs_box_len = 100\n",
    "output_img_dir = output_dir / \"images\"\n",
    "output_img_dir.mkdir(exist_ok=True)\n",
    "for i in range(0, image_lim, plocs_box_len):\n",
    "    for j in range(0, image_lim, plocs_box_len):\n",
    "        plocs_box_origin = torch.tensor([i, j])\n",
    "\n",
    "        cur_target_full_cat = cur_image_true_full_cat.filter_full_catalog_by_ploc_box(plocs_box_origin, plocs_box_len)\n",
    "        cur_bliss_full_cat = bliss_full_cat.filter_full_catalog_by_ploc_box(plocs_box_origin, plocs_box_len)\n",
    "        cur_lsst_full_cat = lsst_full_cat.filter_full_catalog_by_ploc_box(plocs_box_origin, plocs_box_len)\n",
    "        bliss_matching = matcher.match_catalogs(cur_target_full_cat, cur_bliss_full_cat)[0]\n",
    "        lsst_matching = matcher.match_catalogs(cur_target_full_cat, cur_lsst_full_cat)[0]\n",
    "\n",
    "        fig,ax = plt.subplots(figsize=(8, 8))\n",
    "        image = test_sample[\"image\"][0]\n",
    "        image_sub = image[i:(i + plocs_box_len), j:(j + plocs_box_len)]\n",
    "        ax.imshow(np.log((image_sub - image_sub.min()) + 80), cmap=\"viridis\")\n",
    "        ax.scatter(cur_target_full_cat[\"plocs\"][0, :, 1], cur_target_full_cat[\"plocs\"][0, :, 0], \n",
    "                   facecolors=\"none\", edgecolors=\"r\", \n",
    "                   alpha=1, s=130, linewidth=3, label=\"Truth Objects\")\n",
    "        ax.scatter(cur_bliss_full_cat[\"plocs\"][0, bliss_matching[1].tolist(), 1], cur_bliss_full_cat[\"plocs\"][0, bliss_matching[1].tolist(), 0], \n",
    "                marker=\"X\", facecolors=\"lime\", edgecolors=\"k\", \n",
    "                alpha=1, s=100, linewidth=1, label=\"BLISS Detection\")\n",
    "        ax.scatter(cur_lsst_full_cat[\"plocs\"][0, lsst_matching[1].tolist(), 1], cur_lsst_full_cat[\"plocs\"][0, lsst_matching[1].tolist(), 0], \n",
    "                marker=\"P\", facecolors=\"y\", edgecolors=\"k\", \n",
    "                alpha=1, s=80, linewidth=1, label=\"LSST Detection\")\n",
    "\n",
    "        ax.legend()\n",
    "        plt.savefig(output_img_dir / f\"image_{image_idx}_{i}_{j}.pdf\", bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
