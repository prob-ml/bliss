{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from case_studies.dc2_cataloging.utils.load_full_cat import get_full_cat\n",
    "\n",
    "output_dir = Path(\"./match_selector_output/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# change this model path according to your training setting\n",
    "model_path = \"../../../bliss_output/DC2_cataloging_exp/exp_06-16-2/checkpoints/best_encoder.ckpt\"\n",
    "lsst_root_dir = \"/data/scratch/dc2_nfs/\"\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\".\", version_base=None):\n",
    "    notebook_cfg = compose(\"notebook_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = 0\n",
    "test_image, test_image_cat, bliss_full_cat, lsst_full_cat = get_full_cat(notebook_cfg, \n",
    "                                                                        image_idx, \n",
    "                                                                        model_path, \n",
    "                                                                        lsst_root_dir, \n",
    "                                                                        device)\n",
    "image_lim = test_image.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = instantiate(notebook_cfg.encoder.matcher)\n",
    "plocs_box_len = 100\n",
    "output_img_dir = output_dir / \"images\"\n",
    "output_img_dir.mkdir(exist_ok=True)\n",
    "for i in range(0, image_lim, plocs_box_len):\n",
    "    for j in range(0, image_lim, plocs_box_len):\n",
    "        plocs_box_origin = torch.tensor([i, j])\n",
    "\n",
    "        cur_target_full_cat = test_image_cat.filter_full_catalog_by_ploc_box(plocs_box_origin, plocs_box_len)\n",
    "        cur_bliss_full_cat = bliss_full_cat.filter_full_catalog_by_ploc_box(plocs_box_origin, plocs_box_len)\n",
    "        cur_lsst_full_cat = lsst_full_cat.filter_full_catalog_by_ploc_box(plocs_box_origin, plocs_box_len)\n",
    "        bliss_matching = matcher.match_catalogs(cur_target_full_cat, cur_bliss_full_cat)[0]\n",
    "        lsst_matching = matcher.match_catalogs(cur_target_full_cat, cur_lsst_full_cat)[0]\n",
    "        \n",
    "        n_bliss_matching = len(bliss_matching[1])\n",
    "        n_lsst_matching = len(lsst_matching[1])\n",
    "        n_target = cur_target_full_cat[\"plocs\"].shape[1]\n",
    "        bliss_lsst_matching_diff = abs(n_bliss_matching - n_lsst_matching) / n_target if n_target != 0 else 0\n",
    "        if bliss_lsst_matching_diff < 0.5:\n",
    "            continue\n",
    "\n",
    "        fig,ax = plt.subplots(figsize=(8, 8))\n",
    "        image_sub = test_image[i:(i + plocs_box_len), j:(j + plocs_box_len)]\n",
    "        ax.imshow(np.log((image_sub - image_sub.min()) + 80), cmap=\"viridis\")\n",
    "        ax.scatter(cur_target_full_cat[\"plocs\"][0, :, 1], cur_target_full_cat[\"plocs\"][0, :, 0], \n",
    "                   facecolors=\"none\", edgecolors=\"r\", \n",
    "                   alpha=1, s=130, linewidth=3, label=\"Truth Objects\")\n",
    "        ax.scatter(cur_bliss_full_cat[\"plocs\"][0, bliss_matching[1].tolist(), 1], cur_bliss_full_cat[\"plocs\"][0, bliss_matching[1].tolist(), 0], \n",
    "                marker=\"X\", facecolors=\"lime\", edgecolors=\"k\", \n",
    "                alpha=1, s=100, linewidth=1, label=\"BLISS Detection\")\n",
    "        ax.scatter(cur_lsst_full_cat[\"plocs\"][0, lsst_matching[1].tolist(), 1], cur_lsst_full_cat[\"plocs\"][0, lsst_matching[1].tolist(), 0], \n",
    "                marker=\"P\", facecolors=\"y\", edgecolors=\"k\", \n",
    "                alpha=1, s=80, linewidth=1, label=\"LSST Detection\")\n",
    "\n",
    "        ax.legend()\n",
    "        plt.savefig(output_img_dir / f\"image_{image_idx}_{i}_{j}.pdf\", bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
