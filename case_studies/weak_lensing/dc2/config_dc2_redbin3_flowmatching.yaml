---
defaults:
    - _self_
    - override hydra/job_logging: stdout

# completely disable hydra logging
# https://github.com/facebookresearch/hydra/issues/910
hydra:
    output_subdir: null
    run:
        dir: .

mode: train

paths:
    dc2: /data/scratch/dc2local
    output: /home/twhit/bliss

lensing_normalizers_nan:
    nan:
        _target_: case_studies.weak_lensing.image_normalizer.NanNormalizer

lensing_normalizers_nanpsf:
    nan:
        _target_: case_studies.weak_lensing.image_normalizer.NanNormalizer
    psf:
        _target_: bliss.encoder.image_normalizer.PsfAsImage
        num_psf_params: 4

encoder:
    _target_: case_studies.weak_lensing.flowmatching.FlowMatching
    survey_bands: ["u", "g", "r", "i", "z", "y"]
    n_pixels_per_side: 2048
    n_tiles_per_side: 8
    ch_init: 64
    ch_max: 512
    ch_final: 128
    initial_downsample: true
    more_up_layers: true
    num_bottleneck_layers: 0
    image_normalizers: ${lensing_normalizers_nanpsf}
    t_embed_dim: 8
    num_redshift_bins: 3
    velo_net_channels: 128
    scale_factor: 100.0
    optimizer_params:
        lr: 1e-4

surveys:
    dc2:
        _target_: case_studies.weak_lensing.dc2.dc2.LensingDC2DataModule
        dc2_image_dir: /data/scratch/dc2_nfs/run2.2i-dr6-v4/coadd-t3828-t3829/deepCoadd-results/
        dc2_cat_path: ${paths.dc2}/dc2_lensing_catalog.pkl
        image_slen: 4096
        n_image_split: 2  # split into n_image_split**2 subimages
        tile_slen: 256
        splits: 0:80/80:90/90:100
        avg_ellip_kernel_size: 15  # must be odd
        avg_ellip_kernel_sigma: 15
        redshift_quantiles: [0.00, 0.6849667429924011, 1.1680253744125366]
        num_redshift_bins: 3  # length of redshift_quantiles
        batch_size: 1
        num_workers: 1
        cached_data_path: ${paths.dc2}/dc2_lensing_splits_redbin3
        train_transforms:
            - _target_: case_studies.weak_lensing.data_augmentation.LensingRotateFlipTransform
        shuffle_file_order: false  # partition train/val/test by ra/dec so that we can compute 2PCFs on spatially contiguous test set

train:
    trainer:
        _target_: pytorch_lightning.Trainer
        logger:
            _target_: pytorch_lightning.loggers.TensorBoardLogger
            save_dir: ${paths.output}
            name: WeakLensingFlowMatchingDC2
            version: scaled_fm_lr0001_redbin3
            default_hp_metric: false
        reload_dataloaders_every_n_epochs: 0
        check_val_every_n_epoch: 1
        log_every_n_steps: 10  # corresponds to n_batches
        min_epochs: 1
        max_epochs: 300
        accelerator: gpu
        devices: 1
        use_distributed_sampler: false
        precision: 32-true
    callbacks:
        checkpointing:
            _target_: pytorch_lightning.callbacks.ModelCheckpoint
            filename: "encoder_{epoch}"
            save_top_k: 1
            verbose: true
            monitor: val_loss
            mode: min
            save_on_train_epoch_end: false
            auto_insert_metric_name: false
        early_stopping:
            _target_: pytorch_lightning.callbacks.EarlyStopping
            monitor: val_loss
            mode: min
            patience: 100
    data_source: ${surveys.dc2}
    encoder: ${encoder}
    seed: 42
    pretrained_weights: null
    ckpt_path: null
    matmul_precision: high
