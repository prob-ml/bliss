{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998fa796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import healpy as hp\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import pyccl as ccl\n",
    "import galsim\n",
    "import torch\n",
    "from torch.distributions import Normal\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56276108",
   "metadata": {},
   "source": [
    "### Option 1: Original interpolation scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d7cfba",
   "metadata": {},
   "source": [
    "Pros: We now have a better sense of what values are realistic, and this one is easy to implement. Cons: Shear and convergence aren't consistent with each other here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6507b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "n_tiles_h = 48\n",
    "n_tiles_w = 48\n",
    "tile_slen = 4\n",
    "method = \"interpolate\"\n",
    "shear_mean = 0\n",
    "shear_sd = 0.01\n",
    "convergence_mean = 0\n",
    "convergence_sd = 0.01\n",
    "knots = 2\n",
    "\n",
    "latent_dims = (batch_size, n_tiles_h, n_tiles_w, 2)\n",
    "\n",
    "# number of knots in each dimension\n",
    "num_knots = [knots, knots]\n",
    "corners = (batch_size, num_knots[0], num_knots[1], 2)\n",
    "\n",
    "shear_maps = Normal(shear_mean, shear_sd).sample(corners)\n",
    "# want to change from 32 x 20 x 20 x 2 to 32 x 2 x 20 x 20\n",
    "shear_maps = shear_maps.reshape((batch_size, 2, num_knots[0], num_knots[1]))\n",
    "\n",
    "shear_maps = torch.nn.functional.interpolate(\n",
    "    shear_maps,\n",
    "    scale_factor=(n_tiles_h // num_knots[0], n_tiles_w // num_knots[1]),\n",
    "    mode=\"bilinear\",\n",
    "    align_corners=True,\n",
    ")\n",
    "\n",
    "# want to change from 32 x 2 x 20 x 20 to 32 x 20 x 20 x 2\n",
    "shear_maps = torch.swapaxes(shear_maps, 1, 3)\n",
    "shear_maps = torch.swapaxes(shear_maps, 1, 2)\n",
    "\n",
    "\n",
    "\n",
    "latent_dims = (batch_size, n_tiles_h, n_tiles_w, 1)\n",
    "# number of knots in each dimension\n",
    "num_knots = [knots,knots]\n",
    "corners = (batch_size, num_knots[0], num_knots[1], 1)\n",
    "convergence_map = Normal(convergence_mean, convergence_sd).sample(corners)\n",
    "# want to change from 32 x 20 x 20 x 2 to 32 x 2 x 20 x 20\n",
    "convergence_map = convergence_map.reshape(\n",
    "    (batch_size, 1, num_knots[0], num_knots[1])\n",
    ")\n",
    "\n",
    "convergence_map = torch.nn.functional.interpolate(\n",
    "    convergence_map,\n",
    "    scale_factor=(n_tiles_h // num_knots[0], n_tiles_w // num_knots[1]),\n",
    "    mode=\"bilinear\",\n",
    "    align_corners=True,\n",
    ")\n",
    "\n",
    "# want to change from 32 x 1 x 20 x 20 to 32 x 20 x 20 x 1\n",
    "convergence_map = torch.swapaxes(convergence_map, 1, 3)\n",
    "convergence_map = torch.swapaxes(convergence_map, 1, 2)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "im = ax[0].imshow(shear_maps.squeeze()[:,:,0])\n",
    "im = ax[1].imshow(shear_maps.squeeze()[:,:,1])\n",
    "im = ax[2].imshow(convergence_map.squeeze())\n",
    "fig.colorbar(im, shrink = 0.5, ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5038328",
   "metadata": {},
   "source": [
    "### Option 2: `pyccl` + `galsim`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98dbf7",
   "metadata": {},
   "source": [
    "This one doesn't seem to vary on the correct scale, and we can't figure out how to get it to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe298c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "n_tiles_h = 48\n",
    "n_tiles_w = 48\n",
    "tile_slen = 4\n",
    "arcsec_per_pixel = 0.396\n",
    "cosmology = ccl.cosmology.CosmologyVanillaLCDM()\n",
    "\n",
    "\n",
    "ngrid = n_tiles_w\n",
    "\n",
    "# ngrid is tiles, convert tiles to pixels, then to arcsecs, and then degrees\n",
    "grid_size = (ngrid * tile_slen * arcsec_per_pixel) / 3600\n",
    "\n",
    "# redshift taken from https://github.com/LSSTDESC/CCLX/blob/master/CellsCorrelations.ipynb\n",
    "z = np.linspace(0., 3., 512)\n",
    "i_lim = 26. # Limiting i-band magnitude\n",
    "z0 = 0.0417*i_lim - 0.744\n",
    "\n",
    "Ngal = 46. * 100.31 * (i_lim - 25.) # Normalisation, galaxies/arcmin^2\n",
    "pz = 1./(2.*z0) * (z / z0)**2. * np.exp(-z/z0) # Redshift distribution, p(z)\n",
    "dNdz = Ngal * pz # Number density distribution\n",
    "\n",
    "lensing_tracer = ccl.WeakLensingTracer(cosmology, dndz=(z, dNdz))\n",
    "\n",
    "# range of values required by buildGrid\n",
    "ell = np.arange(1, 100000)\n",
    "\n",
    "shear_map = torch.zeros((batch_size, n_tiles_h, n_tiles_w, 2))\n",
    "convergence_map = torch.zeros((batch_size, n_tiles_h, n_tiles_w, 1))\n",
    "for i in range(batch_size):\n",
    "    cls = ccl.angular_cl(cosmology, lensing_tracer, lensing_tracer, ell)\n",
    "    table = galsim.LookupTable(x = ell, f = cls)\n",
    "    my_ps = galsim.PowerSpectrum(table, units = galsim.degrees)\n",
    "    g1, g2, kappa = my_ps.buildGrid(grid_spacing=grid_size/ngrid, ngrid=ngrid,\n",
    "                                    get_convergence=True, units = galsim.degrees)\n",
    "    gamma1 = g1 * (1 - kappa)\n",
    "    gamma2 = g2 * (1 - kappa)\n",
    "\n",
    "    shear_map[i,:,:,0] = torch.from_numpy(gamma1)\n",
    "    shear_map[i,:,:,1] = torch.from_numpy(gamma2)\n",
    "    convergence_map[i,:,:,0] =  torch.from_numpy(kappa)\n",
    "\n",
    "fig, ax = plt.subplots(1,3)\n",
    "_ = ax[0].imshow(shear_map[0,:,:,0])\n",
    "_ = ax[1].imshow(shear_map[0,:,:,1])\n",
    "_ = ax[2].imshow(convergence_map[0,:,:,0])\n",
    "fig.colorbar(im, shrink = 0.5, ax = ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557fa2d3",
   "metadata": {},
   "source": [
    "### Option 3: Maps from N-body simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b43926",
   "metadata": {},
   "source": [
    "From http://cosmo.phys.hirosaki-u.ac.jp/takahasi/allsky_raytracing/. The associated paper is https://iopscience.iop.org/article/10.3847/1538-4357/aa943d/meta. Also used by https://arxiv.org/pdf/2312.08934.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file\n",
    "filename = '/data/scratch/twhit/allskymap_nres12r000.zs15.mag.dat'\n",
    "\n",
    "skip = [0, 536870908, 1073741818, 1610612728, 2147483638, 2684354547, 3221225457]\n",
    "load_blocks = [skip[i+1]-skip[i] for i in range(0, 6)]\n",
    "\n",
    "with open(filename, 'rb') as f:\n",
    "    rec = np.fromfile(f, dtype='uint32', count=1)[0]\n",
    "    nside = np.fromfile(f, dtype='int32', count=1)[0]\n",
    "    npix = np.fromfile(f, dtype='int64', count=1)[0]\n",
    "    rec = np.fromfile(f, dtype='uint32', count=1)[0]\n",
    "    print(\"nside:{} npix:{}\".format(nside, npix))\n",
    "\n",
    "    rec = np.fromfile(f, dtype='uint32', count=1)[0]\n",
    "\n",
    "    kappa = np.array([])\n",
    "    r = npix\n",
    "    for i, l in enumerate(load_blocks):\n",
    "        blocks = min(l, r)\n",
    "        load = np.fromfile(f, dtype='float32', count=blocks)\n",
    "        np.fromfile(f, dtype='uint32', count=2)\n",
    "        kappa = np.append(kappa, load)\n",
    "        r = r-blocks\n",
    "        if r == 0:\n",
    "            break\n",
    "        elif r > 0 and i == len(load_blocks)-1:\n",
    "            load = np.fromfile(f, dtype='float32', count=r)\n",
    "            np.fromfile(f, dtype='uint32', count=2)\n",
    "            kappa = np.append(kappa, load)\n",
    "\n",
    "    gamma1 = np.array([])\n",
    "    r = npix\n",
    "    for i, l in enumerate(load_blocks):\n",
    "        blocks = min(l, r)\n",
    "        load = np.fromfile(f, dtype='float32', count=blocks)\n",
    "        np.fromfile(f, dtype='uint32', count=2)\n",
    "        gamma1 = np.append(gamma1, load)\n",
    "        r = r-blocks\n",
    "        if r == 0:\n",
    "            break\n",
    "        elif r > 0 and i == len(load_blocks)-1:\n",
    "            load = np.fromfile(f, dtype='float32', count=r)\n",
    "            np.fromfile(f, dtype='uint32', count=2)\n",
    "            gamma1 = np.append(gamma1, load)\n",
    "\n",
    "    gamma2 = np.array([])\n",
    "    r = npix\n",
    "    for i, l in enumerate(load_blocks):\n",
    "        blocks = min(l, r)\n",
    "        load = np.fromfile(f, dtype='float32', count=blocks)\n",
    "        np.fromfile(f, dtype='uint32', count=2)\n",
    "        gamma2 = np.append(gamma2, load)\n",
    "        r = r-blocks\n",
    "        if r == 0:\n",
    "            break\n",
    "        elif r > 0 and i == len(load_blocks)-1:\n",
    "            load = np.fromfile(f, dtype='float32', count=r)\n",
    "            np.fromfile(f, dtype='uint32', count=2)\n",
    "            gamma2 = np.append(gamma2, load)\n",
    "\n",
    "    omega = np.array([])\n",
    "    r = npix\n",
    "    for i, l in enumerate(load_blocks):\n",
    "        blocks = min(l, r)\n",
    "        load = np.fromfile(f, dtype='float32', count=blocks)\n",
    "        np.fromfile(f, dtype='uint32', count=2)\n",
    "        omega = np.append(omega, load)\n",
    "        r = r-blocks\n",
    "        if r == 0:\n",
    "            break\n",
    "        elif r > 0 and i == len(load_blocks)-1:\n",
    "            load = np.fromfile(f, dtype='float32', count=r)\n",
    "            np.fromfile(f, dtype='uint32', count=2)\n",
    "            omega = np.append(omega, load)\n",
    "\n",
    "\n",
    "print('loading completed')\n",
    "\n",
    "# example of saving data as a fits file\n",
    "# hp.fitsfunc.write_map('output.fits', kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e881e5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cutout via a cartesian projection that covers 0.02 x 0.02\n",
    "loc = np.random.randint(-90, 90)\n",
    "lonra = [loc, loc+0.02]\n",
    "loc = np.random.randint(-90, 90)\n",
    "latra = [loc, loc+0.02]\n",
    "\n",
    "proj = hp.projector.CartesianProj(\n",
    "    lonra=lonra, latra=latra,\n",
    "    coord='C',\n",
    "    xsize=48, ysize=48)\n",
    "convergence = proj.projmap(kappa, vec2pix_func=partial(hp.vec2pix, nside))\n",
    "shear1 = proj.projmap(gamma1, vec2pix_func=partial(hp.vec2pix, nside))\n",
    "shear2 = proj.projmap(gamma2, vec2pix_func=partial(hp.vec2pix, nside))\n",
    "\n",
    "# Plot the cutout\n",
    "fig, ax = plt.subplots(1,3)\n",
    "im = ax[0].imshow(convergence)\n",
    "im = ax[1].imshow(shear1)\n",
    "im = ax[2].imshow(shear2)\n",
    "fig.colorbar(im, shrink = 0.5, ax = ax)\n",
    "# plt.imshow(reproj_im + np.random.normal(scale = 1e-5, size = reproj_im.shape), origin='lower', interpolation='nearest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
