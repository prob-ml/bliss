{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "import treecorr\n",
    "import pyccl\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.utilities import move_data_to_device\n",
    "\n",
    "from bliss.global_env import GlobalEnv\n",
    "\n",
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate posterior samples of shear and convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 123123\n"
     ]
    }
   ],
   "source": [
    "ckpt = \"/data/scratch/twhit/checkpoints/trained_encoder_dc2.ckpt\"\n",
    "\n",
    "with initialize(config_path=\"../../../\", version_base=None):\n",
    "    cfg = compose(\"lensing_config_dc2\", {\n",
    "        \"train.pretrained_weights=\" + ckpt,\n",
    "        \"surveys.dc2.shuffle_file_order=true\", # <-------- MAKE SURE TO REMOVE THIS LINE ONCE YOU START USING THE NEW ENCODER WEIGHTS\n",
    "        })\n",
    "\n",
    "seed = pl.seed_everything(cfg.train.seed)\n",
    "GlobalEnv.seed_in_this_program = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = instantiate(cfg.train.data_source)\n",
    "data_source.setup(\"test\")\n",
    "test_dl = data_source.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for batch in test_dl:\n",
    "    test_data.append(move_data_to_device(batch, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = instantiate(cfg.encoder).to(device)\n",
    "encoder_state_dict = torch.load(cfg.train.pretrained_weights, map_location=device)[\"state_dict\"]\n",
    "encoder.load_state_dict(encoder_state_dict)\n",
    "encoder = encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "\n",
    "shear1_true = torch.zeros(len(test_data), 8, 8, device=device)\n",
    "shear1_samples = torch.zeros(len(test_data), num_samples, 8, 8, device=device)\n",
    "shear1_mode = torch.zeros(len(test_data), 8, 8, device=device)\n",
    "shear2_true = torch.zeros(len(test_data), 8, 8, device=device)\n",
    "shear2_samples = torch.zeros(len(test_data), num_samples, 8, 8, device=device)\n",
    "shear2_mode = torch.zeros(len(test_data), 8, 8, device=device)\n",
    "convergence_true = torch.zeros(len(test_data), 8, 8, device=device)\n",
    "convergence_samples = torch.zeros(len(test_data), num_samples, 8, 8, device=device)\n",
    "convergence_mode = torch.zeros(len(test_data), 8, 8, device=device)\n",
    "ra = torch.zeros(len(test_data), 8, 8, device=device)\n",
    "dec = torch.zeros(len(test_data), 8, 8, device=device)\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    shear1_true[i] = test_data[i]['tile_catalog']['shear_1'].squeeze()\n",
    "    shear2_true[i] = test_data[i]['tile_catalog']['shear_2'].squeeze()\n",
    "    convergence_true[i] = test_data[i]['tile_catalog']['convergence'].squeeze()\n",
    "    ra[i] = test_data[i]['tile_catalog']['ra'].squeeze()\n",
    "    dec[i] = test_data[i]['tile_catalog']['dec'].squeeze()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_lst = [inorm.get_input_tensor(test_data[i]) for inorm in encoder.image_normalizers]\n",
    "        inputs = torch.cat(input_lst, dim=2)\n",
    "        x_features = encoder.features_net(inputs)\n",
    "        x_cat_marginal = encoder.catalog_net(x_features)\n",
    "        \n",
    "        for n in range(num_samples):            \n",
    "            sample = encoder.var_dist.sample(x_cat_marginal, use_mode=False, return_base_cat=True)\n",
    "            mode = encoder.var_dist.sample(x_cat_marginal, use_mode=True, return_base_cat=True)\n",
    "            shear1_samples[i,n] = sample['shear_1'].squeeze()\n",
    "            shear1_mode[i] = mode['shear_1'].squeeze()\n",
    "            shear2_samples[i,n] = sample['shear_2'].squeeze()\n",
    "            shear2_mode[i] = mode['shear_2'].squeeze()\n",
    "            convergence_samples[i,n] = sample['convergence'].squeeze()\n",
    "            convergence_mode[i] = mode['convergence'].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute two-point correlation function (2PCF) for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sep = 1\n",
    "max_sep = 50\n",
    "sep_units = \"arcmin\"\n",
    "\n",
    "num_bins = 5\n",
    "\n",
    "xip = torch.zeros(num_samples, num_bins, device = device)\n",
    "xim = torch.zeros(num_samples, num_bins, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "for n in range(num_samples):\n",
    "    if n % 100 == 0:\n",
    "        print(n)\n",
    "    treecorr_catalog = treecorr.Catalog(ra = ra.flatten().cpu(), ra_units = \"deg\",\n",
    "                                        dec = dec.flatten().cpu(), dec_units = \"deg\",\n",
    "                                        g1 = shear1_samples[:,n,...].flatten().cpu(),\n",
    "                                        g2 = shear2_samples[:,n,...].flatten().cpu(),\n",
    "                                        k = convergence_samples[:,n,...].flatten().cpu())\n",
    "    \n",
    "    gg = treecorr.GGCorrelation(min_sep = min_sep, max_sep = max_sep,\n",
    "                                nbins = num_bins, sep_units = sep_units)\n",
    "    gg.process(treecorr_catalog)\n",
    "    \n",
    "    xip[n] = torch.from_numpy(gg.xip.copy()).to(device)\n",
    "    xim[n] = torch.from_numpy(gg.xim.copy()).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
