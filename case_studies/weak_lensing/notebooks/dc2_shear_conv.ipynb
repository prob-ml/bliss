{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using DC2 and CosmoDC2 to Extract Shear and Convergence #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: commented portions of cells below to illustrate attempted methods that were suboptimal (esp. from dc2-linked tutorials), included for future observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "from einops import rearrange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "import healpy as hp\n",
    "import pickle as pkl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify here if different\n",
    "file_name = \"lensing_catalog.pkl\"\n",
    "file_path = os.path.join(\"/data\", \"scratch\", \"shreyasc\", file_name)\n",
    "file_already_populated = os.path.isfile(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CosmoDC2 is REALLY big so we don't want to load all of its data into memory when accessing attributes. We set filters below that match dc2's piece of the sky since it's a subset of Cosmo's coverage. In the below cell, we load our DC2 catalog with the fields we are interested in and find the relevant sky quadrant, allowing us to build the filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not file_already_populated:\n",
    "    import GCRCatalogs\n",
    "    from GCRCatalogs import GCRQuery\n",
    "    GCRCatalogs.set_root_dir(\"/data/scratch/dc2_nfs/\")\n",
    "    truth_cat = GCRCatalogs.load_catalog('desc_dc2_run2.2i_dr6_truth')\n",
    "    truth_data = truth_cat.get_quantities([\"id\", \"cosmodc2_id\", \"ra\", \"dec\", \"match_objectId\", \"flux_u\", \"flux_g\", \"flux_r\", \"flux_i\", \"flux_z\", \"flux_y\", \"truth_type\"])\n",
    "\n",
    "    max_ra = np.nanmax(truth_data['ra'])\n",
    "    min_ra = np.nanmin(truth_data['ra'])\n",
    "    max_dec = np.nanmax(truth_data['dec'])\n",
    "    min_dec = np.nanmin(truth_data['dec'])\n",
    "    pos_filters = [f'ra >= {min_ra}',f'ra <= {max_ra}', f'dec >= {min_dec}', f'dec <= {max_dec}']\n",
    "\n",
    "    vertices = hp.ang2vec(np.array([min_ra, max_ra, max_ra, min_ra]),\n",
    "                        np.array([min_dec, min_dec, max_dec, max_dec]), lonlat=True)\n",
    "    ipix = hp.query_polygon(32, vertices, inclusive=True)\n",
    "    healpix_filter = GCRQuery((lambda h: np.isin(h, ipix, True), \"healpix_pixel\"))\n",
    "    truth_data = pd.DataFrame(truth_data)\n",
    "    truth_data.drop(['ra', 'dec'], axis=1, inplace=True)\n",
    "    # print(truth_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth_data.to_csv('/data/scratch/shreyasc/truth_data_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth_data[((truth_data[\"match_objectId\"] > -1) & (truth_data[\"is_unique_truth_entry\"]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load in CosmoDC2 and select the quantities we want bounded by the aforementioned filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not file_already_populated:\n",
    "    config_overwrite = dict(\n",
    "        catalog_root_dir='/data/scratch/dc2_nfs/cosmoDC2'\n",
    "    )\n",
    "\n",
    "    cosmo_cat = GCRCatalogs.load_catalog('desc_cosmodc2', config_overwrite)\n",
    "    cosmo_data = cosmo_cat.get_quantities(quantities = [\"galaxy_id\", \"shear_1\", \"shear_2\", \"convergence\", \"ra\", \"dec\", \"mag_true_r\", \"galaxy_id\", \"position_angle_true\", \"size_minor_disk_true\", \n",
    "        \"size_disk_true\", \"size_minor_bulge_true\", \n",
    "        \"size_bulge_true\", \"bulge_to_total_ratio_i\", \"redshift\"], filters=pos_filters, native_filters=healpix_filter)\n",
    "    cosm_dat = pd.DataFrame(cosmo_data)\n",
    "    # cosm_dat.to_csv(\"/data/scratch/shreyasc/cosmo_only.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosm_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # PSF params - we need object catalog for now\n",
    "if not file_already_populated:\n",
    "    \n",
    "        match_cat = GCRCatalogs.load_catalog('desc_dc2_run2.2i_dr6_object_with_truth_match')\n",
    "        psf_params = match_cat.get_quantities([\n",
    "            \"IxxPSF_pixel_g\", \"IxxPSF_pixel_z\", \n",
    "            \"IxxPSF_pixel_r\", \"IxxPSF_pixel_i\", \"IxxPSF_pixel_u\", \n",
    "            \"IxxPSF_pixel_y\", \"IyyPSF_pixel_g\", \"IyyPSF_pixel_z\", \n",
    "            \"IyyPSF_pixel_r\", \"IyyPSF_pixel_i\", \"IyyPSF_pixel_u\", \n",
    "            \"IyyPSF_pixel_y\", \"IxyPSF_pixel_g\", \"IxyPSF_pixel_z\", \n",
    "            \"IxyPSF_pixel_r\", \"IxyPSF_pixel_i\", \"IxyPSF_pixel_u\", \n",
    "            \"IxyPSF_pixel_y\", \"psf_fwhm_g\", \"psf_fwhm_z\", \"psf_fwhm_r\",\n",
    "            \"psf_fwhm_i\", \"psf_fwhm_u\", \"psf_fwhm_y\", \"cosmodc2_id_truth\"\n",
    "        ])\n",
    "        psf = pd.DataFrame(psf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "# psf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching Attempt 1: Using example code from ####\n",
    "https://github.com/LSSTDESC/DC2-analysis/blob/253625a230d545f4ceb529aae58416ef7a768648/tutorials/matching_fof.ipynb\n",
    "\n",
    "Note: Do not actually run the commented cells below, takes forever and does not converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosmo = pd.DataFrame(cosmo_data)\n",
    "# tru = pd.DataFrame(truth_data)\n",
    "# import FoFCatalogMatching\n",
    "# results = FoFCatalogMatching.match(\n",
    "#     catalog_dict={'truth': tru, 'object': cosmo}, \n",
    "#     linking_lengths=1.0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth_mask = results['catalog_key'] == 'truth'\n",
    "# object_mask = ~truth_mask\n",
    "\n",
    "# # then np.bincount will give up the number of id occurrences (like historgram but with integer input)\n",
    "# n_groups = results['group_id'].max() + 1\n",
    "# n_truth = np.bincount(results['group_id'][truth_mask], minlength=n_groups)\n",
    "# print(n_truth[n_truth>10])\n",
    "# n_object = np.bincount(results['group_id'][object_mask], minlength=n_groups)\n",
    "\n",
    "# # now n_truth and n_object are the number of truth/object objects in each group\n",
    "# # we want to make a 2d histrogram of (n_truth, n_object). \n",
    "# n_max = max(n_truth.max(), n_object.max()) + 1\n",
    "# hist_2d = np.bincount(n_object * n_max + n_truth, minlength=n_max*n_max).reshape(n_max, n_max)\n",
    "\n",
    "# plt.imshow(np.log10(hist_2d+1), extent=(-0.5, n_max-0.5, -0.5, n_max-0.5), origin='lower');\n",
    "# plt.xlabel('Number of truth objects');\n",
    "# plt.ylabel('Number of object objects');\n",
    "# plt.colorbar(label=r'$\\log(N_{\\rm groups} \\, + \\, 1)$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's further inspect the objects in the groups that have 1-to-1 truth/object match.\n",
    "\n",
    "# # first, let's find our the IDs of the groups that have 1-to-1 truth/object match:\n",
    "# one_to_one_group_mask = np.in1d(results['group_id'], np.flatnonzero((n_truth == 1) & (n_object == 1)))\n",
    "\n",
    "# # and then we can find the row indices in the *original* truth/object catalogs for those 1-to-1 groups\n",
    "# truth_idx = results['row_index'][one_to_one_group_mask & truth_mask]\n",
    "# object_idx = results['row_index'][one_to_one_group_mask & object_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"friends.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(results, f)\n",
    "# print(\"saved friends\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, since that approach didn't work, let's try something that was attempted by @Xinyue: ####\n",
    "https://github.com/prob-ml/bliss/blob/master/case_studies/dc2/DC2_galaxy_psf_params.ipynb\n",
    "\n",
    "merging on galaxy_id and cosmodc2_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not file_already_populated:\n",
    "    cosmo_truth = cosm_dat.merge(\n",
    "        truth_data, \n",
    "        left_on=\"galaxy_id\", right_on=\"cosmodc2_id\", \n",
    "        how = \"left\" \n",
    "    )\n",
    "\n",
    "    merge_with_object = cosmo_truth.merge(\n",
    "        psf, \n",
    "        left_on = \"galaxy_id\", \n",
    "        right_on = \"cosmodc2_id_truth\", \n",
    "        how = \"left\" \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not file_already_populated:\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pkl.dump(merge_with_object, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
