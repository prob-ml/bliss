---
defaults:
    - ../../../bliss/conf@_here_: base_config
    - _self_
    - override hydra/job_logging: stdout

mode: train

paths:
    cached_data: /scratch/regier_root/regier0/twhit/data/weak_lensing/weak_lensing_img2048_meta_varying_shear
    output: /scratch/regier_root/regier0/twhit/bliss

cached_simulator:
    batch_size: 1
    train_transforms: []

variational_factors:
  - _target_: bliss.encoder.variational_dist.NormalFactor
    name: shear_1
    nll_gating: null
  - _target_: bliss.encoder.variational_dist.NormalFactor
    name: shear_2
    nll_gating: null

my_normalizers:
    nannorm:
        _target_: case_studies.weak_lensing.image_normalizer.NanNormalizer

my_metrics:
    lensingmetrics:
        _target_: case_studies.weak_lensing.metrics.WeakLensingMetrics
        num_redshift_bins: 1

my_render:
    lensingplots:
        _target_: case_studies.weak_lensing.plots.WeakLensingPlots
        frequency: 1
        save_local: ${paths.output}/${train.trainer.logger.name}/${train.trainer.logger.version}/lensing_plots

encoder:
    _target_: case_studies.weak_lensing.encoder.WeakLensingEncoder
    survey_bands: [i]
    reference_band: 0
    tile_slen: 256
    n_pixels_per_side: 2048
    n_tiles_per_side: 8
    ch_init: 64
    ch_max: 512
    optimizer_params:
        lr: 1e-3
    scheduler_params:
        milestones: [32]
        gamma: 0.1
    image_normalizers: ${my_normalizers}
    var_dist:
        _target_: bliss.encoder.variational_dist.VariationalDist
        tile_slen: ${encoder.tile_slen}
        factors: ${variational_factors}
    mode_metrics:
        _target_: torchmetrics.MetricCollection
        _convert_: partial
        metrics: ${my_metrics}
    sample_metrics:
        _target_: torchmetrics.MetricCollection
        _convert_: partial
        metrics: ${my_metrics}
    sample_image_renders:
        _target_: torchmetrics.MetricCollection
        _convert_: partial
        metrics: ${my_render}
    use_double_detect: false
    use_checkerboard: false
    loss_plots_location: ${paths.output}/${train.trainer.logger.name}/${train.trainer.logger.version}/loss_plots

train:
    trainer:
        logger:
            name: WeakLensingResultsDescwl
            version: ${now:%Y-%m-%d_%H-%M}
        max_epochs: 250
        devices: 1
        use_distributed_sampler: false
        precision: 32-true
    callbacks:
        early_stopping:
            patience: 100
    data_source: ${cached_simulator}
    pretrained_weights: null
    seed: 123123
