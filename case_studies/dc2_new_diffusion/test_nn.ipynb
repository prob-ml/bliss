{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "from pytorch_lightning.utilities import move_data_to_device\n",
    "\n",
    "from bliss.surveys.dc2 import DC2DataModule\n",
    "from bliss.catalog import TileCatalog\n",
    "from bliss.encoder.metrics import CatalogMatcher\n",
    "from bliss.encoder.convnet_layers import C3, ConvBlock\n",
    "from bliss.global_env import GlobalEnv\n",
    "\n",
    "from case_studies.dc2_new_diffusion.utils.catalog_parser import CatalogParser\n",
    "from case_studies.dc2_new_diffusion.utils.metrics import DetectionPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "with initialize(config_path=\".\", version_base=None):\n",
    "    new_diffusion_notebook_cfg = compose(\"new_diffusion_notebook_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_slen = new_diffusion_notebook_cfg.surveys.dc2.tile_slen\n",
    "max_sources_per_tile = new_diffusion_notebook_cfg.surveys.dc2.max_sources_per_tile\n",
    "r_band_min_flux = new_diffusion_notebook_cfg.notebook_var.r_band_min_flux\n",
    "\n",
    "dc2: DC2DataModule = instantiate(new_diffusion_notebook_cfg.surveys.dc2)\n",
    "dc2.batch_size = 1024\n",
    "dc2.setup(stage=\"fit\")\n",
    "GlobalEnv.current_encoder_epoch = 1\n",
    "GlobalEnv.seed_in_this_program = 7272\n",
    "dc2_train_dataloader = dc2.train_dataloader()\n",
    "\n",
    "catalog_parser: CatalogParser = instantiate(new_diffusion_notebook_cfg.encoder.catalog_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ch = catalog_parser.n_params_per_source\n",
    "postprocess_net_ch = 16\n",
    "postprocess_net = nn.Sequential(\n",
    "            ConvBlock(target_ch, postprocess_net_ch, kernel_size=5),\n",
    "            ConvBlock(postprocess_net_ch, postprocess_net_ch * 2, kernel_size=3, stride=2),\n",
    "            C3(postprocess_net_ch * 2, postprocess_net_ch * 2, n=3),\n",
    "            ConvBlock(postprocess_net_ch * 2, postprocess_net_ch * 4, kernel_size=3, stride=2),\n",
    "            C3(postprocess_net_ch * 4, postprocess_net_ch * 4, n=3),\n",
    "            ConvBlock(postprocess_net_ch * 4, postprocess_net_ch * 4, kernel_size=1),\n",
    "            nn.Conv2d(postprocess_net_ch * 4, target_ch, kernel_size=1)\n",
    "        )\n",
    "postprocess_net = postprocess_net.to(device=device)\n",
    "optimizer = optim.Adam(postprocess_net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 50/191 [00:41<02:11,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [50/191], loss: 0.028013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 101/191 [01:14<01:19,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [100/191], loss: 0.017862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 150/191 [01:45<00:31,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [150/191], loss: 0.010165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [02:06<00:00,  1.51it/s]\n",
      "  5%|▌         | 10/191 [00:13<01:07,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [200/191], loss: 0.005332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 60/191 [00:47<00:38,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [250/191], loss: 0.004079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 110/191 [01:16<00:20,  4.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [300/191], loss: 0.003695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 160/191 [01:46<00:07,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [350/191], loss: 0.003214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [02:04<00:00,  1.53it/s]\n",
      "  9%|▉         | 18/191 [00:21<04:24,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [400/191], loss: 0.003123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 69/191 [00:57<01:22,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [450/191], loss: 0.003004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 119/191 [01:31<00:37,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [500/191], loss: 0.002324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 169/191 [02:16<00:08,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [550/191], loss: 0.001919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [02:26<00:00,  1.30it/s]\n",
      " 14%|█▍        | 27/191 [00:25<01:08,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [600/191], loss: 0.001682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 78/191 [01:07<00:42,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [650/191], loss: 0.001770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 127/191 [01:40<00:41,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [700/191], loss: 0.001268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 177/191 [02:20<00:08,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [750/191], loss: 0.000823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [02:27<00:00,  1.30it/s]\n",
      " 19%|█▉        | 36/191 [00:31<01:34,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [800/191], loss: 0.000419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 86/191 [01:10<01:31,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [850/191], loss: 0.000325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 136/191 [01:46<01:48,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [900/191], loss: 0.000242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 187/191 [02:13<00:02,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step [950/191], loss: 0.000209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [02:14<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "postprocess_net.train()\n",
    "total_batch = len(dc2_train_dataloader)\n",
    "i = 0\n",
    "epoch = 5\n",
    "for _ in range(epoch):\n",
    "    dc2_train_dataloader = dc2.train_dataloader()\n",
    "    for batch in tqdm.tqdm(dc2_train_dataloader):\n",
    "        batch_on_device = move_data_to_device(batch, device=device)\n",
    "        target_cat = TileCatalog(batch_on_device[\"tile_catalog\"])\n",
    "        target_cat1 = target_cat.get_brightest_sources_per_tile(\n",
    "            band=2, exclude_num=0\n",
    "        )\n",
    "        encoded_catalog_tensor = catalog_parser.encode(target_cat1).permute([0, 3, 1, 2])  # (b, k, h, w)\n",
    "        upsampled_catalog_tensor = F.interpolate(encoded_catalog_tensor, \n",
    "                                                    scale_factor=4, \n",
    "                                                    mode=\"bilinear\")  # (b, k, H, W)\n",
    "        optimizer.zero_grad()\n",
    "        pred = postprocess_net(upsampled_catalog_tensor)\n",
    "        loss = ((pred - encoded_catalog_tensor) ** 2).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"step [{i + 1}/{total_batch}], loss: {loss.item():.6f}\")\n",
    "        i += 1\n",
    "        GlobalEnv.current_encoder_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = CatalogMatcher(dist_slack=1.0)\n",
    "f1_metric = DetectionPerformance().to(device=device)\n",
    "dc2_val_dataloader = dc2.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:31<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "postprocess_net.eval()\n",
    "for batch in tqdm.tqdm(dc2_val_dataloader):\n",
    "    batch_on_device = move_data_to_device(batch, device=device)\n",
    "    target_tile_cat = TileCatalog(batch_on_device[\"tile_catalog\"])\n",
    "    target_tile_cat = target_tile_cat.get_brightest_sources_per_tile(band=2,  exclude_num=0)\n",
    "    target_full_cat = target_tile_cat.to_full_catalog(tile_slen)\n",
    "\n",
    "    encoded_catalog_tensor = catalog_parser.encode(target_tile_cat).permute([0, 3, 1, 2])  # (b, k, h, w)\n",
    "    upsampled_catalog_tensor = F.interpolate(encoded_catalog_tensor, \n",
    "                                                 scale_factor=4, \n",
    "                                                 mode=\"bilinear\")  # (b, k, H, W)\n",
    "    with torch.no_grad():\n",
    "        pred = postprocess_net(upsampled_catalog_tensor)\n",
    "    pred = catalog_parser.clip_tensor(pred.permute([0, 2, 3, 1]))\n",
    "    pred_tile_cat = catalog_parser.decode(pred)\n",
    "    pred_full_cat = pred_tile_cat.to_full_catalog(tile_slen)\n",
    "\n",
    "    matching = matcher.match_catalogs(target_full_cat, pred_full_cat)\n",
    "    f1_metric.update(target_full_cat, pred_full_cat, matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detection_precision: 0.9716938138008118\n",
      "detection_recall: 0.9717060923576355\n",
      "detection_f1: 0.9716999530792236\n",
      "n_true_sources: 157914.0\n",
      "n_est_sources: 157916.0\n"
     ]
    }
   ],
   "source": [
    "for k, v in f1_metric.compute().items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
