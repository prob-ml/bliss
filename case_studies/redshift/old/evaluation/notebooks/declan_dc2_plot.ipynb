{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will do some plots to estimate redshift results for 4 methods below:\n",
    "1. bliss redshift estimate directly from images \n",
    "2. redshift estimate based on LSST predicted mag and rail pipeline(FLEXZBOOST)\n",
    "3. redshift estimate based on LSST predicted mag and neural network pretrained.\n",
    "4. redshift estimate based on LSST predicted mag and neural network pretrained with filtering(filter out bad predicted position and flux points)\n",
    "\n",
    "each method should have metrics vs galaxy fluxes, mse vs blendedness and mse vs true_redshifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "from einops import rearrange\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from pytorch_lightning.utilities import move_data_to_device\n",
    "\n",
    "from bliss.catalog import FullCatalog, BaseTileCatalog, TileCatalog\n",
    "from bliss.surveys.dc2 import DC2DataModule\n",
    "from case_studies.redshift.evaluation.utils.load_lsst import get_lsst_full_cat\n",
    "from case_studies.redshift.evaluation.utils.safe_metric_collection import SafeMetricCollection as MetricCollection\n",
    "from case_studies.redshift.redshift_from_img.encoder.metrics import RedshiftMeanSquaredErrorBin\n",
    "\n",
    "environ[\"BLISS_HOME\"] = str(Path().resolve().parents[2])\n",
    "\n",
    "output_dir = Path(\"/data/scratch/declan/redshift/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# change this model path according to your training setting\n",
    "model_path = \"/data/scratch/qiaozhih/DC2_redshift_training/DC2_redshift_only_bin_allmetrics/checkpoints/encoder_0.182845.ckpt\"\n",
    "lsst_root_dir = \"/data/scratch/dc2_nfs/\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with initialize(config_path=\".\", version_base=None):\n",
    "#     notebook_cfg = compose(\"notebook_plot\")\n",
    "\n",
    "with initialize(config_path=\".\", version_base=None):\n",
    "    notebook_cfg = compose(\"continuous_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up testing dataset\n",
    "dataset = instantiate(notebook_cfg.train.data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bliss.surveys.dc2.DC2DataModule at 0x7fc0acf751e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method CachedSimulatedDataModule.setup of <bliss.surveys.dc2.DC2DataModule object at 0x7fc0acf751e0>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset._load_file_paths_and_slices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_0,0_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_0,0_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_0,1_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_0,1_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_0,2_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_0,2_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_0,3_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_0,3_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_0,4_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_0,4_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_0,5_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_0,5_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_0,6_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_0,6_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_1,0_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_1,0_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_1,1_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_1,1_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_1,2_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_1,2_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_1,3_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_1,3_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_1,4_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_1,4_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_1,5_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_1,5_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_1,6_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_1,6_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_2,0_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_2,0_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_2,1_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_2,1_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_2,2_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_2,2_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_2,3_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_2,3_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_2,4_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_2,4_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_2,5_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_2,5_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_2,6_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_2,6_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_3,0_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_3,0_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_3,1_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_3,1_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_3,2_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_3,2_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_3,3_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_3,3_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_3,4_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_3,4_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_3,5_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_3,5_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_3,6_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_3,6_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_4,0_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_4,0_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_4,1_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_4,1_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_4,2_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_4,2_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_4,3_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_4,3_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_4,4_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_4,4_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_4,5_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_4,5_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_4,6_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_4,6_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_5,0_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_5,0_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_5,1_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_5,1_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_5,2_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_5,2_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_5,3_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_5,3_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_5,4_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_5,4_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_5,5_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_5,5_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_5,6_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_5,6_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_6,0_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_6,0_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_6,1_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_6,1_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_6,2_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_6,2_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_6,3_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_6,3_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_6,4_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_6,4_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_6,5_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_6,5_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_6,6_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3828_6,6_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_0,0_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_0,0_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_0,1_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_0,1_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_0,2_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_0,2_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_0,3_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_0,3_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_0,4_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_0,4_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_0,5_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_0,5_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_0,6_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_0,6_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_1,0_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_1,0_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_1,1_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_1,1_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_1,2_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_1,2_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_1,3_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_1,3_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_1,4_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_1,4_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_1,5_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_1,5_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_1,6_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_1,6_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_2,0_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_2,0_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_2,1_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_2,1_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_2,2_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_2,2_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_2,3_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_2,3_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_2,4_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_2,4_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_2,5_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_2,5_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_2,6_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_2,6_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_3,0_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_3,0_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_3,1_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_3,1_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_3,2_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_3,2_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_3,3_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_3,3_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_3,4_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_3,4_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_3,5_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_3,5_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_3,6_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_3,6_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_4,0_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_4,0_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_4,1_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_4,1_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_4,2_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_4,2_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_4,3_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_4,3_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_4,4_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_4,4_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_4,5_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_4,5_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_4,6_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_4,6_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_5,0_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_5,0_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_5,1_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_5,1_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_5,2_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_5,2_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_5,3_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_5,3_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_5,4_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_5,4_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_5,5_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_5,5_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_5,6_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_5,6_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_6,0_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_6,0_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_6,1_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_6,1_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_6,2_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_6,2_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_6,3_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_6,3_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_6,4_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_6,4_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_6,5_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_6,5_0001_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_6,6_0000_size_1250.pt',\n",
       " '/data/scratch/declan/redshift/dc2/processed_dc2/cached_data_3829_6,6_0001_size_1250.pt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dataset.file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[slice(0, 156, None), slice(156, 176, None), slice(176, 196, None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.setup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bliss.cached_dataset.ChunkingDataset at 0x7fc2dc20bfa0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '16'\n",
    "os.environ['MKL_NUM_THREADS'] = '16'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '16'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dc2 hdf5 data for rail training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def create_output_file(outfile,xdf, start_rows, end_rows):\n",
    "    outf = h5py.File(outfile,\"w\")\n",
    "    xx = outf.create_group('photometry')\n",
    "    for key in xdf.keys():\n",
    "        print(key)\n",
    "        if key != 'id':\n",
    "            #outf.create_dataset(f'{key}', (num_rows,), dtype='f4')\n",
    "            xx[f'{key}'] = xdf[key][start_rows: end_rows]\n",
    "    outf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/data/scratch/qiaozhih/data/redshift/dc2/rail_train_lsst_2000k.hdf5\"\n",
    "if not os.path.exists(save_path):\n",
    "    train_path = \"/data/scratch/qiaozhih/data/redshift/dc2/desc_dc2_run2.2i_dr6_truth_nona_train.pkl\"\n",
    "    train_set = pd.read_pickle(train_path)\n",
    "    train_set = train_set.rename({\n",
    "        'mag_g':'mag_g_lsst', 'mag_i': 'mag_i_lsst', 'mag_r': 'mag_r_lsst', 'mag_u': 'mag_u_lsst', 'mag_y': 'mag_y_lsst', 'mag_z': 'mag_z_lsst'\n",
    "    }, axis=1)\n",
    "    names = ['magerr_g_lsst', 'magerr_i_lsst', 'magerr_r_lsst', 'magerr_u_lsst', 'magerr_y_lsst', 'magerr_z_lsst']\n",
    "    for name in names:\n",
    "        train_set[name] = 0\n",
    "    create_output_file(save_path, train_set, 0, 2_000_000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create lsst hdf5 data for rail testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/data/scratch/qiaozhih/data/redshift/dc2/test_objid_nona.pkl\"\n",
    "if os.path.exists(save_path):\n",
    "    match_id = pd.read_pickle(save_path)\n",
    "else:\n",
    "    match_id = []\n",
    "    for batch_idx, batch in tqdm(enumerate(dataset.test_dataloader()), total=len(dataset.test_dataloader())):\n",
    "        for ids in batch[\"objid\"]:\n",
    "            match_id += list(ids[ids != 0].tolist())\n",
    "\n",
    "    match_id = pd.DataFrame({\"objid\": list(set(match_id))})\n",
    "    match_id.objid = match_id.objid.replace(-1, np.nan).dropna()\n",
    "    match_id.to_pickle(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load lsst table and load mag_u, match_objectId\n",
    "import GCRCatalogs\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from bliss.catalog import FullCatalog, SourceType\n",
    "\n",
    "# load lsst data\n",
    "def get_lsst_catalog_df(lsst_root_dir: str):\n",
    "    GCRCatalogs.set_root_dir(lsst_root_dir)\n",
    "    lsst_catalog_gcr = GCRCatalogs.load_catalog(\"desc_dc2_run2.2i_dr6_object_with_truth_match\")\n",
    "    print(sorted(lsst_catalog_gcr.list_all_quantities()))\n",
    "    lsst_catalog_sub = lsst_catalog_gcr.get_quantities(\n",
    "        [\n",
    "            \"id_truth\",\n",
    "            \"redshift_truth\",\n",
    "            \"mag_u_cModel\",\n",
    "            \"mag_g_cModel\",\n",
    "            \"mag_r_cModel\",\n",
    "            \"mag_i_cModel\",\n",
    "            \"mag_z_cModel\",\n",
    "            \"mag_y_cModel\",\n",
    "            \"magerr_u_cModel\",\n",
    "            \"magerr_g_cModel\",\n",
    "            \"magerr_r_cModel\",\n",
    "            \"magerr_i_cModel\",\n",
    "            \"magerr_z_cModel\",\n",
    "            \"magerr_y_cModel\",\n",
    "            \"blendedness\"\n",
    "        ]\n",
    "    )\n",
    "    lsst_catalog_df = pd.DataFrame(lsst_catalog_sub)\n",
    "    lsst_catalog_df = lsst_catalog_df.rename({\n",
    "        \"id_truth\": \"id\",\n",
    "        \"redshift_truth\": \"redshift\",\n",
    "        \"mag_u_cModel\": \"mag_u_lsst\",\n",
    "        \"mag_g_cModel\": \"mag_g_lsst\",\n",
    "        \"mag_r_cModel\": \"mag_r_lsst\",\n",
    "        \"mag_i_cModel\": \"mag_i_lsst\",\n",
    "        \"mag_z_cModel\": \"mag_z_lsst\",\n",
    "        \"mag_y_cModel\": \"mag_y_lsst\",\n",
    "        \"magerr_u_cModel\": \"magerr_u_lsst\",\n",
    "        \"magerr_g_cModel\": \"magerr_g_lsst\",\n",
    "        \"magerr_r_cModel\": \"magerr_r_lsst\",\n",
    "        \"magerr_i_cModel\": \"magerr_i_lsst\",\n",
    "        \"magerr_z_cModel\": \"magerr_z_lsst\",\n",
    "        \"magerr_y_cModel\": \"magerr_y_lsst\",\n",
    "    }, axis=1)\n",
    "    return lsst_catalog_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/data/scratch/qiaozhih/data/redshift/dc2/lsst_from_loader.pkl\"\n",
    "\n",
    "if os.path.exists(save_path):\n",
    "    lsst_test_df_cleaned = pd.read_pickle(save_path)\n",
    "else:\n",
    "    lsst_root_dir = \"/data/scratch/dc2_nfs/\"\n",
    "    lsst_df = get_lsst_catalog_df(lsst_root_dir)\n",
    "    lsst_test_df = lsst_df.merge(match_id, left_on=\"id\", right_on=\"objid\", how=\"inner\")\n",
    "    blendedness_col = lsst_test_df['blendedness']\n",
    "    lsst_test_df_cleaned = lsst_test_df.drop(columns=['blendedness'])\n",
    "    lsst_test_df_cleaned = lsst_test_df_cleaned.replace([-np.inf, np.inf], np.nan).dropna()\n",
    "    lsst_test_df_cleaned['blendedness'] = blendedness_col\n",
    "    lsst_test_df_cleaned['blendedness'] = lsst_test_df_cleaned['blendedness'].clip(lower=0)\n",
    "    lsst_test_df_cleaned.to_pickle(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_test_df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/data/scratch/qiaozhih/data/redshift/dc2/rail_test_lsst.hdf5\"\n",
    "if not os.path.exists(save_path):\n",
    "    create_output_file(save_path, lsst_test_df_cleaned, 0, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now, we can use rail_train_lsst.hdf and rail_test_lsst.hdf5 to train/test rail pipeline. You might need to setup rail pipeline following \\\n",
    "https://rail-hub.readthedocs.io/en/latest/source/installation.html. \n",
    "\n",
    "I am using flexzboost pipeline to do training and testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, we will do data/metrics preparation for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. lsst+neural network without filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network used is pretrained using network of /home/qiaozhih/bliss/case_studies/redshift/network_rs.py. For reproduction, run /home/qiaozhih/bliss/case_studies/redshift/train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from case_studies.redshift.network_rs import PhotoZFromMag\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch.nn as nn\n",
    "num_bins = 1\n",
    "group_size = 128\n",
    "batch_size = 1\n",
    "in_dim = 6\n",
    "device = \"cuda\"\n",
    "path = \"/data/scratch/qiaozhih/training_runs/00120-run/tensorboard_logs/version_0/checkpoints/reg_val_loss=0.000367_epoch=29.ckpt\"\n",
    "network_options = {\n",
    "    \"hidden_dim\": 256,\n",
    "    \"out_dim\": num_bins,\n",
    "    \"n_epochs\": 50001,\n",
    "    \"outdir\": \"/home/qiaozhih/bliss/case_studies/redshift/training_runs/\",\n",
    "    \"snap\": 1,  # how many epoches to save one model once\n",
    "    \"loss_fcn\": torch.nn.MSELoss(),  # loss func\n",
    "    # 'loss_fcn': torch.nn.CrossEntropyLoss(),                     # loss func\n",
    "    \"dropout_rate\": 0.5,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"group_size\": group_size,\n",
    "    \"num_gpu\": 1,\n",
    "    \"gpu_device\": [0],\n",
    "}\n",
    "\n",
    "reg = PhotoZFromMag.load_from_checkpoint(\n",
    "    path,\n",
    "    in_dim=in_dim,\n",
    "    hidden_dim=network_options[\"hidden_dim\"],\n",
    "    out_dim=network_options[\"out_dim\"],\n",
    "    dropout_rate=network_options[\"dropout_rate\"],\n",
    "    learning_rate=network_options[\"learning_rate\"],\n",
    "    loss_fcn=network_options[\"loss_fcn\"],\n",
    ")\n",
    "reg.to(device)\n",
    "reg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_lsst = torch.from_numpy(lsst_test_df_cleaned[[\"mag_u_lsst\", \"mag_g_lsst\", \"mag_r_lsst\", \"mag_i_lsst\", \"mag_z_lsst\", \"mag_y_lsst\"]].values).to(torch.float32).to(device)\n",
    "pred_rs = reg.net(mag_lsst)\n",
    "pred_rs = pred_rs.detach().to('cpu')\n",
    "\n",
    "lsst_df = pd.DataFrame({\n",
    "    \"true_red\": lsst_test_df_cleaned['redshift'],\n",
    "    \"est_red\": pred_rs.squeeze(-1),\n",
    "    \"mag_r\": lsst_test_df_cleaned['mag_r_lsst'],\n",
    "    \"id\": lsst_test_df_cleaned['objid'],\n",
    "    \"blendedness\": lsst_test_df_cleaned['blendedness'],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_bins = [-np.inf, 23.9, 24.1, 24.5, 24.9, 25.6, np.inf]\n",
    "mag_labels = [\"<23.9\", \"23.9-24.1\", \"24.1-24.5\", \"24.5-24.9\", \"24.9-25.6\", \">25.6\"]\n",
    "true_red_bins = [0, 0.5, 1, 1.5, 2, 2.5, 3, np.inf]\n",
    "true_red_labels = [\"<0.5\", \"0.5-1.0\", \"1.0-1.5\", \"1.5-2.0\", \"2.0-2.5\", \"2.5-3.0\",\">3.0\"]\n",
    "blendedness_bins = [-np.inf ,0.0001, 0.02, 0.1, 0.2, 0.6, np.inf]\n",
    "blendedness_labels = [\"<0.0001\", \"0.0001-0.02\", \"0.02-0.1\", \"0.1-0.2\", \"0.2-0.6\",\">0.6\"]\n",
    "lsst_df['mag_bins'] = pd.cut(lsst_df['mag_r'], bins=mag_bins, labels=mag_labels, include_lowest=True)\n",
    "lsst_df['true_red_bins'] = pd.cut(lsst_df['true_red'], bins=true_red_bins, labels=true_red_labels, include_lowest=True)\n",
    "lsst_df['blendedness_bins'] = pd.cut(lsst_df['blendedness'], bins=blendedness_bins, labels=blendedness_labels, include_lowest=True)\n",
    "\n",
    "def calculate_mse(group):\n",
    "    return ((group['true_red'] - group['est_red']) ** 2).mean()\n",
    "\n",
    "def calculate_outlier_fraction(group):\n",
    "    metric_outlier = np.abs(group['true_red'] - group['est_red']) / (1 + group['true_red'])\n",
    "    num_outlier = (metric_outlier > 0.15).sum()\n",
    "    return num_outlier / len(metric_outlier)\n",
    "\n",
    "def calculate_outlier_fraction_cata(group):\n",
    "    metric_outlier = np.abs(group['true_red'] - group['est_red']) / (1 + group['true_red'])\n",
    "    num_outlier = (metric_outlier > 1).sum()\n",
    "    return num_outlier / len(metric_outlier)\n",
    "\n",
    "def calculate_nmad(group):\n",
    "    metric = (group['true_red'] - group['est_red']) / (1 + group['true_red'])\n",
    "    bias = np.median(metric)\n",
    "    nmad_all = np.abs(metric - bias)\n",
    "    nmad = 1.4826 * np.median(nmad_all)\n",
    "    return nmad\n",
    "\n",
    "def calculate_bias_abs(group):\n",
    "    metric = np.abs(group['true_red'] - group['est_red']) / (1 + group['true_red'])\n",
    "    return np.median(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"/data/scratch/qiaozhih/data/redshift/metrics_result\"\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mag\n",
    "save_path = os.path.join(out_dir, \"lsst_nn_metrics_mag.csv\")\n",
    "if os.path.exists(save_path):\n",
    "    metrics_df_stratified_by_mag = pd.read_csv(save_path, index_col=0)\n",
    "else:\n",
    "    mse_by_mag_range = lsst_df.groupby('mag_bins').apply(calculate_mse).reset_index(name='mse')\n",
    "    outlier_fraction_by_mag_range = lsst_df.groupby('mag_bins').apply(calculate_outlier_fraction).reset_index(name='outlier_fraction')\n",
    "    outlier_fraction_cata_by_mag_range = lsst_df.groupby('mag_bins').apply(calculate_outlier_fraction_cata).reset_index(name='outlier_fraction')\n",
    "    nmad_by_mag_range = lsst_df.groupby('mag_bins').apply(calculate_nmad).reset_index(name='nmad')\n",
    "    bias_abs_by_mag_range = lsst_df.groupby('mag_bins').apply(calculate_bias_abs).reset_index(name='bias_abs')\n",
    "    merged_df = mse_by_mag_range.merge(outlier_fraction_by_mag_range, on='mag_bins')\n",
    "    merged_df = merged_df.merge(outlier_fraction_cata_by_mag_range, on='mag_bins', suffixes=('', '_cata'))\n",
    "    merged_df = merged_df.merge(nmad_by_mag_range, on='mag_bins')\n",
    "    metrics_df_stratified_by_mag = merged_df.merge(bias_abs_by_mag_range, on='mag_bins')\n",
    "    metrics_df_stratified_by_mag.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true red\n",
    "save_path = os.path.join(out_dir, \"lsst_nn_metrics_truered.csv\")\n",
    "if not os.path.exists(save_path):\n",
    "    mse_by_true_red_range = lsst_df.groupby('true_red_bins').apply(calculate_mse).reset_index(name='mse')\n",
    "    mse_by_true_red_range.to_csv(save_path)\n",
    "else:\n",
    "    mse_by_true_red_range = lsst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blendedness\n",
    "save_path = os.path.join(out_dir, \"lsst_nn_metrics_blendedness.csv\")\n",
    "if os.path.exists(save_path):\n",
    "    mse_by_blendedness_range = pd.read_csv(save_path, index_col=0)\n",
    "else:\n",
    "    mse_by_blendedness_range = lsst_df.groupby('blendedness_bins').apply(calculate_mse).reset_index(name='mse')\n",
    "    mse_by_blendedness_range.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df_stratified_by_mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_by_true_red_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_by_blendedness_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now we got table for lsst + neural network, which can be used for later plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. bliss redshift estimate directly from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/scratch/qiaozhih/DC2_redshift_training/DC2_redshift_only_bin_allmetrics/checkpoints/encoder_0.182845.ckpt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: please don't use str as nll_gating; it will be deprecated\n"
     ]
    }
   ],
   "source": [
    "# Loop through the test set and update the metric\n",
    "# load bliss trained model\n",
    "bliss_encoder = instantiate(notebook_cfg.encoder).to(device=device)\n",
    "pretrained_weights = torch.load(model_path, device)[\"state_dict\"]\n",
    "bliss_encoder.load_state_dict(pretrained_weights)\n",
    "bliss_encoder.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                                                            | 36/6250 [00:07<20:34,  5.03it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mtest_dataloader()), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mtest_dataloader())):\n\u001b[1;32m      5\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mbliss_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m bliss_out_dict \u001b[38;5;241m=\u001b[39m bliss_encoder\u001b[38;5;241m.\u001b[39mmode_metrics\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(bliss_output_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m outp:  \u001b[38;5;66;03m# Overwrites any existing file.\u001b[39;00m\n",
      "File \u001b[0;32m~/bliss/case_studies/redshift/redshift_from_img/encoder/encoder.py:19\u001b[0m, in \u001b[0;36mRedshiftsEncoder.update_metrics\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     16\u001b[0m     matching \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatcher\u001b[38;5;241m.\u001b[39mmatch_catalogs(target_cat, mode_cat)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscrete_metrics[risk_type]\u001b[38;5;241m.\u001b[39mupdate(target_cat, mode_cat, matching)\n\u001b[0;32m---> 19\u001b[0m mode_cat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m matching \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatcher\u001b[38;5;241m.\u001b[39mmatch_catalogs(target_cat, mode_cat)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode_metrics\u001b[38;5;241m.\u001b[39mupdate(target_cat, mode_cat, matching)\n",
      "File \u001b[0;32m~/bliss/case_studies/redshift/redshift_from_img/encoder/encoder.py:55\u001b[0m, in \u001b[0;36mRedshiftsEncoder.sample\u001b[0;34m(self, batch, use_mode)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, use_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 55\u001b[0m     _, x_cat_marginal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_features_and_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_dist\u001b[38;5;241m.\u001b[39msample(x_cat_marginal, use_mode\u001b[38;5;241m=\u001b[39muse_mode)\n",
      "File \u001b[0;32m~/bliss/case_studies/redshift/redshift_from_img/encoder/encoder.py:51\u001b[0m, in \u001b[0;36mRedshiftsEncoder.get_features_and_parameters\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     49\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros([batch_size, ht, wt])\n\u001b[1;32m     50\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_context(\u001b[38;5;28;01mNone\u001b[39;00m, mask)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m x_cat_marginal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcatalog_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_features, x_cat_marginal\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/bliss/bliss/encoder/convnets.py:72\u001b[0m, in \u001b[0;36mCatalogNet.forward\u001b[0;34m(self, x_features, context)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_features, context):\n\u001b[0;32m---> 72\u001b[0m     x_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x_features, x_context), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetection_net(x)\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/bliss/bliss/encoder/convnet_layers.py:52\u001b[0m, in \u001b[0;36mC3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv3(torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(x)), \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1528\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bliss_output_path = output_dir / \"bliss_output_large_split.pkl\"\n",
    "\n",
    "if not bliss_output_path.exists():\n",
    "    for batch_idx, batch in tqdm(enumerate(dataset.test_dataloader()), total=len(dataset.test_dataloader())):\n",
    "        batch[\"images\"] = batch[\"images\"].to(device)\n",
    "        bliss_encoder.update_metrics(batch, batch_idx)\n",
    "    bliss_out_dict = bliss_encoder.mode_metrics.compute()\n",
    "\n",
    "    with open(bliss_output_path, \"wb\") as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(bliss_out_dict, outp, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(bliss_output_path, \"rb\") as inputp:\n",
    "        bliss_out_dict = pickle.load(inputp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_encoder.var_dist.factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_encoder.var_dist_disc.factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_encoder.var_dist_disc.factors[0].n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from case_studies.redshift.network_rs import PhotoZFromMag\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch.nn as nn\n",
    "num_bins = 1\n",
    "group_size = 128\n",
    "batch_size = 1\n",
    "in_dim = 6\n",
    "device = \"cuda\"\n",
    "path = \"/data/scratch/qiaozhih/training_runs/00120-run/tensorboard_logs/version_0/checkpoints/reg_val_loss=0.000367_epoch=29.ckpt\"\n",
    "network_options = {\n",
    "    \"hidden_dim\": 256,\n",
    "    \"out_dim\": num_bins,\n",
    "    \"n_epochs\": 50001,\n",
    "    \"outdir\": \"/home/qiaozhih/bliss/case_studies/redshift/training_runs/\",\n",
    "    \"snap\": 1,  # how many epoches to save one model once\n",
    "    \"loss_fcn\": torch.nn.MSELoss(),  # loss func\n",
    "    # 'loss_fcn': torch.nn.CrossEntropyLoss(),                     # loss func\n",
    "    \"dropout_rate\": 0.5,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"group_size\": group_size,\n",
    "    \"num_gpu\": 1,\n",
    "    \"gpu_device\": [0],\n",
    "}\n",
    "\n",
    "reg = PhotoZFromMag.load_from_checkpoint(\n",
    "    path,\n",
    "    in_dim=in_dim,\n",
    "    hidden_dim=network_options[\"hidden_dim\"],\n",
    "    out_dim=network_options[\"out_dim\"],\n",
    "    dropout_rate=network_options[\"dropout_rate\"],\n",
    "    learning_rate=network_options[\"learning_rate\"],\n",
    "    loss_fcn=network_options[\"loss_fcn\"],\n",
    ")\n",
    "reg.to(device)\n",
    "reg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est_redshifts_with_reg_change_to_cat(cat: TileCatalog, reg: PhotoZFromMag, tile_slen: int, min_flux_for_loss: int=50, reference_band: int=2) -> BaseTileCatalog | FullCatalog:\n",
    "    \"\"\"estimate redshift by inputting true mag using regressor, then convert them to Basetilecatalog\n",
    "\n",
    "    Args:\n",
    "        cat: catalog\n",
    "        reg: regressor that accept ugrizy mag\n",
    "\n",
    "    Returns:\n",
    "        Catalog that containing pred redshifts\n",
    "    \"\"\"\n",
    "    cat = cat.filter_by_flux(\n",
    "        min_flux=min_flux_for_loss,\n",
    "        band=reference_band,\n",
    "    )\n",
    "    mag = cat.on_fluxes(\"njymag\")\n",
    "\n",
    "    new_order = [3, 0, 2, 1, 5, 4] # change giruyz to ugrizy\n",
    "    mag = mag[..., new_order]\n",
    "    is_galaxy = cat.galaxy_bools.to(device)\n",
    "    N, H, W, M, _ = mag.shape\n",
    "    mag = mag.reshape(-1, 6)\n",
    "    is_galaxy = is_galaxy.reshape(-1, 1)\n",
    "    pred_rs = torch.zeros_like(mag[..., 0])\n",
    "    for i in range(len(mag)):\n",
    "        if is_galaxy[i][0]: \n",
    "            x = mag[i].unsqueeze(0).to(device) # 1, 6\n",
    "            pred_rs[i] = reg.net(x).squeeze(0)\n",
    "    pred_rs = pred_rs.to('cpu')\n",
    "    pred_rs = {\"redshifts\": pred_rs.reshape((N, H, W, M, 1))}\n",
    "\n",
    "    cat[\"redshifts\"] = pred_rs[\"redshifts\"]\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. redshift estimate based on LSST predicted flux + neural network with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GCRCatalogs\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from bliss.catalog import FullCatalog, SourceType\n",
    "\n",
    "# load lsst data\n",
    "def get_lsst_catalog_tensors_dict(lsst_root_dir: str):\n",
    "    GCRCatalogs.set_root_dir(lsst_root_dir)\n",
    "    lsst_catalog_gcr = GCRCatalogs.load_catalog(\"desc_dc2_run2.2i_dr6_object_with_truth_match\")\n",
    "    lsst_catalog_sub = lsst_catalog_gcr.get_quantities(\n",
    "        [\n",
    "            \"id_truth\",\n",
    "            \"objectId\",\n",
    "            \"ra\",\n",
    "            \"dec\",\n",
    "            \"truth_type\",\n",
    "            \"cModelFlux_u\",\n",
    "            \"cModelFluxErr_u\",\n",
    "            \"cModelFlux_g\",\n",
    "            \"cModelFluxErr_g\",\n",
    "            \"cModelFlux_r\",\n",
    "            \"cModelFluxErr_r\",\n",
    "            \"cModelFlux_i\",\n",
    "            \"cModelFluxErr_i\",\n",
    "            \"cModelFlux_z\",\n",
    "            \"cModelFluxErr_z\",\n",
    "            \"cModelFlux_y\",\n",
    "            \"cModelFluxErr_y\",\n",
    "        ]\n",
    "    )\n",
    "    lsst_catalog_df = pd.DataFrame(lsst_catalog_sub)\n",
    "    lsst_flux_lst = [\n",
    "        lsst_catalog_df[\"cModelFlux_g\"],\n",
    "        lsst_catalog_df[\"cModelFlux_i\"],\n",
    "        lsst_catalog_df[\"cModelFlux_r\"],\n",
    "        lsst_catalog_df[\"cModelFlux_u\"],\n",
    "        lsst_catalog_df[\"cModelFlux_y\"],\n",
    "        lsst_catalog_df[\"cModelFlux_z\"],\n",
    "    ]\n",
    "    lsst_flux_tensors_lst = [torch.tensor(flux.values).view(-1, 1) for flux in lsst_flux_lst]\n",
    "    return {\n",
    "        \"truth_type\": torch.tensor(lsst_catalog_df[\"truth_type\"].values).view(-1, 1),\n",
    "        \"flux\": torch.cat(lsst_flux_tensors_lst, dim=1),\n",
    "        \"ra\": torch.tensor(lsst_catalog_df[\"ra\"].values),\n",
    "        \"dec\": torch.tensor(lsst_catalog_df[\"dec\"].values),\n",
    "    }\n",
    "    \n",
    "def get_lsst_catalog_tensors_dict(lsst_root_dir: str):\n",
    "    GCRCatalogs.set_root_dir(lsst_root_dir)\n",
    "    lsst_catalog_gcr = GCRCatalogs.load_catalog(\"desc_dc2_run2.2i_dr6_object_with_truth_match\")\n",
    "    lsst_catalog_sub = lsst_catalog_gcr.get_quantities(\n",
    "        [\n",
    "            \"id_truth\",\n",
    "            \"objectId\",\n",
    "            \"ra\",\n",
    "            \"dec\",\n",
    "            \"truth_type\",\n",
    "            \"cModelFlux_u\",\n",
    "            \"cModelFluxErr_u\",\n",
    "            \"cModelFlux_g\",\n",
    "            \"cModelFluxErr_g\",\n",
    "            \"cModelFlux_r\",\n",
    "            \"cModelFluxErr_r\",\n",
    "            \"cModelFlux_i\",\n",
    "            \"cModelFluxErr_i\",\n",
    "            \"cModelFlux_z\",\n",
    "            \"cModelFluxErr_z\",\n",
    "            \"cModelFlux_y\",\n",
    "            \"cModelFluxErr_y\",\n",
    "        ]\n",
    "    )\n",
    "    lsst_catalog_df = pd.DataFrame(lsst_catalog_sub)\n",
    "    lsst_flux_lst = [\n",
    "        lsst_catalog_df[\"cModelFlux_g\"],\n",
    "        lsst_catalog_df[\"cModelFlux_i\"],\n",
    "        lsst_catalog_df[\"cModelFlux_r\"],\n",
    "        lsst_catalog_df[\"cModelFlux_u\"],\n",
    "        lsst_catalog_df[\"cModelFlux_y\"],\n",
    "        lsst_catalog_df[\"cModelFlux_z\"],\n",
    "    ]\n",
    "    lsst_flux_tensors_lst = [torch.tensor(flux.values).view(-1, 1) for flux in lsst_flux_lst]\n",
    "    return {\n",
    "        \"truth_type\": torch.tensor(lsst_catalog_df[\"truth_type\"].values).view(-1, 1),\n",
    "        \"flux\": torch.cat(lsst_flux_tensors_lst, dim=1),\n",
    "        \"ra\": torch.tensor(lsst_catalog_df[\"ra\"].values),\n",
    "        \"dec\": torch.tensor(lsst_catalog_df[\"dec\"].values),\n",
    "    }\n",
    "import torch\n",
    "\n",
    "from bliss.catalog import FullCatalog, SourceType, TileCatalog\n",
    "from bliss.surveys.dc2 import wcs_from_wcs_header_str\n",
    "\n",
    "def concatenate_tile_dicts(tile_dict_list):\n",
    "    output_tile_cat_dict = {}\n",
    "    for k in tile_dict_list[0].keys():\n",
    "        if k not in output_tile_cat_dict:\n",
    "            output_tile_cat_dict[k] = []\n",
    "        for tile_dict in tile_dict_list:\n",
    "            output_tile_cat_dict[k].append(tile_dict[k])\n",
    "\n",
    "    for k, v in output_tile_cat_dict.items():\n",
    "        output_tile_cat_dict[k] = torch.cat(v, dim=0)\n",
    "\n",
    "    return output_tile_cat_dict\n",
    "\n",
    "\n",
    "class LSSTPredictor:\n",
    "    def __init__(\n",
    "        self, lsst_root_dir, r_band_min_flux, tile_slen, max_sources_per_tile, tiles_to_crop\n",
    "    ) -> None:\n",
    "        self.lsst_data = get_lsst_catalog_tensors_dict(lsst_root_dir)\n",
    "        self.r_band_min_flux = r_band_min_flux\n",
    "        self.tile_slen = tile_slen\n",
    "        self.max_sources_per_tile = max_sources_per_tile\n",
    "        self.tiles_to_crop = tiles_to_crop\n",
    "\n",
    "        self.buffered_wcs_header_str = None\n",
    "        self.buffered_lsst_plocs = None\n",
    "\n",
    "    def _predict_one_image(self, wcs_header_str, image_lim, height_index, width_index):\n",
    "        if wcs_header_str != self.buffered_wcs_header_str:\n",
    "            lsst_ra = self.lsst_data[\"ra\"]\n",
    "            lsst_dec = self.lsst_data[\"dec\"]\n",
    "            cur_image_wcs = wcs_from_wcs_header_str(wcs_header_str)\n",
    "            lsst_plocs = FullCatalog.plocs_from_ra_dec(lsst_ra, lsst_dec, cur_image_wcs)\n",
    "            self.buffered_wcs_header_str = wcs_header_str\n",
    "            self.buffered_lsst_plocs = lsst_plocs\n",
    "        else:\n",
    "            lsst_plocs = self.buffered_lsst_plocs\n",
    "    \n",
    "        lsst_source_type = self.lsst_data[\"truth_type\"]\n",
    "        lsst_flux = self.lsst_data[\"flux\"]\n",
    "\n",
    "        x0_mask = (lsst_plocs[:, 0] > height_index * image_lim) & (\n",
    "            lsst_plocs[:, 0] < (height_index + 1) * image_lim\n",
    "        )\n",
    "        x1_mask = (lsst_plocs[:, 1] > width_index * image_lim) & (\n",
    "            lsst_plocs[:, 1] < (width_index + 1) * image_lim\n",
    "        )\n",
    "        lsst_x_mask = x0_mask * x1_mask\n",
    "        # filter r band\n",
    "        filter_band = [\"g\", \"i\", \"r\", \"u\", \"y\", \"z\"]\n",
    "        for i in range(len(filter_band)):\n",
    "            lsst_flux_mask = (lsst_flux[:, i] > self.r_band_min_flux) & (lsst_flux[:, i] < torch.inf)\n",
    "            lsst_x_mask = lsst_x_mask * lsst_flux_mask\n",
    "\n",
    "        lsst_mask = lsst_x_mask\n",
    "        lsst_plocs = lsst_plocs[lsst_mask, :] % image_lim\n",
    "        lsst_source_type = torch.where(\n",
    "            lsst_source_type[lsst_mask] == SourceType.STAR, SourceType.STAR, SourceType.GALAXY\n",
    "        )\n",
    "        lsst_flux = lsst_flux[lsst_mask, :]\n",
    "        lsst_n_sources = torch.tensor([lsst_plocs.shape[0]])\n",
    "\n",
    "        return FullCatalog(\n",
    "            height=image_lim,\n",
    "            width=image_lim,\n",
    "            d={\n",
    "                \"plocs\": lsst_plocs.unsqueeze(0),\n",
    "                \"n_sources\": lsst_n_sources,\n",
    "                \"source_type\": lsst_source_type.unsqueeze(0),\n",
    "                \"galaxy_fluxes\": lsst_flux.unsqueeze(0),\n",
    "                \"star_fluxes\": lsst_flux.unsqueeze(0).clone(),\n",
    "            },\n",
    "        ).to_tile_catalog(self.tile_slen, self.max_sources_per_tile, ignore_extra_sources=True)\n",
    "\n",
    "    def predict(self, wcs_header_str_list, image_lim, height_index_list, width_index_list):\n",
    "        assert len(wcs_header_str_list) == len(height_index_list), \"unequal input list size\"\n",
    "        assert len(wcs_header_str_list) == len(width_index_list), \"unequal input list size\"\n",
    "        tile_dict_list = []\n",
    "        predict_input_data = zip(wcs_header_str_list, height_index_list, width_index_list)\n",
    "        for wcs_header_str, height_index, width_index in predict_input_data:\n",
    "            tile_dict_list.append(\n",
    "                self._predict_one_image(wcs_header_str, image_lim, height_index, width_index).data\n",
    "            )\n",
    "\n",
    "        merged_tile_dict = concatenate_tile_dicts(tile_dict_list)\n",
    "        return TileCatalog(merged_tile_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bliss.encoder.metrics import CatalogMatcher\n",
    "lsst_output_path = output_dir / \"lsst_output_large_split_final.pkl\"\n",
    "mag_dist_path = output_dir / \"lsst_mag_dist_large_split_final.pkl\"\n",
    "blendedness_dist_path = output_dir / \"lsst_blendedness_dist_large_split_final.pkl\"\n",
    "true_redshift_dist_path = output_dir / \"lsst_true_redshift_dist_large_split_final.pkl\"\n",
    "    \n",
    "if not lsst_output_path.exists() or not mag_dist_path.exists():\n",
    "    metrics = instantiate(notebook_cfg.encoder.mode_metrics)\n",
    "    matcher = CatalogMatcher()\n",
    "\n",
    "    metrics.reset()\n",
    "    # args\n",
    "    lsst_root_dir = \"/data/scratch/dc2_nfs/\"\n",
    "    image_lim = 80\n",
    "    r_band_min_flux = 50\n",
    "    tile_slen = 4\n",
    "    max_sources_per_tile = 1\n",
    "    max_batch = -1\n",
    "    tiles_to_crop = 1\n",
    "\n",
    "    lsst_predictor = LSSTPredictor(lsst_root_dir, r_band_min_flux, tile_slen, max_sources_per_tile, tiles_to_crop)\n",
    "    for batch_idx, batch in tqdm(enumerate(dataset.test_dataloader()), total=len(dataset.test_dataloader())):\n",
    "        true_cat = TileCatalog(d=batch[\"tile_catalog\"]).get_brightest_sources_per_tile()\n",
    "        lsst_cat = lsst_predictor.predict(batch[\"wcs_header_str\"], image_lim, batch[\"image_height_index\"], batch[\"image_width_index\"])\n",
    "        est_cat = est_redshifts_with_reg_change_to_cat(lsst_cat, reg, tile_slen=4)\n",
    "        est_cat = est_cat.to_full_catalog(tile_slen=4)\n",
    "        true_cat = true_cat.to_full_catalog(tile_slen=4)\n",
    "        matching = matcher.match_catalogs(true_cat, est_cat)\n",
    "        metrics.update(true_cat, est_cat, matching)\n",
    "        if not (batch_idx < max_batch or max_batch < 0):\n",
    "            break\n",
    "\n",
    "    lsst_out_dict = metrics.compute()\n",
    "    # num_bins = metrics.RedshiftMeanSquaredErrorBin.total.numpy()\n",
    "    num_blendedness = metrics[\"redshift_mean_square_error_blendedness\"].total.numpy()\n",
    "    num_redshifts = metrics[\"redshift_mean_square_error_true_redshifts\"].total.numpy()\n",
    "\n",
    "    with open(blendedness_dist_path, \"wb\") as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(num_blendedness, outp, pickle.HIGHEST_PROTOCOL)    \n",
    "    with open(true_redshift_dist_path, \"wb\") as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(num_redshifts, outp, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(lsst_output_path, \"wb\") as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(lsst_out_dict, outp, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(mag_dist_path, \"wb\") as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(num_bins, outp, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(lsst_output_path, \"rb\") as inputp:\n",
    "        lsst_out_dict = pickle.load(inputp)\n",
    "    with open(mag_dist_path, \"rb\") as inputp: \n",
    "        num_bins = pickle.load(inputp)\n",
    "    with open(blendedness_dist_path, \"rb\") as inputp:  # Overwrites any existing file.\n",
    "        num_blendedness = pickle.load(inputp)\n",
    "    with open(true_redshift_dist_path, \"rb\") as inputp:\n",
    "        num_redshifts = pickle.load(inputp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### num of observation for mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "mag_ranges = ['<23.9', '23.9-24.1', '24.1-24.5', '24.5-24.9', '24.9-25.6', '>25.6']\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.bar(mag_ranges, num_bins)\n",
    "plt.xlabel(\"Magnitude\")\n",
    "plt.ylabel(\"Count\")\n",
    "# plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(os.path.join(\"/home/qiaozhih/bliss/case_studies/redshift/evaluation/plot\",f'dist_mag_lsst.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blendedness_ranges = ['<0.0001', '0.0001-0.02', '0.02-0.1', '0.1-0.2', '0.2-0.6', '>0.6']\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.bar(blendedness_ranges, num_blendedness)\n",
    "plt.xlabel(\"Blendedness\")\n",
    "plt.ylabel(\"Count\")\n",
    "# plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(\"/home/qiaozhih/bliss/case_studies/redshift/evaluation/plot\",f'dist_blendedness_lsst.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift_ranges = ['<0.5', '0.5-1.0', '1.0-1.5', '1.5-2.0', '2.0-2.5', '2.5-3.0']\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.bar(redshift_ranges, num_redshifts[: -1])\n",
    "plt.xlabel(\"Redshift\")\n",
    "plt.ylabel(\"Count\")\n",
    "# plt.legend(loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(\"/home/qiaozhih/bliss/case_studies/redshift/evaluation/plot\",f'dist_redshift_lsst_no3.0.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.LSST + flexzboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this .csv file is generated using rail pipeline. Since rail is based on other env, we can't generate them on this notebook. Just use generated table for simplicity. \n",
    "For reproduction, you can check /home/qiaozhih/bliss/case_studies/redshift/evaluation/rail/RAIL_estimation_demo.ipynb. Make sure you are using rail's env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_path = \"/data/scratch/qiaozhih/data/redshift/metrics_result/lsst_flexzboost_metrics_mag.csv\"\n",
    "lsst_flexzboost_df = pd.read_csv(lsst_path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make plots for all method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.plot all metrics stratified by mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_path = \"/data/scratch/qiaozhih/data/redshift/metrics_result/lsst_nn_metrics_mag.csv\"\n",
    "lsst_nn_df = pd.read_csv(lsst_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "metrics = ['mse', 'nmad', 'outlier_fraction_cata', 'outlier_fraction', 'bias_abs']\n",
    "metric_labels = ['MSE', 'NMAD', 'Catastrophic Outlier Fraction', 'Outlier Fraction', 'Absolute Bias']\n",
    "sns.set_theme()\n",
    "for i, metric in enumerate(metrics):\n",
    "    mag_ranges = lsst_flexzboost_df.mag_bins.values\n",
    "    bliss_values = [bliss_out_dict[f'redshifts/{metric}_bin_{i}'] for i in reversed(range(6))]\n",
    "    lsst_values = [lsst_out_dict[f'redshifts/{metric}_bin_{i}'] for i in range(6)]\n",
    "    lsst_flexzboost_values = lsst_flexzboost_df[metric].values\n",
    "    lsst_nn_values = lsst_nn_df[metric].values\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(mag_ranges, bliss_values, label=\"BLISS\", marker='o', c=\"blue\")\n",
    "    plt.plot(mag_ranges, lsst_values, label=\"LSST+Neural Network\", marker='o', c=\"red\")\n",
    "    # plt.plot(mag_ranges, lsst_nn_values, label=\"lsst+neural network\", marker='o', c=\"purple\")\n",
    "    plt.plot(mag_ranges, lsst_flexzboost_values, label=\"LSST+FlexZBoost\", marker='o', c=\"black\")\n",
    "    plt.xlabel('Magnitude')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel(metric_labels[i])\n",
    "    plt.ylim([0, None])\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(\"/home/qiaozhih/bliss/case_studies/redshift/evaluation/plot\",f'3_line_per_mag_range_{metric}.pdf'))\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Plot stratified by true redsfhits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bliss.encoder.metrics import CatalogMatcher\n",
    "# lsst_output_path = output_dir / \"lsst_output_large_split_redshift.pkl\"\n",
    "lsst_output_path = output_dir / \"lsst_output_large_split_final.pkl\"\n",
    "if not lsst_output_path.exists():\n",
    "    metrics = instantiate(notebook_cfg.encoder.mode_metrics)\n",
    "    matcher = CatalogMatcher()\n",
    "\n",
    "    metrics.reset()\n",
    "    # args\n",
    "    lsst_root_dir = \"/data/scratch/dc2_nfs/\"\n",
    "    image_lim = 80\n",
    "    r_band_min_flux = 50\n",
    "    tile_slen = 4\n",
    "    max_sources_per_tile = 1\n",
    "    max_batch = 300\n",
    "\n",
    "    lsst_predictor = LSSTPredictor(lsst_root_dir, r_band_min_flux, tile_slen, max_sources_per_tile)\n",
    "    for batch_idx, batch in tqdm(enumerate(dataset.test_dataloader()), total=len(dataset.test_dataloader())):\n",
    "        true_cat = TileCatalog(d=batch[\"tile_catalog\"]).get_brightest_sources_per_tile()\n",
    "        lsst_cat = lsst_predictor.predict(batch[\"wcs_header_str\"], image_lim, batch[\"image_height_index\"], batch[\"image_width_index\"])\n",
    "        est_cat = est_redshifts_with_reg_change_to_cat(lsst_cat, reg, tile_slen=4)\n",
    "        est_cat = est_cat.to_full_catalog(tile_slen=4)\n",
    "        true_cat = true_cat.to_full_catalog(tile_slen=4)\n",
    "        matching = matcher.match_catalogs(true_cat, est_cat)\n",
    "        metrics.update(true_cat, est_cat, matching)\n",
    "        if not (batch_idx < max_batch or max_batch < 0):\n",
    "            break\n",
    "\n",
    "    lsst_out_dict = metrics.compute()\n",
    "\n",
    "    with open(lsst_output_path, \"wb\") as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(lsst_out_dict, outp, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(lsst_output_path, \"rb\") as inputp:\n",
    "        lsst_out_dict = pickle.load(inputp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_output_path = output_dir / \"bliss_output_large_split_redshift.pkl\"\n",
    "\n",
    "if not bliss_output_path.exists():\n",
    "    for batch_idx, batch in tqdm(enumerate(dataset.test_dataloader()), total=len(dataset.test_dataloader())):\n",
    "        batch[\"images\"] = batch[\"images\"].to(device)\n",
    "        bliss_encoder.update_metrics(batch, batch_idx)\n",
    "    bliss_out_dict = bliss_encoder.mode_metrics.compute()\n",
    "\n",
    "    with open(bliss_output_path, \"wb\") as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(bliss_out_dict, outp, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(bliss_output_path, \"rb\") as inputp:\n",
    "        bliss_out_dict = pickle.load(inputp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_path = \"/data/scratch/qiaozhih/data/redshift/metrics_result/lsst_flexzboost_metrics_truered.csv\"\n",
    "lsst_flexzboost_df = pd.read_csv(lsst_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_path = \"/data/scratch/qiaozhih/data/redshift/metrics_result/lsst_nn_metrics_truered.csv\"\n",
    "lsst_nn_df = pd.read_csv(lsst_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['mse_redshifts_bin']\n",
    "metric_labels = ['MSE']\n",
    "sns.set_theme()\n",
    "for i, metric in enumerate(metrics):\n",
    "    redshifts_ranges = lsst_flexzboost_df.true_red_bins.values[:-1]\n",
    "    bliss_values = [bliss_out_dict[f'redshifts/{metric}_{i}'] for i in range(6)]\n",
    "    lsst_values = [lsst_out_dict[f'redshifts/{metric}_{i}'] for i in range(6)]\n",
    "    lsst_flexzboost_values = lsst_flexzboost_df[\"mse\"].values[:-1]\n",
    "    lsst_nn_values = lsst_nn_df[\"mse\"].values\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(redshifts_ranges, bliss_values, label=\"BLISS\", marker='o', c=\"blue\")\n",
    "    plt.plot(redshifts_ranges, lsst_values, label=\"LSST+Neural Network\", marker='o', c=\"red\")\n",
    "    # plt.plot(redshifts_ranges, lsst_nn_values, label=\"lsst+neural network\", marker='o', c=\"purple\")\n",
    "    plt.plot(redshifts_ranges, lsst_flexzboost_values, label=\"LSST+FlexZBoost\", marker='o', c=\"black\")\n",
    "    plt.xlabel('Redshift')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel(metric_labels[i])\n",
    "    plt.ylim([0, None])\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(\"/home/qiaozhih/bliss/case_studies/redshift/evaluation/plot\",f'3_lines_per_redshifts_range_sns_max3_{metric}.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plot stratified by blendedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_output_path = output_dir / \"bliss_output_large_split_blend.pkl\"\n",
    "\n",
    "if not bliss_output_path.exists():\n",
    "    for batch_idx, batch in tqdm(enumerate(dataset.test_dataloader()), total=len(dataset.test_dataloader())):\n",
    "        batch[\"images\"] = batch[\"images\"].to(device)\n",
    "        bliss_encoder.update_metrics(batch, batch_idx)\n",
    "    bliss_out_dict = bliss_encoder.mode_metrics.compute()\n",
    "\n",
    "    with open(bliss_output_path, \"wb\") as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(bliss_out_dict, outp, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(bliss_output_path, \"rb\") as inputp:\n",
    "        bliss_out_dict = pickle.load(inputp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsst_output_path = output_dir / \"lsst_output_large_split_blend.pkl\"\n",
    "lsst_output_path = output_dir / \"lsst_output_large_split_final.pkl\"\n",
    "if not lsst_output_path.exists():\n",
    "    metrics = instantiate(notebook_cfg.encoder.mode_metrics)\n",
    "    matcher = instantiate(notebook_cfg.encoder.matcher)\n",
    "    metrics.reset()\n",
    "    # args\n",
    "    lsst_root_dir = \"/data/scratch/dc2_nfs/\"\n",
    "    image_lim = 80\n",
    "    r_band_min_flux = 50\n",
    "    tile_slen = 4\n",
    "    max_sources_per_tile = 1\n",
    "    max_batch = -1\n",
    "\n",
    "    lsst_predictor = LSSTPredictor(lsst_root_dir, r_band_min_flux, tile_slen, max_sources_per_tile)\n",
    "    for batch_idx, batch in tqdm(enumerate(dataset.test_dataloader()), total=len(dataset.test_dataloader())):\n",
    "        true_cat = TileCatalog(d=batch[\"tile_catalog\"]).get_brightest_sources_per_tile()\n",
    "        lsst_cat = lsst_predictor.predict(batch[\"wcs_header_str\"], image_lim, batch[\"image_height_index\"], batch[\"image_width_index\"])\n",
    "        est_cat = est_redshifts_with_reg_change_to_cat(lsst_cat, reg, tile_slen=4)\n",
    "        est_cat = est_cat.to_full_catalog(tile_slen=4)\n",
    "        true_cat = true_cat.to_full_catalog(tile_slen=4)\n",
    "        matching = matcher.match_catalogs(true_cat, est_cat)\n",
    "        metrics.update(true_cat, est_cat, matching)\n",
    "        if not (batch_idx < max_batch or max_batch < 0):\n",
    "            break\n",
    "\n",
    "    lsst_out_dict = metrics.compute()\n",
    "\n",
    "    with open(lsst_output_path, \"wb\") as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(lsst_out_dict, outp, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(lsst_output_path, \"rb\") as inputp:\n",
    "        lsst_out_dict = pickle.load(inputp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_path = \"/data/scratch/qiaozhih/data/redshift/metrics_result/lsst_flexzboost_metrics_blendedness.csv\"\n",
    "lsst_flexzboost_df = pd.read_csv(lsst_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_path = \"/data/scratch/qiaozhih/data/redshift/metrics_result/lsst_nn_metrics_blendedness.csv\"\n",
    "lsst_nn_df = pd.read_csv(lsst_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['mse_blend_bin']\n",
    "metric_labels = ['MSE']\n",
    "sns.set_theme()\n",
    "for i, metric in enumerate(metrics):\n",
    "    blendedness_ranges = ['<0.0001', '0.0001-0.02', '0.02-0.1', '0.1-0.2', '0.2-0.6', '>0.6']\n",
    "    bliss_values = [bliss_out_dict[f'redshifts/{metric}_{i}'] for i in range(len(blendedness_ranges))]\n",
    "    lsst_values = [lsst_out_dict[f'redshifts/{metric}_{i}'] for i in range(len(blendedness_ranges))]\n",
    "    lsst_flexzboost_values = lsst_flexzboost_df[\"mse\"].values\n",
    "    lsst_nn_values = lsst_nn_df[\"mse\"].values\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(blendedness_ranges, bliss_values, label=\"BLISS\", marker='o', c=\"blue\")\n",
    "    plt.plot(blendedness_ranges, lsst_values, label=\"LSST+Neural Network\", marker='o', c=\"red\")\n",
    "    # plt.plot(blendedness_ranges, lsst_nn_values, label=\"lsst+neural network\", marker='o', c=\"purple\")\n",
    "    plt.plot(blendedness_ranges, lsst_flexzboost_values, label=\"LSST+FlexZBoost\", marker='o', c=\"black\")\n",
    "    plt.xlabel('Blendedness')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim([0, None])\n",
    "    ax = plt.gca()\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "    plt.ylabel(metric_labels[i])\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(\"/home/qiaozhih/bliss/case_studies/redshift/evaluation/plot\",f'3_lines_per_blendedness_range_sns_{metric}.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catastrophic outlier fraction optimization using bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
