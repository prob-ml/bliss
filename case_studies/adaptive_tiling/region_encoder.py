import itertools
import math
from typing import Dict, Optional

import torch
from einops import rearrange, repeat
from matplotlib import pyplot as plt
from torch import Tensor
from torch.distributions import Distribution, TransformedDistribution

from bliss.catalog import FullCatalog, SourceType, TileCatalog
from bliss.encoder.encoder import Encoder
from bliss.encoder.image_normalizer import ImageNormalizer
from bliss.encoder.metrics import CatalogMetrics
from bliss.encoder.plotting import plot_detections
from bliss.encoder.unconstrained_dists import UnconstrainedBernoulli
from case_studies.adaptive_tiling.region_catalog import (
    RegionCatalog,
    RegionType,
    region_for_tile_source,
)


class RegionEncoder(Encoder):
    def __init__(
        self,
        survey_bands: list,
        tile_slen: int,  # NOTE: this is the *unpadded* tile length!!
        image_normalizer: ImageNormalizer,
        overlap_slen: float,
        metrics: CatalogMetrics,
        optimizer_params: Optional[dict] = None,
        scheduler_params: Optional[dict] = None,
    ):
        super().__init__(
            survey_bands=survey_bands,
            tile_slen=tile_slen,
            image_normalizer=image_normalizer,
            tiles_to_crop=0,
            metrics=metrics,
            optimizer_params=optimizer_params,
            scheduler_params=scheduler_params,
        )
        self.overlap_slen = overlap_slen

    # region Properties
    @property
    def dist_param_groups(self):
        d = super().dist_param_groups
        # this isn't really a distribution itself, but it's a quick and easy way to get the value
        # parametrizing the priority variable distribution
        d["aux_var"] = UnconstrainedBernoulli()
        return d

    # endregion

    # region General Functions
    def convert_locs_padded_to_unpadded(self, locs):
        """Convert locs from padded tile to unpadded tile coordinates."""
        pad_tile = self.tile_slen + self.overlap_slen
        ol = self.overlap_slen

        # central
        locs[:, 1:-1, :, 0] = (locs[:, 1:-1, :, 0] * pad_tile - ol / 2) / self.tile_slen
        locs[:, :, 1:-1, 1] = (locs[:, :, 1:-1, 1] * pad_tile - ol / 2) / self.tile_slen

        # top/bottom
        locs[:, 0, :, 0] = (locs[:, 0, :, 0] * (pad_tile - ol / 2)) / self.tile_slen
        locs[:, -1, :, 0] = (locs[:, -1, :, 0] * (pad_tile - ol / 2) - ol / 2) / self.tile_slen

        # left/right
        locs[:, :, 0, 1] = (locs[:, :, 0, 1] * (pad_tile - ol / 2)) / self.tile_slen
        locs[:, :, -1, 1] = (locs[:, :, -1, 1] * (pad_tile - ol / 2) - ol / 2) / self.tile_slen

        return locs

    def suppress_tiles(self, d):
        """Suppress tiles at boundaries or corners depending on priority variables.

        Given that a source is in the boundary or corner, we use a priority variable to predict
        which tile it was generated by, and turn off the other(s). The priority variable may be
        sampled, or may be deterministic (e.g. if using the mode).

        Args:
            d (Dict): A dictionary of raw point estimates of parameters in each tile.

        Returns:
            Dict: A dictionary of point estimates with certain tiles turned off.
        """
        # suppress tiles at boundaries/corners based on priority vars
        batch_size, nth, ntw = d["tile_is_on_array"].shape
        threshold = (
            self.overlap_slen / 2 / self.tile_slen,
            1 - (self.overlap_slen / 2 / self.tile_slen),
        )

        locs = d["locs"]
        n_rows, n_cols = nth * 2 - 1, ntw * 2 - 1
        for b, i, j in itertools.product(range(batch_size), range(nth), range(ntw)):
            if not d["tile_is_on_array"][b, i, j]:
                continue

            # check if a source is in a boundary or corner region
            new_i, new_j = region_for_tile_source(locs[b, i, j], (i, j), n_rows, n_cols, threshold)
            int_i, int_j = i * 2, j * 2  # indices of the interior region of tile (i, j)

            # vertical boundary
            if new_i == int_i and new_j != int_j:
                j_left, j_right = (new_j - 1) // 2, (new_j + 1) // 2
                if d["aux_var"][b, i, j_right] >= d["aux_var"][b, i, j_left]:
                    d["tile_is_on_array"][b, i, j_left] = 0
                else:
                    d["tile_is_on_array"][b, i, j_right] = 0

            # horizontal boundary
            elif new_j == int_j and new_i != int_i:
                i_above, i_below = (new_i - 1) // 2, (new_i + 1) // 2
                if d["aux_var"][b, i_below, j] >= d["aux_var"][b, i_above, j]:
                    d["tile_is_on_array"][b, i_above, j] = 0
                else:
                    d["tile_is_on_array"][b, i_below, j] = 0

            # corner
            elif new_i != int_i and new_j != int_j:
                i_above, i_below = (new_i - 1) // 2, (new_i + 1) // 2
                j_left, j_right = (new_j - 1) // 2, (new_j + 1) // 2
                c_idx = (
                    (b, b, b, b),
                    (i_above, i_above, i_below, i_below),
                    (j_left, j_right, j_left, j_right),
                )
                # keep tile with highest aux_var, turn off the rest
                if d["aux_var"][b, i, j] == d["aux_var"][c_idx].max():
                    d["tile_is_on_array"][c_idx] = 0
                    d["tile_is_on_array"][b, i, j] = 1
                else:
                    d["tile_is_on_array"][b, i, j] = 0

        locs = self.convert_locs_padded_to_unpadded(locs.clone())
        return {
            "locs": rearrange(locs, "b ht wt d -> b ht wt 1 d"),
            "star_fluxes": rearrange(d["star_fluxes"], "b ht wt d -> b ht wt 1 d"),
            "n_sources": d["tile_is_on_array"],
            "source_type": rearrange(d["source_type"], "b ht wt -> b ht wt 1 1"),
            "galaxy_params": rearrange(d["galaxy_params"], "b ht wt d -> b ht wt 1 d"),
            "galaxy_fluxes": rearrange(d["galaxy_fluxes"], "b ht wt d -> b ht wt 1 d"),
        }

    def variational_mode(
        self, pred: Dict[str, Tensor], return_full: bool | None = True
    ) -> FullCatalog | TileCatalog:
        """Compute the mode of the variational distribution.

        Args:
            pred (Dict[str, Tensor]): model predictions
            return_full (bool, optional): Returns a FullCatalog if true, otherwise returns a
                RegionCatalog. Defaults to True.

        Returns:
            Union[FullCatalog, TileCatalog]: Catalog based on predictions.
        """
        # Get point estimate of each distribution
        d = {}
        d["tile_is_on_array"] = pred["on_prob"].mode
        d["locs"] = pred["loc"].mode
        d["aux_var"] = pred["aux_var"].probs[..., 1]

        star_fluxes = [pred[name].mode * d["tile_is_on_array"] for name in self.STAR_FLUX_NAMES]
        d["star_fluxes"] = torch.stack(star_fluxes, dim=3)
        galaxy_fluxes = [pred[name].mode * d["tile_is_on_array"] for name in self.GAL_FLUX_NAMES]
        d["galaxy_fluxes"] = torch.stack(galaxy_fluxes, dim=3)

        galaxy_bools = pred["galaxy_prob"].mode
        d["source_type"] = SourceType.STAR * (1 - galaxy_bools) + SourceType.GALAXY * galaxy_bools

        galsim_dists = [pred[f"galsim_{name}"] for name in self.GALSIM_NAMES]
        galsim_param_lst = []
        for dist in galsim_dists:
            # use median for transformed distributions since mode isn't implemented
            if isinstance(dist, TransformedDistribution):
                galsim_param_lst.append(dist.icdf(torch.tensor(0.5)))
            else:
                galsim_param_lst.append(dist.mode)
        d["galaxy_params"] = torch.stack(galsim_param_lst, dim=3)

        est_catalog_dict = self.suppress_tiles(d)
        est_cat = TileCatalog(self.tile_slen, est_catalog_dict)
        return est_cat.to_full_catalog() if return_full else est_cat

    def sample(self, pred):
        # Sample point estimate of each distribution
        d = {}
        d["tile_is_on_array"] = pred["on_prob"].sample()
        d["locs"] = pred["loc"].sample()[0]
        d["aux_var"] = pred["aux_var"].probs[..., 1]  # TODO: actually sample these properly

        star_fluxes = [pred[name].sample() * d["tile_is_on_array"] for name in self.STAR_FLUX_NAMES]
        d["star_fluxes"] = torch.stack(star_fluxes, dim=3)
        gal_fluxes = [pred[name].sample() * d["tile_is_on_array"] for name in self.GAL_FLUX_NAMES]
        d["galaxy_fluxes"] = torch.stack(gal_fluxes, dim=3)

        galaxy_bools = pred["galaxy_prob"].sample()
        d["source_type"] = SourceType.STAR * (1 - galaxy_bools) + SourceType.GALAXY * galaxy_bools

        galsim_dists = [pred[f"galsim_{name}"] for name in self.GALSIM_NAMES]
        galsim_param_lst = [d.sample() for d in galsim_dists]
        d["galaxy_params"] = torch.stack(galsim_param_lst, dim=3)

        est_catalog_dict = self.suppress_tiles(d)
        return TileCatalog(self.tile_slen, est_catalog_dict)

    # endregion

    # region Loss Utility Functions
    def _average_loss(self, loss, mask):
        """Return the average loss in regions specified by mask."""
        if mask.sum() == 0:
            return 0
        return loss.sum() / mask.sum()

    def _get_masked_param(self, param, mask, shape):
        """Get param in masked regions. `shape` controls output shape for different region types."""
        b, nth, ntw, d = *shape, param.shape[-1]
        if len(param.shape) == 3:
            mask = repeat(mask, "nrh nrw -> b nrh nrw", b=b)
            return param[mask].reshape(shape)

        param = param.squeeze(-2)  # remove max_sources dim
        mask = repeat(mask, "r c -> b r c d", b=b, d=d)
        param = param[mask]
        masked_params = rearrange(param, "(b nth ntw d) -> b nth ntw d", b=b, nth=nth, ntw=ntw, d=d)

        return masked_params.squeeze(-1) if d == 1 else masked_params

    def _get_interior_param(self, cat: RegionCatalog, param_name: str):
        """Get param in interior regions."""
        out_shape = (cat.batch_size, cat.nth, cat.ntw)
        param = cat.get_interior_locs_in_tile() if param_name == "locs" else cat[param_name]
        return self._get_masked_param(param, cat.interior_mask, out_shape)

    def _get_vertical_boundary_param(self, cat: RegionCatalog, param_name: str):
        """Get param in vertical boundary regions."""
        out_shape = (cat.batch_size, cat.nth, cat.ntw - 1)
        if param_name == "locs":
            locs_left, locs_right = cat.get_vertical_boundary_locs_in_tiles()
            vals = (
                self._get_masked_param(locs_left, cat.vertical_boundary_mask, out_shape),
                self._get_masked_param(locs_right, cat.vertical_boundary_mask, out_shape),
            )
            return torch.stack(vals, dim=0)

        param = self._get_masked_param(cat[param_name], cat.vertical_boundary_mask, out_shape)
        return param.expand(2, *param.shape)

    def _get_horizontal_boundary_param(self, cat: RegionCatalog, param_name: str):
        """Get param in horizontal boundary regions."""
        out_shape = (cat.batch_size, cat.nth - 1, cat.ntw)
        if param_name == "locs":
            locs_up, locs_down = cat.get_horizontal_boundary_locs_in_tiles()
            vals = (
                self._get_masked_param(locs_up, cat.horizontal_boundary_mask, out_shape),
                self._get_masked_param(locs_down, cat.horizontal_boundary_mask, out_shape),
            )
            return torch.stack(vals, dim=0)

        param = self._get_masked_param(cat[param_name], cat.horizontal_boundary_mask, out_shape)
        return param.expand(2, *param.shape)

    def _get_corner_param(self, cat: RegionCatalog, param_name: str):
        """Get param in corner regions."""
        out_shape = (cat.batch_size, cat.nth - 1, cat.ntw - 1)
        if param_name == "locs":
            locs_ul, locs_ur, locs_bl, locs_br = cat.get_corner_locs_in_tiles()
            vals = (
                self._get_masked_param(locs_ul, cat.corner_mask, out_shape),
                self._get_masked_param(locs_ur, cat.corner_mask, out_shape),
                self._get_masked_param(locs_bl, cat.corner_mask, out_shape),
                self._get_masked_param(locs_br, cat.corner_mask, out_shape),
            )
            return torch.stack(vals, dim=0)

        param = self._get_masked_param(cat[param_name], cat.corner_mask, out_shape)
        return param.expand(4, *param.shape)

    def _get_aux_vertical(self, pred: Dict[str, Distribution], cat: RegionCatalog):
        """Get auxiliary variables in vertical boundary regions."""
        idx_v = repeat(
            cat.vertical_boundary_mask, "nrh nrw -> b nrh nrw", b=cat.batch_size
        ).nonzero(as_tuple=True)
        idx_vi = (idx_v[0], idx_v[1] // 2, idx_v[2] // 2)
        idx_vj = (idx_v[0], idx_v[1] // 2, (idx_v[2] + 1) // 2)

        probs = pred["aux_var"].probs[..., 1]  # prob of yes
        aux_vars = probs[idx_vi] / (probs[idx_vi] + probs[idx_vj])
        return aux_vars.reshape(cat.batch_size, cat.nth, cat.ntw - 1)

    def _get_aux_horizontal(self, pred: Dict[str, Distribution], cat: RegionCatalog):
        """Get auxiliary variables in horizontal boundary regions."""
        idx_h = repeat(
            cat.horizontal_boundary_mask, "nrh nrw -> b nrh nrw", b=cat.batch_size
        ).nonzero(as_tuple=True)
        idx_hi = (idx_h[0], idx_h[1] // 2, idx_h[2] // 2)
        idx_hj = (idx_h[0], (idx_h[1] + 1) // 2, idx_h[2] // 2)

        probs = pred["aux_var"].probs[..., 1]  # prob of yes
        aux_vars = probs[idx_hi] / (probs[idx_hi] + probs[idx_hj])
        return aux_vars.reshape(cat.batch_size, cat.nth - 1, cat.ntw)

    def _get_aux_corner(self, pred: Dict[str, Distribution], cat: RegionCatalog):
        """Get auxiliary variables in corner regions."""
        b, nth, ntw = cat.batch_size, cat.nth, cat.ntw
        idx_c = repeat(cat.corner_mask, "nrh nrw -> b nrh nrw", b=cat.batch_size).nonzero(
            as_tuple=True
        )

        probs = pred["aux_var"].probs[..., 1]  # prob of yes
        shape = (b, nth - 1, ntw - 1)
        probs_ci = probs[(idx_c[0], idx_c[1] // 2, idx_c[2] // 2)].reshape(shape)
        probs_cj = probs[(idx_c[0], idx_c[1] // 2, (idx_c[2] + 1) // 2)].reshape(shape)
        probs_ck = probs[(idx_c[0], (idx_c[1] + 1) // 2, idx_c[2] // 2)].reshape(shape)
        probs_cl = probs[(idx_c[0], (idx_c[1] + 1) // 2, (idx_c[2] + 1) // 2)].reshape(shape)

        aux_vars = torch.stack((probs_ci, probs_cj, probs_ck, probs_cl), dim=0)
        return aux_vars / aux_vars.sum(dim=0, keepdim=True)

    # endregion

    # region Main Loss Functions
    def _get_loss_interior(self, pred: Dict[str, Distribution], cat: RegionCatalog):
        """Compute loss in interior regions.

        Args:
            pred (Dict[str, Distribution]): predicted distributions to evaluate
            cat (RegionCatalog): true catalog

        Returns:
            Dict: dictionary of loss for each component and overall loss
        """
        loss, loss_components = 0, {}
        n_sources = self._get_interior_param(cat, "n_sources")

        # location loss
        locs = self._get_interior_param(cat, "locs")
        locs_loss = (-pred["loc"].log_prob(locs)) * n_sources
        loss += locs_loss
        loss_components["locs_loss"] = self._average_loss(locs_loss, n_sources)

        # star/galaxy classification loss
        gal_bools = self._get_interior_param(cat, "galaxy_bools")
        binary_loss = (-pred["galaxy_prob"].log_prob(gal_bools)) * n_sources
        loss += binary_loss
        loss_components["binary_loss"] = self._average_loss(binary_loss, n_sources)

        # flux losses
        star_bools = self._get_interior_param(cat, "star_bools")
        star_fluxes = self._get_interior_param(cat, "star_fluxes")
        galaxy_fluxes = self._get_interior_param(cat, "galaxy_fluxes")

        # only compute loss over bands we're using
        star_bands = [self.STAR_FLUX_NAMES[band] for band in self.bands]
        gal_bands = [self.GAL_FLUX_NAMES[band] for band in self.bands]
        for band, star_name, gal_name in zip(self.bands, star_bands, gal_bands):
            # star flux loss
            star_flux_loss = -pred[star_name].log_prob(star_fluxes[..., band] + 1e-9) * star_bools
            loss += star_flux_loss
            loss_components[star_name] = self._average_loss(star_flux_loss, star_bools)

            # galaxy flux loss
            gal_flux_loss = -pred[gal_name].log_prob(galaxy_fluxes[..., band] + 1e-9) * gal_bools
            loss += gal_flux_loss
            loss_components[gal_name] = self._average_loss(gal_flux_loss, gal_bools)

        # galaxy properties loss
        galsim_true_vals = self._get_interior_param(cat, "galaxy_params")
        for i, param_name in enumerate(self.GALSIM_NAMES):
            galsim_pn = f"galsim_{param_name}"
            gal_param_loss = -pred[galsim_pn].log_prob(galsim_true_vals[..., i] + 1e-9) * gal_bools
            loss += gal_param_loss
            loss_components[galsim_pn] = self._average_loss(gal_param_loss, gal_bools)

        loss_by_region = torch.zeros(cat.batch_size, cat.n_rows, cat.n_cols, device=cat.device)
        loss_by_region[:, ::2, ::2] = loss
        loss_components["loss_by_region"] = loss_by_region
        return loss_components

    def _get_param_loss_boundary(self, dist, vals, cat, aux_vars, mask, bdry_type):
        """Compute the loss for a single param in boundary regions.

        The loss is computed by evaluating the value of the param in the tiles to the left and
        right of the boundary (or above and below). We use logsumexp for numerical stability.

        Args:
            dist: the distribution to evaluate
            vals: the value to evaluate at. This should be a 2 x ... tensor where the first dim
                corresponds to the value in each tile on either side of the boundary.
            cat: true catalog
            aux_vars: the auxiliary weights of the left and right tiles
            mask: the mask to apply to the final loss
            bdry_type: type of boundary, RegionType.BOUNDARY_VERTICAL or
                RegionType.BOUNDARY_HORIZONTAL

        Returns:
            Tensor: a tensor of the loss for this param in each vertical boundary (and 0s in all
                other regions)
        """
        shape = list(vals.shape[1:])
        c = 1e-12 if isinstance(dist, torch.distributions.LogNormal) else 0  # ensure val in support

        # get probs in left/right tile for vertical, above/below for horizontal
        if bdry_type == RegionType.BOUNDARY_VERTICAL:
            shape[2] = 1
            col = torch.zeros(shape, device=cat.device)
            log_prob_i = dist.log_prob(torch.cat((vals[0], col), dim=2) + c)[:, :, :-1]
            log_prob_j = dist.log_prob(torch.cat((col, vals[1]), dim=2) + c)[:, :, 1:]
        else:
            shape[1] = 1
            row = torch.zeros(shape, device=cat.device)
            log_prob_i = dist.log_prob(torch.cat((vals[0], row), dim=1) + c)[:, :-1, :]
            log_prob_j = dist.log_prob(torch.cat((row, vals[1]), dim=1) + c)[:, 1:, :]

        # evaluate prob using logsumexp for stability
        log_prob_i += torch.log(aux_vars)
        log_prob_j += torch.log(1 - aux_vars)
        prob = -torch.logsumexp(torch.stack((log_prob_i, log_prob_j), dim=3), dim=3)

        # construct loss array and add values to appropriate regions
        loss = torch.zeros(cat.batch_size, cat.n_rows, cat.n_cols, device=cat.device)
        if bdry_type == RegionType.BOUNDARY_VERTICAL:
            loss[:, ::2, 1::2] = prob
        else:
            loss[:, 1::2, ::2] = prob
        return loss * mask

    def _get_loss_boundary(
        self, pred: Dict[str, Distribution], cat: RegionCatalog, bdry_type: RegionType
    ):
        """Compute loss in boundary regions.

        Args:
            pred (Dict[str, Distribution]): predicted distributions to evaluate
            cat (RegionCatalog): true catalog
            bdry_type (RegionType): which regions to evaluate, either RegionType.BOUNDARY_VERTICAL
                or RegionType.BOUNDARY_HORIZONTAL

        Returns:
            Dict: dictionary of loss for each component and overall loss
        """
        assert bdry_type in {RegionType.BOUNDARY_VERTICAL, RegionType.BOUNDARY_HORIZONTAL}
        loss, loss_components = 0, {}
        if bdry_type == RegionType.BOUNDARY_VERTICAL:
            on_mask = cat.vertical_boundary_mask * (cat.n_sources > 0)
            aux_vars = self._get_aux_vertical(pred, cat)
            get_param = self._get_vertical_boundary_param
        else:
            on_mask = cat.horizontal_boundary_mask * (cat.n_sources > 0)
            aux_vars = self._get_aux_horizontal(pred, cat)
            get_param = self._get_horizontal_boundary_param

        # location loss
        locs = get_param(cat, "locs")
        locs_loss = self._get_param_loss_boundary(
            pred["loc"], locs, cat, aux_vars, on_mask, bdry_type
        )
        loss += locs_loss
        loss_components["locs_loss"] = self._average_loss(locs_loss, on_mask)

        # star/galaxy classification loss
        gal_bools = get_param(cat, "galaxy_bools")
        binary_loss = self._get_param_loss_boundary(
            pred["galaxy_prob"], gal_bools, cat, aux_vars, on_mask, bdry_type
        )
        loss += binary_loss
        loss_components["binary_loss"] = self._average_loss(binary_loss, on_mask)

        # flux losses
        star_fluxes = get_param(cat, "star_fluxes")
        galaxy_fluxes = get_param(cat, "galaxy_fluxes")
        star_mask = on_mask * cat.star_bools[..., 0, 0]
        gal_mask = on_mask * cat.galaxy_bools[..., 0, 0]

        for i, (star_name, gal_name) in enumerate(zip(self.STAR_FLUX_NAMES, self.GAL_FLUX_NAMES)):
            if i not in self.bands:  # only compute loss over bands we're using
                continue
            # star flux loss
            star_flux_loss = self._get_param_loss_boundary(
                pred[star_name], star_fluxes[..., i], cat, aux_vars, star_mask, bdry_type
            )
            loss += star_flux_loss
            loss_components[star_name] = self._average_loss(star_flux_loss, star_mask)

            # galaxy flux loss
            galaxy_flux_loss = self._get_param_loss_boundary(
                pred[gal_name], galaxy_fluxes[..., i], cat, aux_vars, gal_mask, bdry_type
            )
            loss += galaxy_flux_loss
            loss_components[gal_name] = self._average_loss(galaxy_flux_loss, gal_mask)

        # galaxy properties loss
        galaxy_params = get_param(cat, "galaxy_params")
        for i, param_name in enumerate(self.GALSIM_NAMES):
            galsim_pn = f"galsim_{param_name}"
            gal_param_loss = self._get_param_loss_boundary(
                pred[galsim_pn], galaxy_params[..., i], cat, aux_vars, gal_mask, bdry_type
            )
            loss += gal_param_loss
            loss_components[galsim_pn] = self._average_loss(gal_param_loss, gal_mask)

        loss_components["loss_by_region"] = loss
        return loss_components

    def _get_param_loss_corner(self, dist, vals, cat, aux_vars, mask):
        """Compute the loss for a single param in corner regions."""
        shape = list(vals.shape)
        c = 1e-12 if isinstance(dist, torch.distributions.LogNormal) else 0  # ensure val in support

        # create nth x ntw array and add vals to appropriate locations
        shape[2] += 1
        shape[3] += 1
        padded_vals = torch.zeros(shape, device=cat.device)
        padded_vals[0, :, :-1, :-1] = vals[0]
        padded_vals[1, :, :-1, 1:] = vals[1]
        padded_vals[2, :, 1:, :-1] = vals[2]
        padded_vals[3, :, 1:, 1:] = vals[3]
        # get probs in each surrounding tile
        log_prob_i = dist.log_prob(padded_vals[0] + c)[:, :-1, :-1]
        log_prob_j = dist.log_prob(padded_vals[1] + c)[:, :-1, 1:]
        log_prob_k = dist.log_prob(padded_vals[2] + c)[:, 1:, :-1]
        log_prob_l = dist.log_prob(padded_vals[3] + c)[:, 1:, 1:]

        # evaluate prob using logsumexp for stability
        log_probs = torch.stack((log_prob_i, log_prob_j, log_prob_k, log_prob_l), dim=0)
        log_probs += torch.log(aux_vars)
        prob = -torch.logsumexp(log_probs, dim=0)

        # construct loss array and add values to appropriate regions
        loss = torch.zeros(cat.batch_size, cat.n_rows, cat.n_cols, device=cat.device)
        loss[:, 1::2, 1::2] = prob
        return loss * mask

    def _get_loss_corner(self, pred: Dict[str, Distribution], cat: RegionCatalog):
        loss, loss_components = 0, {}
        on_mask = cat.corner_mask * (cat.n_sources > 0)
        aux_vars = self._get_aux_corner(pred, cat)

        # location loss
        locs = self._get_corner_param(cat, "locs")
        locs_loss = self._get_param_loss_corner(pred["loc"], locs, cat, aux_vars, on_mask)
        loss += locs_loss
        loss_components["locs_loss"] = self._average_loss(locs_loss, on_mask)

        # star/galaxy classification loss
        gal_bools = self._get_corner_param(cat, "galaxy_bools")
        binary_loss = self._get_param_loss_corner(
            pred["galaxy_prob"], gal_bools, cat, aux_vars, on_mask
        )
        loss += binary_loss
        loss_components["binary_loss"] = self._average_loss(binary_loss, on_mask)

        # flux losses
        star_fluxes = self._get_corner_param(cat, "star_fluxes")
        galaxy_fluxes = self._get_corner_param(cat, "galaxy_fluxes")
        star_mask = on_mask * cat.star_bools[..., 0, 0]
        gal_mask = on_mask * cat.galaxy_bools[..., 0, 0]

        for i, (star_name, gal_name) in enumerate(zip(self.STAR_FLUX_NAMES, self.GAL_FLUX_NAMES)):
            if i not in self.bands:  # only compute loss over bands we're using
                continue
            # star flux loss
            star_flux_loss = self._get_param_loss_corner(
                pred[star_name], star_fluxes[..., i], cat, aux_vars, star_mask
            )
            loss += star_flux_loss
            loss_components[star_name] = self._average_loss(star_flux_loss, star_mask)

            # galaxy flux loss
            galaxy_flux_loss = self._get_param_loss_corner(
                pred[gal_name], galaxy_fluxes[..., i], cat, aux_vars, gal_mask
            )
            loss += galaxy_flux_loss
            loss_components[gal_name] = self._average_loss(galaxy_flux_loss, gal_mask)

        # galaxy properties loss
        galaxy_params = self._get_corner_param(cat, "galaxy_params")
        for i, param_name in enumerate(self.GALSIM_NAMES):
            galsim_pn = f"galsim_{param_name}"
            gal_param_loss = self._get_param_loss_corner(
                pred[galsim_pn], galaxy_params[..., i], cat, aux_vars, gal_mask
            )
            loss += gal_param_loss
            loss_components[galsim_pn] = self._average_loss(gal_param_loss, gal_mask)

        loss_components["loss_by_region"] = loss
        return loss_components

    def _get_loss(
        self, pred: Dict[str, Distribution], true_cat: RegionCatalog
    ):  # pylint: disable=arguments-renamed
        """Compute loss over the catalog."""

        # evaluate counter loss over all tiles together
        n_sources = torch.nn.functional.unfold(
            true_cat.n_sources.unsqueeze(1), kernel_size=(3, 3), padding=1, stride=2
        ).sum(axis=1)
        n_sources = n_sources.reshape(true_cat.batch_size, true_cat.nth, true_cat.ntw)
        counter_loss = -pred["on_prob"].log_prob(n_sources)

        # interior
        loss_interior = self._get_loss_interior(pred, true_cat)

        # vertical boundary
        loss_v_boundary = self._get_loss_boundary(pred, true_cat, RegionType.BOUNDARY_VERTICAL)

        # horizontal boundary
        loss_h_boundary = self._get_loss_boundary(pred, true_cat, RegionType.BOUNDARY_HORIZONTAL)

        # corners
        loss_corner = self._get_loss_corner(pred, true_cat)

        # sum loss for all regions
        loss_dict = {
            key: val + loss_v_boundary[key] + loss_h_boundary[key] + loss_corner[key]
            for key, val in loss_interior.items()
        }
        loss_dict["counter_loss"] = counter_loss.mean()

        loss_by_region = loss_dict.pop("loss_by_region")
        loss_by_region[:, ::2, ::2] += counter_loss
        loss_dict["loss"] = loss_by_region.mean()
        return loss_dict

    # endregion

    # region Lightning Functions
    def _generic_step(self, batch, logging_name, log_metrics=False, plot_images=False):
        batch_size = batch["images"].size(0)
        x_cat_marginal, _ = self.get_marginal(batch)
        pred = self.get_predicted_dist(x_cat_marginal)
        true_cat = RegionCatalog(
            interior_slen=self.tile_slen - self.overlap_slen,
            overlap_slen=self.overlap_slen,
            d=batch["tile_catalog"],
        )

        # log all losses
        loss_dict = self._get_loss(pred, true_cat)
        for k, v in loss_dict.items():
            self.log("{}/{}".format(logging_name, k), v, batch_size=batch_size)

        if log_metrics or plot_images:
            est_full_cat = self.variational_mode(pred, return_full=True)

        # log all metrics
        if log_metrics:
            metrics = self.metrics(true_cat.to_full_catalog(), est_full_cat)
            for k, v in metrics.items():
                self.log("{}/{}".format(logging_name, k), v, batch_size=batch_size)

        # log a grid of figures to the tensorboard
        if plot_images:
            batch_size = len(batch["images"])
            n_samples = min(int(math.sqrt(batch_size)) ** 2, 4)
            nrows = int(n_samples**0.5)  # for figure

            target_full_cat = true_cat.to_full_catalog()
            idx = est_full_cat.n_sources.nonzero().view(-1)[:n_samples]

            margin_px = self.tiles_to_crop * self.tile_slen
            fig = plot_detections(  # pylint: disable=E1124
                batch["images"].squeeze(2),  # squeeze out extra dim
                target_full_cat,
                est_full_cat,
                nrows,
                idx,
                margin_px,
                ticks=true_cat.get_region_coords().reshape(-1, 2),
            )
            title_root = f"Epoch:{self.current_epoch}/"
            title = f"{title_root}{logging_name} images"
            if self.logger:
                self.logger.experiment.add_figure(title, fig)
            plt.close(fig)

        return loss_dict["loss"]

    # endregion
