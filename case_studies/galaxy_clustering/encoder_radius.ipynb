{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test(\n",
      "  (conv1): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout25): Dropout(p=0.25, inplace=False)\n",
      "  (dropout50): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=73728, out_features=512, bias=True)\n",
      "  (bn_fc): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(test, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, padding=1)  # Changed from 3 to 4 channels\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.dropout25 = nn.Dropout(0.25)\n",
    "        self.dropout50 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        # Calculate the correct input size\n",
    "        self.fc1_input_size = self._get_conv_output_size((4, 400, 400))\n",
    "        self.fc1 = nn.Linear(self.fc1_input_size, 512)  # Adjusted dynamically\n",
    "        self.bn_fc = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        \n",
    "    def _forward_features(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout25(x)\n",
    "        \n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.dropout25(x)\n",
    "        \n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.dropout50(x)\n",
    "\n",
    "        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n",
    "        x = self.dropout50(x)\n",
    "        return x\n",
    "\n",
    "    def _get_conv_output_size(self, input_size):\n",
    "        with torch.no_grad():\n",
    "            input = torch.rand(1, *input_size)\n",
    "            output = self._forward_features(input)\n",
    "            return output.data.view(1, -1).size(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.bn_fc(self.fc1(x)))\n",
    "        x = self.dropout50(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = test()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(folder_paths=[\"data/\", \"data2/\", \"data3/\"], batch_size=32, image_size=(400, 400)):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Converts to torch.Tensor and scales to [0, 1]\n",
    "        transforms.Resize(image_size),  # Resize the image\n",
    "    ])\n",
    "\n",
    "    # Create a list of all possible image paths\n",
    "    all_files = []\n",
    "    for folder_path in folder_paths:\n",
    "        for i in range(len(os.listdir(folder_path))//2):  # Assuming each folder has 4000 images\n",
    "            image_path = os.path.join(folder_path, f\"{i}.png\")\n",
    "            if os.path.exists(image_path):  # Ensure the file exists\n",
    "                all_files.append((folder_path, i))\n",
    "\n",
    "    # Shuffle the list to randomize the order of files\n",
    "    np.random.shuffle(all_files)\n",
    "\n",
    "    images, labels = [], []\n",
    "    for folder_path, i in all_files:\n",
    "        image_path = os.path.join(folder_path, f\"{i}.png\")\n",
    "        # Load and preprocess the image\n",
    "        image = Image.open(image_path)\n",
    "        tensor_image = transform(image)\n",
    "\n",
    "        with open(os.path.join(folder_path, f\"{i}_catalog.pkl\"), \"rb\") as f:\n",
    "            info = pickle.load(f)\n",
    "        if info[\"exist\"]:\n",
    "            labels.append(info[\"radius\"]/1000)\n",
    "            images.append(tensor_image)\n",
    "        if len(images) == batch_size:\n",
    "            yield torch.stack(images), (labels)\n",
    "            images, labels = [], []  # Reset for next batch\n",
    "\n",
    "    # Yield any remaining data as the last batch\n",
    "    if images:\n",
    "        yield torch.stack(images), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "criterion = torch.nn.L1Loss()\n",
    "\n",
    "# Specify the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example of using the generator to train the model\n",
    "num_epochs = 10  # Specify the number of epochs\n",
    "batch_size = 32\n",
    "loss_function = torch.nn.GaussianNLLLoss(eps=1e-02, # Epsilon for numerical stability\n",
    "                                full=False, # Computes the necessary terms AND the constants\n",
    "                                reduction=\"mean\" # Alternative is 'sum' or 'none'\n",
    "                                )\n",
    "model.train()  # Set the model to training mode\n",
    "\n",
    "for epoch in range(200):\n",
    "    count = 0\n",
    "    for input, output in data_generator():\n",
    "        count += 1\n",
    "        # Reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        # Compute and print loss\n",
    "        nn_output = model(input)\n",
    "        # loss = criterion(nn_output[:, 0], torch.tensor(output))\n",
    "        loss = criterion(nn_output[:, 0], target = torch.FloatTensor(output))\n",
    "        # loss += criterion(nn_output[:, 1], target = torch.tensor([coord[1][0] for coord in output]))\n",
    "        # loss += criterion(nn_output[:, 2], target = torch.tensor([coord[1][1] for coord in output]))\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "        if count % 5 == 0:\n",
    "            print(nn_output) \n",
    "            # print(criterion(nn_output[:, 0], torch.tensor([radius[0] for radius in output])))\n",
    "            # print(criterion(nn_output[:, 1], target = torch.tensor([coord[1][0] for coord in output])))\n",
    "            # print(criterion(nn_output[:, 2], target = torch.tensor([coord[1][1] for coord in output])))\n",
    "        # Perform a backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shihangl/bliss/.venv/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GaussianMixture from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from prior import Cluster_Prior\n",
    "a = Cluster_Prior()\n",
    "b,c,d, e = a.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[642.4241922656728]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RA</th>\n",
       "      <th>DEC</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>FLUX_R</th>\n",
       "      <th>MAG_R</th>\n",
       "      <th>FLUX_G</th>\n",
       "      <th>MAG_G</th>\n",
       "      <th>FLUX_I</th>\n",
       "      <th>MAG_I</th>\n",
       "      <th>FLUX_Z</th>\n",
       "      <th>MAG_Z</th>\n",
       "      <th>TSIZE</th>\n",
       "      <th>FRACDEV</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.677746</td>\n",
       "      <td>-40.355881</td>\n",
       "      <td>3086.015550</td>\n",
       "      <td>212.598034</td>\n",
       "      <td>1283.348802</td>\n",
       "      <td>22.229138</td>\n",
       "      <td>2885.294697</td>\n",
       "      <td>21.349525</td>\n",
       "      <td>1923.878254</td>\n",
       "      <td>21.789556</td>\n",
       "      <td>4716.652370</td>\n",
       "      <td>20.815915</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.098658</td>\n",
       "      <td>0.043308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.755407</td>\n",
       "      <td>-40.153325</td>\n",
       "      <td>4483.908719</td>\n",
       "      <td>3858.612651</td>\n",
       "      <td>386.762279</td>\n",
       "      <td>23.531390</td>\n",
       "      <td>976.449015</td>\n",
       "      <td>22.525876</td>\n",
       "      <td>600.982220</td>\n",
       "      <td>23.052846</td>\n",
       "      <td>1269.803800</td>\n",
       "      <td>22.240658</td>\n",
       "      <td>0.057785</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-0.008109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.688501</td>\n",
       "      <td>-40.355789</td>\n",
       "      <td>3279.601115</td>\n",
       "      <td>214.258288</td>\n",
       "      <td>294.421447</td>\n",
       "      <td>23.827576</td>\n",
       "      <td>636.363570</td>\n",
       "      <td>22.990737</td>\n",
       "      <td>348.677576</td>\n",
       "      <td>23.643940</td>\n",
       "      <td>526.722146</td>\n",
       "      <td>23.196046</td>\n",
       "      <td>0.054367</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012169</td>\n",
       "      <td>0.280610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.684779</td>\n",
       "      <td>-40.242423</td>\n",
       "      <td>3212.595450</td>\n",
       "      <td>2254.838651</td>\n",
       "      <td>5577.480354</td>\n",
       "      <td>20.633905</td>\n",
       "      <td>11332.807816</td>\n",
       "      <td>19.864156</td>\n",
       "      <td>7094.901914</td>\n",
       "      <td>20.372634</td>\n",
       "      <td>12554.064544</td>\n",
       "      <td>19.753039</td>\n",
       "      <td>0.248012</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.036537</td>\n",
       "      <td>0.187369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.549119</td>\n",
       "      <td>-40.326868</td>\n",
       "      <td>770.724803</td>\n",
       "      <td>734.832462</td>\n",
       "      <td>10082.936263</td>\n",
       "      <td>19.991032</td>\n",
       "      <td>22420.687888</td>\n",
       "      <td>19.123378</td>\n",
       "      <td>15396.111780</td>\n",
       "      <td>19.531472</td>\n",
       "      <td>29506.786753</td>\n",
       "      <td>18.825195</td>\n",
       "      <td>0.410116</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>-0.026597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>50.565427</td>\n",
       "      <td>-40.120810</td>\n",
       "      <td>1064.272367</td>\n",
       "      <td>4443.874843</td>\n",
       "      <td>164.804525</td>\n",
       "      <td>24.457577</td>\n",
       "      <td>187.332807</td>\n",
       "      <td>24.318465</td>\n",
       "      <td>125.315150</td>\n",
       "      <td>24.754991</td>\n",
       "      <td>196.807144</td>\n",
       "      <td>24.264898</td>\n",
       "      <td>0.049568</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.019087</td>\n",
       "      <td>0.039652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>50.705242</td>\n",
       "      <td>-40.337862</td>\n",
       "      <td>3580.941424</td>\n",
       "      <td>536.936316</td>\n",
       "      <td>153.599403</td>\n",
       "      <td>24.534026</td>\n",
       "      <td>159.447912</td>\n",
       "      <td>24.493453</td>\n",
       "      <td>64.339631</td>\n",
       "      <td>25.478804</td>\n",
       "      <td>193.288746</td>\n",
       "      <td>24.284484</td>\n",
       "      <td>0.049153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.098165</td>\n",
       "      <td>0.160761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>50.601854</td>\n",
       "      <td>-40.093381</td>\n",
       "      <td>1719.947737</td>\n",
       "      <td>4937.591103</td>\n",
       "      <td>141.017299</td>\n",
       "      <td>24.626819</td>\n",
       "      <td>146.421307</td>\n",
       "      <td>24.585989</td>\n",
       "      <td>150.451484</td>\n",
       "      <td>24.556509</td>\n",
       "      <td>380.551095</td>\n",
       "      <td>23.548968</td>\n",
       "      <td>0.048687</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.433719</td>\n",
       "      <td>-0.027065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>50.751544</td>\n",
       "      <td>-40.347956</td>\n",
       "      <td>4414.376771</td>\n",
       "      <td>355.239779</td>\n",
       "      <td>249.249191</td>\n",
       "      <td>24.008416</td>\n",
       "      <td>369.237856</td>\n",
       "      <td>23.581734</td>\n",
       "      <td>750.551302</td>\n",
       "      <td>22.811549</td>\n",
       "      <td>1484.788807</td>\n",
       "      <td>22.070838</td>\n",
       "      <td>0.052695</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.054835</td>\n",
       "      <td>-0.031803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>50.636381</td>\n",
       "      <td>-40.170673</td>\n",
       "      <td>2341.434161</td>\n",
       "      <td>3546.333848</td>\n",
       "      <td>296.242534</td>\n",
       "      <td>23.820881</td>\n",
       "      <td>277.525837</td>\n",
       "      <td>23.891741</td>\n",
       "      <td>290.794622</td>\n",
       "      <td>23.841034</td>\n",
       "      <td>547.480138</td>\n",
       "      <td>23.154079</td>\n",
       "      <td>0.054435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.651373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1988 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             RA        DEC            X            Y        FLUX_R      MAG_R  \\\n",
       "0     50.677746 -40.355881  3086.015550   212.598034   1283.348802  22.229138   \n",
       "1     50.755407 -40.153325  4483.908719  3858.612651    386.762279  23.531390   \n",
       "2     50.688501 -40.355789  3279.601115   214.258288    294.421447  23.827576   \n",
       "3     50.684779 -40.242423  3212.595450  2254.838651   5577.480354  20.633905   \n",
       "4     50.549119 -40.326868   770.724803   734.832462  10082.936263  19.991032   \n",
       "...         ...        ...          ...          ...           ...        ...   \n",
       "1983  50.565427 -40.120810  1064.272367  4443.874843    164.804525  24.457577   \n",
       "1984  50.705242 -40.337862  3580.941424   536.936316    153.599403  24.534026   \n",
       "1985  50.601854 -40.093381  1719.947737  4937.591103    141.017299  24.626819   \n",
       "1986  50.751544 -40.347956  4414.376771   355.239779    249.249191  24.008416   \n",
       "1987  50.636381 -40.170673  2341.434161  3546.333848    296.242534  23.820881   \n",
       "\n",
       "            FLUX_G      MAG_G        FLUX_I      MAG_I        FLUX_Z  \\\n",
       "0      2885.294697  21.349525   1923.878254  21.789556   4716.652370   \n",
       "1       976.449015  22.525876    600.982220  23.052846   1269.803800   \n",
       "2       636.363570  22.990737    348.677576  23.643940    526.722146   \n",
       "3     11332.807816  19.864156   7094.901914  20.372634  12554.064544   \n",
       "4     22420.687888  19.123378  15396.111780  19.531472  29506.786753   \n",
       "...            ...        ...           ...        ...           ...   \n",
       "1983    187.332807  24.318465    125.315150  24.754991    196.807144   \n",
       "1984    159.447912  24.493453     64.339631  25.478804    193.288746   \n",
       "1985    146.421307  24.585989    150.451484  24.556509    380.551095   \n",
       "1986    369.237856  23.581734    750.551302  22.811549   1484.788807   \n",
       "1987    277.525837  23.891741    290.794622  23.841034    547.480138   \n",
       "\n",
       "          MAG_Z     TSIZE  FRACDEV        G1        G2  \n",
       "0     20.815915  0.090908        0 -0.098658  0.043308  \n",
       "1     22.240658  0.057785        0  0.001467 -0.008109  \n",
       "2     23.196046  0.054367        0  0.012169  0.280610  \n",
       "3     19.753039  0.248012        0 -0.036537  0.187369  \n",
       "4     18.825195  0.410116        0  0.005558 -0.026597  \n",
       "...         ...       ...      ...       ...       ...  \n",
       "1983  24.264898  0.049568        0 -0.019087  0.039652  \n",
       "1984  24.284484  0.049153        0 -0.098165  0.160761  \n",
       "1985  23.548968  0.048687        0 -0.433719 -0.027065  \n",
       "1986  22.070838  0.052695        0 -0.054835 -0.031803  \n",
       "1987  23.154079  0.054435        0  0.000240  0.651373  \n",
       "\n",
       "[1988 rows x 16 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.953e+03, 1.000e+01, 1.000e+00, 1.000e+00, 2.000e+00, 1.000e+00,\n",
       "        2.000e+00, 0.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([1.07094430e+02, 4.07926974e+04, 8.14783003e+04, 1.22163903e+05,\n",
       "        1.62849506e+05, 2.03535109e+05, 2.44220712e+05, 2.84906315e+05,\n",
       "        3.25591918e+05, 3.66277521e+05, 4.06963124e+05]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(b[0][\"FLUX_R\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
