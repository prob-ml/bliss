{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from hmf import MassFunction\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.cosmology import WMAP7, FlatLambdaCDM\n",
    "from scipy.constants import G\n",
    "import pickle\n",
    "import fitsio as fio\n",
    "import images\n",
    "from scipy.stats import lognorm, gennorm\n",
    "import tutorial.synthetic.tools as tools\n",
    "import tutorial.synthetic.render.frame as frame\n",
    "import tutorial.synthetic.render.render as render\n",
    "# File directory: inside galaxy clustering. Within same folder as gal_gg_nmgy.pkl/\n",
    "# Has a tutorial folder with synthetic in. If following my tutorial you only need to paste gal_gmm_nmgy.pkl or modify the path to there.\n",
    "size = 1000\n",
    "width = 5000\n",
    "height = 5000\n",
    "mean_sources = 0.005\n",
    "flux_min = 500\n",
    "flux_max = 350000\n",
    "galaxy_flux_alpha = 0.48\n",
    "t_min = 0.15\n",
    "t_max = 5\n",
    "t_alpha = 3\n",
    "shape_min = 0.01\n",
    "shape_max = 0.7\n",
    "shape_alpha = 0.2\n",
    "bands = [\"G\", \"R\", \"I\", \"Z\"]\n",
    "n_bands = 4\n",
    "reference_band = 1\n",
    "ra_cen = 50.64516228577292\n",
    "dec_cen = -40.228830895890404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample mass\n",
    "mass_min = 10**14 * 1.989*10**33 # Minimum value of the range solar mass\n",
    "mass_max = 10**15.5 * 1.989*10**33 # Maximum value of the range\n",
    "hmf = MassFunction()\n",
    "hmf.update(Mmin=14, Mmax = 15.5) \n",
    "mass_func = hmf.dndlnm\n",
    "mass_sample = []\n",
    "while(len(mass_sample) < size):\n",
    "    index = np.random.randint(0, len(mass_func))\n",
    "    prob = (mass_func/sum(mass_func))[index]\n",
    "    if np.random.random() < prob:\n",
    "        mass_sample.append((mass_max-mass_min)/len(mass_func)*(index+np.random.random()) + mass_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample redshift\n",
    "redshift_samples = np.random.uniform(0.2, 0.5, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate individual zis\n",
    "def zi_based_Z(z, mass, size):\n",
    "    delta = (WMAP7.H(z).value/100*mass/(10**15*1.989*10**33))**(1/3)*1082.9\n",
    "    # light speed \n",
    "    c = 899377.37\n",
    "    speed_mean = (c*(1+z)**2 - c)/((1+z)**2 + 1)\n",
    "    temp = np.random.normal(speed_mean, delta, size)\n",
    "    temp = [max(0, np.sqrt((c+x)/(c-x)) - 1) for x in temp]\n",
    "    return temp\n",
    "\n",
    "# Calculate radius based on mass and redshift\n",
    "def R_based_Z_M(mass, z):\n",
    "    pho_z = WMAP7.critical_density(z).value\n",
    "    return (mass/(4/3*np.pi*pho_z))**(1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get radius based on mass and redshift in cm.\n",
    "radius_samples = []\n",
    "for i in range(size):\n",
    "    radius_samples.append(R_based_Z_M(mass_sample[i], redshift_samples[i])/(3.086*10**24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine # of galaxies\n",
    "n_galaxy_cluster = []\n",
    "for i in range(size):\n",
    "    n_galaxy_cluster.append(int(((mass_sample[i]/(1.989*10**33))/(2*10**13))**(1/1.2)*20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample center\n",
    "center_sample = []\n",
    "x_coords = np.random.uniform(width * 0.3, width * 0.7, size)\n",
    "y_coords = np.random.uniform(height * 0.3, height * 0.7, size)\n",
    "center_sample = np.vstack((x_coords, y_coords)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pixels_per_au = 100  \n",
    "radius_samples = [x*scale_pixels_per_au for x in radius_samples]  \n",
    "\n",
    "galaxy_locs_cluster = []\n",
    "for i in range(size):\n",
    "    center_x, center_y = center_sample[i]\n",
    "    samples = []\n",
    "    while(len(samples) < int(n_galaxy_cluster[i])):\n",
    "        angles = np.random.uniform(0, 2 * np.pi, 1)\n",
    "        radii = np.random.uniform(0, radius_samples[i], 1)  \n",
    "        sampled_x = float(center_x + radii * np.cos(angles))  \n",
    "        sampled_y = float(center_y + radii * np.sin(angles))\n",
    "        if sampled_x >= 0 and sampled_x < width and sampled_y >= 0 and sampled_y < height:\n",
    "            samples.append([sampled_x, sampled_y])\n",
    "    while(len(samples) < 1.5*int(n_galaxy_cluster[i])):\n",
    "        angles = np.random.uniform(0, 2 * np.pi, 1)\n",
    "        radii = np.random.uniform(radius_samples[i] + 0.001, 2*radius_samples[i], 1)  \n",
    "        sampled_x = float(center_x + radii * np.cos(angles))  \n",
    "        sampled_y = float(center_y + radii * np.sin(angles))\n",
    "        if sampled_x >= 0 and sampled_x < width and sampled_y >= 0 and sampled_y < height and np.random.random() > (((sampled_x - center_x)**2 + (sampled_y - center_y)**2)**0.5 - radius_samples[i])/radius_samples[i]:\n",
    "            samples.append([sampled_x, sampled_y])\n",
    "    galaxy_locs_cluster.append(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_galaxy = np.random.poisson(mean_sources*width*height/36, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(size):\n",
    "    n_galaxy[i] -= n_galaxy_cluster[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxy_locs = []\n",
    "for i in range(size):\n",
    "    x = np.random.uniform(0, width, n_galaxy[i])\n",
    "    y = np.random.uniform(0, height, n_galaxy[i])\n",
    "    galaxy_locs.append(np.column_stack((x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian2geo(coordinates, sky_center=(ra_cen, dec_cen), pixel_scale=0.2, image_offset=(2499.5, 2499.5)):\n",
    "    geo_coordinates = []\n",
    "    for i in range(len(coordinates)):\n",
    "        temp = []\n",
    "        for j in range(len(coordinates[i])):\n",
    "            ra = (coordinates[i][j][0] - image_offset[0])*pixel_scale / (60*60) + sky_center[0]\n",
    "            desc = (coordinates[i][j][1] - image_offset[1])*pixel_scale / (60*60) + sky_center[1]\n",
    "            temp.append((ra, desc))\n",
    "        geo_coordinates.append(temp)\n",
    "    return geo_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_galaxy = cartesian2geo(galaxy_locs)\n",
    "geo_galaxy_cluster = cartesian2geo(galaxy_locs_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_truncated_pareto(alpha, min_x, max_x, n_samples):\n",
    "    # draw pareto conditioned on being less than f_max\n",
    "    u_max = 1 - (min_x / max_x) ** alpha\n",
    "    uniform_samples = np.random.random(int(n_samples)) * u_max\n",
    "    return min_x / (1.0 - uniform_samples) ** (1 / alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_size_samples = []\n",
    "flux_samples = []\n",
    "for i in range(size):\n",
    "    total_element = len(galaxy_locs[i]) + len(galaxy_locs_cluster[i])\n",
    "    t_size_samples.append(lognorm.rvs(s=0.64, loc=0.017, scale=0.23, size=total_element))\n",
    "    mag_samples = 25 - np.random.exponential(1.3, total_element)\n",
    "    for j in range(len(mag_samples)):\n",
    "        while(mag_samples[j] < 15.75):\n",
    "            mag_samples[j] = (25 - np.random.exponential(1.3, 1))[0]\n",
    "        mag_samples[j] = tools.toflux(mag_samples[j])\n",
    "        if j <= len(galaxy_locs_cluster[i]):\n",
    "            mag_samples[j] *= (1+zi_based_Z(redshift_samples[i], mass_sample[i], 1)[0])\n",
    "        else:\n",
    "            mag_samples[j] *= (1+np.random.uniform(0, 0.3))\n",
    "    flux_samples.append(mag_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1_size_samples = []\n",
    "G2_size_samples = []\n",
    "for i in range(size):\n",
    "    total_element = len(galaxy_locs[i]) + len(galaxy_locs_cluster[i])\n",
    "    G1_size_samples.append(gennorm.rvs(0.6, 0, 0.035, total_element))\n",
    "    G2_size_samples.append(gennorm.rvs(0.6, 0, 0.032, total_element))\n",
    "    for j in range(total_element):\n",
    "        while G1_size_samples[i][j]**2 + G2_size_samples[i][j]**2 >= 1 or G1_size_samples[i][j] >= 0.8 or G2_size_samples[i][j] >= 0.8:\n",
    "            G1_size_samples[i][j] = gennorm.rvs(0.6, 0, 0.035, 1)[0]\n",
    "            G2_size_samples[i][j] = gennorm.rvs(0.6, 0, 0.032, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shihangl/bliss/.venv/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GaussianMixture from version 1.2.1 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# This gives [\"u\", \"g\", \"r\", \"i\", \"z\"] \n",
    "with open(\"gal_gmm_nmgy.pkl\", \"rb\") as f:\n",
    "    gmm_gal = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def galaxy_flux_ratio(size, gmm_gal):\n",
    "    # [\"G\", \"R\", \"I\", \"Z\"]\n",
    "    flux_logdiff, _ = gmm_gal.sample(size)\n",
    "    flux_logdiff = flux_logdiff[:][:, 1:]\n",
    "    flux_logdiff = np.clip(flux_logdiff, -2.76, 2.76)        \n",
    "    flux_ratio = np.exp(flux_logdiff)\n",
    "    flux_prop = np.ones((flux_logdiff.shape[0], n_bands))\n",
    "    for band in range(reference_band - 1, -1, -1):\n",
    "        flux_prop[:, band] = flux_prop[:, band + 1] / flux_ratio[:, band]\n",
    "    for band in range(reference_band + 1, n_bands):\n",
    "        flux_prop[:, band] = flux_prop[:, band - 1] * flux_ratio[:, band - 1]\n",
    "    return flux_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux2mag(flux, constant=29.5):\n",
    "    return -2.5*np.log10(flux) + constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_catalog(gmm_gal, flux_samples, t_size_samples, G1_size_samples, G2_size_samples,geo_galaxy, geo_galaxy_cluster, galaxy_locs, galaxy_locs_cluster):\n",
    "    res = []\n",
    "    for i in range(len(flux_samples)):\n",
    "        ratios = galaxy_flux_ratio(len(geo_galaxy_cluster[i]) + len(geo_galaxy[i]), gmm_gal)\n",
    "        fluxes = np.array(flux_samples[i])[:, np.newaxis] * np.array(ratios)\n",
    "        mock_catalog = pd.DataFrame()\n",
    "        mock_catalog[\"RA\"] = np.append(np.array(geo_galaxy_cluster[i])[:, 0], np.array(geo_galaxy[i])[:, 0])\n",
    "        mock_catalog[\"DEC\"] = np.append(np.array(geo_galaxy_cluster[i])[:, 1], np.array(geo_galaxy[i])[:, 1])\n",
    "        mock_catalog[\"X\"] = np.append(np.array(galaxy_locs[i])[:, 0], np.array(galaxy_locs_cluster[i])[:, 0])\n",
    "        mock_catalog[\"Y\"] = np.append(np.array(galaxy_locs[i])[:, 1], np.array(galaxy_locs_cluster[i])[:, 1])\n",
    "        mock_catalog[\"FLUX_R\"] = fluxes[:, 1]\n",
    "        mock_catalog[\"MAG_R\"] = -2.5*np.log10(mock_catalog[\"FLUX_R\"]) + 30\n",
    "        mock_catalog[\"FLUX_G\"] = fluxes[:, 0]\n",
    "        mock_catalog[\"MAG_G\"] = -2.5*np.log10(mock_catalog[\"FLUX_G\"]) + 30\n",
    "        mock_catalog[\"FLUX_I\"] = fluxes[:, 2]\n",
    "        mock_catalog[\"MAG_I\"] = -2.5*np.log10(mock_catalog[\"FLUX_I\"]) + 30\n",
    "        mock_catalog[\"FLUX_Z\"] = fluxes[:, 3]\n",
    "        mock_catalog[\"MAG_Z\"] = -2.5*np.log10(mock_catalog[\"FLUX_Z\"]) + 30\n",
    "        mock_catalog[\"TSIZE\"] = t_size_samples[i]\n",
    "        mock_catalog[\"FRACDEV\"] = 0\n",
    "        mock_catalog[\"G1\"] = G1_size_samples[i]\n",
    "        mock_catalog[\"G2\"] = G2_size_samples[i]\n",
    "        res.append(mock_catalog)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = make_catalog(gmm_gal, flux_samples, t_size_samples, G1_size_samples, G2_size_samples,geo_galaxy, geo_galaxy_cluster, galaxy_locs, galaxy_locs_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name_tag = 'test_canvas_dc2_' #\n",
    "# # Pick one you want to see\n",
    "# index = 1\n",
    "# mock_catalog = res[index]\n",
    "# stds = np.array([2.509813, 5.192254, 8.36335, 15.220351]) / 1.3\n",
    "# for i, band in enumerate((\"g\", \"r\", \"i\")):\n",
    "#     name =  file_name_tag + band\n",
    "#     print(name)\n",
    "#     fr = frame.Frame(mock_catalog.to_records(), band=band, name=name,\n",
    "#                      center=(ra_cen, dec_cen), noise_std=stds[i], canvas_size=5000, )\n",
    "#     fr.render(nprocess=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ims_all = []\n",
    "# for i, band in enumerate((\"g\", \"r\", \"i\")):\n",
    "#     name = file_name_tag + band + \".fits\"\n",
    "#     tmp = fio.read(name)\n",
    "#     print(name)\n",
    "#     ims_all.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(12, 12))\n",
    "# ax = fig.add_subplot(111)\n",
    "# factor = 0.001\n",
    "# scales = np.array([1., 1.2, 2.5]) * factor\n",
    "# nonlinear = 0.12\n",
    "# clip = 0\n",
    "\n",
    "# pad = 0\n",
    "# obs_im = images.get_color_image(ims_all[2],\n",
    "#                                 ims_all[1],\n",
    "#                                 ims_all[0],\n",
    "#                                 nonlinear=nonlinear, clip=clip, scales=scales)  \n",
    "# print(obs_im.max())\n",
    "# ax.imshow(obs_im * 2, origin='upper')\n",
    "# ax.plot(center_sample[index][0], center_sample[index][1], 'rx', markersize=10, markeredgewidth=2)\n",
    "# # ax.set_title(\"cluster + field rendered together\")\n",
    "\n",
    "# ax.set_xlabel(\"X [pix]\")\n",
    "# ax.set_ylabel(\"Y [pix]\")\n",
    "# fig.savefig(\"test.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_width = 25\n",
    "tiles_height = 25\n",
    "def to_tiles(tiles_height, tiles_width, center_sample, mass_sample, width, height):\n",
    "     tiles = []\n",
    "     for i in range(len(mass_sample)):\n",
    "          tiles_X = width // tiles_width\n",
    "          tiles_Y = height // tiles_height\n",
    "          x_index = int(center_sample[i][0] // tiles_width)\n",
    "          y_index = int(center_sample[i][1] // tiles_height)\n",
    "          cluster_grid = [[0 for _ in range(tiles_X)] for _ in range(tiles_Y)]\n",
    "          cluster_grid[x_index][y_index] = 1\n",
    "          mass_grid = [[0 for _ in range(tiles_X)] for _ in range(tiles_Y)]\n",
    "          mass_grid[x_index][y_index] = mass_sample[i]\n",
    "          coordinate_grid = [[(0, 0) for _ in range(tiles_X)] for _ in range(tiles_Y)]\n",
    "          coordinate_grid[x_index][y_index] = (center_sample[i][0]%tiles_width, center_sample[i][1]%tiles_height)\n",
    "          temp = {}\n",
    "          temp[\"mass\"] = mass_grid\n",
    "          temp[\"coordinate\"] = coordinate_grid\n",
    "          temp[\"cluster\"] = cluster_grid\n",
    "          tiles.append(temp)\n",
    "     return tiles\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = to_tiles(tiles_height, tiles_width, center_sample, mass_sample, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import os\n",
    "def catalog_render(catalogs, start_index, tiles):\n",
    "    print(str(start_index) + \" has begun.\")\n",
    "    for i in range(len(catalogs)):\n",
    "        mock_catalog = catalogs[i]\n",
    "        stds = np.array([2.509813, 5.192254, 8.36335, 15.220351]) / 1.3\n",
    "        file_name_tag = str(i+start_index)\n",
    "        for j, band in enumerate((\"g\", \"r\", \"i\")):\n",
    "            name =  file_name_tag + \"_\"+ band\n",
    "            print(name)\n",
    "            fr = frame.Frame(mock_catalog.to_records(), band=band, name=name,\n",
    "                            center=(ra_cen, dec_cen), noise_std=stds[j], canvas_size=5000, )\n",
    "            fr.render(nprocess=8) \n",
    "        ims_all = []\n",
    "        for j, band in enumerate((\"g\", \"r\", \"i\")):\n",
    "            name = file_name_tag + \"_\" + band + \".fits\"\n",
    "            tmp = fio.read(name)\n",
    "            os.remove(name)\n",
    "            os.remove(file_name_tag + \"_\" + band + \"_epsf.fits\")\n",
    "            ims_all.append(tmp)\n",
    "        fig = plt.figure(figsize=(12, 12))\n",
    "        ax = fig.add_subplot(111)\n",
    "        factor = 0.001\n",
    "        scales = np.array([1., 1.2, 2.5]) * factor\n",
    "        nonlinear = 0.12\n",
    "        clip = 0\n",
    "        obs_im = images.get_color_image(ims_all[2],\n",
    "                                        ims_all[1],\n",
    "                                        ims_all[0],\n",
    "                                        nonlinear=nonlinear, clip=clip, scales=scales)  \n",
    "        print(obs_im.max())\n",
    "        ax.imshow(obs_im * 2, origin='upper')\n",
    "\n",
    "        ax.set_xlabel(\"X [pix]\")\n",
    "        ax.set_ylabel(\"Y [pix]\")\n",
    "        fig.savefig(\"data/\" + file_name_tag + \".png\", bbox_inches='tight')\n",
    "        filehandler = open(\"data/\" + file_name_tag + \"_catalog.pkl\", 'wb') \n",
    "        pickle.dump(tiles[i], filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 has begun.\n",
      "0_g\n",
      "200 has begun.\n",
      "200_g\n",
      "400 has begun.\n",
      "400_g\n",
      "600 has begun.\n",
      "600_g\n",
      "800 has begun.\n",
      "800_g\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting postage stamp calculations in 8 processes\n",
      "starting postage stamp calculations in 8 processes\n",
      "starting postage stamp calculations in 8 processes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting postage stamp calculations in 8 processes\n",
      "starting postage stamp calculations in 8 processes\n",
      "starting postage stamp calculations in 8 processes\n",
      "400_r\n",
      "starting postage stamp calculations in 8 processes\n",
      "600_r\n",
      "starting postage stamp calculations in 8 processes\n",
      "800_r\n",
      "starting postage stamp calculations in 8 processes\n",
      "0_r\n",
      "starting postage stamp calculations in 8 processes\n",
      "200_r\n",
      "starting postage stamp calculations in 8 processes\n",
      "400_i\n",
      "starting postage stamp calculations in 8 processes\n",
      "600_i\n",
      "starting postage stamp calculations in 8 processes\n",
      "800_i\n",
      "starting postage stamp calculations in 8 processes\n",
      "0_i\n",
      "starting postage stamp calculations in 8 processes\n",
      "200_i\n",
      "starting postage stamp calculations in 8 processes\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401_g\n",
      "starting postage stamp calculations in 8 processes\n",
      "401_r\n",
      "starting postage stamp calculations in 8 processes\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    x = threading.Thread(target = catalog_render, args = (res[i*size//5:(i+1)*size//5], i*size//5, tiles[i*size//5:(i+1)*size//5], ))\n",
    "    x.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
