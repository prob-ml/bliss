{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test(\n",
      "  (conv1): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout25): Dropout(p=0.25, inplace=False)\n",
      "  (dropout50): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=73728, out_features=512, bias=True)\n",
      "  (bn_fc): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(test, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, padding=1)  # Changed from 3 to 4 channels\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.dropout25 = nn.Dropout(0.25)\n",
    "        self.dropout50 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        # Calculate the correct input size\n",
    "        self.fc1_input_size = self._get_conv_output_size((4, 400, 400))\n",
    "        self.fc1 = nn.Linear(self.fc1_input_size, 512)  # Adjusted dynamically\n",
    "        self.bn_fc = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 2)\n",
    "        \n",
    "    def _forward_features(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout25(x)\n",
    "        \n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.dropout25(x)\n",
    "        \n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.dropout50(x)\n",
    "\n",
    "        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n",
    "        x = self.dropout50(x)\n",
    "        return x\n",
    "\n",
    "    def _get_conv_output_size(self, input_size):\n",
    "        with torch.no_grad():\n",
    "            input = torch.rand(1, *input_size)\n",
    "            output = self._forward_features(input)\n",
    "            return output.data.view(1, -1).size(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.bn_fc(self.fc1(x)))\n",
    "        x = self.dropout50(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = test()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(folder_paths=[\"data/\", \"data2/\", \"data3/\"], batch_size=32, image_size=(400, 400)):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # Converts to torch.Tensor and scales to [0, 1]\n",
    "        transforms.Resize(image_size)  # Resize the image\n",
    "    ])\n",
    "\n",
    "    # Create a list of all possible image paths\n",
    "    all_files = []\n",
    "    for folder_path in folder_paths:\n",
    "        for i in range(len(os.listdir(folder_path))//2):  # Assuming each folder has 4000 images\n",
    "            image_path = os.path.join(folder_path, f\"{i}.png\")\n",
    "            if os.path.exists(image_path):  # Ensure the file exists\n",
    "                all_files.append((folder_path, i))\n",
    "\n",
    "    # Shuffle the list to randomize the order of files\n",
    "    np.random.shuffle(all_files)\n",
    "\n",
    "    images, labels = [], []\n",
    "    for folder_path, i in all_files:\n",
    "        image_path = os.path.join(folder_path, f\"{i}.png\")\n",
    "        # Load and preprocess the image\n",
    "        image = Image.open(image_path)\n",
    "        tensor_image = transform(image)\n",
    "\n",
    "        with open(os.path.join(folder_path, f\"{i}_catalog.pkl\"), \"rb\") as f:\n",
    "            info = pickle.load(f)\n",
    "        labels.append(info[\"coordinate\"] / 5000)\n",
    "\n",
    "        images.append(tensor_image)\n",
    "        if len(images) == batch_size:\n",
    "            yield torch.stack(images), torch.tensor(labels)\n",
    "            images, labels = [], []  # Reset for next batch\n",
    "\n",
    "    # Yield any remaining data as the last batch\n",
    "    if images:\n",
    "        yield torch.stack(images), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shihangl/bliss/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.37730324275936855\n",
      "Epoch 2, Loss: 0.7934645481768532\n",
      "Epoch 3, Loss: 0.6772873986404292\n",
      "Epoch 4, Loss: 0.522347771760068\n",
      "Epoch 5, Loss: 0.6082483164441004\n",
      "Epoch 6, Loss: 0.613479896047374\n",
      "Epoch 7, Loss: 0.5292009580426058\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[165], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Forward pass: Compute predicted y by passing x to the model\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Compute and print loss\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, torch\u001b[38;5;241m.\u001b[39mtensor(output))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[162], line 59\u001b[0m, in \u001b[0;36mtest.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 59\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     61\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_fc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)))\n",
      "Cell \u001b[0;32mIn[162], line 38\u001b[0m, in \u001b[0;36mtest._forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 38\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)))\n\u001b[1;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))))\n\u001b[1;32m     40\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout25(x)\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "criterion = torch.nn.L1Loss()\n",
    "\n",
    "# Specify the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example of using the generator to train the model\n",
    "num_epochs = 10  # Specify the number of epochs\n",
    "batch_size = 32\n",
    "\n",
    "model.train()  # Set the model to training mode\n",
    "\n",
    "for epoch in range(200):\n",
    "    count = 0\n",
    "    for input, output in data_generator():\n",
    "        count += 1\n",
    "        # Reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        # Compute and print loss\n",
    "        outputs = model(input)\n",
    "        loss = criterion(outputs, torch.tensor(output))\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "        if count % 5 == 0:\n",
    "            print(outputs) \n",
    "        # Perform a backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_images, batch_labels = next(data_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Assuming `image_tensor` is your image tensor\n",
    "# Example: image_tensor = torch.rand(3, 900, 900) # Random image for demonstration\n",
    "\n",
    "# Convert the tensor to a PIL Image\n",
    "to_pil = ToPILImage()\n",
    "def visual(batch_images, labels, prediction):\n",
    "    index = random.randint(0, len(batch_images))\n",
    "    plt.imshow(to_pil(batch_images[index]))\n",
    "    plt.scatter(prediction[index][0]*400, prediction[index][1]*400, color='red', s=100, marker='x', label='Predicated Center')\n",
    "    plt.scatter(labels[index][\"coordinate\"][0]/5000*400, labels[index][\"coordinate\"][1]/5000*400, color='green', s=100, marker='x', label='Real Center')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m visual(\u001b[43mbatch_images\u001b[49m, batch_labels, model(batch_images)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_images' is not defined"
     ]
    }
   ],
   "source": [
    "visual(batch_images, batch_labels, model(batch_images).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be (u, sigma, b1, a1, b2, a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_FAVI(\n",
      "  (conv1): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout25): Dropout(p=0.25, inplace=False)\n",
      "  (dropout50): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=73728, out_features=512, bias=True)\n",
      "  (bn_fc): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class test_FAVI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(test_FAVI, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, padding=1)  # Changed from 3 to 4 channels\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        # Dropout layers\n",
    "        self.dropout25 = nn.Dropout(0.25)\n",
    "        self.dropout50 = nn.Dropout(0.5)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        # Calculate the correct input size\n",
    "        self.fc1_input_size = self._get_conv_output_size((4, 400, 400))\n",
    "        self.fc1 = nn.Linear(self.fc1_input_size, 512)  # Adjusted dynamically\n",
    "        self.bn_fc = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 4)\n",
    "        \n",
    "    def _forward_features(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout25(x)\n",
    "        \n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.dropout25(x)\n",
    "        \n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.dropout50(x)\n",
    "\n",
    "        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n",
    "        x = self.dropout50(x)\n",
    "        return x\n",
    "\n",
    "    def _get_conv_output_size(self, input_size):\n",
    "        with torch.no_grad():\n",
    "            input = torch.rand(1, *input_size)\n",
    "            output = self._forward_features(input)\n",
    "            return output.data.view(1, -1).size(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.bn_fc(self.fc1(x)))\n",
    "        x = self.dropout50(x)\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = test_FAVI()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual(batch_images, labels, prediction):\n",
    "    index = random.randint(0, len(batch_images) - 1)\n",
    "    plt.imshow(to_pil(batch_images[index]))\n",
    "    plt.scatter(prediction[index][0]*400, prediction[index][2]*400, color='red', s=100, marker='x', label='Predicated Center')\n",
    "    plt.scatter(labels[index][0]*400, labels[index][1]*400, color='green', s=100, marker='x', label='Real Center')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: -1.0812200317723528\n",
      "Epoch 1, Loss: -0.9984853083752623\n",
      "Epoch 1, Loss: -1.1791935820206747\n",
      "Epoch 1, Loss: -1.326569698463933\n",
      "Epoch 1, Loss: -1.0054624565649564\n",
      "tensor([[0.0265, 0.0221, 0.4933, 0.3134],\n",
      "        [0.2804, 0.2692, 0.6386, 0.3267],\n",
      "        [0.1749, 0.2666, 0.4697, 0.6783],\n",
      "        [0.6823, 0.3866, 0.4757, 0.2744],\n",
      "        [0.4215, 0.1983, 0.6098, 0.6217],\n",
      "        [0.4784, 0.2525, 0.6961, 0.0619],\n",
      "        [0.4282, 0.0861, 0.7985, 0.1487],\n",
      "        [0.6121, 0.6922, 0.2143, 0.1414],\n",
      "        [0.6209, 0.2943, 0.6542, 0.0813],\n",
      "        [0.3183, 0.0938, 0.4951, 0.0638],\n",
      "        [0.9009, 0.1761, 0.4740, 0.3798],\n",
      "        [0.4596, 0.2745, 0.7327, 0.1136],\n",
      "        [0.7038, 0.0645, 0.6497, 0.0752],\n",
      "        [0.4600, 0.7654, 0.2716, 0.1656],\n",
      "        [0.2839, 0.1427, 0.5180, 0.2098],\n",
      "        [0.5001, 0.2454, 0.8306, 0.1021],\n",
      "        [0.6989, 0.6772, 0.1427, 0.0091],\n",
      "        [0.5140, 0.6270, 0.5035, 0.5341],\n",
      "        [0.5697, 0.1930, 0.7452, 0.1992],\n",
      "        [0.5350, 0.2438, 0.7111, 0.3605],\n",
      "        [0.3678, 0.0441, 0.4631, 0.0349],\n",
      "        [0.8782, 0.5515, 0.7134, 0.1181],\n",
      "        [0.2180, 0.6124, 0.5071, 0.0255],\n",
      "        [0.4162, 0.1206, 0.6450, 0.6536],\n",
      "        [0.7756, 0.1706, 0.8313, 0.7501],\n",
      "        [0.8507, 0.2894, 0.9092, 0.6354],\n",
      "        [0.7558, 0.1774, 0.2481, 0.0702],\n",
      "        [0.5351, 0.0814, 0.4176, 0.1156],\n",
      "        [0.1965, 0.1476, 0.2482, 0.0034],\n",
      "        [0.8225, 0.3560, 0.5268, 0.0468],\n",
      "        [0.6030, 0.0891, 0.1791, 0.1594],\n",
      "        [0.2844, 0.5354, 0.3813, 0.6331]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1605, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3927673/2480257759.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(compare(torch.stack(coordinates), torch.tensor(output)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5556549343791832\n",
      "Epoch 1, Loss: -1.731729518903695\n",
      "Epoch 1, Loss: -1.685470171238377\n",
      "Epoch 1, Loss: -1.628515986913028\n",
      "Epoch 1, Loss: -1.6909663217377138\n",
      "tensor([[0.4586, 0.1593, 0.0974, 0.1701],\n",
      "        [0.4068, 0.2712, 0.7726, 0.7398],\n",
      "        [0.1308, 0.0256, 0.7288, 0.1563],\n",
      "        [0.6843, 0.0498, 0.2279, 0.3012],\n",
      "        [0.4658, 0.0991, 0.8692, 0.1821],\n",
      "        [0.2772, 0.0358, 0.7353, 0.0445],\n",
      "        [0.3252, 0.0437, 0.5975, 0.0719],\n",
      "        [0.6215, 0.1601, 0.4049, 0.3815],\n",
      "        [0.8270, 0.1303, 0.2957, 0.0389],\n",
      "        [0.4288, 0.0776, 0.6686, 0.4082],\n",
      "        [0.6397, 0.1479, 0.7780, 0.4777],\n",
      "        [0.7417, 0.0688, 0.0923, 0.1215],\n",
      "        [0.4483, 0.1536, 0.2799, 0.2557],\n",
      "        [0.4175, 0.1844, 0.8541, 0.1524],\n",
      "        [0.9628, 0.0261, 0.1314, 0.1703],\n",
      "        [0.6590, 0.0876, 0.2200, 0.1755],\n",
      "        [0.5067, 0.6166, 0.0218, 0.0063],\n",
      "        [0.4976, 0.1457, 0.2840, 0.1085],\n",
      "        [0.5991, 0.2518, 0.4334, 0.2248],\n",
      "        [0.0504, 0.1449, 0.8334, 0.0159],\n",
      "        [0.5105, 0.0764, 0.3395, 0.2008],\n",
      "        [0.7441, 0.0185, 0.8397, 0.0172],\n",
      "        [0.5785, 0.0715, 0.3534, 0.0271],\n",
      "        [0.5488, 0.1449, 0.1973, 0.1157],\n",
      "        [0.4310, 0.0948, 0.5155, 0.3359],\n",
      "        [0.5450, 0.0382, 0.8471, 0.0903],\n",
      "        [0.4247, 0.4421, 0.5228, 0.1401],\n",
      "        [0.2343, 0.1397, 0.4648, 0.3867],\n",
      "        [0.3800, 0.0594, 0.4266, 0.0280],\n",
      "        [0.5567, 0.0547, 0.6248, 0.2905],\n",
      "        [0.3337, 0.1737, 0.7081, 0.3145],\n",
      "        [0.7591, 0.0276, 0.8987, 0.0850]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1199, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -1.011102465477172\n",
      "Epoch 1, Loss: -2.082308785277193\n",
      "Epoch 1, Loss: -1.8691735927012225\n",
      "Epoch 1, Loss: -2.035664412571757\n",
      "Epoch 1, Loss: -2.1626596981161543\n",
      "tensor([[0.9592, 0.0822, 0.1014, 0.0142],\n",
      "        [0.5051, 0.1596, 0.6422, 0.2114],\n",
      "        [0.6554, 0.1060, 0.3217, 0.1554],\n",
      "        [0.7254, 0.0807, 0.3839, 0.3421],\n",
      "        [0.5621, 0.1587, 0.5012, 0.2081],\n",
      "        [0.0799, 0.0210, 0.5415, 0.0718],\n",
      "        [0.6133, 0.1512, 0.7726, 0.2023],\n",
      "        [0.8098, 0.0261, 0.7872, 0.0363],\n",
      "        [0.4174, 0.1992, 0.3648, 0.4156],\n",
      "        [0.7344, 0.0282, 0.3824, 0.2935],\n",
      "        [0.8210, 0.0550, 0.1943, 0.1911],\n",
      "        [0.0934, 0.0144, 0.8536, 0.3218],\n",
      "        [0.6498, 0.0068, 0.6938, 0.0264],\n",
      "        [0.3974, 0.0663, 0.3341, 0.1001],\n",
      "        [0.1143, 0.0353, 0.5723, 0.1726],\n",
      "        [0.4837, 0.0623, 0.5443, 0.2081],\n",
      "        [0.3500, 0.1760, 0.1718, 0.3454],\n",
      "        [0.5249, 0.1236, 0.4463, 0.2126],\n",
      "        [0.0886, 0.0894, 0.2833, 0.0727],\n",
      "        [0.5020, 0.0613, 0.8251, 0.1051],\n",
      "        [0.7602, 0.1219, 0.3227, 0.1240],\n",
      "        [0.9234, 0.0310, 0.7261, 0.0276],\n",
      "        [0.2189, 0.0241, 0.6276, 0.0923],\n",
      "        [0.8792, 0.0436, 0.1133, 0.0314],\n",
      "        [0.1944, 0.0146, 0.7990, 0.0490],\n",
      "        [0.4834, 0.0705, 0.1248, 0.1475],\n",
      "        [0.3550, 0.0161, 0.8727, 0.4067],\n",
      "        [0.4194, 0.1459, 0.3844, 0.3124],\n",
      "        [0.4014, 0.1253, 0.2967, 0.2879],\n",
      "        [0.3520, 0.0148, 0.8614, 0.0679],\n",
      "        [0.7054, 0.0503, 0.1800, 0.1685],\n",
      "        [0.6202, 0.0655, 0.7874, 0.0654]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1258, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -1.8847653755793208\n",
      "Epoch 1, Loss: -1.823174538506883\n",
      "Epoch 1, Loss: -1.8770122048280173\n",
      "Epoch 1, Loss: -1.3379707569323984\n",
      "Epoch 1, Loss: -1.5314828558312295\n",
      "tensor([[0.6252, 0.0363, 0.4505, 0.0914],\n",
      "        [0.5286, 0.1028, 0.4382, 0.3988],\n",
      "        [0.4738, 0.0398, 0.3311, 0.0356],\n",
      "        [0.3319, 0.0059, 0.1880, 0.0698],\n",
      "        [0.3935, 0.0230, 0.1518, 0.0865],\n",
      "        [0.6732, 0.1139, 0.6032, 0.2673],\n",
      "        [0.2834, 0.0580, 0.6220, 0.2502],\n",
      "        [0.5806, 0.0847, 0.4793, 0.0320],\n",
      "        [0.1142, 0.0425, 0.2973, 0.0751],\n",
      "        [0.4303, 0.0205, 0.8197, 0.1124],\n",
      "        [0.6039, 0.0230, 0.1672, 0.4229],\n",
      "        [0.5018, 0.0385, 0.6964, 0.1404],\n",
      "        [0.6152, 0.0544, 0.2112, 0.0874],\n",
      "        [0.2496, 0.0891, 0.3056, 0.3198],\n",
      "        [0.8276, 0.0427, 0.5515, 0.1431],\n",
      "        [0.3771, 0.0342, 0.4747, 0.1727],\n",
      "        [0.7002, 0.0195, 0.2384, 0.0395],\n",
      "        [0.4577, 0.0235, 0.6677, 0.0557],\n",
      "        [0.8202, 0.0060, 0.8707, 0.0122],\n",
      "        [0.4034, 0.0875, 0.3314, 0.3539],\n",
      "        [0.6389, 0.0767, 0.2208, 0.1902],\n",
      "        [0.2884, 0.0293, 0.1030, 0.1323],\n",
      "        [0.3009, 0.0350, 0.4100, 0.0117],\n",
      "        [0.7572, 0.0681, 0.3982, 0.1817],\n",
      "        [0.9264, 0.0244, 0.8394, 0.0297],\n",
      "        [0.4132, 0.0119, 0.3836, 0.1328],\n",
      "        [0.2973, 0.0513, 0.6871, 0.1969],\n",
      "        [0.4897, 0.0266, 0.7979, 0.0542],\n",
      "        [0.8783, 0.0017, 0.1148, 0.0225],\n",
      "        [0.3427, 0.1434, 0.7138, 0.3624],\n",
      "        [0.6432, 0.0799, 0.5551, 0.2277],\n",
      "        [0.4718, 0.1182, 0.6662, 0.1555]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1339, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -1.302056839688733\n",
      "Epoch 1, Loss: -1.6618895576426986\n",
      "Epoch 1, Loss: -1.3418185860835077\n",
      "Epoch 1, Loss: -1.3389995365112792\n",
      "Epoch 1, Loss: -2.044338284381463\n",
      "tensor([[0.5445, 0.0704, 0.3397, 0.2243],\n",
      "        [0.5448, 0.0150, 0.2482, 0.1973],\n",
      "        [0.6867, 0.0328, 0.4537, 0.0998],\n",
      "        [0.8971, 0.0033, 0.4020, 0.0070],\n",
      "        [0.7607, 0.0307, 0.2990, 0.2450],\n",
      "        [0.5148, 0.0540, 0.6978, 0.0318],\n",
      "        [0.5177, 0.0158, 0.3743, 0.0175],\n",
      "        [0.1758, 0.0247, 0.2789, 0.2685],\n",
      "        [0.7310, 0.0302, 0.4871, 0.0842],\n",
      "        [0.6054, 0.1175, 0.3159, 0.1578],\n",
      "        [0.7627, 0.2035, 0.6983, 0.0763],\n",
      "        [0.5597, 0.0616, 0.1536, 0.2085],\n",
      "        [0.2115, 0.0699, 0.7451, 0.0685],\n",
      "        [0.7396, 0.0830, 0.6975, 0.1068],\n",
      "        [0.6077, 0.1919, 0.5765, 0.3136],\n",
      "        [0.5280, 0.0679, 0.6251, 0.1411],\n",
      "        [0.4626, 0.1323, 0.4693, 0.0619],\n",
      "        [0.6026, 0.0701, 0.3696, 0.1139],\n",
      "        [0.4565, 0.0286, 0.6571, 0.0221],\n",
      "        [0.3086, 0.1276, 0.4607, 0.1214],\n",
      "        [0.5598, 0.1029, 0.6558, 0.1054],\n",
      "        [0.8399, 0.0112, 0.3068, 0.0409],\n",
      "        [0.1384, 0.0228, 0.0824, 0.0253],\n",
      "        [0.8292, 0.0016, 0.9149, 0.0163],\n",
      "        [0.5409, 0.0959, 0.3026, 0.1005],\n",
      "        [0.5883, 0.0503, 0.6293, 0.0151],\n",
      "        [0.7357, 0.1794, 0.8258, 0.0810],\n",
      "        [0.1788, 0.0498, 0.2628, 0.1007],\n",
      "        [0.2749, 0.0439, 0.2725, 0.3021],\n",
      "        [0.7434, 0.1347, 0.7118, 0.1646],\n",
      "        [0.4337, 0.0054, 0.1770, 0.0565],\n",
      "        [0.6036, 0.0834, 0.1329, 0.2541]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1405, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -1.763932095447085\n",
      "Epoch 1, Loss: -1.828289575863674\n",
      "Epoch 1, Loss: -1.9430235239034888\n",
      "Epoch 1, Loss: -2.1016827648311462\n",
      "Epoch 1, Loss: -1.3144991397571206\n",
      "tensor([[0.5924, 0.4135, 0.7070, 0.1438],\n",
      "        [0.6754, 0.3464, 0.5514, 0.2168],\n",
      "        [0.6895, 0.0825, 0.5329, 0.1786],\n",
      "        [0.2248, 0.0387, 0.6438, 0.0397],\n",
      "        [0.8363, 0.0403, 0.0587, 0.0645],\n",
      "        [0.7320, 0.0453, 0.2635, 0.0473],\n",
      "        [0.6983, 0.0922, 0.8169, 0.0693],\n",
      "        [0.3022, 0.1292, 0.7454, 0.0679],\n",
      "        [0.3783, 0.1739, 0.5118, 0.0674],\n",
      "        [0.1616, 0.0182, 0.1222, 0.0802],\n",
      "        [0.5569, 0.0268, 0.6719, 0.0133],\n",
      "        [0.7406, 0.0244, 0.1208, 0.1320],\n",
      "        [0.5744, 0.2397, 0.7309, 0.1669],\n",
      "        [0.0713, 0.0023, 0.3502, 0.0022],\n",
      "        [0.3876, 0.0351, 0.4040, 0.0473],\n",
      "        [0.6638, 0.0203, 0.2507, 0.0158],\n",
      "        [0.5950, 0.1123, 0.3960, 0.0304],\n",
      "        [0.2964, 0.0083, 0.1338, 0.1593],\n",
      "        [0.5851, 0.3890, 0.6731, 0.2539],\n",
      "        [0.6884, 0.0758, 0.6294, 0.1337],\n",
      "        [0.5961, 0.1225, 0.3133, 0.2410],\n",
      "        [0.4950, 0.0172, 0.4082, 0.0039],\n",
      "        [0.6838, 0.0526, 0.0688, 0.2157],\n",
      "        [0.5170, 0.1869, 0.4705, 0.3075],\n",
      "        [0.5964, 0.3353, 0.7327, 0.0758],\n",
      "        [0.5599, 0.0953, 0.5267, 0.1992],\n",
      "        [0.5620, 0.1587, 0.8633, 0.0228],\n",
      "        [0.7613, 0.0624, 0.8147, 0.0846],\n",
      "        [0.3597, 0.3406, 0.4604, 0.0867],\n",
      "        [0.5362, 0.2185, 0.7259, 0.2690],\n",
      "        [0.7943, 0.2225, 0.6599, 0.0599],\n",
      "        [0.8217, 0.0057, 0.0408, 0.0044]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1545, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.0817614435072294\n",
      "Epoch 1, Loss: -1.7651667421799397\n",
      "Epoch 1, Loss: -2.3117839842286143\n",
      "Epoch 1, Loss: -1.7748104747241045\n",
      "Epoch 1, Loss: -1.938811438943091\n",
      "tensor([[0.7890, 0.0194, 0.6785, 0.0057],\n",
      "        [0.7843, 0.2306, 0.5460, 0.0702],\n",
      "        [0.7939, 0.2246, 0.4891, 0.3339],\n",
      "        [0.2903, 0.0103, 0.2221, 0.1061],\n",
      "        [0.7350, 0.0819, 0.2739, 0.1811],\n",
      "        [0.4064, 0.0245, 0.5252, 0.0327],\n",
      "        [0.7609, 0.0824, 0.3153, 0.0592],\n",
      "        [0.5725, 0.0522, 0.6955, 0.0077],\n",
      "        [0.5869, 0.1668, 0.5083, 0.1422],\n",
      "        [0.3940, 0.0539, 0.5834, 0.0200],\n",
      "        [0.7414, 0.3357, 0.4486, 0.1544],\n",
      "        [0.4026, 0.0158, 0.5473, 0.0329],\n",
      "        [0.4064, 0.1958, 0.7419, 0.0365],\n",
      "        [0.4768, 0.0671, 0.0946, 0.1124],\n",
      "        [0.7413, 0.0743, 0.5014, 0.0185],\n",
      "        [0.7137, 0.2993, 0.7906, 0.1807],\n",
      "        [0.4940, 0.2480, 0.5634, 0.1797],\n",
      "        [0.8542, 0.2847, 0.5383, 0.0098],\n",
      "        [0.4672, 0.0495, 0.0769, 0.0838],\n",
      "        [0.6552, 0.5194, 0.7382, 0.0346],\n",
      "        [0.0616, 0.0405, 0.4260, 0.0644],\n",
      "        [0.7845, 0.0293, 0.5447, 0.0219],\n",
      "        [0.6338, 0.2151, 0.4050, 0.2590],\n",
      "        [0.5685, 0.1367, 0.6275, 0.1760],\n",
      "        [0.6424, 0.3904, 0.7396, 0.0457],\n",
      "        [0.3665, 0.0039, 0.3936, 0.0221],\n",
      "        [0.7863, 0.0731, 0.1217, 0.2369],\n",
      "        [0.5321, 0.1021, 0.3986, 0.1423],\n",
      "        [0.4837, 0.1484, 0.5670, 0.0518],\n",
      "        [0.2907, 0.0957, 0.4070, 0.1136],\n",
      "        [0.5540, 0.1332, 0.2617, 0.4784],\n",
      "        [0.4664, 0.3627, 0.8253, 0.0765]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1373, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.0482498648904466\n",
      "Epoch 1, Loss: -2.242238649282601\n",
      "Epoch 1, Loss: -1.8635348960801772\n",
      "Epoch 1, Loss: -1.6981801157906256\n",
      "Epoch 1, Loss: -1.8893357209535488\n",
      "tensor([[0.6724, 0.2045, 0.6557, 0.0687],\n",
      "        [0.6777, 0.3242, 0.9468, 0.0059],\n",
      "        [0.5518, 0.1674, 0.7108, 0.1366],\n",
      "        [0.0589, 0.0667, 0.3391, 0.0435],\n",
      "        [0.7665, 0.2050, 0.6595, 0.0914],\n",
      "        [0.7306, 0.0808, 0.7608, 0.1155],\n",
      "        [0.3344, 0.1894, 0.4949, 0.1468],\n",
      "        [0.4804, 0.0931, 0.4754, 0.1525],\n",
      "        [0.6639, 0.0029, 0.0313, 0.0063],\n",
      "        [0.7610, 0.2374, 0.4087, 0.0662],\n",
      "        [0.2851, 0.3108, 0.7569, 0.0937],\n",
      "        [0.3222, 0.0605, 0.5023, 0.0384],\n",
      "        [0.1224, 0.0440, 0.2493, 0.0354],\n",
      "        [0.7116, 0.1896, 0.7277, 0.1253],\n",
      "        [0.4831, 0.1876, 0.5211, 0.1845],\n",
      "        [0.4822, 0.1972, 0.5666, 0.1691],\n",
      "        [0.7412, 0.0471, 0.3626, 0.0634],\n",
      "        [0.6448, 0.0902, 0.3081, 0.2006],\n",
      "        [0.5441, 0.2036, 0.6429, 0.0511],\n",
      "        [0.8260, 0.0984, 0.3286, 0.1074],\n",
      "        [0.2653, 0.2147, 0.7006, 0.1246],\n",
      "        [0.8319, 0.0068, 0.2596, 0.0514],\n",
      "        [0.6550, 0.0807, 0.4836, 0.0719],\n",
      "        [0.7844, 0.0676, 0.1055, 0.1500],\n",
      "        [0.6099, 0.0980, 0.6098, 0.0461],\n",
      "        [0.8489, 0.1104, 0.4556, 0.0275],\n",
      "        [0.5377, 0.1002, 0.4774, 0.0878],\n",
      "        [0.1395, 0.1816, 0.5062, 0.0121],\n",
      "        [0.4534, 0.0257, 0.3776, 0.0950],\n",
      "        [0.4685, 0.0495, 0.6589, 0.0158],\n",
      "        [0.5939, 0.0749, 0.3391, 0.1689],\n",
      "        [0.3487, 0.3571, 0.8551, 0.0406]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1168, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -1.8627830772940541\n",
      "Epoch 1, Loss: -1.5054228969938002\n",
      "Epoch 1, Loss: -2.000857735019308\n",
      "Epoch 1, Loss: -2.006040242683552\n",
      "Epoch 1, Loss: -2.2324061520867073\n",
      "tensor([[0.6986, 0.0485, 0.8239, 0.0432],\n",
      "        [0.2883, 0.4160, 0.9236, 0.0245],\n",
      "        [0.8113, 0.0435, 0.7058, 0.0130],\n",
      "        [0.6213, 0.0704, 0.8682, 0.0808],\n",
      "        [0.4925, 0.2453, 0.6543, 0.1195],\n",
      "        [0.1397, 0.1858, 0.3433, 0.0590],\n",
      "        [0.6860, 0.0238, 0.5067, 0.0404],\n",
      "        [0.5324, 0.1059, 0.2066, 0.1091],\n",
      "        [0.8808, 0.0735, 0.6347, 0.0293],\n",
      "        [0.7617, 0.0234, 0.3301, 0.0420],\n",
      "        [0.3981, 0.1190, 0.5286, 0.1409],\n",
      "        [0.2222, 0.1144, 0.4364, 0.1497],\n",
      "        [0.3608, 0.0498, 0.3714, 0.0114],\n",
      "        [0.5081, 0.1762, 0.2731, 0.2149],\n",
      "        [0.8228, 0.0433, 0.2114, 0.0938],\n",
      "        [0.3835, 0.2177, 0.7473, 0.0993],\n",
      "        [0.2943, 0.2465, 0.8029, 0.0491],\n",
      "        [0.6308, 0.5068, 0.8535, 0.0403],\n",
      "        [0.0520, 0.0206, 0.1361, 0.0630],\n",
      "        [0.5102, 0.4408, 0.6825, 0.1583],\n",
      "        [0.1039, 0.0408, 0.0763, 0.0725],\n",
      "        [0.7526, 0.0089, 0.1026, 0.0385],\n",
      "        [0.7842, 0.0240, 0.2030, 0.0221],\n",
      "        [0.6312, 0.0719, 0.3656, 0.1404],\n",
      "        [0.4873, 0.1280, 0.6826, 0.0626],\n",
      "        [0.7522, 0.0934, 0.5290, 0.1433],\n",
      "        [0.0919, 0.0743, 0.5498, 0.0656],\n",
      "        [0.5027, 0.0298, 0.2290, 0.1397],\n",
      "        [0.5228, 0.0467, 0.3901, 0.0322],\n",
      "        [0.5826, 0.1970, 0.3410, 0.1859],\n",
      "        [0.0989, 0.0439, 0.0798, 0.0861],\n",
      "        [0.4973, 0.0351, 0.1019, 0.0776]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1146, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.1443566394047155\n",
      "Epoch 1, Loss: -2.2080790099255125\n",
      "Epoch 1, Loss: -1.636827253216416\n",
      "Epoch 1, Loss: -1.8265066811619088\n",
      "Epoch 1, Loss: -2.3042858972474587\n",
      "tensor([[0.4433, 0.2212, 0.5809, 0.0972],\n",
      "        [0.4788, 0.5183, 0.7324, 0.1877],\n",
      "        [0.4850, 0.0864, 0.3093, 0.1389],\n",
      "        [0.3528, 0.4445, 0.8911, 0.0560],\n",
      "        [0.3212, 0.1890, 0.5781, 0.1463],\n",
      "        [0.3868, 0.0926, 0.6695, 0.0304],\n",
      "        [0.5780, 0.1105, 0.5716, 0.0558],\n",
      "        [0.2944, 0.0429, 0.1234, 0.0832],\n",
      "        [0.4742, 0.1929, 0.4409, 0.2073],\n",
      "        [0.7903, 0.0536, 0.3540, 0.0398],\n",
      "        [0.5447, 0.0270, 0.1427, 0.0848],\n",
      "        [0.4037, 0.1052, 0.3872, 0.0243],\n",
      "        [0.4012, 0.2161, 0.6162, 0.1026],\n",
      "        [0.3110, 0.1043, 0.3459, 0.0729],\n",
      "        [0.8582, 0.0149, 0.8104, 0.0209],\n",
      "        [0.1673, 0.0995, 0.3181, 0.0346],\n",
      "        [0.4144, 0.1285, 0.1735, 0.0584],\n",
      "        [0.8344, 0.0136, 0.4487, 0.0202],\n",
      "        [0.4756, 0.1377, 0.7633, 0.0405],\n",
      "        [0.5340, 0.0254, 0.1848, 0.1019],\n",
      "        [0.7174, 0.0509, 0.8034, 0.1585],\n",
      "        [0.6856, 0.1679, 0.6804, 0.0970],\n",
      "        [0.6979, 0.3586, 0.6581, 0.2271],\n",
      "        [0.1126, 0.1908, 0.1521, 0.0421],\n",
      "        [0.7784, 0.0776, 0.6568, 0.0848],\n",
      "        [0.6371, 0.0560, 0.2859, 0.1512],\n",
      "        [0.2581, 0.1803, 0.7400, 0.0510],\n",
      "        [0.8319, 0.0058, 0.3656, 0.0273],\n",
      "        [0.3976, 0.1344, 0.4164, 0.1970],\n",
      "        [0.1997, 0.1613, 0.6723, 0.1030],\n",
      "        [0.8325, 0.0153, 0.4405, 0.0151],\n",
      "        [0.5785, 0.1635, 0.8342, 0.1372]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1037, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.2828730586962207\n",
      "Epoch 1, Loss: -2.3934062454087197\n",
      "Epoch 1, Loss: -2.3562590296772203\n",
      "Epoch 1, Loss: -2.4032999015537406\n",
      "Epoch 1, Loss: -2.2963624343744335\n",
      "tensor([[0.7386, 0.1511, 0.2884, 0.0407],\n",
      "        [0.7806, 0.0619, 0.8917, 0.0379],\n",
      "        [0.5176, 0.1872, 0.4542, 0.2105],\n",
      "        [0.8632, 0.0148, 0.7572, 0.0113],\n",
      "        [0.7590, 0.0729, 0.4842, 0.0220],\n",
      "        [0.7135, 0.0308, 0.7434, 0.0571],\n",
      "        [0.2656, 0.1471, 0.1701, 0.0434],\n",
      "        [0.4448, 0.2999, 0.8522, 0.0351],\n",
      "        [0.5543, 0.0319, 0.5826, 0.0806],\n",
      "        [0.3774, 0.0882, 0.5195, 0.2247],\n",
      "        [0.6432, 0.1042, 0.8160, 0.1260],\n",
      "        [0.2012, 0.1376, 0.3044, 0.1738],\n",
      "        [0.3606, 0.0901, 0.5296, 0.0759],\n",
      "        [0.4178, 0.1639, 0.7324, 0.1204],\n",
      "        [0.8079, 0.0477, 0.4098, 0.2149],\n",
      "        [0.1948, 0.1605, 0.8274, 0.0838],\n",
      "        [0.6975, 0.0178, 0.6994, 0.0514],\n",
      "        [0.5840, 0.0997, 0.5266, 0.0720],\n",
      "        [0.5746, 0.0873, 0.5013, 0.0689],\n",
      "        [0.2824, 0.0597, 0.2054, 0.1061],\n",
      "        [0.2313, 0.0865, 0.6350, 0.0779],\n",
      "        [0.6020, 0.1284, 0.6620, 0.0876],\n",
      "        [0.7556, 0.1123, 0.6557, 0.1443],\n",
      "        [0.8268, 0.0225, 0.6422, 0.0298],\n",
      "        [0.3982, 0.0750, 0.5601, 0.1594],\n",
      "        [0.3278, 0.2087, 0.5012, 0.0875],\n",
      "        [0.1417, 0.0066, 0.3829, 0.0078],\n",
      "        [0.5052, 0.0999, 0.8441, 0.0562],\n",
      "        [0.4325, 0.0581, 0.3902, 0.0832],\n",
      "        [0.1709, 0.0287, 0.0587, 0.0718],\n",
      "        [0.7104, 0.0261, 0.2176, 0.0361],\n",
      "        [0.7442, 0.0253, 0.6747, 0.0056]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1064, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.3929495394281464\n",
      "Epoch 1, Loss: -2.403107686609635\n",
      "Epoch 1, Loss: -2.475204096342879\n",
      "Epoch 1, Loss: -2.3312727358917114\n",
      "Epoch 1, Loss: -2.5800683091586505\n",
      "tensor([[0.5586, 0.0546, 0.3577, 0.1098],\n",
      "        [0.4743, 0.0408, 0.6234, 0.0592],\n",
      "        [0.7135, 0.0297, 0.5681, 0.0696],\n",
      "        [0.5198, 0.0551, 0.2212, 0.0579],\n",
      "        [0.5384, 0.0709, 0.4889, 0.0733],\n",
      "        [0.8767, 0.0185, 0.2448, 0.0440],\n",
      "        [0.3396, 0.1037, 0.7541, 0.0216],\n",
      "        [0.7270, 0.0332, 0.7731, 0.0871],\n",
      "        [0.3971, 0.0114, 0.4304, 0.0345],\n",
      "        [0.1064, 0.0416, 0.5857, 0.0481],\n",
      "        [0.2482, 0.0687, 0.5090, 0.0370],\n",
      "        [0.3099, 0.0468, 0.7825, 0.0495],\n",
      "        [0.5070, 0.0309, 0.4052, 0.0249],\n",
      "        [0.4069, 0.2445, 0.5769, 0.0436],\n",
      "        [0.6725, 0.0145, 0.2111, 0.0201],\n",
      "        [0.6533, 0.0324, 0.2692, 0.0547],\n",
      "        [0.5193, 0.1113, 0.7369, 0.0414],\n",
      "        [0.5990, 0.1186, 0.8041, 0.0576],\n",
      "        [0.7171, 0.2164, 0.7724, 0.0313],\n",
      "        [0.5487, 0.1517, 0.7785, 0.1149],\n",
      "        [0.4308, 0.0498, 0.6544, 0.0912],\n",
      "        [0.6313, 0.1271, 0.5175, 0.1373],\n",
      "        [0.6000, 0.2125, 0.5518, 0.1477],\n",
      "        [0.1782, 0.0429, 0.0514, 0.0223],\n",
      "        [0.7621, 0.1173, 0.5924, 0.1842],\n",
      "        [0.6656, 0.0542, 0.4589, 0.0378],\n",
      "        [0.4528, 0.1248, 0.6601, 0.1086],\n",
      "        [0.2518, 0.0840, 0.2463, 0.0315],\n",
      "        [0.7729, 0.0214, 0.8946, 0.0380],\n",
      "        [0.7823, 0.0154, 0.5648, 0.0191],\n",
      "        [0.5588, 0.1690, 0.7809, 0.0289],\n",
      "        [0.5209, 0.0736, 0.1996, 0.0482]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1048, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.7884222046402494\n",
      "Epoch 1, Loss: -2.214736109327392\n",
      "Epoch 1, Loss: -2.756637025929302\n",
      "Epoch 1, Loss: -2.777139350592032\n",
      "Epoch 1, Loss: -2.3605057871190605\n",
      "tensor([[0.2244, 0.0336, 0.4751, 0.0841],\n",
      "        [0.6334, 0.0416, 0.1500, 0.0269],\n",
      "        [0.3896, 0.0679, 0.2523, 0.0688],\n",
      "        [0.5851, 0.0664, 0.6414, 0.0808],\n",
      "        [0.4895, 0.0929, 0.5388, 0.1841],\n",
      "        [0.4127, 0.0439, 0.6986, 0.0819],\n",
      "        [0.6545, 0.0521, 0.7976, 0.0041],\n",
      "        [0.6157, 0.0187, 0.5470, 0.0301],\n",
      "        [0.6216, 0.0413, 0.4372, 0.0445],\n",
      "        [0.1739, 0.0519, 0.6331, 0.0130],\n",
      "        [0.6202, 0.0206, 0.4267, 0.0194],\n",
      "        [0.9373, 0.0016, 0.8454, 0.0054],\n",
      "        [0.4702, 0.0563, 0.6671, 0.0557],\n",
      "        [0.5008, 0.0552, 0.4324, 0.0724],\n",
      "        [0.8070, 0.0110, 0.2632, 0.0118],\n",
      "        [0.1742, 0.0874, 0.2339, 0.0262],\n",
      "        [0.3904, 0.0234, 0.2646, 0.0219],\n",
      "        [0.6617, 0.0864, 0.2485, 0.0723],\n",
      "        [0.6169, 0.0339, 0.5609, 0.1096],\n",
      "        [0.4554, 0.1637, 0.6381, 0.1298],\n",
      "        [0.1501, 0.0210, 0.2475, 0.0287],\n",
      "        [0.2544, 0.0853, 0.4838, 0.1287],\n",
      "        [0.1931, 0.0109, 0.0598, 0.0167],\n",
      "        [0.5446, 0.0362, 0.3382, 0.0693],\n",
      "        [0.6485, 0.0315, 0.3994, 0.0462],\n",
      "        [0.2654, 0.0364, 0.8045, 0.0279],\n",
      "        [0.5821, 0.0937, 0.6713, 0.0513],\n",
      "        [0.5406, 0.0081, 0.7886, 0.0103],\n",
      "        [0.2668, 0.0440, 0.8111, 0.0072],\n",
      "        [0.6761, 0.0378, 0.7085, 0.0350],\n",
      "        [0.7767, 0.0046, 0.4015, 0.0094],\n",
      "        [0.5986, 0.0857, 0.3866, 0.0475]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1281, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.425273593760758\n",
      "Epoch 1, Loss: -2.25801636798269\n",
      "Epoch 1, Loss: -2.2848628925026038\n",
      "Epoch 1, Loss: -2.4389871453391305\n",
      "Epoch 1, Loss: -2.5375345741799533\n",
      "tensor([[0.6949, 0.0131, 0.5142, 0.0098],\n",
      "        [0.5300, 0.0741, 0.3951, 0.0819],\n",
      "        [0.3028, 0.0290, 0.6567, 0.0658],\n",
      "        [0.5088, 0.1498, 0.5318, 0.2048],\n",
      "        [0.2530, 0.1388, 0.2272, 0.0340],\n",
      "        [0.2349, 0.0690, 0.2268, 0.0515],\n",
      "        [0.2502, 0.1097, 0.3252, 0.0876],\n",
      "        [0.4418, 0.0490, 0.0804, 0.0224],\n",
      "        [0.4566, 0.0745, 0.1813, 0.0381],\n",
      "        [0.4555, 0.0025, 0.7489, 0.0012],\n",
      "        [0.5101, 0.0225, 0.6155, 0.0317],\n",
      "        [0.4704, 0.0285, 0.5418, 0.0426],\n",
      "        [0.7340, 0.0228, 0.5490, 0.0132],\n",
      "        [0.4014, 0.1610, 0.6002, 0.0331],\n",
      "        [0.4796, 0.1607, 0.4194, 0.0823],\n",
      "        [0.4077, 0.0324, 0.3681, 0.0342],\n",
      "        [0.3693, 0.0514, 0.8209, 0.0344],\n",
      "        [0.4177, 0.0297, 0.5362, 0.0318],\n",
      "        [0.3562, 0.1587, 0.7274, 0.0370],\n",
      "        [0.5358, 0.0786, 0.4334, 0.0749],\n",
      "        [0.7472, 0.0029, 0.1156, 0.0571],\n",
      "        [0.4842, 0.0696, 0.6753, 0.0746],\n",
      "        [0.6860, 0.0214, 0.4563, 0.0185],\n",
      "        [0.4046, 0.1058, 0.5535, 0.0954],\n",
      "        [0.3630, 0.0351, 0.5888, 0.0282],\n",
      "        [0.5222, 0.0746, 0.5227, 0.0563],\n",
      "        [0.5150, 0.1225, 0.2262, 0.0123],\n",
      "        [0.7208, 0.0103, 0.5024, 0.0160],\n",
      "        [0.4829, 0.1060, 0.6769, 0.0479],\n",
      "        [0.8127, 0.0061, 0.2950, 0.0355],\n",
      "        [0.6577, 0.0227, 0.5896, 0.0380],\n",
      "        [0.5535, 0.0237, 0.5626, 0.0302]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1017, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.9748049288694496\n",
      "Epoch 1, Loss: -2.513810453230655\n",
      "Epoch 1, Loss: -2.268618530764923\n",
      "Epoch 1, Loss: -2.240120725429075\n",
      "Epoch 1, Loss: -2.475640662800175\n",
      "tensor([[0.4531, 0.1353, 0.3139, 0.0280],\n",
      "        [0.6088, 0.0345, 0.5176, 0.0335],\n",
      "        [0.4963, 0.0266, 0.6659, 0.0080],\n",
      "        [0.3715, 0.1219, 0.7893, 0.0214],\n",
      "        [0.3411, 0.0029, 0.4635, 0.0056],\n",
      "        [0.4994, 0.0668, 0.2087, 0.1450],\n",
      "        [0.4303, 0.0758, 0.4622, 0.0327],\n",
      "        [0.8229, 0.0053, 0.5933, 0.0209],\n",
      "        [0.5319, 0.0798, 0.7338, 0.0369],\n",
      "        [0.2949, 0.0184, 0.5731, 0.0399],\n",
      "        [0.4970, 0.0269, 0.4499, 0.0480],\n",
      "        [0.1001, 0.0246, 0.3328, 0.0138],\n",
      "        [0.8080, 0.0163, 0.7249, 0.0683],\n",
      "        [0.4771, 0.0988, 0.2865, 0.1096],\n",
      "        [0.1237, 0.0118, 0.8601, 0.0034],\n",
      "        [0.6771, 0.0911, 0.3655, 0.1603],\n",
      "        [0.7713, 0.0243, 0.2490, 0.0787],\n",
      "        [0.6218, 0.0536, 0.5077, 0.1099],\n",
      "        [0.6471, 0.0343, 0.3115, 0.0040],\n",
      "        [0.5506, 0.0071, 0.4875, 0.0058],\n",
      "        [0.7934, 0.0095, 0.1150, 0.0234],\n",
      "        [0.2602, 0.0184, 0.6517, 0.0301],\n",
      "        [0.7433, 0.0149, 0.3271, 0.0069],\n",
      "        [0.3296, 0.1755, 0.4850, 0.0366],\n",
      "        [0.7210, 0.0217, 0.2187, 0.0202],\n",
      "        [0.5487, 0.1001, 0.6491, 0.1576],\n",
      "        [0.2946, 0.0184, 0.3973, 0.0160],\n",
      "        [0.4577, 0.0339, 0.4960, 0.1071],\n",
      "        [0.6382, 0.1026, 0.7713, 0.1566],\n",
      "        [0.4563, 0.0930, 0.4063, 0.0605],\n",
      "        [0.1457, 0.0069, 0.3720, 0.0133],\n",
      "        [0.6456, 0.0222, 0.1454, 0.0123]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1099, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.2991084505084274\n",
      "Epoch 1, Loss: -2.7890922587766087\n",
      "Epoch 1, Loss: -2.636711863473556\n",
      "Epoch 1, Loss: -2.644374872902567\n",
      "Epoch 1, Loss: -2.805499387248308\n",
      "tensor([[0.6628, 0.0481, 0.6488, 0.0729],\n",
      "        [0.7872, 0.0274, 0.4672, 0.0437],\n",
      "        [0.5699, 0.0055, 0.5356, 0.0320],\n",
      "        [0.2260, 0.0197, 0.6412, 0.0208],\n",
      "        [0.5568, 0.0075, 0.6293, 0.0141],\n",
      "        [0.7274, 0.0740, 0.5674, 0.0796],\n",
      "        [0.1649, 0.0149, 0.3362, 0.0267],\n",
      "        [0.1582, 0.0044, 0.4519, 0.0080],\n",
      "        [0.7743, 0.0199, 0.4196, 0.1665],\n",
      "        [0.2246, 0.0452, 0.8473, 0.0273],\n",
      "        [0.3748, 0.0673, 0.4873, 0.1119],\n",
      "        [0.5806, 0.1334, 0.4254, 0.0887],\n",
      "        [0.8628, 0.0016, 0.0519, 0.0033],\n",
      "        [0.3097, 0.0403, 0.2944, 0.0951],\n",
      "        [0.2079, 0.0298, 0.8771, 0.0164],\n",
      "        [0.3210, 0.0414, 0.1891, 0.0399],\n",
      "        [0.5818, 0.1028, 0.2017, 0.0829],\n",
      "        [0.5578, 0.0404, 0.8983, 0.0144],\n",
      "        [0.5416, 0.0232, 0.4379, 0.0605],\n",
      "        [0.5806, 0.0406, 0.2031, 0.0641],\n",
      "        [0.6136, 0.0241, 0.8350, 0.0108],\n",
      "        [0.2957, 0.0450, 0.3806, 0.0151],\n",
      "        [0.6106, 0.0460, 0.4695, 0.0150],\n",
      "        [0.6577, 0.0113, 0.3343, 0.0213],\n",
      "        [0.8262, 0.0075, 0.1957, 0.0182],\n",
      "        [0.4075, 0.1072, 0.3993, 0.1082],\n",
      "        [0.1424, 0.0204, 0.7670, 0.0228],\n",
      "        [0.5805, 0.0749, 0.3718, 0.1854],\n",
      "        [0.4962, 0.0408, 0.4081, 0.1833],\n",
      "        [0.7134, 0.0066, 0.2056, 0.0120],\n",
      "        [0.7763, 0.0118, 0.5967, 0.0199],\n",
      "        [0.1142, 0.0038, 0.7544, 0.0028]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0780, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.9133624885861016\n",
      "Epoch 1, Loss: -2.1816704029710956\n",
      "Epoch 1, Loss: -2.868889209759847\n",
      "Epoch 1, Loss: -2.9232854123605128\n",
      "Epoch 1, Loss: -2.863618832970862\n",
      "tensor([[0.2585, 0.0283, 0.9208, 0.0249],\n",
      "        [0.1954, 0.0022, 0.5318, 0.0115],\n",
      "        [0.8887, 0.0138, 0.6311, 0.0530],\n",
      "        [0.3212, 0.0655, 0.2979, 0.0168],\n",
      "        [0.5874, 0.0196, 0.3454, 0.0311],\n",
      "        [0.6592, 0.0152, 0.7782, 0.0320],\n",
      "        [0.7180, 0.0458, 0.6174, 0.0979],\n",
      "        [0.5144, 0.0078, 0.4535, 0.0332],\n",
      "        [0.7207, 0.0060, 0.2629, 0.0132],\n",
      "        [0.6345, 0.0334, 0.4666, 0.1243],\n",
      "        [0.4178, 0.0366, 0.4077, 0.0324],\n",
      "        [0.5385, 0.0161, 0.6375, 0.0145],\n",
      "        [0.2000, 0.0227, 0.4296, 0.0454],\n",
      "        [0.4882, 0.0162, 0.2611, 0.0341],\n",
      "        [0.4037, 0.0633, 0.3862, 0.0945],\n",
      "        [0.7308, 0.0163, 0.6691, 0.0491],\n",
      "        [0.5684, 0.1284, 0.4754, 0.1089],\n",
      "        [0.3366, 0.0195, 0.1901, 0.0056],\n",
      "        [0.2487, 0.0491, 0.6952, 0.0333],\n",
      "        [0.5332, 0.0535, 0.1797, 0.0559],\n",
      "        [0.3458, 0.0918, 0.4313, 0.0717],\n",
      "        [0.6304, 0.0188, 0.5327, 0.0671],\n",
      "        [0.5480, 0.0435, 0.6651, 0.0681],\n",
      "        [0.1853, 0.0076, 0.7406, 0.0097],\n",
      "        [0.4618, 0.0971, 0.5749, 0.1268],\n",
      "        [0.6758, 0.0317, 0.3818, 0.0247],\n",
      "        [0.5687, 0.0376, 0.3754, 0.1504],\n",
      "        [0.2935, 0.0473, 0.6314, 0.0322],\n",
      "        [0.5223, 0.0282, 0.5700, 0.0847],\n",
      "        [0.2594, 0.0158, 0.8659, 0.0300],\n",
      "        [0.6850, 0.0300, 0.3031, 0.0227],\n",
      "        [0.8230, 0.0025, 0.9157, 0.0036]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0984, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.7145491917065097\n",
      "Epoch 1, Loss: -2.8105754116445727\n",
      "Epoch 1, Loss: -2.8409401327946067\n",
      "Epoch 1, Loss: -1.9672120635366581\n",
      "Epoch 1, Loss: -2.7196771229272545\n",
      "tensor([[0.6987, 0.0087, 0.5666, 0.0496],\n",
      "        [0.3547, 0.0079, 0.3512, 0.0164],\n",
      "        [0.3394, 0.0229, 0.7631, 0.0341],\n",
      "        [0.3761, 0.0378, 0.4830, 0.0478],\n",
      "        [0.5023, 0.1207, 0.3906, 0.0654],\n",
      "        [0.8356, 0.0137, 0.5335, 0.0695],\n",
      "        [0.4000, 0.0632, 0.5246, 0.1016],\n",
      "        [0.2779, 0.0258, 0.8502, 0.0192],\n",
      "        [0.7396, 0.0282, 0.6195, 0.0916],\n",
      "        [0.5723, 0.1142, 0.6193, 0.1115],\n",
      "        [0.5647, 0.0377, 0.4795, 0.0633],\n",
      "        [0.7002, 0.0055, 0.6143, 0.0372],\n",
      "        [0.6630, 0.0171, 0.5883, 0.1152],\n",
      "        [0.4031, 0.0232, 0.7919, 0.0237],\n",
      "        [0.4744, 0.0052, 0.4657, 0.0422],\n",
      "        [0.5448, 0.0328, 0.4546, 0.0270],\n",
      "        [0.3908, 0.0079, 0.1788, 0.0317],\n",
      "        [0.3585, 0.0174, 0.2644, 0.0294],\n",
      "        [0.6002, 0.0448, 0.4367, 0.0573],\n",
      "        [0.9319, 0.0047, 0.7936, 0.0568],\n",
      "        [0.7659, 0.0661, 0.7941, 0.0465],\n",
      "        [0.3468, 0.0476, 0.3067, 0.0380],\n",
      "        [0.7928, 0.0891, 0.8633, 0.0357],\n",
      "        [0.1809, 0.0041, 0.8524, 0.0177],\n",
      "        [0.4135, 0.0740, 0.6799, 0.0413],\n",
      "        [0.3619, 0.0429, 0.5098, 0.0217],\n",
      "        [0.5578, 0.1729, 0.4832, 0.1711],\n",
      "        [0.5669, 0.0300, 0.2690, 0.0261],\n",
      "        [0.5759, 0.0292, 0.3710, 0.0531],\n",
      "        [0.5817, 0.0041, 0.2861, 0.0113],\n",
      "        [0.4720, 0.1116, 0.4571, 0.1469],\n",
      "        [0.4100, 0.0353, 0.2440, 0.0548]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1152, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.7150825068629025\n",
      "Epoch 1, Loss: -2.704365283877763\n",
      "Epoch 1, Loss: -2.006812920587973\n",
      "Epoch 1, Loss: -2.6975262435429492\n",
      "Epoch 1, Loss: -2.6425015349338827\n",
      "tensor([[0.5055, 0.0116, 0.4041, 0.0233],\n",
      "        [0.4767, 0.0166, 0.6901, 0.0383],\n",
      "        [0.2951, 0.0573, 0.6365, 0.0961],\n",
      "        [0.6300, 0.0401, 0.7696, 0.0306],\n",
      "        [0.3708, 0.0779, 0.6527, 0.0678],\n",
      "        [0.3938, 0.0414, 0.5102, 0.0306],\n",
      "        [0.2783, 0.0401, 0.3252, 0.0535],\n",
      "        [0.8276, 0.0057, 0.5849, 0.0312],\n",
      "        [0.3641, 0.0294, 0.6896, 0.0370],\n",
      "        [0.6476, 0.0203, 0.7168, 0.0760],\n",
      "        [0.3372, 0.0291, 0.3729, 0.0046],\n",
      "        [0.5480, 0.0024, 0.4234, 0.0027],\n",
      "        [0.4218, 0.0655, 0.4460, 0.0259],\n",
      "        [0.5783, 0.0907, 0.7503, 0.1549],\n",
      "        [0.3037, 0.0378, 0.4603, 0.0395],\n",
      "        [0.4595, 0.1261, 0.4365, 0.1567],\n",
      "        [0.5029, 0.0299, 0.7751, 0.0283],\n",
      "        [0.2710, 0.0214, 0.3388, 0.0152],\n",
      "        [0.4831, 0.0215, 0.7139, 0.0297],\n",
      "        [0.3892, 0.0370, 0.8240, 0.0600],\n",
      "        [0.5653, 0.0373, 0.4645, 0.0434],\n",
      "        [0.8700, 0.0023, 0.5200, 0.0169],\n",
      "        [0.2208, 0.0181, 0.5650, 0.0288],\n",
      "        [0.4238, 0.0144, 0.3203, 0.0205],\n",
      "        [0.7259, 0.0513, 0.6666, 0.1440],\n",
      "        [0.4073, 0.0095, 0.1703, 0.0114],\n",
      "        [0.5488, 0.0142, 0.6286, 0.0413],\n",
      "        [0.4474, 0.0493, 0.6121, 0.1036],\n",
      "        [0.6784, 0.0124, 0.5055, 0.0363],\n",
      "        [0.3992, 0.1372, 0.5223, 0.1574],\n",
      "        [0.7225, 0.0026, 0.5622, 0.0411],\n",
      "        [0.5762, 0.0343, 0.7687, 0.0515]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.1053, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.8725617605290044\n",
      "Epoch 1, Loss: -2.9623047425438647\n",
      "Epoch 1, Loss: -2.0515368961492264\n",
      "Epoch 1, Loss: -2.796020508745226\n",
      "Epoch 1, Loss: -2.9511340046880266\n",
      "tensor([[0.5999, 0.0758, 0.5503, 0.0891],\n",
      "        [0.7524, 0.0336, 0.6714, 0.1247],\n",
      "        [0.4635, 0.0413, 0.6700, 0.0296],\n",
      "        [0.3288, 0.0198, 0.6532, 0.0250],\n",
      "        [0.4018, 0.0391, 0.2941, 0.0336],\n",
      "        [0.4214, 0.0630, 0.4536, 0.0617],\n",
      "        [0.5349, 0.0601, 0.4013, 0.0333],\n",
      "        [0.4469, 0.0216, 0.2414, 0.0204],\n",
      "        [0.8791, 0.0083, 0.2237, 0.0155],\n",
      "        [0.9206, 0.0074, 0.4139, 0.0145],\n",
      "        [0.1979, 0.0538, 0.2742, 0.0681],\n",
      "        [0.2843, 0.0172, 0.8434, 0.0258],\n",
      "        [0.7085, 0.0247, 0.5775, 0.0403],\n",
      "        [0.6893, 0.0179, 0.6873, 0.0158],\n",
      "        [0.3952, 0.0775, 0.6715, 0.1131],\n",
      "        [0.2040, 0.0130, 0.0795, 0.0144],\n",
      "        [0.2683, 0.0608, 0.4605, 0.0345],\n",
      "        [0.4185, 0.0968, 0.4582, 0.0299],\n",
      "        [0.1387, 0.0108, 0.2998, 0.0154],\n",
      "        [0.4621, 0.0503, 0.5085, 0.0560],\n",
      "        [0.5171, 0.0294, 0.7642, 0.0155],\n",
      "        [0.4836, 0.0208, 0.4126, 0.0367],\n",
      "        [0.2345, 0.0343, 0.6151, 0.0187],\n",
      "        [0.7944, 0.0227, 0.5725, 0.0130],\n",
      "        [0.4023, 0.0733, 0.8164, 0.0423],\n",
      "        [0.5213, 0.0423, 0.5412, 0.0371],\n",
      "        [0.1930, 0.0158, 0.5491, 0.0163],\n",
      "        [0.4394, 0.0416, 0.2248, 0.0301],\n",
      "        [0.2393, 0.0019, 0.8123, 0.0033],\n",
      "        [0.3286, 0.0897, 0.5281, 0.0862],\n",
      "        [0.5890, 0.0591, 0.6869, 0.1756],\n",
      "        [0.3810, 0.0851, 0.7213, 0.0292]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0916, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.6788289865021344\n",
      "Epoch 1, Loss: -3.0794257804481067\n",
      "Epoch 1, Loss: -2.639438636460709\n",
      "Epoch 1, Loss: -2.8937712746338873\n",
      "Epoch 1, Loss: -2.9521201789931606\n",
      "tensor([[0.4863, 0.0694, 0.4835, 0.0602],\n",
      "        [0.5152, 0.0889, 0.5111, 0.0498],\n",
      "        [0.5893, 0.0633, 0.1768, 0.0321],\n",
      "        [0.3322, 0.0354, 0.6286, 0.0193],\n",
      "        [0.4780, 0.0582, 0.3247, 0.0355],\n",
      "        [0.0690, 0.0161, 0.8231, 0.0043],\n",
      "        [0.3922, 0.0422, 0.8356, 0.0197],\n",
      "        [0.7458, 0.0060, 0.4894, 0.0095],\n",
      "        [0.4152, 0.0455, 0.5366, 0.0771],\n",
      "        [0.6115, 0.0504, 0.2187, 0.0283],\n",
      "        [0.5526, 0.2126, 0.4785, 0.1107],\n",
      "        [0.2711, 0.0105, 0.2302, 0.0145],\n",
      "        [0.5641, 0.0612, 0.5471, 0.0606],\n",
      "        [0.4731, 0.1403, 0.5044, 0.0676],\n",
      "        [0.3074, 0.0141, 0.8028, 0.0075],\n",
      "        [0.4751, 0.0441, 0.5342, 0.0478],\n",
      "        [0.7621, 0.0110, 0.8279, 0.0386],\n",
      "        [0.4257, 0.0494, 0.7544, 0.0247],\n",
      "        [0.6865, 0.0359, 0.1935, 0.0098],\n",
      "        [0.3779, 0.0306, 0.5855, 0.0308],\n",
      "        [0.6654, 0.0380, 0.4500, 0.0326],\n",
      "        [0.4149, 0.0677, 0.1775, 0.1321],\n",
      "        [0.4144, 0.0186, 0.7688, 0.0072],\n",
      "        [0.7632, 0.0076, 0.4047, 0.0372],\n",
      "        [0.6151, 0.0450, 0.6127, 0.0639],\n",
      "        [0.8161, 0.0368, 0.3167, 0.0510],\n",
      "        [0.1538, 0.0168, 0.5124, 0.0055],\n",
      "        [0.8919, 0.0020, 0.2408, 0.0221],\n",
      "        [0.4737, 0.1410, 0.5175, 0.0565],\n",
      "        [0.8000, 0.0384, 0.5201, 0.1158],\n",
      "        [0.6952, 0.0294, 0.2555, 0.0258],\n",
      "        [0.1611, 0.0094, 0.6437, 0.0063]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0865, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.966346112694098\n",
      "Epoch 1, Loss: -3.091958770284525\n",
      "Epoch 1, Loss: -2.7477310535659205\n",
      "Epoch 1, Loss: -2.871924853845945\n",
      "Epoch 1, Loss: -2.7679446224318394\n",
      "tensor([[5.6035e-01, 7.9863e-02, 2.5051e-01, 9.2837e-02],\n",
      "        [3.8106e-01, 1.4803e-02, 3.7938e-01, 1.2890e-02],\n",
      "        [7.1128e-01, 8.3023e-03, 3.7159e-01, 2.7381e-02],\n",
      "        [7.8619e-01, 5.5985e-04, 2.1760e-01, 3.0136e-03],\n",
      "        [1.0860e-01, 9.0416e-03, 1.1218e-01, 1.9191e-03],\n",
      "        [2.6929e-01, 4.5851e-02, 3.0681e-01, 1.4434e-02],\n",
      "        [1.0662e-01, 4.8116e-03, 7.1205e-01, 1.2371e-02],\n",
      "        [5.4810e-01, 6.7384e-02, 5.4013e-01, 7.0079e-02],\n",
      "        [5.2967e-01, 9.0206e-02, 4.7836e-01, 5.8022e-02],\n",
      "        [5.0557e-01, 1.2231e-01, 4.9861e-01, 1.1671e-01],\n",
      "        [6.8777e-01, 6.0261e-02, 2.6375e-01, 8.0748e-02],\n",
      "        [1.7500e-01, 5.3631e-02, 4.5959e-01, 1.4934e-02],\n",
      "        [4.8613e-01, 1.2290e-01, 3.7878e-01, 2.5505e-02],\n",
      "        [6.9283e-01, 7.2940e-02, 5.6557e-01, 8.8144e-02],\n",
      "        [6.4200e-01, 3.5702e-02, 3.2008e-01, 5.2074e-02],\n",
      "        [5.5033e-01, 8.6507e-02, 2.9376e-01, 5.5547e-02],\n",
      "        [7.3298e-01, 1.8240e-02, 7.5098e-01, 1.1521e-02],\n",
      "        [5.2281e-01, 6.8665e-02, 5.6216e-01, 3.6579e-02],\n",
      "        [6.6333e-01, 1.6543e-02, 7.8249e-01, 1.5146e-02],\n",
      "        [2.9917e-01, 4.2090e-02, 6.5228e-01, 3.8825e-02],\n",
      "        [4.6093e-01, 1.5028e-02, 5.1292e-01, 9.6630e-03],\n",
      "        [2.1861e-01, 9.5933e-03, 6.9167e-01, 2.7267e-02],\n",
      "        [4.9558e-01, 7.5738e-02, 5.3704e-01, 4.6130e-02],\n",
      "        [7.1825e-01, 8.0668e-03, 4.4141e-01, 8.6528e-03],\n",
      "        [4.3494e-01, 4.1016e-02, 5.5095e-01, 3.8191e-02],\n",
      "        [5.5272e-01, 3.2885e-02, 8.2809e-01, 1.0114e-02],\n",
      "        [6.1503e-01, 6.3577e-02, 6.2851e-01, 3.9720e-02],\n",
      "        [3.3327e-01, 7.6583e-02, 5.2194e-01, 4.4082e-02],\n",
      "        [2.8614e-01, 1.1731e-02, 8.4409e-01, 5.5279e-03],\n",
      "        [3.1734e-01, 3.6096e-02, 3.6424e-01, 2.0530e-02],\n",
      "        [1.7082e-01, 4.2958e-02, 5.4139e-01, 6.8116e-02],\n",
      "        [5.7299e-01, 5.5179e-02, 5.4938e-01, 6.8616e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0878, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -1.7956681677364927\n",
      "Epoch 1, Loss: -2.6327714553818398\n",
      "Epoch 1, Loss: -2.6088758723633045\n",
      "Epoch 1, Loss: -2.783511300406012\n",
      "Epoch 1, Loss: -3.123508964133775\n",
      "tensor([[0.4798, 0.0594, 0.7200, 0.0209],\n",
      "        [0.3704, 0.0078, 0.5313, 0.0332],\n",
      "        [0.4056, 0.0377, 0.7376, 0.0410],\n",
      "        [0.3522, 0.1287, 0.4821, 0.2086],\n",
      "        [0.5639, 0.0182, 0.4490, 0.0089],\n",
      "        [0.3382, 0.0637, 0.6009, 0.0633],\n",
      "        [0.4708, 0.0490, 0.5515, 0.0532],\n",
      "        [0.2731, 0.0208, 0.5295, 0.0331],\n",
      "        [0.4477, 0.0571, 0.2687, 0.0302],\n",
      "        [0.6767, 0.0218, 0.6908, 0.0272],\n",
      "        [0.7857, 0.0120, 0.2534, 0.0095],\n",
      "        [0.3355, 0.0137, 0.5764, 0.0057],\n",
      "        [0.3877, 0.0713, 0.5949, 0.0627],\n",
      "        [0.3424, 0.0724, 0.5679, 0.0971],\n",
      "        [0.3072, 0.0321, 0.5872, 0.0647],\n",
      "        [0.5368, 0.0480, 0.6620, 0.0288],\n",
      "        [0.5486, 0.0317, 0.2100, 0.0145],\n",
      "        [0.1251, 0.0389, 0.6882, 0.0370],\n",
      "        [0.6427, 0.0079, 0.5447, 0.0245],\n",
      "        [0.7420, 0.0302, 0.3782, 0.0337],\n",
      "        [0.7620, 0.0091, 0.2343, 0.0139],\n",
      "        [0.5098, 0.1427, 0.4102, 0.0879],\n",
      "        [0.3128, 0.0329, 0.2641, 0.0058],\n",
      "        [0.3794, 0.0675, 0.6465, 0.0230],\n",
      "        [0.3277, 0.0188, 0.5077, 0.0239],\n",
      "        [0.4211, 0.0384, 0.1868, 0.0260],\n",
      "        [0.8357, 0.0060, 0.6732, 0.0236],\n",
      "        [0.4718, 0.0389, 0.5421, 0.0415],\n",
      "        [0.5297, 0.1106, 0.6726, 0.0453],\n",
      "        [0.0494, 0.0078, 0.1551, 0.0065],\n",
      "        [0.5875, 0.0238, 0.5971, 0.0180],\n",
      "        [0.6617, 0.0946, 0.5113, 0.0333]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0790, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.661398180580173\n",
      "Epoch 1, Loss: -2.646302404516863\n",
      "Epoch 1, Loss: -2.5460221497761584\n",
      "Epoch 1, Loss: -2.316728847902299\n",
      "Epoch 1, Loss: -3.0654065747624317\n",
      "tensor([[0.7129, 0.0346, 0.6051, 0.0470],\n",
      "        [0.7107, 0.0314, 0.3153, 0.0420],\n",
      "        [0.6599, 0.0206, 0.4735, 0.0078],\n",
      "        [0.4745, 0.0327, 0.6236, 0.0341],\n",
      "        [0.7414, 0.0191, 0.5028, 0.0134],\n",
      "        [0.4745, 0.1084, 0.4749, 0.0467],\n",
      "        [0.5252, 0.0094, 0.1897, 0.0062],\n",
      "        [0.7301, 0.0082, 0.3843, 0.0134],\n",
      "        [0.1151, 0.0220, 0.5341, 0.0262],\n",
      "        [0.3006, 0.0626, 0.7792, 0.0277],\n",
      "        [0.1814, 0.0120, 0.2284, 0.0023],\n",
      "        [0.5467, 0.0809, 0.2740, 0.0909],\n",
      "        [0.3211, 0.0472, 0.3152, 0.0132],\n",
      "        [0.4130, 0.0419, 0.4156, 0.0291],\n",
      "        [0.2235, 0.0216, 0.4846, 0.0225],\n",
      "        [0.4936, 0.0185, 0.5064, 0.0045],\n",
      "        [0.2773, 0.0242, 0.3869, 0.0145],\n",
      "        [0.4710, 0.0229, 0.6316, 0.0273],\n",
      "        [0.3841, 0.0885, 0.7305, 0.0513],\n",
      "        [0.6095, 0.1277, 0.2434, 0.0191],\n",
      "        [0.4453, 0.0526, 0.5875, 0.0330],\n",
      "        [0.4051, 0.0526, 0.5577, 0.0561],\n",
      "        [0.6375, 0.0184, 0.2989, 0.0171],\n",
      "        [0.5828, 0.0766, 0.3894, 0.0260],\n",
      "        [0.6496, 0.0236, 0.7453, 0.0118],\n",
      "        [0.1492, 0.0243, 0.6857, 0.0338],\n",
      "        [0.6425, 0.0988, 0.4266, 0.0634],\n",
      "        [0.4260, 0.0864, 0.3651, 0.0630],\n",
      "        [0.4423, 0.0671, 0.3480, 0.0571],\n",
      "        [0.2252, 0.0430, 0.7460, 0.0997],\n",
      "        [0.3689, 0.0257, 0.6012, 0.0140],\n",
      "        [0.3291, 0.0861, 0.2736, 0.0936]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0935, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.0206072093117786\n",
      "Epoch 1, Loss: -2.518014801712592\n",
      "Epoch 1, Loss: -2.999641681161105\n",
      "Epoch 1, Loss: -2.8840729817589974\n",
      "Epoch 1, Loss: -2.7797481614603052\n",
      "tensor([[0.4252, 0.0183, 0.1252, 0.0137],\n",
      "        [0.3325, 0.0152, 0.2842, 0.0049],\n",
      "        [0.4905, 0.0731, 0.6572, 0.0265],\n",
      "        [0.4974, 0.0816, 0.7102, 0.0980],\n",
      "        [0.2798, 0.0325, 0.7135, 0.0116],\n",
      "        [0.4463, 0.0150, 0.6717, 0.0172],\n",
      "        [0.3026, 0.1206, 0.6240, 0.0909],\n",
      "        [0.3728, 0.0617, 0.3939, 0.0221],\n",
      "        [0.5283, 0.0640, 0.5493, 0.0541],\n",
      "        [0.2416, 0.0295, 0.3206, 0.0250],\n",
      "        [0.3149, 0.0544, 0.7327, 0.0128],\n",
      "        [0.3114, 0.0193, 0.4028, 0.0080],\n",
      "        [0.5662, 0.1361, 0.6016, 0.2246],\n",
      "        [0.5079, 0.1072, 0.4546, 0.0719],\n",
      "        [0.5285, 0.0753, 0.6573, 0.0139],\n",
      "        [0.5794, 0.0427, 0.6899, 0.0474],\n",
      "        [0.3890, 0.0197, 0.2963, 0.0198],\n",
      "        [0.6697, 0.0058, 0.2754, 0.0061],\n",
      "        [0.6504, 0.0309, 0.8158, 0.0023],\n",
      "        [0.5712, 0.0481, 0.5308, 0.0147],\n",
      "        [0.5761, 0.0485, 0.2809, 0.0033],\n",
      "        [0.6953, 0.0081, 0.0929, 0.0047],\n",
      "        [0.3159, 0.0124, 0.0917, 0.0013],\n",
      "        [0.7454, 0.0142, 0.5161, 0.0394],\n",
      "        [0.4325, 0.0077, 0.6599, 0.0058],\n",
      "        [0.4229, 0.1030, 0.7378, 0.0388],\n",
      "        [0.3663, 0.0522, 0.7046, 0.0427],\n",
      "        [0.5572, 0.0163, 0.3757, 0.0103],\n",
      "        [0.4745, 0.1177, 0.7483, 0.0658],\n",
      "        [0.3280, 0.0475, 0.8450, 0.0643],\n",
      "        [0.5943, 0.0172, 0.5583, 0.0213],\n",
      "        [0.5826, 0.0387, 0.2846, 0.0362]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0988, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.8079477536755015\n",
      "Epoch 1, Loss: -2.938885454715736\n",
      "Epoch 1, Loss: -2.934144809980624\n",
      "Epoch 1, Loss: -2.844647014045578\n",
      "Epoch 1, Loss: -1.6090492560934913\n",
      "tensor([[4.6420e-01, 4.0955e-02, 4.7823e-01, 3.5301e-02],\n",
      "        [3.9597e-01, 6.7008e-02, 5.5850e-01, 5.2128e-02],\n",
      "        [5.7598e-01, 6.7823e-02, 7.9053e-01, 1.0797e-02],\n",
      "        [4.5919e-01, 5.5534e-02, 5.3816e-01, 5.8133e-02],\n",
      "        [4.6019e-01, 1.4045e-01, 6.9413e-01, 1.0152e-01],\n",
      "        [1.8252e-01, 9.0012e-03, 2.9822e-01, 4.2167e-03],\n",
      "        [5.1888e-01, 4.5720e-02, 6.1365e-01, 2.0125e-02],\n",
      "        [3.6500e-01, 9.6455e-02, 6.0623e-01, 6.5989e-02],\n",
      "        [1.7727e-01, 3.8744e-02, 8.7767e-01, 5.4512e-02],\n",
      "        [4.0708e-01, 2.7794e-02, 3.8592e-01, 4.4570e-02],\n",
      "        [3.7228e-01, 5.0742e-02, 7.6776e-01, 6.1823e-02],\n",
      "        [4.3039e-01, 1.8804e-01, 7.3310e-01, 6.6283e-02],\n",
      "        [5.9128e-01, 8.8015e-02, 7.9859e-01, 3.1133e-02],\n",
      "        [1.8410e-01, 1.2723e-01, 6.8174e-01, 1.2750e-01],\n",
      "        [5.0708e-01, 2.5629e-02, 6.2428e-01, 1.8638e-02],\n",
      "        [4.8145e-01, 5.9625e-03, 1.1650e-01, 1.4488e-04],\n",
      "        [4.6592e-01, 6.2015e-02, 6.3334e-01, 7.1020e-02],\n",
      "        [8.3937e-01, 1.2696e-02, 5.4542e-01, 3.6560e-02],\n",
      "        [8.0301e-01, 4.6712e-03, 2.3498e-01, 1.9692e-03],\n",
      "        [6.0014e-01, 8.5177e-02, 7.5587e-01, 1.8354e-02],\n",
      "        [7.6921e-01, 2.5247e-02, 4.5440e-01, 3.2553e-02],\n",
      "        [5.3840e-01, 3.6327e-02, 3.1195e-01, 2.7605e-02],\n",
      "        [4.5360e-01, 2.9597e-02, 2.8457e-01, 2.0029e-02],\n",
      "        [3.0188e-01, 1.4163e-02, 4.3481e-01, 2.0934e-02],\n",
      "        [4.9937e-01, 4.3645e-02, 6.1055e-01, 1.5687e-02],\n",
      "        [4.7196e-01, 3.4499e-02, 3.7310e-01, 3.1579e-02],\n",
      "        [5.3670e-01, 5.2423e-03, 1.6009e-01, 3.9999e-03],\n",
      "        [3.2965e-01, 1.2399e-02, 4.7328e-01, 6.3898e-04],\n",
      "        [5.3105e-01, 2.8309e-01, 7.5661e-01, 1.7374e-01],\n",
      "        [3.5863e-01, 7.5543e-02, 6.0847e-01, 1.4870e-01],\n",
      "        [6.1091e-01, 6.9441e-02, 7.1288e-01, 4.7621e-02],\n",
      "        [6.7201e-01, 1.7898e-02, 1.8710e-01, 1.6067e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0890, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.8827858900488885\n",
      "Epoch 1, Loss: -2.7098496763537483\n",
      "Epoch 1, Loss: -2.162290041634136\n",
      "Epoch 1, Loss: -3.012242358088902\n",
      "Epoch 1, Loss: -3.0380873299509283\n",
      "tensor([[0.7642, 0.0196, 0.4950, 0.0228],\n",
      "        [0.5623, 0.0532, 0.4517, 0.0676],\n",
      "        [0.2005, 0.0324, 0.3446, 0.0598],\n",
      "        [0.5023, 0.0969, 0.6971, 0.0632],\n",
      "        [0.5218, 0.0352, 0.4280, 0.0693],\n",
      "        [0.6241, 0.0571, 0.7164, 0.0257],\n",
      "        [0.3788, 0.0579, 0.4349, 0.0227],\n",
      "        [0.6207, 0.0388, 0.4255, 0.0543],\n",
      "        [0.4013, 0.0345, 0.3352, 0.0396],\n",
      "        [0.2028, 0.0720, 0.3291, 0.0328],\n",
      "        [0.1917, 0.0473, 0.3260, 0.0795],\n",
      "        [0.3444, 0.0358, 0.7504, 0.0225],\n",
      "        [0.6377, 0.0286, 0.9166, 0.0231],\n",
      "        [0.8233, 0.0085, 0.4468, 0.0116],\n",
      "        [0.5271, 0.0230, 0.8543, 0.0039],\n",
      "        [0.5920, 0.0513, 0.5731, 0.0229],\n",
      "        [0.3394, 0.1355, 0.4513, 0.0600],\n",
      "        [0.6562, 0.0215, 0.3119, 0.0475],\n",
      "        [0.4884, 0.0388, 0.5193, 0.1071],\n",
      "        [0.1306, 0.0131, 0.4158, 0.0105],\n",
      "        [0.3329, 0.0289, 0.8982, 0.0296],\n",
      "        [0.7342, 0.0146, 0.3862, 0.0130],\n",
      "        [0.6949, 0.0172, 0.6066, 0.0117],\n",
      "        [0.1985, 0.0471, 0.2435, 0.0537],\n",
      "        [0.7729, 0.0142, 0.7873, 0.0022],\n",
      "        [0.5398, 0.0713, 0.8815, 0.0396],\n",
      "        [0.4290, 0.0317, 0.2455, 0.0322],\n",
      "        [0.7738, 0.0313, 0.5392, 0.0191],\n",
      "        [0.5731, 0.0434, 0.3954, 0.0515],\n",
      "        [0.5544, 0.0338, 0.4770, 0.0386],\n",
      "        [0.5152, 0.0120, 0.9455, 0.0366],\n",
      "        [0.1394, 0.0099, 0.2113, 0.0195]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0846, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.833218768611151\n",
      "Epoch 1, Loss: -2.7913340716959105\n",
      "Epoch 1, Loss: -2.980231235181785\n",
      "Epoch 1, Loss: -2.988552357944222\n",
      "Epoch 1, Loss: -2.746391011258071\n",
      "tensor([[0.8632, 0.0295, 0.5765, 0.0076],\n",
      "        [0.2661, 0.0317, 0.3648, 0.0131],\n",
      "        [0.5371, 0.0350, 0.5963, 0.0394],\n",
      "        [0.5905, 0.0036, 0.6402, 0.0098],\n",
      "        [0.3152, 0.0156, 0.7621, 0.0056],\n",
      "        [0.8844, 0.0064, 0.4685, 0.0080],\n",
      "        [0.2609, 0.0230, 0.6151, 0.0165],\n",
      "        [0.4375, 0.0380, 0.4394, 0.0419],\n",
      "        [0.4212, 0.0519, 0.2453, 0.0847],\n",
      "        [0.7396, 0.0101, 0.5075, 0.0067],\n",
      "        [0.3110, 0.0159, 0.6888, 0.0521],\n",
      "        [0.6025, 0.1474, 0.8133, 0.0528],\n",
      "        [0.7553, 0.0177, 0.4405, 0.0330],\n",
      "        [0.3031, 0.0468, 0.7560, 0.0454],\n",
      "        [0.2246, 0.0392, 0.3448, 0.0569],\n",
      "        [0.3941, 0.1710, 0.4703, 0.0645],\n",
      "        [0.2813, 0.0184, 0.2182, 0.0366],\n",
      "        [0.2162, 0.0823, 0.7667, 0.0611],\n",
      "        [0.1567, 0.0267, 0.5631, 0.0298],\n",
      "        [0.4164, 0.0855, 0.3499, 0.1577],\n",
      "        [0.5846, 0.0690, 0.7661, 0.0145],\n",
      "        [0.5054, 0.0296, 0.7091, 0.0087],\n",
      "        [0.5685, 0.0175, 0.3280, 0.0462],\n",
      "        [0.3315, 0.0873, 0.6839, 0.0862],\n",
      "        [0.5957, 0.0184, 0.4475, 0.0211],\n",
      "        [0.2894, 0.1642, 0.2445, 0.1096],\n",
      "        [0.3696, 0.0276, 0.8088, 0.0496],\n",
      "        [0.7397, 0.0168, 0.2544, 0.0276],\n",
      "        [0.2878, 0.1039, 0.2883, 0.1565],\n",
      "        [0.1107, 0.0143, 0.1658, 0.0285],\n",
      "        [0.3666, 0.0598, 0.8450, 0.0301],\n",
      "        [0.8958, 0.0043, 0.5839, 0.0024]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0945, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.048195010991312\n",
      "Epoch 1, Loss: -2.6923875278673384\n",
      "Epoch 1, Loss: -1.5248256533175795\n",
      "Epoch 1, Loss: -3.010351574036065\n",
      "Epoch 1, Loss: -3.0186801236323424\n",
      "tensor([[5.6865e-01, 1.3333e-01, 5.0563e-01, 1.7527e-01],\n",
      "        [3.1899e-01, 9.0028e-02, 2.5902e-01, 7.5741e-02],\n",
      "        [6.1373e-01, 2.2022e-02, 5.2333e-01, 2.1488e-02],\n",
      "        [6.9987e-01, 2.3877e-02, 4.8047e-01, 3.0513e-02],\n",
      "        [8.5382e-01, 4.1745e-03, 2.0616e-01, 4.8564e-04],\n",
      "        [7.2265e-01, 1.1196e-02, 7.5578e-01, 6.1912e-03],\n",
      "        [5.9667e-01, 1.9128e-01, 4.2554e-01, 1.2460e-01],\n",
      "        [6.9299e-02, 4.2798e-03, 7.4813e-01, 3.3006e-02],\n",
      "        [6.1357e-01, 2.7517e-02, 7.8638e-01, 8.6706e-03],\n",
      "        [4.3071e-01, 3.6775e-02, 3.7788e-01, 3.0977e-02],\n",
      "        [2.5817e-01, 8.2659e-02, 5.9835e-01, 1.0284e-01],\n",
      "        [6.0076e-01, 1.8974e-02, 4.2647e-01, 1.7012e-02],\n",
      "        [5.8738e-01, 2.3989e-02, 6.0158e-01, 6.3593e-03],\n",
      "        [9.5902e-02, 8.1162e-03, 6.8447e-01, 1.0041e-02],\n",
      "        [7.8860e-01, 1.5950e-02, 6.2702e-01, 2.2578e-02],\n",
      "        [6.9273e-01, 7.7401e-02, 6.2631e-01, 5.1958e-02],\n",
      "        [7.9534e-01, 7.7811e-02, 7.6706e-01, 2.4535e-02],\n",
      "        [7.8164e-01, 1.2977e-02, 7.3162e-01, 1.2378e-02],\n",
      "        [6.2166e-01, 5.3639e-02, 4.2703e-01, 1.1580e-01],\n",
      "        [1.6013e-01, 4.9517e-02, 4.3655e-01, 3.9368e-02],\n",
      "        [1.8406e-01, 1.0920e-01, 1.1905e-01, 5.8571e-02],\n",
      "        [7.0761e-01, 4.6827e-02, 6.9321e-01, 7.5372e-02],\n",
      "        [1.7137e-01, 6.5996e-03, 8.3877e-01, 1.3778e-02],\n",
      "        [3.9456e-01, 3.5404e-02, 7.7760e-01, 8.0687e-02],\n",
      "        [7.3998e-01, 5.5532e-03, 3.8146e-01, 1.2843e-02],\n",
      "        [5.6057e-01, 3.8206e-02, 5.3083e-01, 1.7230e-02],\n",
      "        [7.7021e-02, 5.3926e-03, 2.7915e-01, 1.5095e-02],\n",
      "        [4.7037e-01, 3.0952e-02, 2.2330e-01, 5.6009e-02],\n",
      "        [3.2059e-01, 1.0229e-01, 5.3469e-01, 7.0916e-02],\n",
      "        [1.4098e-01, 2.1492e-02, 1.8368e-01, 3.9709e-02],\n",
      "        [5.7430e-01, 3.1096e-02, 2.2050e-01, 4.6418e-02],\n",
      "        [2.1304e-01, 8.6603e-02, 2.2923e-01, 6.5053e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0804, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.0406265174420977\n",
      "Epoch 1, Loss: -3.1869849957547105\n",
      "Epoch 1, Loss: -2.612632984374997\n",
      "Epoch 1, Loss: -3.022860945668172\n",
      "Epoch 1, Loss: -2.9711192807351505\n",
      "tensor([[0.2286, 0.0295, 0.3091, 0.0345],\n",
      "        [0.3845, 0.0525, 0.3562, 0.0435],\n",
      "        [0.5963, 0.0352, 0.5868, 0.0281],\n",
      "        [0.2314, 0.0201, 0.5565, 0.0392],\n",
      "        [0.5459, 0.0415, 0.7632, 0.0137],\n",
      "        [0.5098, 0.0899, 0.4647, 0.0841],\n",
      "        [0.5021, 0.0274, 0.6833, 0.0202],\n",
      "        [0.5339, 0.0174, 0.5954, 0.0218],\n",
      "        [0.5344, 0.0506, 0.3440, 0.1118],\n",
      "        [0.3333, 0.1033, 0.2436, 0.1470],\n",
      "        [0.6840, 0.0631, 0.5220, 0.0834],\n",
      "        [0.5239, 0.0174, 0.3249, 0.0186],\n",
      "        [0.4370, 0.0190, 0.4694, 0.0362],\n",
      "        [0.6182, 0.0115, 0.5040, 0.0278],\n",
      "        [0.7259, 0.0175, 0.2770, 0.0203],\n",
      "        [0.7027, 0.0240, 0.4062, 0.0269],\n",
      "        [0.7449, 0.0292, 0.5295, 0.0709],\n",
      "        [0.3236, 0.0786, 0.7617, 0.0412],\n",
      "        [0.5107, 0.0869, 0.4193, 0.1526],\n",
      "        [0.4286, 0.0223, 0.1984, 0.0259],\n",
      "        [0.3795, 0.0191, 0.6540, 0.0295],\n",
      "        [0.4582, 0.0276, 0.5790, 0.0229],\n",
      "        [0.2449, 0.0253, 0.7003, 0.0333],\n",
      "        [0.4538, 0.0245, 0.3832, 0.0306],\n",
      "        [0.2981, 0.0109, 0.4129, 0.0101],\n",
      "        [0.8216, 0.0111, 0.8095, 0.0262],\n",
      "        [0.5602, 0.0260, 0.4027, 0.0357],\n",
      "        [0.7713, 0.0025, 0.6537, 0.0014],\n",
      "        [0.6353, 0.0393, 0.5956, 0.1084],\n",
      "        [0.4124, 0.0044, 0.0963, 0.0095],\n",
      "        [0.8280, 0.0299, 0.7012, 0.0316],\n",
      "        [0.2105, 0.0048, 0.2570, 0.0058]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0816, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.03071478691352\n",
      "Epoch 1, Loss: -2.702227759370742\n",
      "Epoch 1, Loss: -3.1556429920406703\n",
      "Epoch 1, Loss: -3.090230107270887\n",
      "Epoch 1, Loss: -3.244720823262808\n",
      "tensor([[0.3904, 0.0128, 0.5555, 0.0105],\n",
      "        [0.3693, 0.0058, 0.3735, 0.0187],\n",
      "        [0.7395, 0.0108, 0.4060, 0.0246],\n",
      "        [0.7781, 0.0115, 0.6470, 0.0064],\n",
      "        [0.6397, 0.0415, 0.4262, 0.0551],\n",
      "        [0.3949, 0.0197, 0.3563, 0.0220],\n",
      "        [0.4597, 0.0783, 0.4737, 0.1090],\n",
      "        [0.5184, 0.0212, 0.5708, 0.0194],\n",
      "        [0.5206, 0.0516, 0.5472, 0.0568],\n",
      "        [0.5814, 0.0920, 0.3385, 0.1122],\n",
      "        [0.5326, 0.0177, 0.2963, 0.0700],\n",
      "        [0.4632, 0.0524, 0.5010, 0.0755],\n",
      "        [0.5128, 0.0323, 0.5221, 0.0395],\n",
      "        [0.7385, 0.0100, 0.6405, 0.0175],\n",
      "        [0.4214, 0.0283, 0.7447, 0.0569],\n",
      "        [0.3221, 0.0031, 0.3121, 0.0088],\n",
      "        [0.4339, 0.0599, 0.6276, 0.0338],\n",
      "        [0.4502, 0.0698, 0.4643, 0.1001],\n",
      "        [0.7576, 0.0055, 0.2514, 0.0099],\n",
      "        [0.2412, 0.0318, 0.4077, 0.0453],\n",
      "        [0.5208, 0.0414, 0.7572, 0.0146],\n",
      "        [0.1116, 0.0096, 0.6700, 0.0056],\n",
      "        [0.4900, 0.0386, 0.1877, 0.0872],\n",
      "        [0.7859, 0.0053, 0.7574, 0.0069],\n",
      "        [0.6372, 0.0057, 0.3383, 0.0149],\n",
      "        [0.4961, 0.0537, 0.3997, 0.0402],\n",
      "        [0.5231, 0.0354, 0.3823, 0.0430],\n",
      "        [0.3984, 0.0457, 0.7360, 0.0462],\n",
      "        [0.2853, 0.0724, 0.6047, 0.1224],\n",
      "        [0.7636, 0.0124, 0.2804, 0.0194],\n",
      "        [0.4016, 0.0204, 0.3317, 0.0859],\n",
      "        [0.4609, 0.0201, 0.6686, 0.0288]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0769, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.2644777857009677\n",
      "Epoch 1, Loss: -3.1883244614699944\n",
      "Epoch 1, Loss: -3.2538914943593804\n",
      "Epoch 1, Loss: -3.3809444443946735\n",
      "Epoch 1, Loss: -3.0803000249480146\n",
      "tensor([[0.4359, 0.0189, 0.2776, 0.0503],\n",
      "        [0.4340, 0.0413, 0.6881, 0.0278],\n",
      "        [0.3739, 0.0597, 0.5417, 0.0540],\n",
      "        [0.2284, 0.0103, 0.8173, 0.0152],\n",
      "        [0.4839, 0.0528, 0.3118, 0.1222],\n",
      "        [0.5498, 0.0175, 0.4467, 0.0266],\n",
      "        [0.4804, 0.0099, 0.6683, 0.0069],\n",
      "        [0.7895, 0.0067, 0.7631, 0.0172],\n",
      "        [0.3488, 0.0407, 0.6528, 0.0285],\n",
      "        [0.2507, 0.0251, 0.2998, 0.0291],\n",
      "        [0.6809, 0.0208, 0.2575, 0.0342],\n",
      "        [0.3845, 0.0361, 0.4711, 0.0779],\n",
      "        [0.6771, 0.0524, 0.4659, 0.1208],\n",
      "        [0.4096, 0.0126, 0.3339, 0.0107],\n",
      "        [0.3858, 0.0160, 0.1242, 0.0259],\n",
      "        [0.3756, 0.0452, 0.6001, 0.0343],\n",
      "        [0.5100, 0.0439, 0.3291, 0.0550],\n",
      "        [0.4361, 0.0329, 0.6656, 0.0236],\n",
      "        [0.1864, 0.0103, 0.6553, 0.0385],\n",
      "        [0.3545, 0.0538, 0.6599, 0.0650],\n",
      "        [0.4951, 0.0375, 0.6539, 0.0475],\n",
      "        [0.5082, 0.0966, 0.2521, 0.0551],\n",
      "        [0.4917, 0.0418, 0.4344, 0.0549],\n",
      "        [0.7103, 0.0271, 0.3657, 0.0363],\n",
      "        [0.7158, 0.0167, 0.2733, 0.0321],\n",
      "        [0.7535, 0.0049, 0.6330, 0.0124],\n",
      "        [0.4799, 0.0207, 0.3814, 0.0178],\n",
      "        [0.5741, 0.0724, 0.5044, 0.0709],\n",
      "        [0.3172, 0.0088, 0.4804, 0.0338],\n",
      "        [0.6416, 0.0066, 0.4355, 0.0168],\n",
      "        [0.7820, 0.0198, 0.8016, 0.0136],\n",
      "        [0.4204, 0.0368, 0.7886, 0.0233]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0915, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.256976045146697\n",
      "Epoch 1, Loss: -3.20313120761425\n",
      "Epoch 1, Loss: -3.20754848213496\n",
      "Epoch 1, Loss: -3.339219421328463\n",
      "Epoch 1, Loss: -3.3611815674675167\n",
      "tensor([[0.1682, 0.0046, 0.2311, 0.0115],\n",
      "        [0.3242, 0.0333, 0.2851, 0.0521],\n",
      "        [0.7517, 0.0180, 0.4329, 0.0238],\n",
      "        [0.4826, 0.0889, 0.5560, 0.0731],\n",
      "        [0.7987, 0.0049, 0.5069, 0.0067],\n",
      "        [0.2469, 0.0067, 0.3961, 0.0127],\n",
      "        [0.1713, 0.0127, 0.7130, 0.0105],\n",
      "        [0.4060, 0.0411, 0.6234, 0.0348],\n",
      "        [0.5378, 0.0127, 0.2347, 0.0231],\n",
      "        [0.5099, 0.1098, 0.4789, 0.0538],\n",
      "        [0.5154, 0.0111, 0.2968, 0.0091],\n",
      "        [0.3181, 0.0170, 0.7522, 0.0274],\n",
      "        [0.2011, 0.0036, 0.5937, 0.0093],\n",
      "        [0.6661, 0.0330, 0.2965, 0.0282],\n",
      "        [0.5146, 0.0269, 0.6927, 0.0062],\n",
      "        [0.3459, 0.0259, 0.8057, 0.0280],\n",
      "        [0.5154, 0.0308, 0.5508, 0.0296],\n",
      "        [0.7563, 0.0456, 0.3891, 0.0273],\n",
      "        [0.3680, 0.0196, 0.7305, 0.0106],\n",
      "        [0.3482, 0.0062, 0.2134, 0.0056],\n",
      "        [0.2384, 0.0068, 0.2029, 0.0184],\n",
      "        [0.4991, 0.0194, 0.7669, 0.0577],\n",
      "        [0.4075, 0.0251, 0.4704, 0.0211],\n",
      "        [0.6525, 0.0225, 0.5173, 0.0559],\n",
      "        [0.6666, 0.0097, 0.6026, 0.0058],\n",
      "        [0.5613, 0.0960, 0.3714, 0.0709],\n",
      "        [0.4796, 0.0134, 0.7689, 0.0272],\n",
      "        [0.4554, 0.0130, 0.5182, 0.0320],\n",
      "        [0.4651, 0.0335, 0.4818, 0.0253],\n",
      "        [0.5970, 0.0357, 0.1934, 0.0124],\n",
      "        [0.5339, 0.0509, 0.3448, 0.0421],\n",
      "        [0.5053, 0.0059, 0.8671, 0.0109]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0890, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.1209025467533884\n",
      "Epoch 1, Loss: -2.9236245966144194\n",
      "Epoch 1, Loss: -3.3195943680165323\n",
      "Epoch 1, Loss: -3.590763807702812\n",
      "Epoch 1, Loss: -1.2054276960103931\n",
      "tensor([[4.9844e-01, 3.0451e-02, 5.4517e-01, 2.8037e-02],\n",
      "        [6.0245e-01, 1.0656e-01, 6.2860e-01, 5.7939e-02],\n",
      "        [7.7278e-01, 1.8647e-03, 7.4235e-01, 3.1993e-03],\n",
      "        [5.8644e-01, 1.8092e-02, 6.6170e-01, 1.5507e-02],\n",
      "        [6.1589e-01, 6.8447e-02, 5.2898e-01, 8.2361e-02],\n",
      "        [6.5862e-01, 2.9596e-02, 4.3030e-01, 1.1149e-02],\n",
      "        [5.9723e-01, 5.2338e-03, 3.0628e-01, 1.3039e-02],\n",
      "        [1.6582e-01, 2.6625e-03, 8.1624e-01, 3.7579e-03],\n",
      "        [7.6922e-01, 7.6459e-03, 5.1995e-01, 7.9648e-03],\n",
      "        [6.7421e-01, 1.4347e-02, 6.6770e-01, 3.5534e-02],\n",
      "        [3.6418e-01, 2.0453e-02, 3.2635e-01, 8.5462e-03],\n",
      "        [4.1977e-01, 3.1296e-03, 1.6007e-01, 1.8440e-03],\n",
      "        [5.2715e-01, 2.3478e-02, 6.9596e-01, 1.4992e-02],\n",
      "        [3.7083e-01, 6.2685e-03, 3.7980e-01, 1.1137e-02],\n",
      "        [5.7527e-01, 1.6065e-01, 3.8715e-01, 9.3613e-02],\n",
      "        [5.1967e-01, 1.2607e-02, 2.9145e-01, 7.7609e-03],\n",
      "        [4.0806e-01, 1.9845e-02, 6.6151e-01, 3.4586e-02],\n",
      "        [6.1631e-01, 2.8699e-02, 2.0094e-01, 4.5490e-02],\n",
      "        [1.5069e-01, 3.6092e-04, 2.4029e-01, 7.7323e-04],\n",
      "        [5.1447e-01, 2.2131e-02, 4.8575e-01, 1.6556e-02],\n",
      "        [3.0137e-01, 7.9778e-03, 7.8260e-01, 7.9070e-03],\n",
      "        [4.9033e-01, 1.2758e-02, 5.2074e-01, 5.9651e-03],\n",
      "        [5.5484e-01, 7.0863e-02, 3.8364e-01, 5.7742e-02],\n",
      "        [6.2938e-01, 1.8490e-02, 2.1375e-01, 1.4831e-02],\n",
      "        [6.2528e-01, 5.8596e-02, 5.0394e-01, 7.8401e-02],\n",
      "        [3.1091e-01, 2.2223e-02, 4.6892e-01, 1.5814e-02],\n",
      "        [7.6240e-01, 1.2663e-02, 4.7299e-01, 3.4630e-02],\n",
      "        [4.9838e-01, 1.3436e-02, 2.6098e-01, 3.1417e-02],\n",
      "        [1.9701e-01, 5.7756e-03, 4.4046e-01, 1.1465e-02],\n",
      "        [7.0116e-01, 1.5856e-02, 7.3710e-01, 1.7841e-02],\n",
      "        [2.3687e-01, 2.2458e-02, 6.6245e-01, 3.3701e-02],\n",
      "        [1.7151e-01, 1.7601e-02, 7.2414e-01, 1.4380e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0822, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.525431445834675\n",
      "Epoch 1, Loss: -3.3975542864634987\n",
      "Epoch 1, Loss: -3.407615823104238\n",
      "Epoch 1, Loss: -2.618417449841152\n",
      "Epoch 1, Loss: -3.5012203641424993\n",
      "tensor([[4.3911e-01, 1.6740e-02, 4.8028e-01, 2.8741e-02],\n",
      "        [2.0792e-01, 5.8706e-03, 2.9405e-01, 7.2340e-03],\n",
      "        [4.1637e-01, 3.7307e-02, 1.9436e-01, 8.6047e-03],\n",
      "        [5.9579e-01, 2.7371e-02, 6.8613e-01, 4.8720e-02],\n",
      "        [2.3767e-01, 1.0530e-02, 7.1369e-01, 1.2322e-02],\n",
      "        [5.9691e-01, 5.9427e-02, 7.4189e-01, 2.5501e-02],\n",
      "        [5.8732e-01, 3.3240e-02, 2.9546e-01, 9.5149e-03],\n",
      "        [4.0740e-01, 3.3602e-02, 5.4213e-01, 3.6875e-02],\n",
      "        [7.5523e-01, 1.2261e-03, 6.5452e-01, 2.7413e-03],\n",
      "        [6.2329e-01, 6.7176e-02, 4.7100e-01, 3.4149e-02],\n",
      "        [6.0818e-01, 1.4038e-02, 5.7537e-01, 1.3716e-02],\n",
      "        [4.4738e-01, 2.4660e-02, 6.1844e-01, 1.2231e-02],\n",
      "        [3.1330e-01, 9.2576e-03, 5.4559e-01, 1.3768e-02],\n",
      "        [3.6479e-01, 2.7832e-02, 2.1648e-01, 1.5000e-02],\n",
      "        [8.2057e-01, 1.7805e-02, 6.1282e-01, 1.7052e-02],\n",
      "        [1.9471e-01, 4.4026e-03, 7.2597e-01, 2.0603e-02],\n",
      "        [3.3783e-01, 2.7935e-02, 5.1357e-01, 2.6479e-02],\n",
      "        [5.6024e-01, 2.4361e-02, 2.8412e-01, 2.2615e-02],\n",
      "        [3.8581e-01, 1.3206e-02, 6.2027e-01, 2.0270e-02],\n",
      "        [4.7955e-01, 4.1095e-02, 5.1669e-01, 2.2574e-02],\n",
      "        [6.5183e-01, 1.6422e-02, 7.0693e-01, 1.6219e-02],\n",
      "        [8.2850e-01, 7.3430e-04, 6.6200e-01, 3.5575e-03],\n",
      "        [7.6299e-01, 9.2984e-03, 6.2270e-01, 1.0819e-02],\n",
      "        [7.2924e-01, 1.8873e-02, 4.4548e-01, 9.9414e-03],\n",
      "        [6.0368e-01, 1.1390e-01, 7.0894e-01, 6.1689e-02],\n",
      "        [2.0312e-01, 6.2756e-03, 5.3138e-01, 1.3405e-02],\n",
      "        [3.9126e-01, 1.9381e-02, 5.8328e-01, 2.2550e-02],\n",
      "        [4.2748e-01, 3.8494e-02, 5.3365e-01, 4.7788e-02],\n",
      "        [8.4138e-01, 5.0673e-03, 6.5146e-01, 1.3306e-02],\n",
      "        [6.8079e-01, 2.7159e-02, 6.3627e-01, 2.8015e-02],\n",
      "        [6.5424e-01, 3.8807e-03, 1.0103e-01, 9.4749e-03],\n",
      "        [1.6751e-01, 1.7235e-02, 7.2219e-01, 2.6262e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0783, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.4470266777327065\n",
      "Epoch 1, Loss: -3.218101048236158\n",
      "Epoch 1, Loss: -2.692566053126106\n",
      "Epoch 1, Loss: -3.219070505104309\n",
      "Epoch 1, Loss: -3.5107624359493608\n",
      "tensor([[0.3293, 0.0308, 0.4129, 0.0161],\n",
      "        [0.2730, 0.0164, 0.3072, 0.0087],\n",
      "        [0.6345, 0.0146, 0.8413, 0.0083],\n",
      "        [0.8259, 0.0019, 0.7654, 0.0022],\n",
      "        [0.7365, 0.0051, 0.4189, 0.0054],\n",
      "        [0.5202, 0.0412, 0.4532, 0.0197],\n",
      "        [0.3153, 0.0285, 0.4930, 0.0557],\n",
      "        [0.5335, 0.0055, 0.2074, 0.0049],\n",
      "        [0.6090, 0.0164, 0.5996, 0.0096],\n",
      "        [0.7196, 0.0091, 0.4483, 0.0052],\n",
      "        [0.5737, 0.0256, 0.6690, 0.0101],\n",
      "        [0.6361, 0.0638, 0.4793, 0.0420],\n",
      "        [0.8068, 0.0067, 0.4595, 0.0070],\n",
      "        [0.4177, 0.0198, 0.5076, 0.0132],\n",
      "        [0.2450, 0.0068, 0.5770, 0.0067],\n",
      "        [0.4531, 0.0710, 0.6431, 0.0288],\n",
      "        [0.3831, 0.0311, 0.4385, 0.1021],\n",
      "        [0.4329, 0.0349, 0.4733, 0.0549],\n",
      "        [0.6653, 0.0292, 0.8058, 0.0279],\n",
      "        [0.6280, 0.0340, 0.5952, 0.0596],\n",
      "        [0.6454, 0.0365, 0.6099, 0.0161],\n",
      "        [0.7956, 0.0084, 0.4375, 0.0110],\n",
      "        [0.5985, 0.0098, 0.6861, 0.0089],\n",
      "        [0.3673, 0.0193, 0.7008, 0.0288],\n",
      "        [0.4621, 0.0237, 0.5630, 0.0326],\n",
      "        [0.6390, 0.0202, 0.5618, 0.0217],\n",
      "        [0.3693, 0.0303, 0.7223, 0.0228],\n",
      "        [0.5198, 0.0613, 0.5920, 0.0323],\n",
      "        [0.1208, 0.0141, 0.4624, 0.0155],\n",
      "        [0.6673, 0.0110, 0.7290, 0.0157],\n",
      "        [0.3279, 0.0676, 0.7716, 0.0366],\n",
      "        [0.4024, 0.0266, 0.6042, 0.0378]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0661, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.366844793443782\n",
      "Epoch 1, Loss: -2.781362915391758\n",
      "Epoch 1, Loss: -3.1406275886507924\n",
      "Epoch 1, Loss: -3.2561344675294404\n",
      "Epoch 1, Loss: -3.734381274735198\n",
      "tensor([[0.4175, 0.0289, 0.5773, 0.0164],\n",
      "        [0.2116, 0.0162, 0.5754, 0.0181],\n",
      "        [0.6354, 0.0279, 0.5879, 0.0325],\n",
      "        [0.8357, 0.0152, 0.2313, 0.0091],\n",
      "        [0.2995, 0.0176, 0.2090, 0.0077],\n",
      "        [0.6614, 0.0053, 0.5570, 0.0024],\n",
      "        [0.4035, 0.0435, 0.3807, 0.0692],\n",
      "        [0.6275, 0.0124, 0.2957, 0.0475],\n",
      "        [0.5381, 0.0358, 0.6209, 0.0197],\n",
      "        [0.5943, 0.0895, 0.5583, 0.0377],\n",
      "        [0.5825, 0.0226, 0.7853, 0.0072],\n",
      "        [0.6550, 0.0623, 0.4527, 0.0226],\n",
      "        [0.4461, 0.0938, 0.4596, 0.0690],\n",
      "        [0.6346, 0.0427, 0.3494, 0.0261],\n",
      "        [0.5018, 0.0112, 0.8555, 0.0019],\n",
      "        [0.6162, 0.0229, 0.2577, 0.0134],\n",
      "        [0.7308, 0.0046, 0.7050, 0.0024],\n",
      "        [0.3379, 0.0445, 0.3589, 0.0588],\n",
      "        [0.1719, 0.0186, 0.4828, 0.0272],\n",
      "        [0.3197, 0.1205, 0.4744, 0.1225],\n",
      "        [0.6719, 0.0029, 0.2599, 0.0059],\n",
      "        [0.7876, 0.0030, 0.4103, 0.0033],\n",
      "        [0.3814, 0.0132, 0.3882, 0.0170],\n",
      "        [0.1510, 0.0285, 0.7813, 0.0199],\n",
      "        [0.5888, 0.0032, 0.1927, 0.0022],\n",
      "        [0.1743, 0.0044, 0.8513, 0.0088],\n",
      "        [0.2351, 0.0108, 0.6792, 0.0065],\n",
      "        [0.5190, 0.0296, 0.3910, 0.0215],\n",
      "        [0.2688, 0.0318, 0.7602, 0.0387],\n",
      "        [0.7706, 0.0203, 0.4856, 0.0049],\n",
      "        [0.5095, 0.0519, 0.5515, 0.0379],\n",
      "        [0.7603, 0.0142, 0.4118, 0.0046]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0566, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.6948950126970153\n",
      "Epoch 1, Loss: -2.9317300996333158\n",
      "Epoch 1, Loss: -3.3116951963615224\n",
      "Epoch 1, Loss: -3.5126266279150675\n",
      "Epoch 1, Loss: -3.3634469404099736\n",
      "tensor([[0.3654, 0.0118, 0.4908, 0.0207],\n",
      "        [0.2003, 0.0254, 0.6759, 0.0130],\n",
      "        [0.4738, 0.0541, 0.5653, 0.0433],\n",
      "        [0.5906, 0.0436, 0.7120, 0.0307],\n",
      "        [0.3058, 0.0087, 0.6513, 0.0188],\n",
      "        [0.3914, 0.0431, 0.5697, 0.0347],\n",
      "        [0.5273, 0.0268, 0.2562, 0.0268],\n",
      "        [0.6596, 0.0263, 0.6761, 0.0250],\n",
      "        [0.6537, 0.0547, 0.6124, 0.1096],\n",
      "        [0.6540, 0.0396, 0.3738, 0.0283],\n",
      "        [0.7051, 0.0320, 0.6494, 0.0302],\n",
      "        [0.7531, 0.0042, 0.7831, 0.0074],\n",
      "        [0.2600, 0.0048, 0.6882, 0.0111],\n",
      "        [0.6826, 0.0106, 0.3939, 0.0088],\n",
      "        [0.4764, 0.0178, 0.3291, 0.0218],\n",
      "        [0.6069, 0.0326, 0.2105, 0.0302],\n",
      "        [0.2773, 0.0112, 0.5399, 0.0235],\n",
      "        [0.7761, 0.0132, 0.7027, 0.0202],\n",
      "        [0.1853, 0.0079, 0.8083, 0.0044],\n",
      "        [0.6930, 0.0010, 0.1394, 0.0047],\n",
      "        [0.3106, 0.0140, 0.1789, 0.0150],\n",
      "        [0.6430, 0.0426, 0.4707, 0.0319],\n",
      "        [0.2846, 0.0091, 0.6225, 0.0043],\n",
      "        [0.4316, 0.1098, 0.5942, 0.0898],\n",
      "        [0.4890, 0.0359, 0.5979, 0.0506],\n",
      "        [0.4933, 0.0112, 0.1392, 0.0046],\n",
      "        [0.5234, 0.0497, 0.4532, 0.0224],\n",
      "        [0.5027, 0.0315, 0.4810, 0.0576],\n",
      "        [0.6729, 0.0363, 0.6923, 0.0347],\n",
      "        [0.2982, 0.0782, 0.1940, 0.0297],\n",
      "        [0.1723, 0.0057, 0.7577, 0.0204],\n",
      "        [0.5745, 0.0556, 0.5011, 0.0782]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0731, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.3406460855005955\n",
      "Epoch 1, Loss: -0.9151560571744675\n",
      "Epoch 1, Loss: -3.492377452136073\n",
      "Epoch 1, Loss: -3.5817446903048915\n",
      "Epoch 1, Loss: -3.0850725578599656\n",
      "tensor([[2.4408e-01, 4.7455e-02, 3.4866e-01, 7.5447e-02],\n",
      "        [8.7589e-01, 2.3507e-03, 4.6214e-01, 4.8099e-03],\n",
      "        [8.1355e-01, 2.9159e-03, 2.8444e-01, 2.0780e-03],\n",
      "        [3.3101e-01, 2.9787e-02, 6.8214e-01, 1.1083e-02],\n",
      "        [6.2316e-01, 1.5697e-02, 4.9040e-01, 1.5675e-02],\n",
      "        [7.0084e-01, 4.1263e-03, 2.5804e-01, 9.6764e-03],\n",
      "        [4.0606e-01, 3.4646e-02, 8.4129e-01, 1.5383e-02],\n",
      "        [6.9151e-01, 1.7555e-02, 4.4788e-01, 2.6954e-02],\n",
      "        [2.0619e-01, 1.1291e-02, 3.7997e-01, 3.1352e-02],\n",
      "        [4.2286e-01, 1.0764e-01, 6.9389e-01, 1.3500e-02],\n",
      "        [4.6635e-01, 1.0989e-02, 5.6159e-01, 7.1140e-03],\n",
      "        [4.5837e-01, 1.0177e-01, 6.5359e-01, 4.2568e-02],\n",
      "        [5.2904e-01, 1.9571e-02, 2.4292e-01, 7.4848e-03],\n",
      "        [4.9882e-01, 6.7467e-03, 5.6178e-01, 9.4827e-03],\n",
      "        [6.9094e-01, 9.0601e-04, 2.0861e-01, 6.7852e-04],\n",
      "        [7.4951e-01, 1.5293e-02, 7.9085e-01, 3.1945e-02],\n",
      "        [4.5307e-01, 8.4192e-03, 4.9335e-01, 8.4355e-03],\n",
      "        [2.3294e-01, 2.4244e-02, 3.9985e-01, 6.1885e-02],\n",
      "        [8.5933e-01, 7.3128e-03, 9.0405e-01, 6.0370e-03],\n",
      "        [5.6530e-01, 1.8127e-02, 6.1860e-01, 1.8724e-02],\n",
      "        [2.6083e-01, 4.2724e-02, 5.6255e-01, 1.7743e-02],\n",
      "        [5.3412e-01, 3.0945e-02, 6.3393e-01, 5.6782e-02],\n",
      "        [3.7606e-01, 5.7444e-02, 4.4141e-01, 9.4895e-02],\n",
      "        [5.0882e-01, 1.4100e-02, 5.0812e-01, 2.9413e-02],\n",
      "        [7.8292e-01, 1.0238e-02, 6.7983e-01, 1.5628e-02],\n",
      "        [4.4722e-01, 2.1621e-02, 3.1856e-01, 2.2745e-02],\n",
      "        [3.7619e-01, 6.6327e-02, 7.2558e-01, 4.1477e-02],\n",
      "        [3.4491e-01, 6.1426e-02, 4.9341e-01, 8.7787e-02],\n",
      "        [3.1588e-01, 1.7637e-02, 8.4894e-01, 2.1910e-03],\n",
      "        [3.3358e-01, 1.0479e-02, 4.4107e-01, 2.2332e-02],\n",
      "        [7.1222e-01, 5.5482e-03, 6.7633e-01, 9.4611e-03],\n",
      "        [4.2180e-01, 8.1740e-02, 6.3498e-01, 5.9724e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0873, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.803846073103501\n",
      "Epoch 1, Loss: -3.580285499772821\n",
      "Epoch 1, Loss: -2.2082921283063204\n",
      "Epoch 1, Loss: -1.7547220382572117\n",
      "Epoch 1, Loss: -3.34292575423017\n",
      "tensor([[0.6222, 0.0109, 0.7578, 0.0322],\n",
      "        [0.2689, 0.0204, 0.4247, 0.0270],\n",
      "        [0.5016, 0.0961, 0.7787, 0.0683],\n",
      "        [0.6754, 0.0206, 0.8334, 0.0301],\n",
      "        [0.3895, 0.0117, 0.2726, 0.0133],\n",
      "        [0.4856, 0.0148, 0.5670, 0.0154],\n",
      "        [0.6489, 0.0586, 0.6298, 0.0636],\n",
      "        [0.2697, 0.0054, 0.2125, 0.0039],\n",
      "        [0.8589, 0.0022, 0.3822, 0.0023],\n",
      "        [0.3613, 0.0392, 0.6384, 0.0087],\n",
      "        [0.5133, 0.0398, 0.3830, 0.0284],\n",
      "        [0.5729, 0.0141, 0.5401, 0.0204],\n",
      "        [0.6733, 0.0233, 0.5811, 0.0232],\n",
      "        [0.7520, 0.0275, 0.6261, 0.0518],\n",
      "        [0.3710, 0.0087, 0.1619, 0.0143],\n",
      "        [0.6914, 0.0149, 0.8390, 0.0394],\n",
      "        [0.4528, 0.0317, 0.4760, 0.0303],\n",
      "        [0.4136, 0.0475, 0.4134, 0.0233],\n",
      "        [0.3849, 0.0034, 0.4972, 0.0302],\n",
      "        [0.4922, 0.0789, 0.7867, 0.0280],\n",
      "        [0.6196, 0.0030, 0.4766, 0.0117],\n",
      "        [0.4117, 0.0076, 0.1767, 0.0129],\n",
      "        [0.4632, 0.1317, 0.6672, 0.0504],\n",
      "        [0.6969, 0.0300, 0.6385, 0.0331],\n",
      "        [0.6249, 0.2287, 0.5974, 0.0922],\n",
      "        [0.3196, 0.0209, 0.5532, 0.0286],\n",
      "        [0.4231, 0.3516, 0.6939, 0.0219],\n",
      "        [0.6365, 0.0063, 0.3498, 0.0033],\n",
      "        [0.4951, 0.0195, 0.1678, 0.0134],\n",
      "        [0.3407, 0.1072, 0.6293, 0.0746],\n",
      "        [0.2811, 0.0265, 0.5614, 0.0097],\n",
      "        [0.7989, 0.0090, 0.8451, 0.0132]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0820, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.3633035667531366\n",
      "Epoch 1, Loss: -2.724394117201355\n",
      "Epoch 1, Loss: -3.2380536704586347\n",
      "Epoch 1, Loss: -3.4233487134603395\n",
      "Epoch 1, Loss: -3.25920602642518\n",
      "tensor([[0.3593, 0.0146, 0.5693, 0.0209],\n",
      "        [0.2696, 0.0067, 0.7139, 0.0043],\n",
      "        [0.3948, 0.0790, 0.3956, 0.0770],\n",
      "        [0.2714, 0.0160, 0.3231, 0.0308],\n",
      "        [0.2977, 0.0220, 0.2727, 0.0109],\n",
      "        [0.6334, 0.0489, 0.3357, 0.0274],\n",
      "        [0.7160, 0.0545, 0.5851, 0.0522],\n",
      "        [0.4870, 0.0413, 0.2768, 0.0400],\n",
      "        [0.5702, 0.0358, 0.6251, 0.0335],\n",
      "        [0.7064, 0.0118, 0.5927, 0.0289],\n",
      "        [0.5918, 0.0472, 0.3870, 0.0471],\n",
      "        [0.2412, 0.0184, 0.2693, 0.0122],\n",
      "        [0.3294, 0.0217, 0.1999, 0.0064],\n",
      "        [0.6519, 0.0056, 0.6450, 0.0125],\n",
      "        [0.5422, 0.0724, 0.3847, 0.0289],\n",
      "        [0.3742, 0.0768, 0.2364, 0.0402],\n",
      "        [0.3464, 0.0214, 0.4969, 0.0288],\n",
      "        [0.7717, 0.0097, 0.7768, 0.0087],\n",
      "        [0.2240, 0.0135, 0.5774, 0.0124],\n",
      "        [0.2733, 0.0082, 0.5006, 0.0179],\n",
      "        [0.4925, 0.0813, 0.4992, 0.0577],\n",
      "        [0.5682, 0.1237, 0.6828, 0.0341],\n",
      "        [0.4106, 0.0384, 0.5509, 0.0176],\n",
      "        [0.5651, 0.0489, 0.4716, 0.0309],\n",
      "        [0.3393, 0.0122, 0.5147, 0.0089],\n",
      "        [0.6937, 0.0172, 0.7605, 0.0232],\n",
      "        [0.7702, 0.0086, 0.6251, 0.0060],\n",
      "        [0.5258, 0.2966, 0.7838, 0.0136],\n",
      "        [0.5015, 0.0068, 0.2272, 0.0070],\n",
      "        [0.4716, 0.0339, 0.6443, 0.0277],\n",
      "        [0.6317, 0.0244, 0.6640, 0.0619],\n",
      "        [0.4759, 0.0052, 0.3939, 0.0103]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0918, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.14967632971445\n",
      "Epoch 1, Loss: -3.403951844628714\n",
      "Epoch 1, Loss: -3.281592734914579\n",
      "Epoch 1, Loss: -2.9942065485488767\n",
      "Epoch 1, Loss: -3.443459814299928\n",
      "tensor([[0.5114, 0.0402, 0.3331, 0.0770],\n",
      "        [0.2327, 0.0130, 0.2445, 0.0013],\n",
      "        [0.5764, 0.0519, 0.4967, 0.0961],\n",
      "        [0.6972, 0.1028, 0.3561, 0.0340],\n",
      "        [0.3289, 0.0306, 0.3678, 0.0153],\n",
      "        [0.3601, 0.1813, 0.8498, 0.0032],\n",
      "        [0.4091, 0.0128, 0.1670, 0.0119],\n",
      "        [0.5969, 0.0276, 0.4001, 0.0353],\n",
      "        [0.3963, 0.0126, 0.5464, 0.0081],\n",
      "        [0.5715, 0.0147, 0.6027, 0.0212],\n",
      "        [0.6693, 0.0274, 0.4348, 0.0722],\n",
      "        [0.5335, 0.0032, 0.7037, 0.0113],\n",
      "        [0.5747, 0.0223, 0.7344, 0.0201],\n",
      "        [0.4064, 0.1540, 0.3204, 0.1245],\n",
      "        [0.4271, 0.0804, 0.5857, 0.0097],\n",
      "        [0.6468, 0.0143, 0.4967, 0.0261],\n",
      "        [0.6492, 0.0152, 0.5573, 0.0104],\n",
      "        [0.7188, 0.0207, 0.6533, 0.0064],\n",
      "        [0.3970, 0.0678, 0.7228, 0.0125],\n",
      "        [0.5635, 0.0213, 0.6508, 0.0243],\n",
      "        [0.4949, 0.0575, 0.3338, 0.0243],\n",
      "        [0.6688, 0.0220, 0.5964, 0.0455],\n",
      "        [0.5862, 0.0072, 0.5469, 0.0065],\n",
      "        [0.4364, 0.0184, 0.5065, 0.0170],\n",
      "        [0.4540, 0.0222, 0.6546, 0.0028],\n",
      "        [0.4715, 0.0990, 0.2891, 0.0458],\n",
      "        [0.3125, 0.0055, 0.3449, 0.0046],\n",
      "        [0.3181, 0.0678, 0.4963, 0.0530],\n",
      "        [0.2373, 0.0099, 0.5003, 0.0086],\n",
      "        [0.4523, 0.0200, 0.2643, 0.0246],\n",
      "        [0.6791, 0.0123, 0.5473, 0.0384],\n",
      "        [0.5173, 0.0548, 0.4741, 0.0496]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0674, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.2485640605863617\n",
      "Epoch 1, Loss: -3.0435772905660192\n",
      "Epoch 1, Loss: -3.16185944401219\n",
      "Epoch 1, Loss: -2.85924283175473\n",
      "Epoch 1, Loss: -3.0029959161671305\n",
      "tensor([[0.5312, 0.0452, 0.4211, 0.0667],\n",
      "        [0.5258, 0.1238, 0.3340, 0.1529],\n",
      "        [0.5610, 0.1158, 0.3885, 0.0565],\n",
      "        [0.4921, 0.0131, 0.3973, 0.0115],\n",
      "        [0.4101, 0.0249, 0.0615, 0.0076],\n",
      "        [0.4260, 0.0610, 0.5175, 0.0469],\n",
      "        [0.3085, 0.0158, 0.5352, 0.0069],\n",
      "        [0.4728, 0.1485, 0.2542, 0.0508],\n",
      "        [0.2949, 0.0359, 0.5054, 0.0179],\n",
      "        [0.6784, 0.0170, 0.5136, 0.0287],\n",
      "        [0.5385, 0.1173, 0.2560, 0.0735],\n",
      "        [0.5322, 0.1716, 0.4764, 0.0834],\n",
      "        [0.5475, 0.2403, 0.3223, 0.0758],\n",
      "        [0.3793, 0.0246, 0.7560, 0.0037],\n",
      "        [0.5973, 0.1949, 0.4362, 0.0337],\n",
      "        [0.6608, 0.0041, 0.6303, 0.0137],\n",
      "        [0.5065, 0.0253, 0.5101, 0.0238],\n",
      "        [0.5804, 0.0160, 0.5275, 0.0144],\n",
      "        [0.3499, 0.0187, 0.2623, 0.0172],\n",
      "        [0.6631, 0.0073, 0.6995, 0.0092],\n",
      "        [0.5333, 0.0594, 0.4549, 0.0437],\n",
      "        [0.5180, 0.1381, 0.3203, 0.1227],\n",
      "        [0.1291, 0.0054, 0.3114, 0.0053],\n",
      "        [0.2398, 0.0038, 0.5919, 0.0153],\n",
      "        [0.3718, 0.0155, 0.6371, 0.0089],\n",
      "        [0.4690, 0.0068, 0.5570, 0.0107],\n",
      "        [0.3711, 0.0026, 0.7480, 0.0061],\n",
      "        [0.4627, 0.0552, 0.6243, 0.0080],\n",
      "        [0.2775, 0.0025, 0.2788, 0.0070],\n",
      "        [0.3438, 0.0027, 0.3626, 0.0076],\n",
      "        [0.3911, 0.0543, 0.6755, 0.0055],\n",
      "        [0.5095, 0.1687, 0.7559, 0.0185]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0903, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.6223898030107855\n",
      "Epoch 1, Loss: -3.110703080333246\n",
      "Epoch 1, Loss: -3.3372570726538204\n",
      "Epoch 1, Loss: -2.5187689964381788\n",
      "Epoch 1, Loss: -2.9768126287908734\n",
      "tensor([[0.1702, 0.0356, 0.3831, 0.0150],\n",
      "        [0.7646, 0.0082, 0.6568, 0.0058],\n",
      "        [0.7120, 0.0593, 0.6933, 0.0154],\n",
      "        [0.5689, 0.0747, 0.4947, 0.0629],\n",
      "        [0.6815, 0.0750, 0.5819, 0.0293],\n",
      "        [0.5282, 0.0185, 0.1612, 0.0128],\n",
      "        [0.7482, 0.0352, 0.5115, 0.0142],\n",
      "        [0.3286, 0.0678, 0.5948, 0.0065],\n",
      "        [0.2349, 0.0064, 0.4338, 0.0030],\n",
      "        [0.5500, 0.0400, 0.6338, 0.0344],\n",
      "        [0.5801, 0.0120, 0.4065, 0.0208],\n",
      "        [0.5803, 0.0640, 0.3185, 0.0306],\n",
      "        [0.5472, 0.0165, 0.2661, 0.0076],\n",
      "        [0.6059, 0.0235, 0.6033, 0.0138],\n",
      "        [0.5818, 0.0238, 0.6464, 0.0164],\n",
      "        [0.4952, 0.1064, 0.6685, 0.0108],\n",
      "        [0.5661, 0.0463, 0.4043, 0.0200],\n",
      "        [0.4964, 0.0199, 0.3208, 0.0136],\n",
      "        [0.4980, 0.0595, 0.1945, 0.0307],\n",
      "        [0.5437, 0.0148, 0.5160, 0.0171],\n",
      "        [0.6720, 0.0727, 0.4480, 0.0206],\n",
      "        [0.1996, 0.0048, 0.1392, 0.0016],\n",
      "        [0.5865, 0.0097, 0.4123, 0.0075],\n",
      "        [0.5609, 0.0251, 0.7749, 0.0096],\n",
      "        [0.5931, 0.0267, 0.4018, 0.0226],\n",
      "        [0.5766, 0.0328, 0.6208, 0.0218],\n",
      "        [0.4475, 0.0221, 0.4236, 0.0238],\n",
      "        [0.4706, 0.0961, 0.5116, 0.0441],\n",
      "        [0.3447, 0.0921, 0.5226, 0.0129],\n",
      "        [0.5025, 0.0059, 0.6110, 0.0050],\n",
      "        [0.6079, 0.0165, 0.6323, 0.0062],\n",
      "        [0.4490, 0.1789, 0.5223, 0.1829]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0803, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.238489344267764\n",
      "Epoch 1, Loss: -3.3265277664017017\n",
      "Epoch 1, Loss: -3.4849484914520894\n",
      "Epoch 1, Loss: -3.383028698217442\n",
      "Epoch 1, Loss: -3.186661121367592\n",
      "tensor([[0.7842, 0.0126, 0.7940, 0.0071],\n",
      "        [0.6864, 0.0582, 0.4479, 0.0123],\n",
      "        [0.7053, 0.0308, 0.6008, 0.0114],\n",
      "        [0.4634, 0.0570, 0.3421, 0.0402],\n",
      "        [0.3194, 0.0255, 0.3291, 0.0144],\n",
      "        [0.5688, 0.0946, 0.9415, 0.0137],\n",
      "        [0.6314, 0.0723, 0.5176, 0.0132],\n",
      "        [0.5801, 0.0144, 0.5456, 0.0162],\n",
      "        [0.7986, 0.0475, 0.6208, 0.0235],\n",
      "        [0.6281, 0.0398, 0.8409, 0.0050],\n",
      "        [0.6948, 0.0205, 0.6268, 0.0096],\n",
      "        [0.4603, 0.0549, 0.3181, 0.0181],\n",
      "        [0.1855, 0.0064, 0.6102, 0.0212],\n",
      "        [0.4442, 0.0208, 0.6547, 0.0251],\n",
      "        [0.5336, 0.0700, 0.6774, 0.0282],\n",
      "        [0.5192, 0.0237, 0.5549, 0.0263],\n",
      "        [0.3173, 0.0057, 0.6313, 0.0019],\n",
      "        [0.3927, 0.0184, 0.5473, 0.0146],\n",
      "        [0.5323, 0.1282, 0.2603, 0.0568],\n",
      "        [0.5749, 0.0683, 0.2564, 0.0185],\n",
      "        [0.3329, 0.0020, 0.1183, 0.0022],\n",
      "        [0.5271, 0.0572, 0.8196, 0.0131],\n",
      "        [0.5838, 0.1145, 0.3069, 0.0807],\n",
      "        [0.2416, 0.0052, 0.2489, 0.0048],\n",
      "        [0.2382, 0.0079, 0.6934, 0.0280],\n",
      "        [0.2062, 0.0450, 0.2915, 0.0191],\n",
      "        [0.7006, 0.0102, 0.6478, 0.0045],\n",
      "        [0.7836, 0.0122, 0.7689, 0.0057],\n",
      "        [0.7245, 0.0445, 0.6671, 0.0219],\n",
      "        [0.6139, 0.0512, 0.3796, 0.0362],\n",
      "        [0.6652, 0.0737, 0.4798, 0.0388],\n",
      "        [0.3891, 0.0295, 0.7047, 0.0092]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0879, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.4332056596486398\n",
      "Epoch 1, Loss: -3.0828306291129435\n",
      "Epoch 1, Loss: -3.151311147756781\n",
      "Epoch 1, Loss: -2.4374335038824717\n",
      "Epoch 1, Loss: -3.3624696981966546\n",
      "tensor([[2.4680e-01, 7.7266e-03, 4.2838e-01, 1.2154e-02],\n",
      "        [6.1345e-01, 7.9698e-02, 3.7792e-01, 4.1203e-02],\n",
      "        [3.8943e-01, 2.2874e-02, 5.4301e-01, 4.3425e-02],\n",
      "        [5.0223e-01, 9.5167e-02, 3.2876e-01, 5.3596e-02],\n",
      "        [4.3995e-01, 1.8908e-02, 8.0353e-01, 3.6325e-02],\n",
      "        [6.2356e-01, 2.4167e-02, 4.4957e-01, 1.1541e-02],\n",
      "        [4.2819e-01, 2.7140e-02, 5.5600e-01, 2.7623e-02],\n",
      "        [6.2468e-01, 4.1256e-02, 5.4010e-01, 2.4462e-02],\n",
      "        [5.6157e-01, 1.5819e-03, 4.2851e-01, 1.0234e-03],\n",
      "        [4.1860e-01, 4.6690e-02, 2.2891e-01, 3.5047e-02],\n",
      "        [4.6570e-01, 1.3759e-02, 7.9389e-01, 1.1145e-02],\n",
      "        [5.6662e-01, 1.7117e-01, 2.6793e-01, 4.3605e-02],\n",
      "        [7.7364e-01, 1.7053e-02, 5.4758e-01, 1.1159e-02],\n",
      "        [5.9261e-01, 9.8772e-02, 4.3586e-01, 5.5744e-02],\n",
      "        [7.9900e-01, 5.7032e-03, 6.6430e-01, 2.8288e-03],\n",
      "        [5.9440e-01, 1.3301e-01, 3.3906e-01, 3.0879e-02],\n",
      "        [3.7988e-01, 5.7523e-02, 8.9376e-01, 1.0614e-02],\n",
      "        [5.8223e-01, 1.6592e-02, 3.4741e-01, 8.0835e-03],\n",
      "        [4.7110e-01, 6.5481e-03, 5.7636e-01, 1.2416e-02],\n",
      "        [6.4506e-01, 2.8425e-02, 6.0791e-01, 1.9378e-02],\n",
      "        [6.9366e-01, 4.7375e-02, 7.9846e-01, 2.1859e-02],\n",
      "        [5.9604e-01, 5.2149e-02, 6.3460e-01, 2.1293e-02],\n",
      "        [7.0382e-01, 2.0936e-02, 6.1687e-01, 1.3071e-02],\n",
      "        [3.9699e-01, 2.1457e-02, 5.4359e-01, 2.8074e-02],\n",
      "        [7.2367e-01, 1.3421e-02, 5.3565e-01, 8.2255e-03],\n",
      "        [4.5119e-01, 2.2220e-02, 8.5159e-01, 1.3555e-02],\n",
      "        [6.1384e-01, 3.6528e-02, 8.7757e-01, 6.5783e-03],\n",
      "        [5.1722e-01, 8.7986e-02, 3.7837e-01, 2.8720e-02],\n",
      "        [7.5208e-01, 6.4645e-02, 8.0052e-01, 1.2564e-02],\n",
      "        [6.0285e-01, 6.6904e-02, 6.9305e-01, 3.3313e-02],\n",
      "        [1.9935e-01, 7.6069e-04, 2.3530e-01, 2.4619e-03],\n",
      "        [5.6006e-01, 3.0863e-02, 2.1040e-01, 1.1120e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0811, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.019548455816324\n",
      "Epoch 1, Loss: -3.392940330708483\n",
      "Epoch 1, Loss: -3.0764417987801647\n",
      "Epoch 1, Loss: -3.3576475858673067\n",
      "Epoch 1, Loss: -3.114859887104953\n",
      "tensor([[0.4808, 0.0168, 0.2703, 0.0113],\n",
      "        [0.6031, 0.0557, 0.4996, 0.0381],\n",
      "        [0.4315, 0.0353, 0.6948, 0.0141],\n",
      "        [0.7416, 0.0288, 0.5730, 0.0188],\n",
      "        [0.6131, 0.0351, 0.2450, 0.0157],\n",
      "        [0.1057, 0.0106, 0.2787, 0.0215],\n",
      "        [0.7598, 0.0187, 0.7396, 0.0091],\n",
      "        [0.6068, 0.0620, 0.6266, 0.0314],\n",
      "        [0.6159, 0.0284, 0.6618, 0.0255],\n",
      "        [0.6527, 0.0230, 0.7322, 0.0145],\n",
      "        [0.3930, 0.0034, 0.3860, 0.0062],\n",
      "        [0.4218, 0.1212, 0.8355, 0.0602],\n",
      "        [0.4398, 0.0427, 0.2384, 0.0169],\n",
      "        [0.7949, 0.0315, 0.5131, 0.0181],\n",
      "        [0.6245, 0.1551, 0.5720, 0.1179],\n",
      "        [0.5374, 0.0275, 0.6304, 0.0228],\n",
      "        [0.5050, 0.0233, 0.6377, 0.0172],\n",
      "        [0.3183, 0.0093, 0.2339, 0.0017],\n",
      "        [0.3814, 0.0020, 0.6161, 0.0044],\n",
      "        [0.4035, 0.0669, 0.8310, 0.0110],\n",
      "        [0.6497, 0.0284, 0.4568, 0.0073],\n",
      "        [0.6125, 0.0436, 0.6972, 0.0135],\n",
      "        [0.7864, 0.0232, 0.5458, 0.0205],\n",
      "        [0.6376, 0.0321, 0.8032, 0.0124],\n",
      "        [0.6975, 0.0443, 0.6307, 0.0522],\n",
      "        [0.1596, 0.0116, 0.3406, 0.0191],\n",
      "        [0.1033, 0.0012, 0.5786, 0.0029],\n",
      "        [0.5787, 0.0664, 0.7425, 0.0234],\n",
      "        [0.2058, 0.0414, 0.5602, 0.0209],\n",
      "        [0.7000, 0.0358, 0.5251, 0.0338],\n",
      "        [0.2576, 0.0050, 0.3973, 0.0031],\n",
      "        [0.4777, 0.0009, 0.5197, 0.0053]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0788, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.5045273479454133\n",
      "Epoch 1, Loss: -3.5171801910011085\n",
      "Epoch 1, Loss: -3.534953884865928\n",
      "Epoch 1, Loss: -3.6278907344555043\n",
      "Epoch 1, Loss: -3.5510885806164447\n",
      "tensor([[0.6374, 0.0138, 0.5805, 0.0110],\n",
      "        [0.3830, 0.0234, 0.8547, 0.0076],\n",
      "        [0.6143, 0.0123, 0.4929, 0.0130],\n",
      "        [0.6474, 0.0188, 0.3489, 0.0127],\n",
      "        [0.6902, 0.0287, 0.6721, 0.0091],\n",
      "        [0.7158, 0.0232, 0.6788, 0.0115],\n",
      "        [0.6270, 0.0120, 0.1887, 0.0065],\n",
      "        [0.3594, 0.0144, 0.8081, 0.0053],\n",
      "        [0.4637, 0.1390, 0.7259, 0.0176],\n",
      "        [0.4799, 0.0796, 0.4989, 0.0886],\n",
      "        [0.5656, 0.0036, 0.4935, 0.0072],\n",
      "        [0.6075, 0.0030, 0.6698, 0.0053],\n",
      "        [0.2066, 0.0215, 0.2589, 0.0218],\n",
      "        [0.5888, 0.0221, 0.4284, 0.0169],\n",
      "        [0.3633, 0.0655, 0.7087, 0.0876],\n",
      "        [0.4991, 0.0469, 0.5634, 0.0529],\n",
      "        [0.2669, 0.0257, 0.6381, 0.0376],\n",
      "        [0.2628, 0.0362, 0.4564, 0.0741],\n",
      "        [0.6649, 0.0229, 0.3488, 0.0042],\n",
      "        [0.6594, 0.0120, 0.3803, 0.0048],\n",
      "        [0.6178, 0.0932, 0.3256, 0.0241],\n",
      "        [0.6356, 0.0829, 0.3795, 0.0382],\n",
      "        [0.1978, 0.0149, 0.4885, 0.0132],\n",
      "        [0.8077, 0.0116, 0.4277, 0.0066],\n",
      "        [0.4998, 0.0094, 0.7203, 0.0063],\n",
      "        [0.6044, 0.0395, 0.8855, 0.0042],\n",
      "        [0.3595, 0.0295, 0.3892, 0.0379],\n",
      "        [0.3590, 0.0124, 0.5068, 0.0193],\n",
      "        [0.6278, 0.0817, 0.6590, 0.0446],\n",
      "        [0.4366, 0.0226, 0.1482, 0.0074],\n",
      "        [0.2091, 0.0123, 0.3953, 0.0328],\n",
      "        [0.4812, 0.0239, 0.1298, 0.0144]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0682, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.550412458304134\n",
      "Epoch 1, Loss: -3.3585749006600785\n",
      "Epoch 1, Loss: -3.543644669743748\n",
      "Epoch 1, Loss: -2.8612614482039427\n",
      "Epoch 1, Loss: -3.259769792498847\n",
      "tensor([[6.8251e-01, 7.9273e-03, 7.5424e-01, 3.6347e-03],\n",
      "        [6.3840e-01, 9.1493e-03, 4.0926e-01, 2.9968e-03],\n",
      "        [5.9608e-01, 3.7606e-02, 2.2899e-01, 1.1401e-02],\n",
      "        [4.3530e-01, 8.2215e-03, 6.0012e-01, 4.9131e-03],\n",
      "        [5.1792e-01, 1.1958e-02, 6.8056e-01, 4.1208e-03],\n",
      "        [4.1627e-01, 3.3503e-02, 2.7209e-01, 1.5829e-02],\n",
      "        [5.3943e-01, 2.0285e-03, 4.9746e-01, 4.5926e-03],\n",
      "        [7.6389e-01, 1.6710e-03, 8.5934e-01, 3.4689e-03],\n",
      "        [1.4884e-01, 7.6147e-03, 1.6562e-01, 1.3225e-02],\n",
      "        [2.6345e-01, 8.9896e-02, 6.5267e-01, 2.9019e-02],\n",
      "        [4.9406e-01, 1.6696e-01, 6.7266e-01, 3.8305e-02],\n",
      "        [5.4856e-01, 2.5479e-02, 3.8991e-01, 1.4893e-02],\n",
      "        [3.4005e-01, 6.2839e-03, 5.5104e-01, 1.6992e-02],\n",
      "        [5.1526e-01, 5.6175e-02, 1.9862e-01, 5.2986e-02],\n",
      "        [2.6895e-01, 5.3580e-03, 1.2004e-01, 3.7307e-03],\n",
      "        [4.4356e-01, 6.7086e-02, 6.0792e-01, 2.8605e-02],\n",
      "        [3.8502e-01, 1.1492e-02, 4.6394e-01, 1.4740e-02],\n",
      "        [6.2659e-01, 1.8918e-02, 5.1211e-01, 1.8447e-02],\n",
      "        [5.1125e-01, 7.1948e-02, 5.9378e-01, 6.0152e-02],\n",
      "        [4.3088e-01, 2.7223e-03, 4.4310e-01, 3.7248e-03],\n",
      "        [2.3824e-01, 1.8869e-02, 4.3197e-01, 1.9403e-02],\n",
      "        [5.7655e-01, 9.9354e-02, 7.2534e-01, 5.7553e-02],\n",
      "        [5.8004e-01, 4.8554e-02, 5.3592e-01, 3.4867e-02],\n",
      "        [8.0821e-01, 8.2478e-03, 4.1040e-01, 4.7333e-03],\n",
      "        [5.1446e-01, 2.1092e-02, 8.6026e-01, 7.3173e-03],\n",
      "        [5.0932e-01, 4.6320e-04, 4.4126e-01, 7.3942e-04],\n",
      "        [2.7100e-01, 4.1477e-02, 3.1044e-01, 3.5681e-02],\n",
      "        [4.3023e-01, 4.1682e-02, 2.0398e-01, 1.0507e-02],\n",
      "        [4.4497e-01, 4.3087e-02, 6.5390e-01, 2.9366e-02],\n",
      "        [5.4706e-01, 2.5548e-02, 6.8191e-01, 1.2375e-02],\n",
      "        [6.5386e-01, 1.8081e-02, 2.6260e-01, 7.6188e-03],\n",
      "        [7.5516e-01, 1.1702e-02, 4.8193e-01, 8.1468e-03]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0700, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.366294629530681\n",
      "Epoch 1, Loss: -3.8731178234692747\n",
      "Epoch 1, Loss: -3.8978567234924895\n",
      "Epoch 1, Loss: -3.4593200610643207\n",
      "Epoch 1, Loss: -3.7874351500253676\n",
      "tensor([[5.4676e-01, 5.0304e-03, 1.4480e-01, 5.3960e-03],\n",
      "        [4.7155e-01, 6.4072e-02, 4.7674e-01, 4.2622e-02],\n",
      "        [2.6826e-01, 1.0527e-02, 2.9222e-01, 1.1222e-02],\n",
      "        [3.2407e-01, 3.1594e-02, 4.0524e-01, 6.5796e-02],\n",
      "        [7.4026e-01, 1.1461e-02, 6.2159e-01, 1.0927e-02],\n",
      "        [3.6234e-01, 1.8852e-02, 7.5832e-01, 4.8439e-03],\n",
      "        [6.3837e-01, 4.6362e-02, 5.0384e-01, 1.8047e-02],\n",
      "        [2.5322e-01, 4.6611e-02, 6.3249e-01, 5.2803e-02],\n",
      "        [7.0806e-01, 8.9105e-03, 2.7556e-01, 4.2382e-03],\n",
      "        [5.7704e-01, 3.9673e-02, 6.6529e-01, 3.0081e-02],\n",
      "        [4.7512e-01, 4.5681e-02, 2.0906e-01, 1.1864e-02],\n",
      "        [6.2670e-01, 4.1804e-02, 3.4772e-01, 8.4863e-03],\n",
      "        [5.0628e-01, 9.8191e-03, 5.8064e-01, 8.5203e-03],\n",
      "        [4.1633e-01, 1.9836e-02, 4.8845e-01, 5.1572e-02],\n",
      "        [5.8010e-01, 7.1553e-03, 8.7761e-01, 7.5021e-04],\n",
      "        [2.5764e-01, 1.4818e-02, 4.0923e-01, 2.2174e-02],\n",
      "        [6.1945e-01, 8.4808e-03, 5.6159e-01, 1.1005e-02],\n",
      "        [5.4837e-01, 1.9971e-02, 7.2616e-01, 4.0566e-03],\n",
      "        [2.7957e-01, 1.6714e-02, 1.4213e-01, 8.9886e-03],\n",
      "        [3.4234e-01, 9.9022e-03, 4.8189e-01, 1.0741e-02],\n",
      "        [6.7151e-01, 6.5500e-02, 4.8634e-01, 3.7637e-02],\n",
      "        [5.2358e-01, 3.7906e-02, 6.3840e-01, 1.7698e-02],\n",
      "        [7.0757e-01, 9.2664e-03, 4.5740e-01, 7.7755e-03],\n",
      "        [2.0661e-01, 8.8613e-03, 1.4123e-01, 1.2410e-02],\n",
      "        [7.3564e-01, 1.0076e-02, 4.6071e-01, 8.0562e-03],\n",
      "        [6.6950e-01, 7.1888e-03, 2.6512e-01, 2.4758e-03],\n",
      "        [2.3558e-01, 9.7860e-03, 3.7610e-01, 1.3265e-02],\n",
      "        [6.0945e-01, 2.2799e-02, 4.3041e-01, 7.2047e-03],\n",
      "        [7.3889e-01, 2.2403e-03, 6.4546e-01, 2.9932e-03],\n",
      "        [4.0074e-01, 6.2782e-02, 3.1621e-01, 7.1836e-02],\n",
      "        [3.9889e-01, 3.4986e-03, 6.7356e-01, 4.8266e-03],\n",
      "        [5.9677e-01, 2.2218e-02, 2.9102e-01, 1.8564e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0559, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.685365166480875\n",
      "Epoch 1, Loss: -3.6162291643263096\n",
      "Epoch 1, Loss: -3.0877669901640714\n",
      "Epoch 1, Loss: -3.689704517431805\n",
      "Epoch 1, Loss: -3.7266812939327236\n",
      "tensor([[0.3031, 0.0070, 0.1731, 0.0034],\n",
      "        [0.3275, 0.0548, 0.4233, 0.0633],\n",
      "        [0.1888, 0.0042, 0.6240, 0.0077],\n",
      "        [0.2059, 0.0033, 0.3307, 0.0177],\n",
      "        [0.7523, 0.0065, 0.7690, 0.0058],\n",
      "        [0.3423, 0.0211, 0.6599, 0.0366],\n",
      "        [0.2179, 0.0114, 0.8520, 0.0096],\n",
      "        [0.5708, 0.0350, 0.4686, 0.0178],\n",
      "        [0.5321, 0.0261, 0.7505, 0.0071],\n",
      "        [0.5520, 0.0469, 0.3758, 0.0476],\n",
      "        [0.4736, 0.0125, 0.5770, 0.0060],\n",
      "        [0.3946, 0.0346, 0.4372, 0.0735],\n",
      "        [0.7428, 0.0229, 0.2690, 0.0083],\n",
      "        [0.4675, 0.0168, 0.1206, 0.0071],\n",
      "        [0.4344, 0.0246, 0.4253, 0.0649],\n",
      "        [0.7822, 0.0058, 0.4912, 0.0027],\n",
      "        [0.4430, 0.0626, 0.6942, 0.0148],\n",
      "        [0.4111, 0.0182, 0.4292, 0.0242],\n",
      "        [0.4469, 0.0036, 0.2936, 0.0010],\n",
      "        [0.5924, 0.0300, 0.6944, 0.0157],\n",
      "        [0.8139, 0.0029, 0.3881, 0.0017],\n",
      "        [0.4033, 0.0232, 0.7735, 0.0029],\n",
      "        [0.5277, 0.0116, 0.5142, 0.0104],\n",
      "        [0.5050, 0.0102, 0.6279, 0.0077],\n",
      "        [0.4443, 0.0231, 0.4888, 0.0212],\n",
      "        [0.4091, 0.0063, 0.3727, 0.0098],\n",
      "        [0.5414, 0.0162, 0.3689, 0.0030],\n",
      "        [0.7772, 0.0295, 0.2543, 0.0049],\n",
      "        [0.2666, 0.0120, 0.4062, 0.0248],\n",
      "        [0.3506, 0.0095, 0.4181, 0.0271],\n",
      "        [0.5046, 0.0081, 0.2292, 0.0082],\n",
      "        [0.7957, 0.0027, 0.5794, 0.0016]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0594, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -4.189552187562658\n",
      "Epoch 1, Loss: -3.502400931461359\n",
      "Epoch 1, Loss: -4.107579660864185\n",
      "Epoch 1, Loss: -3.6009745341900192\n",
      "Epoch 1, Loss: -3.8745809567620926\n",
      "tensor([[6.7153e-01, 2.3732e-02, 5.0137e-01, 2.5613e-02],\n",
      "        [3.7892e-01, 5.7394e-03, 2.9344e-01, 1.6451e-02],\n",
      "        [4.3521e-01, 1.5748e-02, 6.2603e-01, 1.3146e-02],\n",
      "        [8.2426e-01, 5.9792e-03, 2.7894e-01, 5.1365e-03],\n",
      "        [1.9358e-01, 5.6180e-03, 1.9437e-01, 2.8122e-02],\n",
      "        [4.9951e-01, 2.9134e-02, 5.0416e-01, 1.5858e-02],\n",
      "        [7.2896e-01, 5.4533e-02, 6.1066e-01, 1.8129e-02],\n",
      "        [3.9294e-01, 3.9080e-03, 1.9517e-01, 4.1445e-03],\n",
      "        [2.5853e-01, 6.0416e-03, 5.7998e-01, 1.4208e-02],\n",
      "        [6.8956e-01, 7.0526e-03, 8.3539e-01, 2.3214e-03],\n",
      "        [7.5550e-01, 1.5448e-02, 5.9771e-01, 1.2329e-02],\n",
      "        [3.6232e-01, 4.6591e-02, 7.0839e-01, 6.6450e-03],\n",
      "        [2.6643e-01, 1.0358e-02, 6.1603e-01, 2.0997e-02],\n",
      "        [7.2488e-01, 2.2274e-03, 8.4457e-01, 9.5966e-04],\n",
      "        [8.0158e-01, 9.3618e-03, 2.1866e-01, 2.8656e-03],\n",
      "        [5.3516e-01, 3.0198e-02, 3.6484e-01, 2.5956e-02],\n",
      "        [2.3111e-01, 8.5909e-03, 7.5425e-01, 7.2578e-03],\n",
      "        [6.0703e-01, 3.1141e-03, 1.7671e-01, 6.8611e-04],\n",
      "        [2.1143e-01, 6.9559e-03, 7.6047e-01, 2.8922e-02],\n",
      "        [2.0091e-01, 1.5925e-02, 7.5198e-01, 1.7444e-02],\n",
      "        [3.5300e-01, 1.9328e-02, 1.8551e-01, 2.7903e-02],\n",
      "        [5.8180e-01, 2.4415e-03, 4.3223e-01, 4.2272e-03],\n",
      "        [6.9868e-01, 1.7558e-02, 6.8060e-01, 2.0214e-02],\n",
      "        [3.1195e-01, 2.3997e-02, 7.6117e-01, 4.0275e-02],\n",
      "        [6.0873e-01, 8.7739e-03, 7.3252e-01, 7.8184e-03],\n",
      "        [5.8743e-01, 4.4135e-02, 8.2483e-01, 2.7042e-02],\n",
      "        [6.4292e-01, 2.1663e-02, 5.6093e-01, 1.4497e-02],\n",
      "        [4.9303e-01, 1.3168e-02, 5.2440e-01, 9.2973e-03],\n",
      "        [2.8834e-01, 1.7425e-02, 3.3036e-01, 2.1014e-02],\n",
      "        [1.5221e-01, 8.1956e-04, 4.0124e-01, 3.7311e-03],\n",
      "        [4.7731e-01, 3.5829e-03, 6.4175e-01, 2.1131e-03],\n",
      "        [7.8532e-01, 3.7142e-03, 4.4354e-01, 3.9932e-03]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0505, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.547889640920004\n",
      "Epoch 1, Loss: -3.9559822545762007\n",
      "Epoch 1, Loss: -3.8416530912930726\n",
      "Epoch 1, Loss: -3.3305244590157916\n",
      "Epoch 1, Loss: -4.058717417827737\n",
      "tensor([[0.2000, 0.0056, 0.6720, 0.0173],\n",
      "        [0.6508, 0.0105, 0.8455, 0.0050],\n",
      "        [0.7452, 0.0057, 0.7449, 0.0035],\n",
      "        [0.4840, 0.0215, 0.4174, 0.0352],\n",
      "        [0.6968, 0.0088, 0.8872, 0.0035],\n",
      "        [0.1293, 0.0095, 0.7638, 0.0232],\n",
      "        [0.7396, 0.0208, 0.6180, 0.0183],\n",
      "        [0.5644, 0.0019, 0.7249, 0.0019],\n",
      "        [0.5613, 0.0302, 0.5586, 0.0314],\n",
      "        [0.1423, 0.0017, 0.2777, 0.0348],\n",
      "        [0.7168, 0.0117, 0.3537, 0.0133],\n",
      "        [0.2358, 0.0048, 0.5353, 0.0152],\n",
      "        [0.2069, 0.0034, 0.4925, 0.0261],\n",
      "        [0.4571, 0.0075, 0.2771, 0.0140],\n",
      "        [0.7453, 0.0045, 0.2227, 0.0069],\n",
      "        [0.7654, 0.0044, 0.2309, 0.0026],\n",
      "        [0.5423, 0.0152, 0.5693, 0.0084],\n",
      "        [0.2218, 0.0043, 0.4336, 0.0139],\n",
      "        [0.5970, 0.0823, 0.6763, 0.0328],\n",
      "        [0.7339, 0.0120, 0.5084, 0.0098],\n",
      "        [0.6188, 0.0115, 0.3927, 0.0126],\n",
      "        [0.5907, 0.0104, 0.5794, 0.0053],\n",
      "        [0.5482, 0.0076, 0.6435, 0.0017],\n",
      "        [0.6145, 0.0248, 0.3401, 0.0432],\n",
      "        [0.7116, 0.0168, 0.8375, 0.0060],\n",
      "        [0.4390, 0.0097, 0.4662, 0.0157],\n",
      "        [0.4727, 0.0119, 0.5465, 0.0066],\n",
      "        [0.4900, 0.0066, 0.3471, 0.0067],\n",
      "        [0.6485, 0.0354, 0.5697, 0.0345],\n",
      "        [0.1351, 0.0036, 0.6046, 0.0140],\n",
      "        [0.3460, 0.0068, 0.2646, 0.0107],\n",
      "        [0.2074, 0.0106, 0.7285, 0.0109]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0470, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -4.026834185446833\n",
      "Epoch 1, Loss: -3.2795890355270148\n",
      "Epoch 1, Loss: -3.821799357935249\n",
      "Epoch 1, Loss: -1.0363157632653346\n",
      "Epoch 1, Loss: -4.048583340121548\n",
      "tensor([[3.8990e-01, 3.0477e-02, 3.3569e-01, 4.5297e-02],\n",
      "        [1.3339e-01, 3.3685e-03, 6.6183e-01, 1.5853e-02],\n",
      "        [2.2436e-01, 7.8844e-03, 2.6943e-01, 2.1767e-02],\n",
      "        [6.4389e-01, 2.0775e-03, 4.2552e-01, 5.0492e-04],\n",
      "        [4.8872e-01, 1.2193e-02, 7.0212e-01, 1.0694e-02],\n",
      "        [4.4761e-01, 7.9204e-03, 6.2835e-01, 9.9872e-03],\n",
      "        [7.2019e-01, 4.7793e-03, 5.6869e-01, 7.1272e-03],\n",
      "        [7.4192e-01, 2.1017e-02, 4.9961e-01, 1.3893e-02],\n",
      "        [4.0024e-01, 1.6630e-02, 6.1467e-01, 1.3668e-02],\n",
      "        [4.7460e-01, 6.4056e-03, 2.8547e-01, 5.8091e-03],\n",
      "        [4.4247e-01, 4.0090e-03, 2.5869e-01, 1.6027e-02],\n",
      "        [7.3556e-01, 4.8887e-03, 4.8277e-01, 4.7238e-03],\n",
      "        [3.2473e-01, 2.1670e-03, 6.1561e-01, 5.9334e-03],\n",
      "        [4.1862e-01, 9.6322e-03, 5.5529e-01, 1.3486e-02],\n",
      "        [3.4872e-01, 1.5628e-02, 5.4194e-01, 3.4911e-02],\n",
      "        [5.5598e-01, 9.2946e-03, 8.1941e-01, 3.4059e-03],\n",
      "        [6.7182e-01, 2.3268e-03, 3.5670e-01, 5.5590e-03],\n",
      "        [5.5085e-01, 7.1325e-02, 5.6435e-01, 2.2777e-02],\n",
      "        [6.9874e-01, 7.4605e-03, 3.7807e-01, 8.9559e-03],\n",
      "        [4.9464e-01, 1.0283e-02, 3.0533e-01, 2.7692e-02],\n",
      "        [7.8427e-01, 1.7323e-03, 8.4679e-01, 1.6062e-03],\n",
      "        [6.4660e-01, 2.2075e-02, 6.7444e-01, 2.6934e-02],\n",
      "        [6.7095e-01, 3.8656e-03, 5.4143e-01, 1.0271e-02],\n",
      "        [6.9162e-01, 1.1830e-02, 7.1535e-01, 1.5905e-02],\n",
      "        [4.2106e-01, 4.7632e-02, 7.3442e-01, 3.1082e-02],\n",
      "        [3.8924e-01, 2.0420e-03, 5.5261e-01, 2.7217e-03],\n",
      "        [3.4895e-01, 5.5704e-03, 4.8645e-01, 9.5418e-03],\n",
      "        [4.3444e-01, 7.3760e-03, 2.9731e-01, 1.0076e-02],\n",
      "        [6.9069e-01, 5.6897e-03, 3.3848e-01, 6.1187e-03],\n",
      "        [4.8924e-01, 8.8725e-03, 4.2135e-01, 1.1274e-02],\n",
      "        [3.6192e-01, 1.7019e-02, 6.3719e-01, 3.6435e-02],\n",
      "        [2.7525e-01, 6.7222e-03, 3.8333e-01, 1.1809e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0628, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.366220796158996\n",
      "Epoch 1, Loss: -3.875779171360943\n",
      "Epoch 1, Loss: -3.754720435609964\n",
      "Epoch 1, Loss: -3.6014382628825743\n",
      "Epoch 1, Loss: -3.0575021594112717\n",
      "tensor([[6.7129e-01, 2.3595e-02, 3.2263e-01, 3.5494e-02],\n",
      "        [7.3013e-01, 1.2806e-02, 3.9683e-01, 7.6630e-03],\n",
      "        [4.2664e-01, 9.5493e-03, 4.9776e-01, 8.8109e-03],\n",
      "        [6.3582e-01, 2.1032e-02, 5.5441e-01, 4.8699e-02],\n",
      "        [6.2656e-01, 1.4408e-02, 5.3691e-01, 3.2660e-02],\n",
      "        [4.4488e-01, 3.1462e-03, 6.2967e-01, 9.2372e-03],\n",
      "        [3.1654e-01, 9.1229e-04, 1.9816e-01, 3.8888e-03],\n",
      "        [6.8947e-01, 2.2126e-02, 6.9587e-01, 3.9238e-02],\n",
      "        [6.6957e-01, 2.5642e-02, 4.3484e-01, 2.9056e-02],\n",
      "        [1.3978e-01, 1.4392e-03, 9.1458e-01, 2.6647e-03],\n",
      "        [5.6601e-01, 2.8143e-02, 3.8616e-01, 4.0954e-02],\n",
      "        [3.9230e-01, 4.0055e-03, 6.9228e-01, 9.1056e-03],\n",
      "        [5.6084e-01, 1.7346e-02, 4.0176e-01, 1.8305e-02],\n",
      "        [3.8045e-01, 3.4389e-02, 5.4465e-01, 5.8884e-02],\n",
      "        [2.8618e-01, 1.0472e-02, 2.6750e-01, 1.0180e-02],\n",
      "        [5.0540e-01, 4.9487e-03, 6.7147e-01, 5.4564e-03],\n",
      "        [4.8362e-01, 6.2008e-02, 5.4474e-01, 6.3767e-02],\n",
      "        [8.0614e-01, 4.5692e-03, 2.0749e-01, 3.3248e-03],\n",
      "        [2.8315e-01, 2.6376e-03, 6.4943e-01, 6.2953e-03],\n",
      "        [5.9668e-01, 1.2453e-02, 3.6470e-01, 1.5062e-02],\n",
      "        [4.1834e-01, 1.9585e-03, 5.2914e-01, 5.7100e-03],\n",
      "        [5.6460e-01, 5.6141e-02, 4.6758e-01, 8.6754e-02],\n",
      "        [5.3263e-01, 6.3528e-02, 4.3478e-01, 5.8304e-02],\n",
      "        [5.5555e-01, 5.3586e-03, 1.6041e-01, 5.3463e-03],\n",
      "        [1.8933e-01, 2.2673e-03, 2.2158e-01, 1.0470e-02],\n",
      "        [3.5247e-01, 1.1165e-03, 6.9082e-01, 7.0892e-03],\n",
      "        [6.8141e-01, 1.8333e-02, 4.2066e-01, 2.9346e-02],\n",
      "        [6.3965e-01, 4.1998e-02, 3.9621e-01, 5.2370e-02],\n",
      "        [6.5911e-01, 3.5529e-02, 7.0589e-01, 4.0006e-02],\n",
      "        [4.0604e-01, 1.2855e-02, 6.6908e-01, 2.2160e-02],\n",
      "        [5.6469e-01, 1.5853e-03, 2.1214e-01, 3.2226e-03],\n",
      "        [5.3049e-01, 4.2494e-02, 4.7081e-01, 3.3354e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0916, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -2.257875111573605\n",
      "Epoch 1, Loss: -3.631079521076839\n",
      "Epoch 1, Loss: -0.3713023918153604\n",
      "Epoch 1, Loss: -3.847024647884096\n",
      "Epoch 1, Loss: -3.557529164618087\n",
      "tensor([[0.2879, 0.0135, 0.5391, 0.0235],\n",
      "        [0.2120, 0.0166, 0.3327, 0.0155],\n",
      "        [0.3671, 0.0215, 0.4058, 0.0229],\n",
      "        [0.5837, 0.0325, 0.3759, 0.0078],\n",
      "        [0.7730, 0.0037, 0.6134, 0.0128],\n",
      "        [0.7731, 0.0059, 0.7265, 0.0242],\n",
      "        [0.7281, 0.0063, 0.4640, 0.0119],\n",
      "        [0.3402, 0.0115, 0.7669, 0.0083],\n",
      "        [0.6258, 0.0039, 0.3691, 0.0024],\n",
      "        [0.4195, 0.0104, 0.7412, 0.0175],\n",
      "        [0.3324, 0.0439, 0.3117, 0.0405],\n",
      "        [0.3446, 0.0889, 0.7109, 0.0917],\n",
      "        [0.4373, 0.0327, 0.4480, 0.0104],\n",
      "        [0.5155, 0.0426, 0.3316, 0.0334],\n",
      "        [0.4303, 0.0056, 0.2423, 0.0211],\n",
      "        [0.4271, 0.0203, 0.4315, 0.0188],\n",
      "        [0.6017, 0.0106, 0.2632, 0.0169],\n",
      "        [0.3803, 0.0071, 0.6876, 0.0171],\n",
      "        [0.7974, 0.0096, 0.3833, 0.0113],\n",
      "        [0.7787, 0.0023, 0.2101, 0.0023],\n",
      "        [0.6207, 0.0091, 0.4985, 0.0056],\n",
      "        [0.7915, 0.0078, 0.6554, 0.0335],\n",
      "        [0.5997, 0.0070, 0.1503, 0.0044],\n",
      "        [0.5313, 0.0043, 0.5908, 0.0080],\n",
      "        [0.7235, 0.0150, 0.5276, 0.0515],\n",
      "        [0.6149, 0.0279, 0.3692, 0.0308],\n",
      "        [0.6382, 0.0153, 0.4563, 0.0157],\n",
      "        [0.7090, 0.0144, 0.5726, 0.0237],\n",
      "        [0.4363, 0.0326, 0.4122, 0.0464],\n",
      "        [0.5536, 0.0201, 0.7341, 0.0160],\n",
      "        [0.2908, 0.0190, 0.3470, 0.0346],\n",
      "        [0.3092, 0.0257, 0.2690, 0.0255]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0770, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.844797093842769\n",
      "Epoch 1, Loss: -3.809101373838517\n",
      "Epoch 1, Loss: -3.570076898509731\n",
      "Epoch 1, Loss: -3.573061052267203\n",
      "Epoch 1, Loss: -3.671593221669593\n",
      "tensor([[0.5261, 0.0091, 0.7161, 0.0271],\n",
      "        [0.5417, 0.0275, 0.2245, 0.0134],\n",
      "        [0.7712, 0.0056, 0.7834, 0.0219],\n",
      "        [0.5209, 0.0087, 0.3950, 0.0112],\n",
      "        [0.5629, 0.0151, 0.4054, 0.0055],\n",
      "        [0.5336, 0.0184, 0.7850, 0.0123],\n",
      "        [0.4768, 0.2542, 0.6495, 0.0248],\n",
      "        [0.6618, 0.0246, 0.3270, 0.0229],\n",
      "        [0.6538, 0.0071, 0.5435, 0.0069],\n",
      "        [0.3231, 0.0553, 0.8503, 0.0099],\n",
      "        [0.5028, 0.0381, 0.6629, 0.0391],\n",
      "        [0.6136, 0.0140, 0.6647, 0.0157],\n",
      "        [0.6898, 0.0136, 0.5810, 0.0501],\n",
      "        [0.7505, 0.0038, 0.6190, 0.0268],\n",
      "        [0.4538, 0.1294, 0.3923, 0.0377],\n",
      "        [0.6354, 0.0123, 0.4474, 0.0034],\n",
      "        [0.1676, 0.0251, 0.3198, 0.0210],\n",
      "        [0.6855, 0.0075, 0.2942, 0.0142],\n",
      "        [0.4317, 0.0117, 0.4451, 0.0052],\n",
      "        [0.3809, 0.0368, 0.2708, 0.0147],\n",
      "        [0.3057, 0.0589, 0.3965, 0.0322],\n",
      "        [0.6233, 0.0058, 0.1515, 0.0077],\n",
      "        [0.6481, 0.0168, 0.4441, 0.0307],\n",
      "        [0.4069, 0.0413, 0.7956, 0.0248],\n",
      "        [0.6129, 0.0164, 0.4589, 0.0108],\n",
      "        [0.6176, 0.0115, 0.7178, 0.0314],\n",
      "        [0.6847, 0.0052, 0.1898, 0.0053],\n",
      "        [0.5810, 0.0398, 0.2943, 0.0319],\n",
      "        [0.6083, 0.0200, 0.4718, 0.0448],\n",
      "        [0.6581, 0.0083, 0.6218, 0.0467],\n",
      "        [0.2526, 0.0658, 0.2046, 0.0530],\n",
      "        [0.2948, 0.0199, 0.6386, 0.0162]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0613, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.4140295368174507\n",
      "Epoch 1, Loss: -3.759045879831865\n",
      "Epoch 1, Loss: -3.4933826172171534\n",
      "Epoch 1, Loss: -3.4243758973322476\n",
      "Epoch 1, Loss: -3.6874490209304347\n",
      "tensor([[7.2559e-01, 1.3124e-02, 3.6848e-01, 1.1360e-02],\n",
      "        [4.4563e-01, 6.1327e-02, 6.9917e-01, 3.8466e-02],\n",
      "        [2.6079e-01, 8.3296e-03, 9.4478e-02, 2.4831e-03],\n",
      "        [3.9296e-01, 1.3331e-02, 3.4626e-01, 1.9088e-02],\n",
      "        [6.6205e-01, 9.8043e-03, 7.4944e-01, 3.5574e-02],\n",
      "        [3.9014e-01, 6.4175e-02, 3.8240e-01, 5.6686e-02],\n",
      "        [3.1157e-01, 3.7896e-02, 5.4045e-01, 1.4654e-02],\n",
      "        [6.6619e-01, 1.0272e-02, 7.2649e-01, 1.8418e-02],\n",
      "        [5.8764e-01, 1.2095e-02, 5.0951e-01, 1.9559e-02],\n",
      "        [2.6739e-01, 9.1313e-03, 1.4849e-01, 7.0677e-03],\n",
      "        [4.0121e-01, 2.3002e-02, 6.3980e-01, 1.5170e-02],\n",
      "        [7.9695e-01, 3.3521e-03, 3.5760e-01, 2.9118e-03],\n",
      "        [5.0298e-01, 2.8460e-02, 7.4574e-01, 1.7575e-02],\n",
      "        [8.5873e-01, 1.9036e-03, 8.3212e-01, 8.2791e-03],\n",
      "        [5.7341e-01, 6.7175e-03, 5.9790e-01, 8.5144e-03],\n",
      "        [6.3807e-01, 5.4263e-03, 5.3792e-01, 9.2602e-03],\n",
      "        [3.4357e-01, 7.7198e-02, 8.9044e-01, 2.3337e-02],\n",
      "        [4.8859e-01, 6.1071e-02, 5.9371e-01, 3.5592e-02],\n",
      "        [7.3433e-01, 1.3353e-02, 3.9550e-01, 1.6511e-02],\n",
      "        [4.6958e-01, 2.2891e-01, 3.4626e-01, 9.0678e-02],\n",
      "        [4.6343e-01, 7.3815e-02, 3.0879e-01, 2.6611e-02],\n",
      "        [3.6913e-01, 1.5373e-02, 2.3461e-01, 1.3030e-02],\n",
      "        [5.6245e-01, 2.4447e-02, 4.3187e-01, 1.0997e-02],\n",
      "        [5.0500e-01, 1.6050e-02, 5.7719e-01, 1.1213e-02],\n",
      "        [4.4273e-01, 5.5393e-02, 6.8740e-01, 1.1529e-02],\n",
      "        [3.5519e-01, 5.1651e-02, 4.1472e-01, 2.1703e-02],\n",
      "        [8.3855e-01, 3.4091e-03, 4.6056e-01, 1.6374e-03],\n",
      "        [6.5029e-01, 5.1681e-03, 3.1932e-01, 6.0725e-03],\n",
      "        [6.9020e-01, 8.6664e-03, 4.7256e-01, 2.0644e-02],\n",
      "        [3.3605e-01, 1.4535e-02, 4.2727e-01, 5.3004e-03],\n",
      "        [7.4277e-01, 3.0699e-03, 2.2949e-01, 7.9988e-04],\n",
      "        [3.9500e-01, 7.1600e-02, 7.1177e-01, 3.1690e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0674, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.709617879781933\n",
      "Epoch 1, Loss: -3.6243632959729766\n",
      "Epoch 1, Loss: -3.6626570636085107\n",
      "Epoch 1, Loss: -3.7604972890183292\n",
      "Epoch 1, Loss: -3.8534770040335236\n",
      "tensor([[0.7164, 0.0166, 0.6058, 0.0443],\n",
      "        [0.7138, 0.0032, 0.1937, 0.0024],\n",
      "        [0.5334, 0.0050, 0.3654, 0.0017],\n",
      "        [0.4796, 0.0425, 0.3502, 0.0163],\n",
      "        [0.5659, 0.0223, 0.4364, 0.0417],\n",
      "        [0.7778, 0.0164, 0.4111, 0.0185],\n",
      "        [0.7070, 0.0110, 0.4334, 0.0188],\n",
      "        [0.2353, 0.0080, 0.3341, 0.0033],\n",
      "        [0.8069, 0.0026, 0.8118, 0.0066],\n",
      "        [0.4022, 0.1847, 0.7707, 0.0186],\n",
      "        [0.4180, 0.0724, 0.5344, 0.0082],\n",
      "        [0.4195, 0.0619, 0.7475, 0.0106],\n",
      "        [0.4863, 0.0025, 0.8239, 0.0163],\n",
      "        [0.3700, 0.1017, 0.7509, 0.0144],\n",
      "        [0.4530, 0.0094, 0.4582, 0.0029],\n",
      "        [0.7286, 0.0174, 0.7424, 0.0310],\n",
      "        [0.6294, 0.0058, 0.7025, 0.0362],\n",
      "        [0.6007, 0.0073, 0.3458, 0.0080],\n",
      "        [0.7803, 0.0020, 0.4804, 0.0029],\n",
      "        [0.5094, 0.0535, 0.6540, 0.0358],\n",
      "        [0.3132, 0.0453, 0.5169, 0.0078],\n",
      "        [0.4747, 0.0041, 0.6352, 0.0032],\n",
      "        [0.6815, 0.0164, 0.7301, 0.0361],\n",
      "        [0.3703, 0.0487, 0.2195, 0.0025],\n",
      "        [0.7046, 0.0082, 0.7181, 0.0137],\n",
      "        [0.2744, 0.0121, 0.1733, 0.0086],\n",
      "        [0.2728, 0.0941, 0.4872, 0.0221],\n",
      "        [0.4050, 0.0129, 0.3727, 0.0039],\n",
      "        [0.5769, 0.0370, 0.4660, 0.0427],\n",
      "        [0.2891, 0.1254, 0.5063, 0.0267],\n",
      "        [0.4691, 0.0242, 0.7773, 0.0051],\n",
      "        [0.2779, 0.0313, 0.2835, 0.0152]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0573, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.907216372465004\n",
      "Epoch 1, Loss: -3.8091722898879072\n",
      "Epoch 1, Loss: -3.7001564188352396\n",
      "Epoch 1, Loss: -3.845468543858381\n",
      "Epoch 1, Loss: -3.792539983357655\n",
      "tensor([[0.6144, 0.0021, 0.8610, 0.0030],\n",
      "        [0.7868, 0.0038, 0.4982, 0.0091],\n",
      "        [0.7099, 0.0237, 0.3038, 0.0137],\n",
      "        [0.2574, 0.0311, 0.3569, 0.0052],\n",
      "        [0.8122, 0.0016, 0.6652, 0.0026],\n",
      "        [0.5234, 0.0112, 0.3356, 0.0090],\n",
      "        [0.4218, 0.0515, 0.5413, 0.0037],\n",
      "        [0.3898, 0.0286, 0.3457, 0.0207],\n",
      "        [0.7976, 0.0096, 0.3732, 0.0181],\n",
      "        [0.3240, 0.0677, 0.6955, 0.0090],\n",
      "        [0.3933, 0.0569, 0.4276, 0.0243],\n",
      "        [0.6464, 0.0214, 0.4749, 0.0095],\n",
      "        [0.2588, 0.0240, 0.7896, 0.0031],\n",
      "        [0.5429, 0.0225, 0.2131, 0.0168],\n",
      "        [0.5464, 0.0041, 0.3802, 0.0038],\n",
      "        [0.3589, 0.0910, 0.4701, 0.0117],\n",
      "        [0.3040, 0.0289, 0.3461, 0.0078],\n",
      "        [0.3844, 0.0166, 0.6888, 0.0035],\n",
      "        [0.4682, 0.0343, 0.7954, 0.0106],\n",
      "        [0.4203, 0.0075, 0.4495, 0.0041],\n",
      "        [0.5388, 0.0203, 0.2374, 0.0086],\n",
      "        [0.6704, 0.0135, 0.4552, 0.0401],\n",
      "        [0.3794, 0.0214, 0.4194, 0.0093],\n",
      "        [0.5944, 0.0018, 0.6033, 0.0099],\n",
      "        [0.8082, 0.0018, 0.6137, 0.0056],\n",
      "        [0.4017, 0.0590, 0.4021, 0.0102],\n",
      "        [0.2604, 0.0198, 0.3611, 0.0127],\n",
      "        [0.3057, 0.1420, 0.6325, 0.0051],\n",
      "        [0.7422, 0.0041, 0.2567, 0.0099],\n",
      "        [0.5891, 0.0050, 0.5728, 0.0050],\n",
      "        [0.4605, 0.1508, 0.3758, 0.0214],\n",
      "        [0.5109, 0.0122, 0.5998, 0.0091]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0523, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.489514890892967\n",
      "Epoch 1, Loss: -3.6044041255051837\n",
      "Epoch 1, Loss: -4.090148539787611\n",
      "Epoch 1, Loss: -4.252506547916697\n",
      "Epoch 1, Loss: -4.014313182443653\n",
      "tensor([[4.1510e-01, 1.1880e-02, 4.7533e-01, 1.1980e-03],\n",
      "        [4.1523e-01, 2.6772e-02, 4.7251e-01, 1.0475e-02],\n",
      "        [5.1508e-01, 3.5736e-03, 4.5195e-01, 3.8047e-03],\n",
      "        [6.5457e-01, 5.0796e-02, 4.5170e-01, 4.8167e-02],\n",
      "        [7.4682e-01, 1.9481e-02, 2.7441e-01, 3.1995e-02],\n",
      "        [8.1913e-01, 2.8764e-03, 5.2970e-01, 3.4212e-03],\n",
      "        [7.7311e-01, 3.8896e-02, 5.0550e-01, 2.6098e-02],\n",
      "        [4.1194e-01, 3.8748e-02, 2.4306e-01, 2.8601e-02],\n",
      "        [3.1395e-01, 2.5307e-02, 3.1584e-01, 2.3913e-03],\n",
      "        [6.8834e-01, 2.5154e-02, 3.6782e-01, 2.5943e-02],\n",
      "        [2.3590e-01, 2.7476e-02, 8.4941e-01, 2.9260e-03],\n",
      "        [5.8002e-01, 3.2290e-02, 2.8382e-01, 2.3708e-02],\n",
      "        [5.6236e-01, 1.2973e-03, 8.0438e-01, 8.3560e-04],\n",
      "        [2.2657e-01, 5.3367e-03, 5.9050e-01, 4.5630e-04],\n",
      "        [5.0280e-01, 1.2290e-02, 3.9589e-01, 7.2870e-03],\n",
      "        [2.3912e-01, 3.9430e-02, 5.8157e-01, 1.1644e-03],\n",
      "        [2.3947e-01, 6.8571e-02, 7.5614e-01, 5.9617e-03],\n",
      "        [5.5924e-01, 8.7627e-03, 4.7236e-01, 3.9023e-03],\n",
      "        [8.1127e-01, 2.0461e-03, 5.2046e-01, 2.2797e-03],\n",
      "        [6.6529e-01, 4.8425e-03, 6.8957e-01, 9.4758e-03],\n",
      "        [7.2791e-01, 7.7473e-03, 7.0308e-01, 3.0440e-02],\n",
      "        [4.9564e-01, 1.6330e-02, 4.8898e-01, 8.0416e-03],\n",
      "        [7.7171e-01, 6.4640e-03, 2.8736e-01, 6.0875e-03],\n",
      "        [7.3604e-01, 8.9148e-03, 6.2203e-01, 3.0024e-02],\n",
      "        [7.3159e-01, 5.5828e-03, 5.6110e-01, 7.8480e-03],\n",
      "        [3.9081e-01, 4.9890e-03, 1.5821e-01, 2.1246e-03],\n",
      "        [5.7784e-01, 2.5574e-02, 3.4242e-01, 2.8009e-02],\n",
      "        [1.9731e-01, 1.4583e-02, 5.2725e-01, 3.8018e-03],\n",
      "        [3.0689e-01, 7.0461e-02, 7.7982e-01, 2.6169e-02],\n",
      "        [5.2811e-01, 1.3057e-02, 2.0906e-01, 1.5017e-02],\n",
      "        [3.0264e-01, 4.3329e-02, 4.6849e-01, 4.3814e-03],\n",
      "        [5.9416e-01, 1.7174e-02, 4.0155e-01, 1.3460e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0544, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.9463356102702445\n",
      "Epoch 1, Loss: -3.620864516953023\n",
      "Epoch 1, Loss: -3.44364054499113\n",
      "Epoch 1, Loss: -3.825712204432118\n",
      "Epoch 1, Loss: -3.784775314546198\n",
      "tensor([[4.3401e-01, 5.1252e-02, 5.5954e-01, 1.2397e-02],\n",
      "        [5.4489e-01, 2.8002e-02, 3.0135e-01, 2.5606e-02],\n",
      "        [5.5691e-01, 9.0393e-03, 4.8144e-01, 7.6905e-03],\n",
      "        [5.1973e-01, 1.0391e-02, 3.1240e-01, 8.4246e-03],\n",
      "        [6.7964e-01, 5.3234e-03, 4.2359e-01, 5.5218e-03],\n",
      "        [4.9614e-01, 7.3335e-03, 8.7711e-01, 2.6978e-03],\n",
      "        [6.7488e-01, 2.1174e-02, 4.6743e-01, 1.8220e-02],\n",
      "        [3.5455e-01, 2.1710e-01, 7.0809e-01, 2.3017e-02],\n",
      "        [5.6883e-01, 5.1291e-03, 4.6754e-01, 4.2275e-03],\n",
      "        [3.3187e-01, 2.6091e-02, 2.2397e-01, 1.2245e-02],\n",
      "        [6.4300e-01, 1.8136e-02, 7.1224e-01, 2.0089e-02],\n",
      "        [3.3899e-01, 5.9115e-02, 5.1357e-01, 5.3430e-03],\n",
      "        [6.4686e-01, 2.8570e-03, 6.7794e-01, 3.3629e-03],\n",
      "        [2.7515e-01, 1.2829e-02, 5.8822e-01, 4.1748e-03],\n",
      "        [6.0544e-01, 3.9117e-02, 3.8634e-01, 3.3551e-02],\n",
      "        [4.8581e-01, 6.8488e-02, 4.1999e-01, 8.7448e-02],\n",
      "        [7.8577e-01, 4.9018e-03, 4.2564e-01, 3.3886e-03],\n",
      "        [9.0468e-01, 3.3362e-04, 7.7486e-01, 7.4640e-04],\n",
      "        [7.3174e-01, 6.3483e-03, 2.9568e-01, 2.3614e-02],\n",
      "        [4.0516e-01, 2.2573e-02, 7.0220e-01, 1.5498e-02],\n",
      "        [8.3246e-01, 8.2546e-04, 7.5658e-01, 3.1271e-03],\n",
      "        [2.7377e-01, 8.6449e-03, 4.6714e-01, 4.6273e-04],\n",
      "        [7.1928e-01, 6.8054e-03, 2.2438e-01, 9.5015e-03],\n",
      "        [4.6247e-01, 6.2497e-03, 5.0717e-01, 5.3358e-03],\n",
      "        [4.0326e-01, 2.0277e-02, 2.9714e-01, 7.1366e-03],\n",
      "        [3.0557e-01, 1.1597e-02, 2.2157e-01, 3.0890e-03],\n",
      "        [5.6094e-01, 1.6204e-02, 2.1039e-01, 1.2701e-02],\n",
      "        [5.9891e-01, 1.3533e-02, 3.1401e-01, 5.9659e-03],\n",
      "        [6.1315e-01, 1.6075e-02, 5.4547e-01, 9.3626e-03],\n",
      "        [3.4076e-01, 2.9519e-02, 5.0658e-01, 1.3405e-03],\n",
      "        [1.2979e-01, 6.3654e-03, 3.3446e-01, 1.0664e-03],\n",
      "        [6.5744e-01, 8.7931e-03, 4.3648e-01, 4.5791e-03]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0438, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.84139799941443\n",
      "Epoch 1, Loss: -3.5919120831399254\n",
      "Epoch 1, Loss: -3.980498942946035\n",
      "Epoch 1, Loss: -1.833573971598943\n",
      "Epoch 1, Loss: -3.3907987051817\n",
      "tensor([[0.2472, 0.0574, 0.8083, 0.0049],\n",
      "        [0.6527, 0.0205, 0.2743, 0.0151],\n",
      "        [0.6065, 0.0078, 0.3678, 0.0085],\n",
      "        [0.6458, 0.0256, 0.4955, 0.0202],\n",
      "        [0.6224, 0.0022, 0.4187, 0.0025],\n",
      "        [0.2195, 0.0181, 0.6542, 0.0048],\n",
      "        [0.4504, 0.0101, 0.2399, 0.0085],\n",
      "        [0.2701, 0.1414, 0.7566, 0.0114],\n",
      "        [0.3744, 0.0881, 0.6358, 0.0097],\n",
      "        [0.2276, 0.0282, 0.7196, 0.0072],\n",
      "        [0.6158, 0.0301, 0.6057, 0.0151],\n",
      "        [0.6973, 0.0096, 0.4797, 0.0084],\n",
      "        [0.5893, 0.0098, 0.2224, 0.0160],\n",
      "        [0.4829, 0.0055, 0.5192, 0.0037],\n",
      "        [0.5118, 0.0078, 0.6977, 0.0125],\n",
      "        [0.4922, 0.0117, 0.3489, 0.0086],\n",
      "        [0.3028, 0.0606, 0.6979, 0.0260],\n",
      "        [0.2584, 0.0140, 0.5924, 0.0049],\n",
      "        [0.3522, 0.0041, 0.5117, 0.0022],\n",
      "        [0.6443, 0.0227, 0.3514, 0.0155],\n",
      "        [0.7009, 0.0114, 0.4263, 0.0080],\n",
      "        [0.6684, 0.0042, 0.7199, 0.0063],\n",
      "        [0.6202, 0.0046, 0.4065, 0.0096],\n",
      "        [0.6282, 0.0106, 0.5753, 0.0085],\n",
      "        [0.5806, 0.0492, 0.6434, 0.0398],\n",
      "        [0.7111, 0.0025, 0.5260, 0.0042],\n",
      "        [0.2721, 0.0306, 0.6814, 0.0030],\n",
      "        [0.2058, 0.0072, 0.4462, 0.0012],\n",
      "        [0.3045, 0.0180, 0.6118, 0.0060],\n",
      "        [0.6061, 0.0352, 0.7665, 0.0171],\n",
      "        [0.5899, 0.0037, 0.6668, 0.0017],\n",
      "        [0.7102, 0.0106, 0.2681, 0.0128]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0720, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.0681390554218684\n",
      "Epoch 1, Loss: -3.767691243085757\n",
      "Epoch 1, Loss: -3.151125358425526\n",
      "Epoch 1, Loss: -3.644589942332323\n",
      "Epoch 1, Loss: -3.026713801121919\n",
      "tensor([[0.3166, 0.0985, 0.7795, 0.0103],\n",
      "        [0.5889, 0.0245, 0.3030, 0.0235],\n",
      "        [0.5002, 0.0059, 0.4418, 0.0059],\n",
      "        [0.4722, 0.0723, 0.4522, 0.0296],\n",
      "        [0.5300, 0.0121, 0.5332, 0.0080],\n",
      "        [0.7161, 0.0025, 0.4239, 0.0095],\n",
      "        [0.5112, 0.0322, 0.3705, 0.0172],\n",
      "        [0.3620, 0.0096, 0.8374, 0.0049],\n",
      "        [0.5344, 0.0056, 0.3688, 0.0085],\n",
      "        [0.5591, 0.0036, 0.3213, 0.0127],\n",
      "        [0.6942, 0.0167, 0.3428, 0.0374],\n",
      "        [0.1913, 0.0158, 0.7841, 0.0016],\n",
      "        [0.6870, 0.0065, 0.3517, 0.0146],\n",
      "        [0.4399, 0.0180, 0.4847, 0.0190],\n",
      "        [0.4946, 0.0246, 0.6527, 0.0059],\n",
      "        [0.1599, 0.0201, 0.4846, 0.0805],\n",
      "        [0.4244, 0.0156, 0.6412, 0.0064],\n",
      "        [0.2366, 0.0123, 0.7371, 0.0021],\n",
      "        [0.3495, 0.0238, 0.4875, 0.0401],\n",
      "        [0.5665, 0.0073, 0.2436, 0.0096],\n",
      "        [0.5524, 0.0196, 0.5550, 0.0158],\n",
      "        [0.3155, 0.0319, 0.8143, 0.0069],\n",
      "        [0.3176, 0.0168, 0.5525, 0.0145],\n",
      "        [0.8404, 0.0017, 0.3203, 0.0049],\n",
      "        [0.7148, 0.0009, 0.5691, 0.0038],\n",
      "        [0.5400, 0.0052, 0.5919, 0.0038],\n",
      "        [0.4100, 0.0237, 0.7627, 0.0071],\n",
      "        [0.2043, 0.0193, 0.5588, 0.0338],\n",
      "        [0.5381, 0.0140, 0.6034, 0.0058],\n",
      "        [0.4521, 0.0128, 0.8679, 0.0085],\n",
      "        [0.3996, 0.0202, 0.5459, 0.0212],\n",
      "        [0.4227, 0.0461, 0.6110, 0.0154]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0749, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.785854927502209\n",
      "Epoch 1, Loss: -3.575501174276824\n",
      "Epoch 1, Loss: -3.903742191716589\n",
      "Epoch 1, Loss: -3.9652022479424587\n",
      "Epoch 1, Loss: -3.7500753388329753\n",
      "tensor([[0.3087, 0.0277, 0.4157, 0.0982],\n",
      "        [0.7901, 0.0023, 0.2415, 0.0058],\n",
      "        [0.7225, 0.0207, 0.3985, 0.0145],\n",
      "        [0.6133, 0.0030, 0.2247, 0.0067],\n",
      "        [0.6925, 0.0053, 0.2906, 0.0083],\n",
      "        [0.3938, 0.0264, 0.3875, 0.0290],\n",
      "        [0.3596, 0.0040, 0.4761, 0.0029],\n",
      "        [0.3826, 0.0100, 0.5687, 0.0033],\n",
      "        [0.1874, 0.0346, 0.3356, 0.1108],\n",
      "        [0.1744, 0.0411, 0.4679, 0.0795],\n",
      "        [0.2228, 0.0055, 0.7971, 0.0019],\n",
      "        [0.5126, 0.0057, 0.6739, 0.0035],\n",
      "        [0.6813, 0.0072, 0.5536, 0.0037],\n",
      "        [0.7291, 0.0301, 0.5370, 0.0363],\n",
      "        [0.5726, 0.0018, 0.4468, 0.0039],\n",
      "        [0.4603, 0.0038, 0.4020, 0.0043],\n",
      "        [0.6377, 0.0094, 0.3947, 0.0065],\n",
      "        [0.1470, 0.0025, 0.7269, 0.0022],\n",
      "        [0.4942, 0.0140, 0.4599, 0.0104],\n",
      "        [0.7526, 0.0339, 0.6718, 0.0249],\n",
      "        [0.3294, 0.0155, 0.3389, 0.0324],\n",
      "        [0.3852, 0.0066, 0.7254, 0.0058],\n",
      "        [0.2969, 0.0295, 0.5417, 0.0667],\n",
      "        [0.4159, 0.0270, 0.4651, 0.0403],\n",
      "        [0.3968, 0.0303, 0.3561, 0.0700],\n",
      "        [0.5439, 0.0437, 0.4028, 0.0558],\n",
      "        [0.4238, 0.0189, 0.7268, 0.0240],\n",
      "        [0.3661, 0.0252, 0.4720, 0.0876],\n",
      "        [0.6637, 0.0125, 0.5441, 0.0263],\n",
      "        [0.3546, 0.0306, 0.5483, 0.0394],\n",
      "        [0.7424, 0.0067, 0.4932, 0.0087],\n",
      "        [0.4860, 0.0385, 0.4780, 0.0267]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0685, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.5423716042877893\n",
      "Epoch 1, Loss: -3.7161233337587323\n",
      "Epoch 1, Loss: -3.9711067351153844\n",
      "Epoch 1, Loss: -3.5698546444899275\n",
      "Epoch 1, Loss: -3.966446055462953\n",
      "tensor([[0.6731, 0.0063, 0.3248, 0.0106],\n",
      "        [0.3068, 0.0121, 0.5078, 0.0090],\n",
      "        [0.5446, 0.0024, 0.4021, 0.0011],\n",
      "        [0.6002, 0.0021, 0.6421, 0.0020],\n",
      "        [0.7703, 0.0026, 0.3846, 0.0079],\n",
      "        [0.3227, 0.0432, 0.3616, 0.1335],\n",
      "        [0.8165, 0.0031, 0.4287, 0.0027],\n",
      "        [0.5685, 0.0067, 0.2310, 0.0266],\n",
      "        [0.4949, 0.0258, 0.3611, 0.0236],\n",
      "        [0.2978, 0.0163, 0.4015, 0.0314],\n",
      "        [0.5943, 0.0187, 0.6946, 0.0192],\n",
      "        [0.5552, 0.0329, 0.6310, 0.0200],\n",
      "        [0.3800, 0.0321, 0.3455, 0.1361],\n",
      "        [0.4729, 0.0042, 0.5551, 0.0066],\n",
      "        [0.6701, 0.0027, 0.3647, 0.0073],\n",
      "        [0.1875, 0.0061, 0.3640, 0.1475],\n",
      "        [0.7581, 0.0060, 0.3701, 0.0037],\n",
      "        [0.1633, 0.0283, 0.4972, 0.0299],\n",
      "        [0.3754, 0.0087, 0.3898, 0.0157],\n",
      "        [0.3891, 0.0502, 0.4275, 0.0580],\n",
      "        [0.8379, 0.0127, 0.6042, 0.0247],\n",
      "        [0.4651, 0.0053, 0.8809, 0.0039],\n",
      "        [0.6668, 0.0305, 0.6741, 0.0294],\n",
      "        [0.5424, 0.0136, 0.2801, 0.0368],\n",
      "        [0.6490, 0.0159, 0.4934, 0.0131],\n",
      "        [0.5090, 0.0096, 0.3658, 0.0082],\n",
      "        [0.4780, 0.0104, 0.3945, 0.0206],\n",
      "        [0.5081, 0.0163, 0.6325, 0.0121],\n",
      "        [0.3832, 0.0128, 0.8214, 0.0108],\n",
      "        [0.5392, 0.0046, 0.6812, 0.0043],\n",
      "        [0.6352, 0.0181, 0.3598, 0.0223],\n",
      "        [0.3113, 0.0368, 0.3933, 0.1481]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0552, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.2398444559706903\n",
      "Epoch 1, Loss: -3.5758947346194203\n",
      "Epoch 1, Loss: -3.945135763836408\n",
      "Epoch 1, Loss: -3.1962795592227233\n",
      "Epoch 1, Loss: -3.681221163575426\n",
      "tensor([[6.0387e-01, 2.7532e-02, 6.1488e-01, 2.5417e-02],\n",
      "        [4.2182e-01, 2.8840e-03, 6.5567e-01, 2.7551e-03],\n",
      "        [7.1142e-01, 2.1595e-02, 5.5672e-01, 4.9216e-02],\n",
      "        [6.2539e-01, 2.9457e-03, 3.3760e-01, 1.7591e-03],\n",
      "        [6.4501e-01, 4.5474e-02, 7.1390e-01, 5.3885e-02],\n",
      "        [4.3097e-01, 7.6798e-03, 7.2358e-01, 7.3569e-03],\n",
      "        [4.9560e-01, 3.5946e-02, 6.0253e-01, 5.6217e-02],\n",
      "        [1.9933e-01, 1.0560e-02, 3.1179e-01, 1.2392e-02],\n",
      "        [6.2023e-01, 2.8344e-02, 5.9149e-01, 5.1354e-02],\n",
      "        [6.4125e-01, 5.8607e-03, 2.4926e-01, 1.2338e-02],\n",
      "        [5.5380e-01, 2.1096e-02, 4.8023e-01, 2.0009e-02],\n",
      "        [5.9317e-01, 1.0982e-02, 6.1734e-01, 9.1468e-03],\n",
      "        [2.5777e-01, 8.4820e-03, 3.7046e-01, 5.6905e-02],\n",
      "        [6.4018e-01, 6.6575e-02, 5.5187e-01, 9.3197e-02],\n",
      "        [4.4205e-01, 1.6084e-02, 2.8000e-01, 2.4439e-02],\n",
      "        [6.9003e-01, 5.4749e-02, 5.9337e-01, 8.4376e-02],\n",
      "        [1.3064e-01, 5.7083e-04, 7.6255e-01, 1.2949e-03],\n",
      "        [4.4978e-01, 2.1755e-03, 6.8430e-01, 6.9501e-03],\n",
      "        [4.8315e-01, 9.4157e-03, 4.2697e-01, 8.1821e-03],\n",
      "        [8.4201e-01, 4.2305e-03, 5.0534e-01, 5.0093e-03],\n",
      "        [3.8324e-01, 3.2380e-03, 6.1777e-01, 4.7966e-03],\n",
      "        [2.1366e-01, 1.2265e-02, 3.6784e-01, 1.1525e-01],\n",
      "        [6.6813e-01, 5.3329e-02, 5.1862e-01, 7.4913e-02],\n",
      "        [3.2710e-01, 6.7978e-03, 8.1956e-01, 1.6548e-02],\n",
      "        [5.9180e-01, 5.0643e-02, 6.4855e-01, 4.6698e-02],\n",
      "        [7.5184e-01, 3.8601e-03, 4.1992e-01, 5.4639e-03],\n",
      "        [1.5079e-01, 6.9780e-03, 4.0873e-01, 2.7673e-02],\n",
      "        [7.4541e-01, 2.2298e-02, 6.1534e-01, 2.1708e-02],\n",
      "        [6.2443e-01, 1.2743e-02, 5.0444e-01, 5.9077e-03],\n",
      "        [6.4385e-01, 5.3302e-03, 3.2885e-01, 6.2311e-03],\n",
      "        [2.6048e-01, 5.0256e-03, 3.3178e-01, 1.1491e-02],\n",
      "        [4.6576e-01, 2.3463e-03, 2.2543e-01, 5.1275e-03]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0610, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.8623705609222636\n",
      "Epoch 1, Loss: -3.51737705262863\n",
      "Epoch 1, Loss: -4.014864258404893\n",
      "Epoch 1, Loss: -3.474912836512387\n",
      "Epoch 1, Loss: -3.543437780792047\n",
      "tensor([[0.8313, 0.0030, 0.4798, 0.0033],\n",
      "        [0.2937, 0.0058, 0.5060, 0.0178],\n",
      "        [0.4471, 0.0085, 0.7885, 0.0054],\n",
      "        [0.3612, 0.0044, 0.5548, 0.0047],\n",
      "        [0.6597, 0.0410, 0.7853, 0.0180],\n",
      "        [0.2393, 0.0276, 0.4235, 0.0182],\n",
      "        [0.3749, 0.0055, 0.6575, 0.0107],\n",
      "        [0.6673, 0.0014, 0.3621, 0.0016],\n",
      "        [0.3958, 0.0094, 0.7841, 0.0129],\n",
      "        [0.5425, 0.0317, 0.6634, 0.0609],\n",
      "        [0.4423, 0.0236, 0.7843, 0.0196],\n",
      "        [0.6376, 0.0263, 0.4924, 0.0199],\n",
      "        [0.5676, 0.0039, 0.2372, 0.0059],\n",
      "        [0.4951, 0.0039, 0.6708, 0.0165],\n",
      "        [0.2241, 0.0059, 0.3446, 0.0348],\n",
      "        [0.2992, 0.0072, 0.2782, 0.0458],\n",
      "        [0.5023, 0.0769, 0.5518, 0.0624],\n",
      "        [0.4887, 0.0235, 0.5649, 0.0149],\n",
      "        [0.5819, 0.0168, 0.3501, 0.0188],\n",
      "        [0.4270, 0.0120, 0.2416, 0.0138],\n",
      "        [0.7490, 0.0240, 0.6371, 0.0164],\n",
      "        [0.6405, 0.0191, 0.4668, 0.0142],\n",
      "        [0.2285, 0.0040, 0.7847, 0.0038],\n",
      "        [0.5960, 0.0033, 0.2417, 0.0069],\n",
      "        [0.5287, 0.0033, 0.3253, 0.0040],\n",
      "        [0.7276, 0.0119, 0.1938, 0.0069],\n",
      "        [0.2689, 0.0069, 0.5449, 0.0127],\n",
      "        [0.6192, 0.0268, 0.6787, 0.0446],\n",
      "        [0.5536, 0.0050, 0.8325, 0.0112],\n",
      "        [0.5507, 0.0350, 0.5276, 0.0353],\n",
      "        [0.2578, 0.0042, 0.3487, 0.0254],\n",
      "        [0.6253, 0.0477, 0.6810, 0.0493]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0766, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -4.149619855706433\n",
      "Epoch 1, Loss: -3.609765350396638\n",
      "Epoch 1, Loss: -3.4394684282000503\n",
      "Epoch 1, Loss: -3.6226355443557523\n",
      "Epoch 1, Loss: -3.5303155758629114\n",
      "tensor([[0.4052, 0.0120, 0.3030, 0.0835],\n",
      "        [0.3377, 0.0063, 0.5326, 0.0159],\n",
      "        [0.6964, 0.0158, 0.6410, 0.0196],\n",
      "        [0.7980, 0.0020, 0.2241, 0.0036],\n",
      "        [0.4520, 0.0313, 0.6177, 0.0196],\n",
      "        [0.2063, 0.0054, 0.4250, 0.0602],\n",
      "        [0.2523, 0.0013, 0.4944, 0.0024],\n",
      "        [0.7184, 0.0082, 0.6870, 0.0139],\n",
      "        [0.5045, 0.0171, 0.4435, 0.0135],\n",
      "        [0.6453, 0.0059, 0.3952, 0.0110],\n",
      "        [0.6774, 0.0201, 0.7626, 0.0124],\n",
      "        [0.7230, 0.0112, 0.1616, 0.0165],\n",
      "        [0.6339, 0.0092, 0.1812, 0.0144],\n",
      "        [0.2055, 0.0154, 0.4433, 0.0496],\n",
      "        [0.5716, 0.0290, 0.6830, 0.0350],\n",
      "        [0.7718, 0.0106, 0.4200, 0.0111],\n",
      "        [0.5560, 0.0042, 0.3494, 0.0034],\n",
      "        [0.3940, 0.0165, 0.4262, 0.0511],\n",
      "        [0.1834, 0.0037, 0.8511, 0.0068],\n",
      "        [0.3918, 0.0169, 0.5788, 0.0127],\n",
      "        [0.4238, 0.0114, 0.7493, 0.0056],\n",
      "        [0.4926, 0.0147, 0.7186, 0.0192],\n",
      "        [0.2238, 0.0105, 0.5536, 0.0141],\n",
      "        [0.4675, 0.0335, 0.4203, 0.0151],\n",
      "        [0.2709, 0.0152, 0.3676, 0.0330],\n",
      "        [0.6085, 0.0116, 0.4691, 0.0073],\n",
      "        [0.7612, 0.0264, 0.6967, 0.0240],\n",
      "        [0.4169, 0.0050, 0.5351, 0.0038],\n",
      "        [0.3672, 0.0032, 0.8229, 0.0021],\n",
      "        [0.4879, 0.0377, 0.3309, 0.0355],\n",
      "        [0.4941, 0.0355, 0.3664, 0.0341],\n",
      "        [0.5169, 0.0122, 0.6738, 0.0128]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0624, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.597069596037767\n",
      "Epoch 1, Loss: -4.007604773034423\n",
      "Epoch 1, Loss: -3.4880570005742566\n",
      "Epoch 1, Loss: -4.164678406783622\n",
      "Epoch 1, Loss: -4.288365210044943\n",
      "tensor([[4.9035e-01, 2.4314e-02, 6.1749e-01, 1.3713e-02],\n",
      "        [6.2637e-01, 1.5438e-02, 2.5476e-01, 1.4195e-02],\n",
      "        [3.4189e-01, 4.5134e-03, 6.5946e-01, 2.1830e-03],\n",
      "        [6.4166e-01, 1.3762e-02, 4.7855e-01, 8.9644e-03],\n",
      "        [1.5815e-01, 5.9827e-04, 2.9292e-01, 1.7639e-02],\n",
      "        [7.9253e-01, 8.4683e-03, 5.4436e-01, 1.2964e-02],\n",
      "        [8.5154e-01, 5.3937e-03, 5.8259e-01, 5.6085e-03],\n",
      "        [5.5101e-01, 8.3052e-03, 2.3947e-01, 4.6555e-03],\n",
      "        [5.3779e-01, 2.8146e-03, 4.6551e-01, 2.1249e-03],\n",
      "        [6.7171e-01, 3.6805e-02, 2.7564e-01, 1.9495e-02],\n",
      "        [2.4961e-01, 8.9565e-03, 5.9504e-01, 1.0230e-02],\n",
      "        [1.2766e-01, 1.8483e-03, 7.2669e-01, 2.4734e-03],\n",
      "        [6.9802e-01, 6.3431e-03, 5.2785e-01, 3.4722e-03],\n",
      "        [5.5296e-01, 9.7219e-03, 7.7077e-01, 1.5260e-02],\n",
      "        [3.0911e-01, 6.0158e-03, 4.7006e-01, 4.5360e-03],\n",
      "        [4.9718e-01, 1.2713e-02, 6.0851e-01, 6.5072e-03],\n",
      "        [3.1844e-01, 5.7943e-03, 3.6106e-01, 2.2308e-02],\n",
      "        [8.1403e-01, 6.3777e-03, 4.3832e-01, 2.8967e-03],\n",
      "        [4.5612e-01, 1.2599e-02, 2.6968e-01, 1.3400e-02],\n",
      "        [5.1037e-01, 1.4424e-02, 5.1929e-01, 7.8639e-03],\n",
      "        [4.7884e-01, 1.9112e-02, 3.0185e-01, 2.4451e-02],\n",
      "        [5.4424e-01, 1.9550e-02, 6.2377e-01, 2.1067e-02],\n",
      "        [4.7205e-01, 5.4022e-03, 2.6483e-01, 3.1015e-03],\n",
      "        [3.3409e-01, 8.3826e-03, 6.9177e-01, 8.5297e-03],\n",
      "        [3.3085e-01, 1.3750e-02, 6.5177e-01, 1.7301e-02],\n",
      "        [4.1145e-01, 3.4304e-03, 7.5132e-01, 5.4296e-03],\n",
      "        [1.7072e-01, 7.1643e-03, 3.0748e-01, 1.6017e-02],\n",
      "        [6.1107e-01, 4.3378e-02, 4.7833e-01, 3.4187e-02],\n",
      "        [4.9657e-01, 1.8032e-02, 6.5380e-01, 2.9328e-02],\n",
      "        [7.3167e-01, 2.3861e-02, 2.2624e-01, 3.4455e-02],\n",
      "        [4.6232e-01, 1.3661e-02, 5.6892e-01, 8.1705e-03],\n",
      "        [7.9390e-01, 9.5189e-03, 2.1389e-01, 4.9315e-03]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0480, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.8477869995319813\n",
      "Epoch 1, Loss: -4.210965928018594\n",
      "Epoch 1, Loss: -3.7819242564483013\n",
      "Epoch 1, Loss: -4.16475837890362\n",
      "Epoch 1, Loss: -3.7707162368477567\n",
      "tensor([[5.0773e-01, 1.7755e-02, 3.8200e-01, 1.3155e-02],\n",
      "        [7.6936e-01, 3.9719e-03, 5.0833e-01, 4.0089e-03],\n",
      "        [3.5446e-01, 2.7252e-02, 3.6838e-01, 3.4605e-02],\n",
      "        [6.9573e-01, 8.9001e-03, 6.4732e-01, 3.7560e-03],\n",
      "        [4.5880e-01, 1.0985e-02, 7.1591e-01, 5.9041e-03],\n",
      "        [4.5667e-01, 2.1192e-02, 5.5186e-01, 2.2767e-02],\n",
      "        [7.2414e-01, 8.8767e-03, 2.3962e-01, 2.2600e-03],\n",
      "        [3.9860e-01, 2.2047e-03, 3.6173e-01, 4.1938e-03],\n",
      "        [3.7223e-01, 6.7354e-03, 5.9253e-01, 9.8529e-03],\n",
      "        [6.4359e-01, 3.1942e-03, 4.0881e-01, 3.5507e-03],\n",
      "        [3.3366e-01, 3.2976e-02, 3.8320e-01, 3.3063e-02],\n",
      "        [6.7285e-01, 9.3961e-03, 2.5987e-01, 1.0248e-02],\n",
      "        [5.9060e-01, 1.1703e-03, 3.7710e-01, 4.0301e-04],\n",
      "        [2.9644e-01, 7.1476e-03, 4.9399e-01, 3.4754e-02],\n",
      "        [4.5161e-01, 5.8108e-03, 3.6994e-01, 3.1343e-03],\n",
      "        [3.5965e-01, 3.1362e-03, 2.9890e-01, 2.5977e-03],\n",
      "        [6.0862e-01, 1.0238e-02, 7.6999e-01, 4.3914e-03],\n",
      "        [6.1173e-01, 2.2525e-02, 5.7421e-01, 1.9419e-02],\n",
      "        [2.4939e-01, 9.0949e-03, 7.3580e-01, 1.2655e-02],\n",
      "        [4.0651e-01, 2.6285e-02, 3.9206e-01, 2.5951e-02],\n",
      "        [6.1228e-01, 2.0183e-02, 6.6416e-01, 1.4812e-02],\n",
      "        [6.1759e-01, 1.0388e-02, 7.5169e-01, 7.6719e-03],\n",
      "        [3.1073e-01, 4.0177e-03, 3.4944e-01, 1.8233e-02],\n",
      "        [7.6027e-01, 9.4213e-03, 6.7435e-01, 1.0164e-02],\n",
      "        [7.2657e-01, 1.0601e-02, 6.1596e-01, 4.3258e-03],\n",
      "        [2.1099e-01, 1.9541e-03, 3.2167e-01, 1.2586e-02],\n",
      "        [3.3825e-01, 4.4274e-03, 7.0666e-01, 4.5655e-03],\n",
      "        [1.8289e-01, 1.1757e-02, 2.9883e-01, 2.5401e-02],\n",
      "        [5.9958e-01, 5.6989e-02, 2.5207e-01, 2.6495e-02],\n",
      "        [7.2913e-01, 3.9754e-03, 4.7600e-01, 1.2180e-03],\n",
      "        [2.3625e-01, 4.0997e-03, 6.1926e-01, 1.3237e-02],\n",
      "        [8.2347e-01, 2.8235e-03, 4.6441e-01, 1.6301e-03]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0645, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -4.0982407039137\n",
      "Epoch 1, Loss: -4.030484180005715\n",
      "Epoch 1, Loss: -4.413394966352581\n",
      "Epoch 1, Loss: -4.0753667024794\n",
      "Epoch 1, Loss: -3.6174409898590447\n",
      "tensor([[0.3154, 0.0178, 0.7913, 0.0162],\n",
      "        [0.6669, 0.0021, 0.7052, 0.0028],\n",
      "        [0.3900, 0.0127, 0.3753, 0.0210],\n",
      "        [0.4544, 0.0133, 0.3583, 0.0157],\n",
      "        [0.6135, 0.0114, 0.3082, 0.0137],\n",
      "        [0.5131, 0.0081, 0.5051, 0.0085],\n",
      "        [0.5324, 0.0056, 0.3567, 0.0044],\n",
      "        [0.4526, 0.0073, 0.7611, 0.0042],\n",
      "        [0.3190, 0.0146, 0.6563, 0.0122],\n",
      "        [0.3195, 0.0178, 0.5998, 0.0445],\n",
      "        [0.8155, 0.0092, 0.8346, 0.0050],\n",
      "        [0.8036, 0.0029, 0.5294, 0.0016],\n",
      "        [0.3609, 0.0356, 0.6936, 0.0169],\n",
      "        [0.5302, 0.0095, 0.5549, 0.0027],\n",
      "        [0.7097, 0.0371, 0.3701, 0.0405],\n",
      "        [0.7694, 0.0213, 0.3643, 0.0186],\n",
      "        [0.4638, 0.0025, 0.7914, 0.0014],\n",
      "        [0.7759, 0.0161, 0.2892, 0.0176],\n",
      "        [0.2662, 0.0040, 0.5744, 0.0041],\n",
      "        [0.5780, 0.0048, 0.6691, 0.0028],\n",
      "        [0.1813, 0.0023, 0.5517, 0.0026],\n",
      "        [0.2352, 0.0096, 0.5764, 0.0102],\n",
      "        [0.3038, 0.0015, 0.3675, 0.0046],\n",
      "        [0.5852, 0.0137, 0.4380, 0.0082],\n",
      "        [0.7113, 0.0045, 0.5742, 0.0071],\n",
      "        [0.3434, 0.0337, 0.6778, 0.0196],\n",
      "        [0.7885, 0.0047, 0.8167, 0.0043],\n",
      "        [0.4391, 0.0040, 0.3073, 0.0146],\n",
      "        [0.8313, 0.0041, 0.6349, 0.0096],\n",
      "        [0.3561, 0.0051, 0.5402, 0.0110],\n",
      "        [0.7533, 0.0162, 0.2373, 0.0038],\n",
      "        [0.7734, 0.0035, 0.3668, 0.0022]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0690, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.7334948226509317\n",
      "Epoch 1, Loss: -3.710891991003118\n",
      "Epoch 1, Loss: -4.251575361375176\n",
      "Epoch 1, Loss: -3.6664033281104302\n",
      "Epoch 1, Loss: -4.185400474697854\n",
      "tensor([[6.6425e-01, 3.7497e-03, 7.1742e-01, 2.4927e-03],\n",
      "        [6.5224e-01, 2.9838e-02, 2.8314e-01, 1.7567e-02],\n",
      "        [5.4096e-01, 9.4049e-03, 2.8311e-01, 3.2884e-02],\n",
      "        [3.7934e-01, 7.2668e-03, 7.2689e-01, 7.0428e-03],\n",
      "        [7.8850e-01, 2.1389e-03, 7.8703e-01, 4.1793e-03],\n",
      "        [6.8786e-01, 3.0018e-02, 7.1546e-01, 1.4090e-02],\n",
      "        [5.1724e-01, 1.1595e-02, 6.1310e-01, 9.5747e-03],\n",
      "        [5.0876e-01, 8.2898e-03, 3.9773e-01, 3.3098e-03],\n",
      "        [7.4632e-01, 4.5166e-03, 4.9251e-01, 5.1484e-03],\n",
      "        [2.3073e-01, 1.5747e-02, 6.8619e-01, 1.0896e-02],\n",
      "        [6.9094e-01, 1.8906e-02, 4.8439e-01, 2.0622e-02],\n",
      "        [6.4562e-01, 1.7580e-02, 5.2247e-01, 2.0960e-02],\n",
      "        [3.1251e-01, 1.6631e-02, 6.9894e-01, 1.4344e-02],\n",
      "        [2.7019e-01, 6.1883e-04, 5.1910e-01, 2.7381e-03],\n",
      "        [5.0697e-01, 4.0136e-02, 7.5311e-01, 1.8033e-02],\n",
      "        [7.4179e-01, 1.7676e-02, 3.2646e-01, 1.0073e-02],\n",
      "        [6.4937e-01, 1.3525e-02, 4.9724e-01, 1.2340e-02],\n",
      "        [4.2031e-01, 1.6522e-02, 2.3761e-01, 1.5864e-02],\n",
      "        [4.2873e-01, 9.8231e-03, 6.6731e-01, 9.7812e-03],\n",
      "        [4.3444e-01, 1.1112e-02, 6.6065e-01, 1.0111e-02],\n",
      "        [6.8501e-01, 1.3844e-02, 5.7005e-01, 1.7776e-02],\n",
      "        [6.0091e-01, 1.5036e-02, 5.1317e-01, 2.3985e-02],\n",
      "        [7.0772e-01, 1.0019e-02, 3.2165e-01, 7.9258e-03],\n",
      "        [7.9795e-01, 3.4262e-03, 4.2157e-01, 5.0170e-03],\n",
      "        [2.8738e-01, 2.4697e-03, 2.9495e-01, 7.7167e-03],\n",
      "        [2.2458e-01, 6.3159e-03, 4.6061e-01, 7.4659e-03],\n",
      "        [3.4514e-01, 9.3617e-03, 1.7639e-01, 2.1231e-02],\n",
      "        [2.6223e-01, 1.1994e-03, 1.6397e-01, 2.9239e-03],\n",
      "        [2.1336e-01, 4.3922e-03, 3.5618e-01, 3.3419e-03],\n",
      "        [3.8485e-01, 7.2112e-03, 7.9631e-01, 3.8877e-03],\n",
      "        [6.3197e-01, 2.5086e-03, 3.2767e-01, 1.9275e-03],\n",
      "        [5.3421e-01, 8.1734e-03, 7.0980e-01, 1.1941e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0551, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.494298627831137\n",
      "Epoch 1, Loss: -4.158915589845597\n",
      "Epoch 1, Loss: -4.52431445699146\n",
      "Epoch 1, Loss: -4.275621189727606\n",
      "Epoch 1, Loss: -3.7568085324526104\n",
      "tensor([[2.5137e-01, 7.2886e-03, 2.2218e-01, 1.5927e-02],\n",
      "        [1.7579e-01, 7.5120e-03, 6.1494e-01, 2.1759e-03],\n",
      "        [1.9583e-01, 5.0232e-03, 2.8036e-01, 1.0304e-02],\n",
      "        [5.4621e-01, 1.3080e-02, 5.6449e-01, 2.8606e-02],\n",
      "        [4.6160e-01, 1.1066e-02, 6.8024e-01, 1.2655e-02],\n",
      "        [4.9257e-01, 2.3564e-02, 4.0359e-01, 1.6338e-02],\n",
      "        [7.2264e-01, 3.4219e-03, 2.6468e-01, 2.8127e-03],\n",
      "        [3.3438e-01, 1.0091e-03, 4.4343e-01, 1.3450e-03],\n",
      "        [5.0811e-01, 1.0179e-03, 2.6697e-01, 6.4435e-04],\n",
      "        [4.8285e-01, 1.7130e-02, 5.2007e-01, 1.5836e-02],\n",
      "        [3.9557e-01, 3.0205e-02, 5.2536e-01, 1.8542e-02],\n",
      "        [5.4871e-01, 2.9547e-02, 6.9240e-01, 2.2291e-02],\n",
      "        [3.2607e-01, 9.6077e-04, 3.9018e-01, 1.7442e-03],\n",
      "        [6.8135e-01, 1.2049e-02, 4.2966e-01, 8.7137e-03],\n",
      "        [3.7550e-01, 2.8977e-03, 1.1354e-01, 2.7306e-03],\n",
      "        [4.1092e-01, 1.4626e-02, 8.1315e-01, 9.3791e-03],\n",
      "        [4.6974e-01, 3.5541e-02, 5.0892e-01, 4.6322e-02],\n",
      "        [5.5454e-01, 1.0239e-02, 7.1186e-01, 1.3566e-02],\n",
      "        [5.4258e-01, 4.3476e-02, 5.3193e-01, 3.9110e-02],\n",
      "        [4.8653e-01, 9.9206e-03, 6.3451e-01, 1.2500e-02],\n",
      "        [3.7354e-01, 2.5740e-02, 6.2977e-01, 3.3199e-02],\n",
      "        [4.9867e-01, 2.7296e-02, 6.7816e-01, 1.9009e-02],\n",
      "        [2.8046e-01, 8.9154e-03, 1.7718e-01, 1.0305e-02],\n",
      "        [6.9902e-01, 1.2004e-02, 7.1606e-01, 9.3464e-03],\n",
      "        [1.4530e-01, 2.1610e-03, 8.4385e-01, 1.5861e-03],\n",
      "        [6.5324e-01, 1.2420e-02, 5.9158e-01, 2.5678e-02],\n",
      "        [6.6196e-01, 2.3788e-03, 3.7764e-01, 3.1680e-03],\n",
      "        [3.5495e-01, 1.3005e-02, 5.9433e-01, 9.1945e-03],\n",
      "        [8.0636e-01, 4.5151e-03, 3.1139e-01, 5.0067e-03],\n",
      "        [4.2373e-01, 6.3191e-03, 2.8442e-01, 4.4107e-03],\n",
      "        [4.7894e-01, 1.9739e-02, 4.2604e-01, 2.2101e-02],\n",
      "        [5.1783e-01, 4.7493e-02, 5.2683e-01, 3.4398e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0586, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 1, Loss: -3.5771474884113763\n",
      "Epoch 1, Loss: -2.4288006092240586\n",
      "Epoch 1, Loss: -3.945764071804655\n",
      "Epoch 1, Loss: -0.7482963134648938\n",
      "Epoch 1, Loss: -3.9825089334967094\n",
      "tensor([[6.2724e-01, 1.3446e-02, 5.7931e-01, 1.6106e-02],\n",
      "        [6.8070e-01, 1.6422e-02, 2.2986e-01, 1.4912e-02],\n",
      "        [5.2920e-01, 1.4810e-03, 5.9061e-01, 2.2313e-03],\n",
      "        [5.1008e-01, 1.2519e-02, 7.5446e-01, 8.2962e-03],\n",
      "        [3.4604e-01, 1.1718e-03, 6.7431e-01, 5.0287e-04],\n",
      "        [5.2501e-01, 2.2803e-02, 6.6625e-01, 1.2910e-02],\n",
      "        [2.7318e-01, 2.2685e-03, 4.8660e-01, 2.7858e-03],\n",
      "        [3.5128e-01, 2.5117e-02, 3.3889e-01, 3.7493e-02],\n",
      "        [2.0435e-01, 9.9876e-03, 2.4006e-01, 1.0585e-02],\n",
      "        [5.5544e-01, 7.6282e-03, 4.4097e-01, 1.2124e-02],\n",
      "        [4.3938e-01, 5.4851e-03, 7.5080e-01, 4.0284e-03],\n",
      "        [4.7552e-01, 1.5572e-02, 7.8807e-01, 9.3439e-03],\n",
      "        [5.0716e-01, 1.2071e-02, 4.7329e-01, 2.2215e-02],\n",
      "        [7.4060e-01, 5.5559e-03, 7.1532e-01, 6.1315e-03],\n",
      "        [7.0698e-01, 1.4872e-02, 5.3188e-01, 1.2919e-02],\n",
      "        [2.6657e-01, 9.7099e-03, 3.6067e-01, 1.6216e-02],\n",
      "        [2.3427e-01, 5.6579e-03, 3.0774e-01, 2.1917e-02],\n",
      "        [5.3629e-01, 3.4099e-03, 6.8443e-01, 2.0466e-03],\n",
      "        [2.5585e-01, 2.3005e-03, 5.1922e-01, 1.1545e-03],\n",
      "        [5.8683e-01, 4.6629e-03, 2.3819e-01, 5.4940e-03],\n",
      "        [5.8560e-01, 9.6620e-03, 4.1847e-01, 8.2123e-03],\n",
      "        [6.1367e-01, 4.7049e-03, 5.4463e-01, 4.2299e-03],\n",
      "        [2.1413e-01, 3.9120e-03, 8.1432e-01, 1.4243e-03],\n",
      "        [4.2453e-01, 2.5466e-02, 4.1634e-01, 4.9121e-02],\n",
      "        [6.7571e-01, 1.0801e-02, 4.9028e-01, 1.2764e-02],\n",
      "        [2.5372e-01, 2.6075e-04, 8.4169e-01, 3.6241e-04],\n",
      "        [6.7603e-01, 1.4716e-02, 3.1255e-01, 9.2456e-03],\n",
      "        [5.3753e-01, 6.8255e-03, 4.7170e-01, 1.5746e-02],\n",
      "        [7.1489e-01, 1.0955e-02, 4.3120e-01, 1.5816e-02],\n",
      "        [5.8664e-01, 8.3842e-03, 3.7692e-01, 1.2297e-02],\n",
      "        [7.4191e-01, 1.0993e-02, 4.3217e-01, 1.3739e-02],\n",
      "        [5.0282e-01, 1.3538e-02, 3.6540e-01, 2.5958e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0596, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.068954464163684\n",
      "Epoch 2, Loss: -3.9560382771234694\n",
      "Epoch 2, Loss: -4.062903660361086\n",
      "Epoch 2, Loss: -3.312275677340403\n",
      "Epoch 2, Loss: -3.844165215211801\n",
      "tensor([[2.4098e-01, 5.2364e-03, 4.2254e-01, 3.5730e-03],\n",
      "        [4.8781e-01, 1.0601e-02, 5.1969e-01, 2.1525e-02],\n",
      "        [7.3740e-01, 1.7227e-02, 4.5187e-01, 1.7283e-02],\n",
      "        [5.0553e-01, 5.9297e-03, 5.8317e-01, 8.8224e-03],\n",
      "        [7.9421e-01, 5.4682e-03, 3.4270e-01, 1.3310e-02],\n",
      "        [6.6968e-01, 1.1474e-02, 5.7948e-01, 1.9166e-02],\n",
      "        [2.7423e-01, 1.2164e-02, 3.7706e-01, 1.2682e-02],\n",
      "        [5.3226e-01, 6.5956e-03, 5.1860e-01, 1.4682e-02],\n",
      "        [8.0125e-01, 1.5386e-03, 7.6496e-01, 7.6818e-04],\n",
      "        [4.8448e-01, 1.4637e-02, 6.2751e-01, 1.2230e-02],\n",
      "        [5.8280e-01, 5.1393e-03, 6.7387e-01, 7.9432e-03],\n",
      "        [2.9219e-01, 2.6532e-03, 3.9358e-01, 3.4848e-03],\n",
      "        [6.7580e-01, 1.2174e-02, 3.7965e-01, 2.2262e-02],\n",
      "        [7.8803e-01, 4.6384e-03, 3.5053e-01, 5.2116e-03],\n",
      "        [5.2636e-01, 7.3172e-03, 6.2434e-01, 7.2484e-03],\n",
      "        [4.5849e-01, 3.2127e-02, 3.2986e-01, 3.4929e-02],\n",
      "        [6.5003e-01, 2.5814e-02, 3.0708e-01, 2.3380e-02],\n",
      "        [2.8791e-01, 2.1527e-02, 3.8989e-01, 1.5769e-02],\n",
      "        [3.4981e-01, 1.0670e-02, 3.5180e-01, 4.3830e-03],\n",
      "        [4.7609e-01, 1.0797e-02, 4.5144e-01, 2.2991e-02],\n",
      "        [6.4748e-01, 1.6988e-02, 3.2407e-01, 3.2691e-02],\n",
      "        [5.4203e-01, 1.8037e-02, 3.0942e-01, 1.9122e-02],\n",
      "        [5.8795e-01, 3.5949e-02, 3.8579e-01, 4.6787e-02],\n",
      "        [6.9440e-01, 8.6166e-03, 4.0835e-01, 1.0918e-02],\n",
      "        [3.7346e-01, 1.1321e-02, 4.1810e-01, 1.7403e-02],\n",
      "        [6.8402e-01, 1.0408e-02, 5.5318e-01, 2.0138e-02],\n",
      "        [5.5830e-01, 3.3695e-03, 4.3929e-01, 8.4776e-03],\n",
      "        [4.1603e-01, 1.4558e-02, 7.1837e-01, 1.0928e-02],\n",
      "        [5.6403e-01, 8.9518e-03, 6.9085e-01, 8.6100e-03],\n",
      "        [7.9526e-01, 4.3703e-03, 7.1888e-01, 4.5648e-03],\n",
      "        [2.9404e-01, 7.2302e-03, 6.0498e-01, 6.4244e-03],\n",
      "        [4.6546e-01, 2.0168e-02, 4.6053e-01, 2.3515e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0644, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -3.841092779676184\n",
      "Epoch 2, Loss: -3.9206459307677264\n",
      "Epoch 2, Loss: -3.6574024230248163\n",
      "Epoch 2, Loss: -3.921528846915408\n",
      "Epoch 2, Loss: -3.9668011188768144\n",
      "tensor([[0.6548, 0.0050, 0.7843, 0.0078],\n",
      "        [0.4584, 0.0069, 0.4955, 0.0117],\n",
      "        [0.4609, 0.0722, 0.5254, 0.0992],\n",
      "        [0.5759, 0.0275, 0.5492, 0.0388],\n",
      "        [0.7967, 0.0031, 0.3091, 0.0045],\n",
      "        [0.5521, 0.0074, 0.7703, 0.0050],\n",
      "        [0.4738, 0.0019, 0.5053, 0.0031],\n",
      "        [0.4051, 0.0281, 0.3504, 0.0271],\n",
      "        [0.3871, 0.0081, 0.4963, 0.0143],\n",
      "        [0.4150, 0.0277, 0.5771, 0.0238],\n",
      "        [0.7008, 0.0066, 0.6955, 0.0092],\n",
      "        [0.6673, 0.0100, 0.5341, 0.0131],\n",
      "        [0.3179, 0.0196, 0.4221, 0.0165],\n",
      "        [0.3935, 0.0491, 0.5305, 0.0617],\n",
      "        [0.2616, 0.0014, 0.4622, 0.0040],\n",
      "        [0.2610, 0.0227, 0.3224, 0.0314],\n",
      "        [0.4568, 0.0053, 0.4997, 0.0125],\n",
      "        [0.2484, 0.0237, 0.4399, 0.0240],\n",
      "        [0.5264, 0.0020, 0.7050, 0.0026],\n",
      "        [0.5877, 0.0086, 0.4322, 0.0078],\n",
      "        [0.5071, 0.0293, 0.3087, 0.0244],\n",
      "        [0.2866, 0.0187, 0.4805, 0.0337],\n",
      "        [0.4885, 0.0205, 0.3201, 0.0410],\n",
      "        [0.5634, 0.0135, 0.8068, 0.0112],\n",
      "        [0.7834, 0.0045, 0.5065, 0.0087],\n",
      "        [0.4181, 0.1292, 0.4992, 0.1018],\n",
      "        [0.4353, 0.0355, 0.6461, 0.0560],\n",
      "        [0.5789, 0.0040, 0.5592, 0.0079],\n",
      "        [0.7904, 0.0084, 0.7127, 0.0083],\n",
      "        [0.7183, 0.0066, 0.2869, 0.0061],\n",
      "        [0.7009, 0.0014, 0.2898, 0.0041],\n",
      "        [0.5948, 0.0057, 0.4445, 0.0089]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0684, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.02070231115996\n",
      "Epoch 2, Loss: -3.7220761068044066\n",
      "Epoch 2, Loss: -3.867805453405351\n",
      "Epoch 2, Loss: -3.647500690374457\n",
      "Epoch 2, Loss: -3.9341834754299656\n",
      "tensor([[3.6157e-01, 1.1278e-01, 7.0494e-01, 5.7295e-02],\n",
      "        [4.9931e-01, 5.1171e-03, 5.1693e-01, 9.2076e-03],\n",
      "        [4.9342e-01, 6.4701e-03, 3.4024e-01, 1.1954e-02],\n",
      "        [5.8382e-01, 5.0524e-03, 6.5462e-01, 6.8270e-03],\n",
      "        [8.0238e-01, 7.9155e-04, 5.1563e-01, 2.2428e-03],\n",
      "        [3.0587e-01, 3.0909e-02, 5.7110e-01, 4.2635e-02],\n",
      "        [2.4242e-01, 8.8763e-03, 4.6620e-01, 1.7858e-02],\n",
      "        [6.7469e-01, 1.8943e-02, 6.4095e-01, 1.5800e-02],\n",
      "        [8.4137e-01, 6.5543e-04, 4.9383e-01, 1.0292e-03],\n",
      "        [6.3860e-01, 1.0341e-02, 5.1143e-01, 1.7729e-02],\n",
      "        [4.4681e-01, 1.3885e-02, 6.6572e-01, 1.0430e-02],\n",
      "        [6.0252e-01, 1.0905e-02, 2.1211e-01, 8.5524e-03],\n",
      "        [2.5008e-01, 1.4382e-03, 3.5163e-01, 2.6755e-03],\n",
      "        [3.5927e-01, 4.5329e-03, 5.3868e-01, 9.9277e-03],\n",
      "        [4.7360e-01, 4.5617e-03, 6.9381e-01, 3.7134e-03],\n",
      "        [4.6637e-01, 2.5512e-02, 7.2839e-01, 2.9973e-02],\n",
      "        [6.0635e-01, 3.9582e-03, 7.4873e-01, 2.9513e-03],\n",
      "        [4.3564e-01, 2.7939e-02, 6.7686e-01, 3.0762e-02],\n",
      "        [4.8623e-01, 3.6210e-02, 3.8916e-01, 2.8908e-02],\n",
      "        [5.9886e-01, 1.7203e-02, 4.1081e-01, 1.9165e-02],\n",
      "        [3.3548e-01, 6.2214e-03, 3.2015e-01, 7.1784e-03],\n",
      "        [5.8602e-01, 9.8188e-03, 2.3069e-01, 1.0667e-02],\n",
      "        [4.6389e-01, 5.0932e-02, 5.9225e-01, 4.2113e-02],\n",
      "        [7.4176e-01, 2.3511e-03, 5.7819e-01, 1.4360e-02],\n",
      "        [6.7733e-01, 6.1989e-03, 2.8692e-01, 4.6976e-03],\n",
      "        [6.9818e-01, 6.6895e-03, 2.7097e-01, 3.7862e-03],\n",
      "        [4.0841e-01, 2.0861e-02, 6.2475e-01, 2.2482e-02],\n",
      "        [4.6624e-01, 3.2422e-02, 4.0856e-01, 5.0481e-02],\n",
      "        [4.6778e-01, 1.1948e-02, 4.6965e-01, 1.2386e-02],\n",
      "        [4.0977e-01, 2.1853e-02, 4.1304e-01, 1.0936e-02],\n",
      "        [6.0181e-01, 1.4604e-02, 2.5924e-01, 2.0717e-02],\n",
      "        [4.9401e-01, 1.5445e-02, 7.9143e-01, 2.5466e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0606, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -3.8495280628196022\n",
      "Epoch 2, Loss: -3.948324909175075\n",
      "Epoch 2, Loss: -4.2187468566437545\n",
      "Epoch 2, Loss: -3.8934037850253054\n",
      "Epoch 2, Loss: -3.650838776865952\n",
      "tensor([[4.4392e-01, 2.5883e-03, 5.1074e-01, 2.5692e-03],\n",
      "        [5.8432e-01, 5.8158e-04, 3.9809e-01, 1.5527e-03],\n",
      "        [1.7028e-01, 3.1390e-03, 3.9093e-01, 6.1739e-03],\n",
      "        [7.1460e-01, 4.1317e-02, 5.4011e-01, 2.6791e-02],\n",
      "        [2.4830e-01, 4.7797e-03, 3.4728e-01, 1.2117e-02],\n",
      "        [6.9356e-01, 7.9341e-03, 6.8418e-01, 7.2335e-03],\n",
      "        [6.8347e-01, 5.5126e-03, 4.7529e-01, 1.0199e-02],\n",
      "        [4.3363e-01, 6.2543e-02, 7.2068e-01, 3.4249e-02],\n",
      "        [3.9479e-01, 2.5384e-03, 2.5406e-01, 8.1800e-03],\n",
      "        [7.0706e-01, 6.7055e-04, 4.8590e-01, 2.0561e-03],\n",
      "        [4.9966e-01, 2.4871e-02, 2.5149e-01, 3.3682e-02],\n",
      "        [3.6718e-01, 8.6056e-03, 3.3024e-01, 1.1492e-02],\n",
      "        [7.1707e-01, 1.2208e-03, 3.5355e-01, 3.2920e-03],\n",
      "        [7.2900e-01, 8.0085e-03, 2.3528e-01, 3.0265e-03],\n",
      "        [3.3378e-01, 3.9406e-02, 4.1448e-01, 3.6400e-02],\n",
      "        [3.2224e-01, 2.2572e-02, 5.5379e-01, 2.5531e-02],\n",
      "        [3.1306e-01, 1.4541e-02, 4.4605e-01, 1.8987e-02],\n",
      "        [4.9699e-01, 2.1806e-02, 7.7487e-01, 1.8687e-02],\n",
      "        [7.3208e-01, 4.4016e-03, 3.1658e-01, 3.1869e-03],\n",
      "        [6.8935e-01, 9.2918e-03, 5.2831e-01, 1.2589e-02],\n",
      "        [6.0033e-01, 1.6552e-02, 2.2454e-01, 4.3377e-03],\n",
      "        [3.6940e-01, 2.2436e-02, 5.3943e-01, 1.6206e-02],\n",
      "        [3.6402e-01, 8.7322e-03, 2.2054e-01, 2.3537e-02],\n",
      "        [3.8925e-01, 9.7079e-02, 5.1466e-01, 1.0967e-01],\n",
      "        [6.3155e-01, 7.6018e-03, 8.1434e-01, 6.5433e-03],\n",
      "        [5.7739e-01, 3.5402e-03, 3.1542e-01, 2.8032e-03],\n",
      "        [6.1671e-01, 1.3315e-02, 4.4558e-01, 9.5458e-03],\n",
      "        [7.3609e-01, 1.7628e-02, 7.1009e-01, 1.1420e-02],\n",
      "        [5.4687e-01, 4.7481e-02, 5.4571e-01, 3.4477e-02],\n",
      "        [4.4367e-01, 7.8340e-03, 6.5049e-01, 1.7334e-02],\n",
      "        [2.8046e-01, 5.2875e-02, 5.2607e-01, 3.3780e-02],\n",
      "        [4.8392e-01, 7.7844e-03, 3.7974e-01, 1.6070e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0756, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -2.532393649701962\n",
      "Epoch 2, Loss: -4.12012681691332\n",
      "Epoch 2, Loss: -4.236263419031528\n",
      "Epoch 2, Loss: -4.262671514736994\n",
      "Epoch 2, Loss: -4.107582829872827\n",
      "tensor([[6.7943e-01, 1.0781e-02, 6.3847e-01, 1.4130e-02],\n",
      "        [4.8246e-01, 2.5884e-02, 7.2736e-01, 2.1562e-02],\n",
      "        [5.4111e-01, 2.0496e-03, 5.3269e-01, 9.3894e-03],\n",
      "        [4.8623e-01, 2.9905e-02, 3.0392e-01, 3.9371e-02],\n",
      "        [7.4144e-01, 3.7888e-03, 7.2825e-01, 4.3623e-03],\n",
      "        [6.5564e-01, 4.5941e-03, 6.9271e-01, 8.2571e-03],\n",
      "        [8.5395e-01, 6.6480e-04, 5.4357e-01, 2.7907e-03],\n",
      "        [5.7136e-01, 4.6678e-03, 6.1167e-01, 7.0171e-03],\n",
      "        [4.9626e-01, 8.4497e-03, 5.2766e-01, 7.8928e-03],\n",
      "        [5.3693e-01, 4.0433e-02, 7.3470e-01, 1.0136e-02],\n",
      "        [7.4949e-01, 2.4472e-03, 6.6129e-01, 1.1878e-02],\n",
      "        [1.9078e-01, 2.9701e-03, 2.7290e-01, 1.0454e-02],\n",
      "        [1.7683e-01, 5.8073e-03, 4.9946e-01, 1.4025e-02],\n",
      "        [6.5108e-01, 8.8433e-03, 5.0889e-01, 1.8453e-02],\n",
      "        [8.1254e-01, 1.7951e-03, 4.4548e-01, 5.8430e-03],\n",
      "        [4.3666e-01, 2.6188e-02, 6.3407e-01, 6.4216e-02],\n",
      "        [6.4657e-01, 7.5615e-03, 5.0098e-01, 1.4556e-02],\n",
      "        [2.3927e-01, 1.5816e-02, 4.7307e-01, 2.4973e-02],\n",
      "        [2.7461e-01, 3.5245e-03, 4.0168e-01, 8.6231e-03],\n",
      "        [5.2764e-01, 1.0026e-02, 7.9687e-01, 5.8174e-03],\n",
      "        [4.3406e-01, 2.4883e-02, 3.9159e-01, 2.1522e-02],\n",
      "        [2.9836e-01, 3.6902e-02, 5.8681e-01, 7.0665e-02],\n",
      "        [6.0070e-01, 1.0855e-02, 3.2135e-01, 1.4193e-02],\n",
      "        [2.6950e-01, 1.2641e-02, 2.2881e-01, 2.1306e-02],\n",
      "        [7.3184e-01, 6.8081e-03, 5.1382e-01, 7.5336e-03],\n",
      "        [6.1445e-01, 9.8457e-03, 5.6371e-01, 1.2465e-02],\n",
      "        [4.7626e-01, 2.6859e-02, 2.5808e-01, 2.6324e-02],\n",
      "        [3.5539e-01, 1.6420e-02, 7.3599e-01, 3.1842e-02],\n",
      "        [4.3831e-01, 1.6657e-02, 5.9826e-01, 2.5945e-02],\n",
      "        [3.5820e-01, 2.9062e-02, 6.7412e-01, 1.6430e-02],\n",
      "        [7.6981e-01, 1.0343e-02, 6.1490e-01, 1.2172e-02],\n",
      "        [5.2157e-01, 1.8177e-03, 4.1979e-01, 6.5201e-03]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0553, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -3.3633957763142295\n",
      "Epoch 2, Loss: -2.8202764283553714\n",
      "Epoch 2, Loss: -3.092880535335783\n",
      "Epoch 2, Loss: -3.670313684379262\n",
      "Epoch 2, Loss: -4.11914053467925\n",
      "tensor([[0.5793, 0.0047, 0.2321, 0.0016],\n",
      "        [0.3307, 0.0041, 0.2931, 0.0174],\n",
      "        [0.6697, 0.0040, 0.3323, 0.0044],\n",
      "        [0.6164, 0.0131, 0.7392, 0.0136],\n",
      "        [0.3273, 0.0010, 0.4875, 0.0025],\n",
      "        [0.3603, 0.0418, 0.5303, 0.0760],\n",
      "        [0.7633, 0.0075, 0.6631, 0.0152],\n",
      "        [0.5713, 0.0439, 0.6165, 0.0594],\n",
      "        [0.7254, 0.0013, 0.3955, 0.0043],\n",
      "        [0.5413, 0.0017, 0.8795, 0.0025],\n",
      "        [0.2280, 0.0038, 0.3669, 0.0036],\n",
      "        [0.4210, 0.0255, 0.2795, 0.0294],\n",
      "        [0.3594, 0.0033, 0.4722, 0.0112],\n",
      "        [0.2715, 0.0082, 0.6528, 0.0103],\n",
      "        [0.6730, 0.0027, 0.6267, 0.0192],\n",
      "        [0.2636, 0.0168, 0.6765, 0.0096],\n",
      "        [0.8003, 0.0029, 0.8691, 0.0028],\n",
      "        [0.6267, 0.0128, 0.7666, 0.0157],\n",
      "        [0.3537, 0.0157, 0.2440, 0.0081],\n",
      "        [0.7177, 0.0038, 0.4336, 0.0141],\n",
      "        [0.6522, 0.0179, 0.4733, 0.0215],\n",
      "        [0.7320, 0.0066, 0.4779, 0.0210],\n",
      "        [0.5249, 0.0133, 0.6484, 0.0212],\n",
      "        [0.5679, 0.0089, 0.6328, 0.0294],\n",
      "        [0.5343, 0.0507, 0.4000, 0.0890],\n",
      "        [0.2246, 0.0040, 0.5206, 0.0145],\n",
      "        [0.5635, 0.0081, 0.8051, 0.0169],\n",
      "        [0.5054, 0.0101, 0.6262, 0.0147],\n",
      "        [0.5494, 0.0079, 0.3744, 0.0183],\n",
      "        [0.2424, 0.0138, 0.3176, 0.0057],\n",
      "        [0.4837, 0.0018, 0.5115, 0.0066],\n",
      "        [0.6468, 0.0178, 0.7220, 0.0305]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0551, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.16285060832266\n",
      "Epoch 2, Loss: -2.870538605224673\n",
      "Epoch 2, Loss: -3.4038727823405637\n",
      "Epoch 2, Loss: -4.001216498757132\n",
      "Epoch 2, Loss: -4.097177716983557\n",
      "tensor([[0.6761, 0.0254, 0.3701, 0.0151],\n",
      "        [0.4416, 0.0056, 0.3402, 0.0042],\n",
      "        [0.4173, 0.0147, 0.2921, 0.0162],\n",
      "        [0.5447, 0.0193, 0.4313, 0.0263],\n",
      "        [0.1367, 0.0019, 0.2653, 0.0055],\n",
      "        [0.3214, 0.0267, 0.7127, 0.0252],\n",
      "        [0.4201, 0.0136, 0.2212, 0.0066],\n",
      "        [0.5020, 0.0042, 0.5230, 0.0188],\n",
      "        [0.5177, 0.0182, 0.4332, 0.0308],\n",
      "        [0.6447, 0.0168, 0.5803, 0.0256],\n",
      "        [0.4537, 0.0155, 0.2995, 0.0152],\n",
      "        [0.6632, 0.0109, 0.4906, 0.0211],\n",
      "        [0.4338, 0.0040, 0.7630, 0.0077],\n",
      "        [0.3919, 0.0150, 0.2275, 0.0081],\n",
      "        [0.4464, 0.0246, 0.2178, 0.0247],\n",
      "        [0.2663, 0.0100, 0.6748, 0.0163],\n",
      "        [0.5538, 0.0093, 0.5228, 0.0434],\n",
      "        [0.2290, 0.0491, 0.7699, 0.0484],\n",
      "        [0.5708, 0.0067, 0.8233, 0.0045],\n",
      "        [0.5961, 0.0054, 0.7915, 0.0056],\n",
      "        [0.6457, 0.0097, 0.6617, 0.0134],\n",
      "        [0.5330, 0.0078, 0.7146, 0.0178],\n",
      "        [0.3895, 0.0035, 0.5201, 0.0099],\n",
      "        [0.7610, 0.0018, 0.5712, 0.0039],\n",
      "        [0.3431, 0.0043, 0.2831, 0.0064],\n",
      "        [0.6892, 0.0143, 0.5208, 0.0256],\n",
      "        [0.4897, 0.0128, 0.4185, 0.0186],\n",
      "        [0.7437, 0.0091, 0.7345, 0.0069],\n",
      "        [0.2298, 0.0044, 0.3904, 0.0051],\n",
      "        [0.6412, 0.0099, 0.2660, 0.0072],\n",
      "        [0.4441, 0.0115, 0.2230, 0.0170],\n",
      "        [0.4449, 0.0035, 0.5576, 0.0079]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0599, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -3.436964299380535\n",
      "Epoch 2, Loss: -3.8446958032531944\n",
      "Epoch 2, Loss: -3.506380314753806\n",
      "Epoch 2, Loss: -3.637407903372006\n",
      "Epoch 2, Loss: -3.792588047689539\n",
      "tensor([[0.5722, 0.0410, 0.2436, 0.0147],\n",
      "        [0.5196, 0.0105, 0.4841, 0.0303],\n",
      "        [0.5846, 0.0265, 0.5278, 0.0328],\n",
      "        [0.5062, 0.0032, 0.5731, 0.0145],\n",
      "        [0.3804, 0.0046, 0.2928, 0.0076],\n",
      "        [0.3907, 0.0118, 0.4903, 0.0129],\n",
      "        [0.6903, 0.0062, 0.5860, 0.0062],\n",
      "        [0.4943, 0.0125, 0.4634, 0.0196],\n",
      "        [0.4433, 0.0241, 0.3692, 0.0270],\n",
      "        [0.5413, 0.0498, 0.2345, 0.0102],\n",
      "        [0.4054, 0.0114, 0.6477, 0.0140],\n",
      "        [0.5886, 0.0136, 0.7368, 0.0236],\n",
      "        [0.6295, 0.0319, 0.2696, 0.0096],\n",
      "        [0.2551, 0.0078, 0.4147, 0.0115],\n",
      "        [0.4164, 0.0056, 0.4094, 0.0084],\n",
      "        [0.3624, 0.0461, 0.5465, 0.0358],\n",
      "        [0.2968, 0.0133, 0.4841, 0.0222],\n",
      "        [0.5841, 0.0272, 0.5457, 0.0381],\n",
      "        [0.2251, 0.0038, 0.1076, 0.0029],\n",
      "        [0.2637, 0.0157, 0.2525, 0.0118],\n",
      "        [0.7900, 0.0059, 0.7666, 0.0051],\n",
      "        [0.2627, 0.0179, 0.5831, 0.0180],\n",
      "        [0.4642, 0.0251, 0.4915, 0.0387],\n",
      "        [0.6408, 0.0092, 0.2137, 0.0025],\n",
      "        [0.4821, 0.0354, 0.5329, 0.0657],\n",
      "        [0.4784, 0.0052, 0.6521, 0.0115],\n",
      "        [0.7121, 0.0093, 0.5654, 0.0072],\n",
      "        [0.5786, 0.0088, 0.1824, 0.0071],\n",
      "        [0.5926, 0.0037, 0.7760, 0.0031],\n",
      "        [0.5498, 0.0013, 0.7961, 0.0096],\n",
      "        [0.5311, 0.0146, 0.5613, 0.0235],\n",
      "        [0.2356, 0.0040, 0.4946, 0.0092]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0710, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -3.74271226824693\n",
      "Epoch 2, Loss: -4.055308797819993\n",
      "Epoch 2, Loss: -3.82838510756166\n",
      "Epoch 2, Loss: -2.7492050543093627\n",
      "Epoch 2, Loss: -3.9385121408805848\n",
      "tensor([[4.0766e-01, 1.0178e-02, 1.9597e-01, 4.2730e-03],\n",
      "        [7.7016e-01, 1.1133e-02, 7.0434e-01, 1.0706e-02],\n",
      "        [5.6346e-01, 2.0207e-02, 5.1399e-01, 1.6029e-02],\n",
      "        [3.5500e-01, 2.8648e-02, 3.6425e-01, 2.8846e-02],\n",
      "        [6.5536e-01, 1.1993e-02, 5.5438e-01, 2.4253e-02],\n",
      "        [6.2134e-01, 2.5581e-02, 2.3376e-01, 1.1982e-02],\n",
      "        [2.9506e-01, 6.8710e-03, 7.4834e-01, 1.8283e-02],\n",
      "        [3.2837e-01, 4.9791e-02, 6.7789e-01, 8.8225e-02],\n",
      "        [5.6495e-01, 2.1161e-02, 5.0523e-01, 1.7456e-02],\n",
      "        [7.0838e-01, 6.4247e-03, 5.8790e-01, 7.2914e-03],\n",
      "        [5.1769e-01, 7.5705e-04, 5.7718e-01, 1.9682e-03],\n",
      "        [1.9638e-01, 5.3296e-03, 5.0052e-01, 7.0276e-03],\n",
      "        [4.9561e-01, 6.1615e-03, 3.6291e-01, 4.9420e-03],\n",
      "        [3.9477e-01, 9.3973e-03, 5.8759e-01, 8.7497e-03],\n",
      "        [7.1297e-01, 8.0186e-03, 7.4608e-01, 5.7593e-03],\n",
      "        [3.9475e-01, 1.3969e-02, 2.9544e-01, 1.3758e-02],\n",
      "        [4.5659e-01, 1.2887e-02, 3.0511e-01, 1.2503e-02],\n",
      "        [3.5610e-01, 6.4251e-03, 1.8642e-01, 2.7195e-03],\n",
      "        [2.1674e-01, 1.0247e-03, 1.9813e-01, 1.8545e-03],\n",
      "        [5.9292e-01, 3.4594e-02, 1.7902e-01, 8.4542e-03],\n",
      "        [4.6735e-01, 5.7005e-03, 4.6941e-01, 1.8123e-02],\n",
      "        [7.7366e-01, 4.6678e-03, 7.3106e-01, 5.3474e-03],\n",
      "        [6.2262e-01, 2.6083e-03, 6.4388e-01, 7.5012e-03],\n",
      "        [5.6366e-01, 8.3352e-02, 4.4972e-01, 3.0482e-02],\n",
      "        [1.7552e-01, 3.5583e-03, 6.1457e-01, 6.4209e-03],\n",
      "        [3.9094e-01, 2.7396e-02, 5.3486e-01, 2.2035e-02],\n",
      "        [2.6898e-01, 2.1842e-02, 3.4225e-01, 1.1829e-02],\n",
      "        [3.4996e-01, 1.2635e-02, 5.9041e-01, 1.8794e-02],\n",
      "        [3.7228e-01, 2.5884e-03, 5.6591e-01, 4.6054e-03],\n",
      "        [6.8206e-01, 5.5766e-02, 2.0004e-01, 4.8901e-03],\n",
      "        [6.3213e-01, 1.1148e-01, 4.3751e-01, 4.3291e-02],\n",
      "        [2.0670e-01, 3.7031e-03, 3.5450e-01, 3.8405e-03]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0618, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -3.9746522711161667\n",
      "Epoch 2, Loss: -4.051212615109577\n",
      "Epoch 2, Loss: -4.091982132742579\n",
      "Epoch 2, Loss: -3.6992201052725013\n",
      "Epoch 2, Loss: -4.292894714596727\n",
      "tensor([[0.6694, 0.0127, 0.7198, 0.0045],\n",
      "        [0.6057, 0.0036, 0.1241, 0.0009],\n",
      "        [0.2498, 0.0053, 0.6612, 0.0221],\n",
      "        [0.4030, 0.0067, 0.2906, 0.0056],\n",
      "        [0.6064, 0.0021, 0.7176, 0.0020],\n",
      "        [0.2630, 0.0053, 0.5078, 0.0111],\n",
      "        [0.4115, 0.0039, 0.4856, 0.0027],\n",
      "        [0.2644, 0.0090, 0.7189, 0.0141],\n",
      "        [0.2112, 0.0032, 0.4371, 0.0009],\n",
      "        [0.5933, 0.0040, 0.5521, 0.0094],\n",
      "        [0.1874, 0.0111, 0.5294, 0.0217],\n",
      "        [0.5032, 0.0270, 0.3899, 0.0236],\n",
      "        [0.7392, 0.0389, 0.2120, 0.0159],\n",
      "        [0.7721, 0.0104, 0.5704, 0.0058],\n",
      "        [0.3639, 0.0011, 0.5057, 0.0016],\n",
      "        [0.7037, 0.0065, 0.6069, 0.0070],\n",
      "        [0.5054, 0.0079, 0.1580, 0.0040],\n",
      "        [0.6324, 0.0842, 0.3780, 0.0302],\n",
      "        [0.3849, 0.0143, 0.5205, 0.0176],\n",
      "        [0.6545, 0.0255, 0.5525, 0.0160],\n",
      "        [0.6091, 0.0124, 0.2270, 0.0065],\n",
      "        [0.2833, 0.0079, 0.6129, 0.0115],\n",
      "        [0.3998, 0.0061, 0.3752, 0.0063],\n",
      "        [0.6401, 0.0580, 0.2456, 0.0092],\n",
      "        [0.5178, 0.0218, 0.3568, 0.0131],\n",
      "        [0.3088, 0.0168, 0.3355, 0.0089],\n",
      "        [0.3321, 0.0044, 0.7112, 0.0117],\n",
      "        [0.1939, 0.0041, 0.6700, 0.0061],\n",
      "        [0.7779, 0.0113, 0.6587, 0.0034],\n",
      "        [0.7217, 0.0347, 0.5320, 0.0163],\n",
      "        [0.6057, 0.1065, 0.3753, 0.0267],\n",
      "        [0.4611, 0.0138, 0.7941, 0.0114]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0424, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.13865114916974\n",
      "Epoch 2, Loss: -3.9992925195636673\n",
      "Epoch 2, Loss: -3.990302429270941\n",
      "Epoch 2, Loss: -4.179475039137335\n",
      "Epoch 2, Loss: -4.309791682493721\n",
      "tensor([[0.6468, 0.0573, 0.6599, 0.0238],\n",
      "        [0.5144, 0.0102, 0.1998, 0.0024],\n",
      "        [0.5746, 0.0446, 0.4085, 0.0179],\n",
      "        [0.2272, 0.0013, 0.6405, 0.0029],\n",
      "        [0.3525, 0.0162, 0.2629, 0.0071],\n",
      "        [0.6980, 0.0370, 0.7090, 0.0134],\n",
      "        [0.7750, 0.0149, 0.7747, 0.0029],\n",
      "        [0.4627, 0.0166, 0.6564, 0.0254],\n",
      "        [0.3167, 0.0069, 0.8608, 0.0076],\n",
      "        [0.4481, 0.0066, 0.5486, 0.0118],\n",
      "        [0.7073, 0.0424, 0.6207, 0.0156],\n",
      "        [0.4069, 0.0062, 0.5927, 0.0075],\n",
      "        [0.1962, 0.0049, 0.4532, 0.0024],\n",
      "        [0.3618, 0.0108, 0.6504, 0.0188],\n",
      "        [0.5531, 0.0023, 0.3884, 0.0036],\n",
      "        [0.5709, 0.0137, 0.3844, 0.0112],\n",
      "        [0.5672, 0.0165, 0.6497, 0.0140],\n",
      "        [0.8292, 0.0062, 0.6321, 0.0043],\n",
      "        [0.5377, 0.0037, 0.5145, 0.0091],\n",
      "        [0.2894, 0.0154, 0.3247, 0.0113],\n",
      "        [0.7625, 0.0410, 0.6085, 0.0115],\n",
      "        [0.4588, 0.0112, 0.2617, 0.0049],\n",
      "        [0.6164, 0.0103, 0.4611, 0.0145],\n",
      "        [0.2245, 0.0040, 0.5994, 0.0075],\n",
      "        [0.4707, 0.0256, 0.8342, 0.0164],\n",
      "        [0.7810, 0.0209, 0.1964, 0.0022],\n",
      "        [0.2043, 0.0074, 0.2506, 0.0020],\n",
      "        [0.3054, 0.0071, 0.4148, 0.0041],\n",
      "        [0.6038, 0.0358, 0.8286, 0.0095],\n",
      "        [0.1871, 0.0028, 0.4388, 0.0012],\n",
      "        [0.4284, 0.0029, 0.4441, 0.0032],\n",
      "        [0.2778, 0.0068, 0.3024, 0.0033]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0443, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.065755846291839\n",
      "Epoch 2, Loss: -3.68547826304112\n",
      "Epoch 2, Loss: -3.7484254142068214\n",
      "Epoch 2, Loss: -3.439183562733424\n",
      "Epoch 2, Loss: -4.266894894518589\n",
      "tensor([[0.2189, 0.0084, 0.8676, 0.0104],\n",
      "        [0.5151, 0.0025, 0.3985, 0.0039],\n",
      "        [0.5491, 0.0126, 0.5247, 0.0131],\n",
      "        [0.7290, 0.0057, 0.6472, 0.0018],\n",
      "        [0.7598, 0.0228, 0.2859, 0.0050],\n",
      "        [0.6539, 0.0028, 0.5930, 0.0030],\n",
      "        [0.6973, 0.0188, 0.7375, 0.0103],\n",
      "        [0.6631, 0.0150, 0.7005, 0.0126],\n",
      "        [0.6615, 0.1233, 0.4718, 0.0331],\n",
      "        [0.4086, 0.0090, 0.6299, 0.0088],\n",
      "        [0.7256, 0.0359, 0.2850, 0.0120],\n",
      "        [0.3810, 0.0072, 0.4165, 0.0033],\n",
      "        [0.3436, 0.0145, 0.3727, 0.0129],\n",
      "        [0.6983, 0.0432, 0.3775, 0.0198],\n",
      "        [0.1475, 0.0054, 0.4881, 0.0039],\n",
      "        [0.4490, 0.0038, 0.4932, 0.0020],\n",
      "        [0.6197, 0.0126, 0.7113, 0.0058],\n",
      "        [0.2029, 0.0096, 0.6760, 0.0053],\n",
      "        [0.5846, 0.0084, 0.2998, 0.0032],\n",
      "        [0.6655, 0.0200, 0.8118, 0.0089],\n",
      "        [0.7590, 0.0594, 0.3294, 0.0102],\n",
      "        [0.4227, 0.0040, 0.2731, 0.0040],\n",
      "        [0.1367, 0.0014, 0.5873, 0.0020],\n",
      "        [0.6532, 0.0276, 0.3029, 0.0064],\n",
      "        [0.2782, 0.0062, 0.3208, 0.0037],\n",
      "        [0.2037, 0.0020, 0.5782, 0.0020],\n",
      "        [0.5052, 0.0050, 0.3263, 0.0052],\n",
      "        [0.6590, 0.0363, 0.8487, 0.0115],\n",
      "        [0.2494, 0.0045, 0.7551, 0.0040],\n",
      "        [0.5145, 0.0167, 0.7273, 0.0036],\n",
      "        [0.7066, 0.0471, 0.3136, 0.0175],\n",
      "        [0.3683, 0.0042, 0.5782, 0.0047]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0512, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.03726375504966\n",
      "Epoch 2, Loss: -3.7803683588370403\n",
      "Epoch 2, Loss: -4.249306707206359\n",
      "Epoch 2, Loss: -4.1839378933662585\n",
      "Epoch 2, Loss: -3.778624272414748\n",
      "tensor([[7.0055e-01, 2.5561e-02, 3.7742e-01, 8.9147e-03],\n",
      "        [4.0601e-01, 1.1260e-03, 4.3523e-01, 1.1240e-03],\n",
      "        [7.0048e-01, 5.3224e-02, 3.1576e-01, 1.3987e-02],\n",
      "        [4.2659e-01, 1.0323e-02, 7.7955e-01, 1.4599e-02],\n",
      "        [2.8877e-01, 4.8210e-03, 6.6167e-01, 1.1216e-02],\n",
      "        [5.6062e-01, 5.7170e-03, 7.4814e-01, 3.1317e-03],\n",
      "        [7.8210e-01, 2.2113e-02, 5.9311e-01, 6.1561e-03],\n",
      "        [7.9776e-01, 1.7546e-02, 4.7921e-01, 9.5407e-03],\n",
      "        [5.6800e-01, 2.1777e-03, 5.1363e-01, 2.6096e-03],\n",
      "        [7.5231e-01, 4.0246e-02, 2.0044e-01, 4.9771e-03],\n",
      "        [4.1366e-01, 3.0497e-02, 5.2466e-01, 1.1563e-02],\n",
      "        [6.4523e-01, 1.1971e-02, 6.6241e-01, 1.1104e-02],\n",
      "        [5.5596e-01, 6.5818e-03, 6.2935e-01, 7.6477e-03],\n",
      "        [2.4472e-01, 1.3266e-02, 5.9144e-01, 1.6502e-02],\n",
      "        [6.6265e-01, 2.2117e-03, 2.0131e-01, 9.0149e-04],\n",
      "        [6.7879e-01, 1.1256e-02, 5.3073e-01, 8.3647e-03],\n",
      "        [4.5517e-01, 2.9905e-03, 6.3863e-01, 6.0834e-03],\n",
      "        [2.5324e-01, 6.6903e-03, 3.8671e-01, 1.0553e-02],\n",
      "        [3.2535e-01, 6.8468e-03, 5.2844e-01, 4.5209e-03],\n",
      "        [5.7311e-01, 5.4936e-03, 5.6961e-01, 6.9698e-03],\n",
      "        [7.5812e-01, 3.0757e-02, 8.7152e-01, 5.1263e-03],\n",
      "        [3.1473e-01, 1.6314e-02, 4.3113e-01, 2.2550e-02],\n",
      "        [5.1770e-01, 7.9941e-04, 6.8101e-01, 7.8779e-04],\n",
      "        [6.5852e-01, 1.1331e-01, 3.9789e-01, 2.5096e-02],\n",
      "        [4.3008e-01, 1.4824e-02, 3.6765e-01, 8.3992e-03],\n",
      "        [6.1457e-01, 1.2215e-02, 4.6345e-01, 1.1717e-02],\n",
      "        [6.2581e-01, 7.3716e-04, 7.6309e-02, 3.2548e-04],\n",
      "        [3.3087e-01, 1.0339e-02, 8.7980e-01, 5.2529e-03],\n",
      "        [6.9975e-01, 4.7613e-02, 3.1452e-01, 1.7177e-02],\n",
      "        [6.7874e-01, 9.3944e-02, 3.1945e-01, 1.3535e-02],\n",
      "        [2.7752e-01, 1.9887e-02, 3.1407e-01, 1.3055e-02],\n",
      "        [2.5811e-01, 3.4118e-03, 4.7967e-01, 2.9803e-03]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0508, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -3.2672923649048577\n",
      "Epoch 2, Loss: -3.960062537456989\n",
      "Epoch 2, Loss: -4.192042155912798\n",
      "Epoch 2, Loss: -4.377723097545382\n",
      "Epoch 2, Loss: -4.071297627095146\n",
      "tensor([[0.5924, 0.0493, 0.6342, 0.0235],\n",
      "        [0.5568, 0.0164, 0.6609, 0.0069],\n",
      "        [0.4605, 0.0092, 0.7032, 0.0082],\n",
      "        [0.4937, 0.0067, 0.6467, 0.0065],\n",
      "        [0.6403, 0.0045, 0.4067, 0.0016],\n",
      "        [0.5143, 0.0015, 0.5113, 0.0015],\n",
      "        [0.5845, 0.0047, 0.6175, 0.0045],\n",
      "        [0.2837, 0.0193, 0.2271, 0.0338],\n",
      "        [0.3018, 0.0139, 0.7959, 0.0083],\n",
      "        [0.4038, 0.0111, 0.2806, 0.0073],\n",
      "        [0.2365, 0.0074, 0.5278, 0.0072],\n",
      "        [0.3009, 0.0135, 0.4734, 0.0224],\n",
      "        [0.1921, 0.0032, 0.5470, 0.0025],\n",
      "        [0.7850, 0.0059, 0.5907, 0.0135],\n",
      "        [0.6480, 0.0767, 0.4192, 0.0374],\n",
      "        [0.4151, 0.0056, 0.1811, 0.0144],\n",
      "        [0.2982, 0.0085, 0.2601, 0.0149],\n",
      "        [0.2680, 0.0037, 0.6856, 0.0070],\n",
      "        [0.7735, 0.0125, 0.6074, 0.0076],\n",
      "        [0.6642, 0.0053, 0.6095, 0.0041],\n",
      "        [0.3592, 0.0051, 0.4915, 0.0148],\n",
      "        [0.4570, 0.0052, 0.5517, 0.0032],\n",
      "        [0.5542, 0.0037, 0.2440, 0.0027],\n",
      "        [0.6094, 0.0091, 0.8314, 0.0035],\n",
      "        [0.4080, 0.0131, 0.2470, 0.0420],\n",
      "        [0.6022, 0.0189, 0.6229, 0.0166],\n",
      "        [0.2794, 0.0416, 0.3595, 0.0279],\n",
      "        [0.2250, 0.0264, 0.4627, 0.0572],\n",
      "        [0.4588, 0.0112, 0.6484, 0.0091],\n",
      "        [0.6067, 0.0011, 0.4539, 0.0029],\n",
      "        [0.7334, 0.0061, 0.2036, 0.0101],\n",
      "        [0.3859, 0.0038, 0.1913, 0.0028]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0539, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -3.95748717790217\n",
      "Epoch 2, Loss: -3.6990845221433672\n",
      "Epoch 2, Loss: -4.089178694754882\n",
      "Epoch 2, Loss: -4.231153360779418\n",
      "Epoch 2, Loss: -4.225489576186951\n",
      "tensor([[3.5802e-01, 2.3398e-02, 6.3630e-01, 3.4534e-02],\n",
      "        [7.7583e-01, 5.5857e-03, 2.1201e-01, 2.0219e-03],\n",
      "        [4.9260e-01, 7.4949e-04, 5.3140e-01, 1.0246e-03],\n",
      "        [4.4779e-01, 1.1343e-03, 3.5169e-01, 1.5793e-03],\n",
      "        [5.4073e-01, 8.2364e-03, 5.3258e-01, 9.1087e-03],\n",
      "        [3.3681e-01, 2.0886e-02, 3.7792e-01, 2.0861e-02],\n",
      "        [7.3677e-01, 8.2303e-03, 2.8591e-01, 4.7819e-03],\n",
      "        [2.6870e-01, 1.0259e-02, 1.0802e-01, 9.8106e-03],\n",
      "        [2.2605e-01, 1.2494e-02, 4.0898e-01, 8.6975e-03],\n",
      "        [4.1323e-01, 1.4581e-02, 3.4231e-01, 1.0989e-02],\n",
      "        [3.1012e-01, 1.1735e-02, 7.9208e-01, 2.3148e-03],\n",
      "        [3.4643e-01, 5.2933e-02, 3.9329e-01, 5.4747e-02],\n",
      "        [5.5131e-01, 2.0682e-02, 5.3825e-01, 8.0300e-03],\n",
      "        [3.7157e-01, 1.0740e-02, 5.8811e-01, 1.0975e-02],\n",
      "        [5.7968e-01, 7.6926e-03, 5.6906e-01, 1.0596e-02],\n",
      "        [4.0905e-01, 4.7512e-02, 6.0575e-01, 3.0488e-02],\n",
      "        [5.3202e-01, 1.7811e-02, 6.4274e-01, 1.4561e-02],\n",
      "        [7.1589e-01, 9.8235e-03, 2.0753e-01, 3.1979e-03],\n",
      "        [9.0751e-01, 1.8642e-03, 7.4084e-01, 2.5314e-03],\n",
      "        [5.2669e-01, 7.2860e-03, 6.3876e-01, 1.0438e-02],\n",
      "        [8.0193e-01, 5.2824e-03, 2.8940e-01, 2.1536e-03],\n",
      "        [2.9391e-01, 7.9568e-03, 6.7005e-01, 8.2018e-03],\n",
      "        [2.1941e-01, 8.0411e-03, 6.6395e-01, 4.7614e-03],\n",
      "        [4.6122e-01, 2.7638e-03, 5.3463e-01, 3.1055e-03],\n",
      "        [3.4811e-01, 1.5787e-02, 6.1891e-01, 1.5555e-02],\n",
      "        [5.1853e-01, 8.5483e-03, 6.7394e-01, 5.8458e-03],\n",
      "        [4.0773e-01, 4.6811e-03, 3.0618e-01, 5.4797e-03],\n",
      "        [2.2056e-01, 5.2954e-03, 6.5301e-01, 8.6552e-03],\n",
      "        [6.8344e-01, 1.9766e-02, 5.6741e-01, 1.6376e-02],\n",
      "        [4.5988e-01, 2.9474e-03, 4.7417e-01, 8.3946e-03],\n",
      "        [6.2545e-01, 4.8483e-03, 7.0131e-01, 3.4555e-03],\n",
      "        [3.5808e-01, 4.3464e-02, 6.5958e-01, 3.1822e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0483, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.323570685948506\n",
      "Epoch 2, Loss: -3.189756887273802\n",
      "Epoch 2, Loss: -4.038322952020516\n",
      "Epoch 2, Loss: -3.095723020604467\n",
      "Epoch 2, Loss: -4.348605927391621\n",
      "tensor([[0.3960, 0.0042, 0.8420, 0.0022],\n",
      "        [0.8502, 0.0030, 0.3822, 0.0015],\n",
      "        [0.5950, 0.0118, 0.2426, 0.0073],\n",
      "        [0.4016, 0.0124, 0.2340, 0.0268],\n",
      "        [0.4395, 0.0131, 0.3213, 0.0163],\n",
      "        [0.5307, 0.0171, 0.7128, 0.0098],\n",
      "        [0.7718, 0.0121, 0.3701, 0.0054],\n",
      "        [0.5985, 0.0215, 0.5101, 0.0247],\n",
      "        [0.2905, 0.0016, 0.5829, 0.0024],\n",
      "        [0.7661, 0.0098, 0.5298, 0.0112],\n",
      "        [0.5228, 0.0131, 0.4154, 0.0121],\n",
      "        [0.6446, 0.0055, 0.1768, 0.0030],\n",
      "        [0.4155, 0.0108, 0.3195, 0.0140],\n",
      "        [0.3374, 0.0172, 0.6550, 0.0174],\n",
      "        [0.4055, 0.0171, 0.2736, 0.0437],\n",
      "        [0.2665, 0.0055, 0.6527, 0.0034],\n",
      "        [0.1764, 0.0016, 0.5271, 0.0015],\n",
      "        [0.6638, 0.0051, 0.5947, 0.0034],\n",
      "        [0.5087, 0.0012, 0.4308, 0.0035],\n",
      "        [0.5566, 0.0438, 0.3650, 0.0370],\n",
      "        [0.2845, 0.0039, 0.4206, 0.0047],\n",
      "        [0.6634, 0.0232, 0.5275, 0.0111],\n",
      "        [0.6879, 0.0310, 0.3917, 0.0114],\n",
      "        [0.4720, 0.0031, 0.3987, 0.0086],\n",
      "        [0.5138, 0.0073, 0.4424, 0.0124],\n",
      "        [0.4047, 0.0115, 0.4485, 0.0136],\n",
      "        [0.3349, 0.0165, 0.5675, 0.0128],\n",
      "        [0.4320, 0.0060, 0.4206, 0.0094],\n",
      "        [0.2426, 0.0029, 0.7239, 0.0013],\n",
      "        [0.6456, 0.0042, 0.6513, 0.0031],\n",
      "        [0.5325, 0.0165, 0.7017, 0.0121],\n",
      "        [0.8202, 0.0078, 0.8086, 0.0055]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0442, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.199625590729285\n",
      "Epoch 2, Loss: -4.307344902018393\n",
      "Epoch 2, Loss: -4.332807741341022\n",
      "Epoch 2, Loss: -4.156279364322065\n",
      "Epoch 2, Loss: -3.8849830753480266\n",
      "tensor([[6.4306e-01, 1.2773e-03, 3.6401e-01, 2.9067e-03],\n",
      "        [2.6163e-01, 1.5631e-02, 3.8798e-01, 2.0009e-02],\n",
      "        [2.7679e-01, 1.7935e-03, 1.8810e-01, 8.3933e-03],\n",
      "        [3.6896e-01, 4.8239e-03, 1.7742e-01, 5.9174e-03],\n",
      "        [3.0186e-01, 1.1006e-02, 7.5178e-01, 1.1517e-02],\n",
      "        [4.6634e-01, 1.5327e-02, 6.0141e-01, 1.7349e-02],\n",
      "        [3.4992e-01, 3.1871e-03, 5.5554e-01, 5.1625e-03],\n",
      "        [7.1372e-01, 7.8644e-03, 4.4506e-01, 1.2430e-02],\n",
      "        [4.7339e-01, 2.9640e-03, 3.5733e-01, 3.1393e-03],\n",
      "        [5.2078e-01, 1.0985e-02, 6.6816e-01, 1.1332e-02],\n",
      "        [2.6764e-01, 8.2511e-03, 4.0265e-01, 8.3923e-03],\n",
      "        [3.7208e-01, 9.9153e-03, 1.7305e-01, 1.1221e-02],\n",
      "        [8.0294e-01, 2.0060e-02, 6.4449e-01, 6.8046e-03],\n",
      "        [7.5766e-01, 8.4579e-03, 6.2020e-01, 7.3390e-03],\n",
      "        [5.6204e-01, 1.4752e-03, 4.5947e-01, 2.3179e-03],\n",
      "        [2.5273e-01, 1.0359e-02, 7.9403e-01, 8.4881e-03],\n",
      "        [7.7559e-01, 8.0158e-04, 5.0667e-01, 4.5606e-03],\n",
      "        [6.1848e-01, 8.4955e-03, 4.0854e-01, 9.8362e-03],\n",
      "        [4.6777e-01, 2.2132e-02, 2.2480e-01, 2.0772e-02],\n",
      "        [7.2028e-01, 9.7576e-03, 6.1455e-01, 1.3188e-02],\n",
      "        [3.6847e-01, 1.7269e-03, 3.9772e-01, 2.8649e-03],\n",
      "        [6.4242e-01, 1.1410e-02, 3.2574e-01, 9.1458e-03],\n",
      "        [8.6687e-01, 1.8212e-03, 6.0438e-01, 3.2137e-03],\n",
      "        [6.7066e-01, 1.2858e-02, 2.2698e-01, 9.4889e-03],\n",
      "        [5.6048e-01, 2.4444e-03, 4.0111e-01, 2.9151e-03],\n",
      "        [3.9375e-01, 7.7967e-03, 6.0617e-01, 5.2767e-03],\n",
      "        [8.1409e-01, 4.2917e-03, 2.2449e-01, 1.7512e-03],\n",
      "        [7.1272e-01, 1.3956e-02, 6.6535e-01, 1.5801e-02],\n",
      "        [4.7563e-01, 3.6697e-03, 4.6573e-01, 4.5331e-03],\n",
      "        [4.3659e-01, 2.0371e-02, 6.2672e-01, 1.6822e-02],\n",
      "        [4.5912e-01, 4.7456e-03, 3.9137e-01, 6.3642e-03],\n",
      "        [6.3435e-01, 1.0392e-02, 5.1715e-01, 9.3904e-03]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0661, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.296003186546409\n",
      "Epoch 2, Loss: -4.1504604491807875\n",
      "Epoch 2, Loss: -4.032010127875829\n",
      "Epoch 2, Loss: -4.466167711578709\n",
      "Epoch 2, Loss: -4.111069386839856\n",
      "tensor([[5.8423e-01, 3.3193e-02, 3.1729e-01, 3.6169e-02],\n",
      "        [5.6363e-01, 3.9954e-03, 4.7793e-01, 7.6243e-03],\n",
      "        [3.1649e-01, 6.5926e-03, 3.1435e-01, 8.8277e-03],\n",
      "        [4.4571e-01, 2.0873e-04, 3.4227e-01, 1.3559e-03],\n",
      "        [6.1541e-01, 1.6439e-02, 3.7718e-01, 2.3679e-02],\n",
      "        [7.1737e-01, 2.0169e-03, 7.6223e-01, 1.8547e-03],\n",
      "        [7.0783e-01, 4.9247e-03, 2.1371e-01, 7.9357e-03],\n",
      "        [3.6677e-01, 1.6057e-03, 4.0407e-01, 1.6177e-03],\n",
      "        [4.8339e-01, 3.1156e-03, 5.5734e-01, 7.6823e-03],\n",
      "        [3.8152e-01, 7.0925e-03, 6.3444e-01, 5.4477e-03],\n",
      "        [3.9129e-01, 5.6077e-03, 6.0381e-01, 6.9026e-03],\n",
      "        [3.2301e-01, 8.9220e-03, 3.3170e-01, 6.7609e-03],\n",
      "        [5.5352e-01, 1.1555e-02, 8.3807e-01, 3.8207e-03],\n",
      "        [7.3034e-01, 1.1357e-02, 2.6195e-01, 7.9846e-03],\n",
      "        [7.9695e-01, 1.9873e-03, 5.7866e-01, 5.5969e-03],\n",
      "        [1.6077e-01, 3.8923e-03, 7.9409e-01, 3.3075e-03],\n",
      "        [6.9493e-01, 3.8304e-03, 5.2800e-01, 1.1397e-02],\n",
      "        [6.5339e-01, 9.8839e-03, 7.7094e-01, 5.8855e-03],\n",
      "        [5.5141e-01, 3.8650e-02, 4.7442e-01, 4.5404e-02],\n",
      "        [2.0357e-01, 4.4306e-03, 5.0269e-01, 2.8715e-03],\n",
      "        [5.0091e-01, 7.1105e-03, 5.0902e-01, 5.0849e-03],\n",
      "        [3.0093e-01, 1.0626e-02, 4.9032e-01, 9.7558e-03],\n",
      "        [3.0389e-01, 6.7492e-03, 7.5248e-01, 6.3978e-03],\n",
      "        [7.2315e-01, 1.1933e-03, 6.9951e-01, 1.9549e-03],\n",
      "        [6.6686e-01, 2.3120e-02, 4.1661e-01, 1.6268e-02],\n",
      "        [5.6157e-01, 1.2098e-02, 4.0976e-01, 1.3909e-02],\n",
      "        [7.0257e-01, 1.9883e-02, 5.0487e-01, 5.3665e-02],\n",
      "        [6.5395e-01, 3.6956e-02, 4.6833e-01, 2.4107e-02],\n",
      "        [3.3343e-01, 3.8262e-03, 6.6387e-01, 4.2219e-03],\n",
      "        [2.4456e-01, 7.4645e-03, 2.1425e-01, 1.7163e-02],\n",
      "        [6.4332e-01, 3.2064e-03, 2.3122e-01, 9.8989e-03],\n",
      "        [4.5087e-01, 6.8324e-03, 2.3374e-01, 8.3016e-03]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0435, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.372489690383245\n",
      "Epoch 2, Loss: -4.275585538999053\n",
      "Epoch 2, Loss: -2.4903084167225527\n",
      "Epoch 2, Loss: -4.698311005147252\n",
      "Epoch 2, Loss: -4.159730971129931\n",
      "tensor([[7.1512e-01, 2.7182e-03, 6.4622e-01, 7.7963e-03],\n",
      "        [7.7483e-01, 1.2047e-02, 3.8026e-01, 2.4743e-02],\n",
      "        [3.4327e-01, 5.9873e-03, 2.9597e-01, 4.3182e-03],\n",
      "        [2.7521e-01, 5.2930e-03, 6.0761e-01, 8.9917e-03],\n",
      "        [5.4986e-01, 2.9813e-03, 6.9319e-01, 4.6262e-03],\n",
      "        [4.6941e-01, 7.6504e-03, 8.6879e-01, 5.3619e-03],\n",
      "        [5.6760e-01, 3.9310e-03, 3.0458e-01, 6.8964e-03],\n",
      "        [4.4209e-01, 1.7094e-03, 7.8729e-01, 2.3635e-03],\n",
      "        [5.6379e-01, 1.5476e-03, 7.4388e-01, 5.6919e-03],\n",
      "        [2.6864e-01, 6.1662e-03, 2.9195e-01, 1.0135e-02],\n",
      "        [4.5667e-01, 5.9742e-03, 1.9366e-01, 3.8186e-03],\n",
      "        [1.9963e-01, 6.0153e-03, 4.6405e-01, 1.0168e-02],\n",
      "        [6.1230e-01, 8.9710e-03, 8.3254e-01, 6.1109e-03],\n",
      "        [6.3114e-01, 1.4071e-02, 3.6082e-01, 1.1650e-02],\n",
      "        [6.6631e-01, 8.4819e-03, 2.9339e-01, 4.2449e-03],\n",
      "        [2.9334e-01, 5.7066e-03, 7.3334e-01, 6.3652e-03],\n",
      "        [6.1445e-01, 2.0472e-03, 5.8816e-01, 5.6844e-03],\n",
      "        [6.9731e-01, 6.1346e-03, 5.0473e-01, 9.1690e-03],\n",
      "        [5.8739e-01, 7.7884e-03, 8.1875e-01, 8.4933e-03],\n",
      "        [2.2343e-01, 3.7339e-04, 6.4931e-01, 4.9511e-04],\n",
      "        [2.2151e-01, 7.6584e-03, 3.5650e-01, 1.4863e-02],\n",
      "        [4.8683e-01, 2.6253e-03, 5.7090e-01, 3.9630e-03],\n",
      "        [7.0406e-01, 1.4599e-02, 4.3145e-01, 2.2180e-02],\n",
      "        [7.0487e-01, 3.3305e-03, 4.3305e-01, 5.0824e-03],\n",
      "        [6.6700e-01, 1.2352e-02, 2.8275e-01, 2.4288e-02],\n",
      "        [4.1961e-01, 5.0506e-03, 6.5650e-01, 9.0137e-03],\n",
      "        [7.2062e-01, 1.0879e-02, 3.7308e-01, 1.3711e-02],\n",
      "        [3.0826e-01, 3.7889e-02, 3.4696e-01, 3.7212e-02],\n",
      "        [5.5448e-01, 2.1506e-03, 6.3576e-01, 4.1472e-03],\n",
      "        [2.3129e-01, 1.8150e-03, 5.7759e-01, 2.2185e-03],\n",
      "        [2.7451e-01, 9.3586e-03, 7.4196e-01, 1.0995e-02],\n",
      "        [5.2838e-01, 1.8540e-03, 4.3526e-01, 2.2055e-03]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0563, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -3.1147854128757313\n",
      "Epoch 2, Loss: -4.070661514439882\n",
      "Epoch 2, Loss: -3.9563653408120283\n",
      "Epoch 2, Loss: -4.586972233955253\n",
      "Epoch 2, Loss: -4.168672674605816\n",
      "tensor([[8.2428e-01, 9.2191e-03, 3.5514e-01, 3.1013e-03],\n",
      "        [5.8219e-01, 1.9523e-02, 4.3506e-01, 1.9062e-02],\n",
      "        [4.7709e-01, 2.2421e-02, 2.6572e-01, 1.3076e-02],\n",
      "        [6.4883e-01, 4.1849e-02, 5.1191e-01, 2.8312e-02],\n",
      "        [7.6909e-01, 6.8618e-03, 5.0931e-01, 1.5014e-02],\n",
      "        [2.7396e-01, 3.3728e-03, 4.5751e-01, 7.9516e-03],\n",
      "        [3.9418e-01, 3.4417e-03, 4.0072e-01, 4.6763e-03],\n",
      "        [4.2548e-01, 4.3197e-03, 3.2206e-01, 5.5713e-03],\n",
      "        [4.4675e-01, 1.5572e-02, 3.7089e-01, 1.6479e-02],\n",
      "        [6.0135e-01, 4.3529e-03, 3.7414e-01, 6.7703e-03],\n",
      "        [4.1432e-01, 1.6008e-02, 2.8655e-01, 1.5113e-02],\n",
      "        [3.2228e-01, 5.6806e-03, 4.0298e-01, 5.3542e-03],\n",
      "        [6.0862e-01, 3.3409e-03, 4.2827e-01, 9.9370e-03],\n",
      "        [7.4718e-01, 1.6835e-03, 6.5009e-01, 6.9309e-03],\n",
      "        [6.8029e-01, 6.3654e-03, 5.1459e-01, 3.8222e-02],\n",
      "        [5.8030e-01, 4.9255e-02, 3.4105e-01, 6.6474e-02],\n",
      "        [5.7911e-01, 6.6056e-04, 6.3909e-01, 2.4787e-03],\n",
      "        [7.0666e-01, 2.3659e-03, 5.7345e-01, 4.1001e-03],\n",
      "        [6.0699e-01, 6.2895e-03, 5.7202e-01, 9.5936e-03],\n",
      "        [6.1172e-01, 3.8071e-02, 4.2988e-01, 1.7509e-02],\n",
      "        [6.9295e-01, 1.0608e-02, 3.9692e-01, 6.0137e-03],\n",
      "        [4.9033e-01, 1.2025e-02, 6.0347e-01, 8.6693e-03],\n",
      "        [4.3769e-01, 2.2323e-03, 8.8975e-01, 2.9154e-03],\n",
      "        [6.4674e-01, 2.0313e-02, 5.3097e-01, 1.6367e-02],\n",
      "        [4.7100e-01, 1.6919e-02, 3.9362e-01, 2.1274e-02],\n",
      "        [2.6102e-01, 3.5635e-03, 6.5206e-01, 3.9791e-03],\n",
      "        [3.6912e-01, 3.8298e-03, 8.9377e-01, 5.7194e-03],\n",
      "        [2.2441e-01, 7.9233e-03, 3.3638e-01, 1.1712e-02],\n",
      "        [7.0837e-01, 7.7508e-03, 5.7162e-01, 1.6643e-02],\n",
      "        [2.1114e-01, 6.9579e-03, 8.0774e-01, 6.1175e-03],\n",
      "        [3.0036e-01, 5.8620e-03, 4.2573e-01, 5.3960e-03],\n",
      "        [4.9561e-01, 1.3628e-02, 3.5672e-01, 2.1608e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0585, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -3.8508225884626803\n",
      "Epoch 2, Loss: -2.2653594631390574\n",
      "Epoch 2, Loss: -4.44655018585704\n",
      "Epoch 2, Loss: -3.7561302314233282\n",
      "Epoch 2, Loss: -4.349470830467906\n",
      "tensor([[3.6929e-01, 7.5347e-03, 7.0428e-01, 1.3877e-02],\n",
      "        [7.1707e-01, 2.6299e-02, 4.1091e-01, 1.2273e-02],\n",
      "        [4.8853e-01, 7.9718e-03, 8.3579e-01, 5.4210e-03],\n",
      "        [3.4351e-01, 5.0110e-03, 7.1541e-01, 6.1917e-03],\n",
      "        [3.0365e-01, 4.4601e-03, 5.2409e-01, 5.1626e-03],\n",
      "        [4.5334e-01, 2.2218e-03, 7.5922e-01, 3.5430e-03],\n",
      "        [5.1253e-01, 8.4628e-03, 3.2103e-01, 2.1893e-02],\n",
      "        [4.9226e-01, 5.2690e-03, 8.0390e-01, 6.0394e-03],\n",
      "        [5.5861e-01, 2.0064e-02, 3.1132e-01, 1.1712e-02],\n",
      "        [7.3439e-01, 8.7807e-04, 8.5758e-01, 7.4755e-04],\n",
      "        [6.2462e-01, 1.1425e-02, 4.1241e-01, 8.2774e-03],\n",
      "        [5.6449e-01, 4.6975e-03, 5.5301e-01, 8.3196e-03],\n",
      "        [2.5669e-01, 1.0168e-02, 3.4042e-01, 7.5964e-03],\n",
      "        [4.9371e-01, 1.5455e-02, 3.7835e-01, 1.9048e-02],\n",
      "        [6.5288e-01, 2.5524e-02, 2.4563e-01, 1.8615e-02],\n",
      "        [6.7110e-01, 2.8478e-02, 3.7227e-01, 2.2241e-02],\n",
      "        [4.2372e-01, 2.5843e-02, 2.8483e-01, 2.1785e-02],\n",
      "        [2.5484e-01, 1.8508e-02, 4.8023e-01, 2.2442e-02],\n",
      "        [1.7256e-01, 1.8575e-03, 7.3025e-01, 9.1037e-04],\n",
      "        [5.8240e-01, 7.9881e-03, 5.4383e-01, 5.8841e-03],\n",
      "        [6.7681e-01, 2.1291e-02, 4.3312e-01, 1.3847e-02],\n",
      "        [7.4239e-01, 1.5937e-02, 2.3717e-01, 1.0781e-02],\n",
      "        [6.6363e-01, 1.8525e-03, 5.9594e-01, 3.0869e-03],\n",
      "        [5.3680e-01, 1.4009e-03, 5.3924e-01, 3.7544e-03],\n",
      "        [3.4577e-01, 9.2875e-03, 2.8673e-01, 1.7129e-02],\n",
      "        [5.2559e-01, 7.2237e-03, 5.6105e-01, 1.5313e-02],\n",
      "        [4.8048e-01, 2.1286e-02, 2.7394e-01, 1.3890e-02],\n",
      "        [5.1900e-01, 3.1088e-03, 6.1627e-01, 4.9437e-03],\n",
      "        [2.5634e-01, 5.7556e-03, 3.0458e-01, 9.2717e-03],\n",
      "        [4.7231e-01, 4.3309e-03, 4.6815e-01, 9.7745e-03],\n",
      "        [2.0999e-01, 4.7136e-03, 3.9792e-01, 5.8552e-03],\n",
      "        [4.0920e-01, 5.3981e-02, 3.5326e-01, 4.1406e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0483, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.104467737855753\n",
      "Epoch 2, Loss: -4.314589616917097\n",
      "Epoch 2, Loss: -4.243934749348799\n",
      "Epoch 2, Loss: -3.9134324690640137\n",
      "Epoch 2, Loss: -4.342003076334247\n",
      "tensor([[4.9261e-01, 8.7760e-03, 8.6076e-01, 4.6031e-03],\n",
      "        [7.9506e-01, 1.5727e-03, 6.4504e-01, 7.9327e-04],\n",
      "        [7.5786e-01, 4.4289e-03, 6.6702e-01, 3.5896e-03],\n",
      "        [2.3200e-01, 2.6960e-02, 7.0868e-01, 2.1112e-02],\n",
      "        [4.6106e-01, 4.7800e-02, 2.6304e-01, 2.0328e-02],\n",
      "        [5.3884e-01, 1.0662e-03, 5.7649e-01, 2.7457e-03],\n",
      "        [4.7317e-01, 6.0109e-03, 5.3847e-01, 1.4306e-02],\n",
      "        [5.6637e-01, 1.1442e-02, 3.9069e-01, 5.5655e-03],\n",
      "        [2.4826e-01, 1.3347e-03, 8.2182e-01, 3.3072e-03],\n",
      "        [5.7346e-01, 7.9086e-02, 4.2744e-01, 6.1408e-02],\n",
      "        [2.8814e-01, 4.7518e-03, 8.3383e-01, 5.9628e-03],\n",
      "        [5.1402e-01, 1.1074e-02, 2.1968e-01, 7.6123e-03],\n",
      "        [4.7683e-01, 2.1383e-03, 7.9054e-01, 3.1504e-03],\n",
      "        [2.2581e-01, 2.9737e-03, 2.0103e-01, 2.8562e-03],\n",
      "        [3.1330e-01, 1.9848e-02, 5.1170e-01, 3.6009e-02],\n",
      "        [7.3329e-01, 1.3360e-02, 3.2619e-01, 2.5423e-03],\n",
      "        [3.9867e-01, 3.3768e-03, 3.6483e-01, 6.2781e-03],\n",
      "        [3.7277e-01, 2.5872e-03, 4.8380e-01, 5.5099e-03],\n",
      "        [2.9703e-01, 5.5183e-03, 4.9177e-01, 1.8439e-02],\n",
      "        [5.2493e-01, 3.6978e-03, 6.2455e-01, 3.2953e-03],\n",
      "        [5.2659e-01, 6.2370e-03, 4.8261e-01, 5.6381e-03],\n",
      "        [3.0909e-01, 1.0996e-02, 7.3698e-01, 7.3550e-03],\n",
      "        [3.6960e-01, 1.7616e-02, 3.8071e-01, 1.0048e-02],\n",
      "        [1.8074e-01, 6.4754e-03, 7.4290e-01, 6.7404e-03],\n",
      "        [1.8245e-01, 2.0914e-03, 5.6313e-01, 4.3821e-03],\n",
      "        [5.0124e-01, 4.8000e-02, 5.2038e-01, 5.1936e-02],\n",
      "        [6.1743e-01, 1.0572e-02, 4.4219e-01, 1.3841e-02],\n",
      "        [7.9357e-01, 1.2232e-02, 2.7899e-01, 5.6999e-03],\n",
      "        [5.9953e-01, 9.1306e-03, 5.2167e-01, 9.0971e-03],\n",
      "        [7.3451e-01, 1.7920e-02, 2.9088e-01, 4.5331e-03],\n",
      "        [1.7867e-01, 6.7554e-03, 3.0840e-01, 3.9976e-03],\n",
      "        [6.3846e-01, 4.2707e-02, 4.8421e-01, 2.9045e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0503, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.157358949536989\n",
      "Epoch 2, Loss: -4.025873348613722\n",
      "Epoch 2, Loss: -3.9108528638237505\n",
      "Epoch 2, Loss: -4.231413240741405\n",
      "Epoch 2, Loss: -4.2208373502839365\n",
      "tensor([[0.2645, 0.0109, 0.3778, 0.0220],\n",
      "        [0.3563, 0.0215, 0.4659, 0.0210],\n",
      "        [0.3235, 0.0040, 0.6336, 0.0063],\n",
      "        [0.4401, 0.0146, 0.5080, 0.0391],\n",
      "        [0.4496, 0.0134, 0.5184, 0.0157],\n",
      "        [0.3700, 0.0054, 0.6656, 0.0190],\n",
      "        [0.6848, 0.0101, 0.6459, 0.0105],\n",
      "        [0.7918, 0.0197, 0.5951, 0.0133],\n",
      "        [0.5402, 0.0056, 0.4508, 0.0049],\n",
      "        [0.7913, 0.0065, 0.1730, 0.0013],\n",
      "        [0.6648, 0.0087, 0.7712, 0.0061],\n",
      "        [0.1961, 0.0016, 0.2071, 0.0031],\n",
      "        [0.7862, 0.0048, 0.4556, 0.0033],\n",
      "        [0.7289, 0.0108, 0.6010, 0.0115],\n",
      "        [0.6755, 0.0182, 0.6968, 0.0147],\n",
      "        [0.1943, 0.0031, 0.1961, 0.0030],\n",
      "        [0.4079, 0.0118, 0.4615, 0.0167],\n",
      "        [0.5912, 0.0127, 0.6222, 0.0131],\n",
      "        [0.5379, 0.0037, 0.7471, 0.0030],\n",
      "        [0.5394, 0.0068, 0.8393, 0.0025],\n",
      "        [0.7376, 0.0122, 0.3762, 0.0036],\n",
      "        [0.6895, 0.0183, 0.3345, 0.0063],\n",
      "        [0.4853, 0.0168, 0.5529, 0.0270],\n",
      "        [0.5563, 0.0077, 0.4593, 0.0136],\n",
      "        [0.2774, 0.0046, 0.7468, 0.0092],\n",
      "        [0.6076, 0.0070, 0.6640, 0.0066],\n",
      "        [0.4611, 0.0337, 0.3802, 0.0119],\n",
      "        [0.3060, 0.0103, 0.3874, 0.0119],\n",
      "        [0.5072, 0.0125, 0.6092, 0.0167],\n",
      "        [0.6414, 0.0289, 0.2758, 0.0045],\n",
      "        [0.2715, 0.0021, 0.5464, 0.0050],\n",
      "        [0.6848, 0.0171, 0.2305, 0.0050]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0498, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.030410204054142\n",
      "Epoch 2, Loss: -4.2652828835793954\n",
      "Epoch 2, Loss: -4.270878145553192\n",
      "Epoch 2, Loss: -4.296172922405903\n",
      "Epoch 2, Loss: -3.931203274310233\n",
      "tensor([[0.2908, 0.0037, 0.3572, 0.0045],\n",
      "        [0.6766, 0.0386, 0.4855, 0.0208],\n",
      "        [0.5936, 0.0046, 0.2014, 0.0016],\n",
      "        [0.2136, 0.0085, 0.7127, 0.0053],\n",
      "        [0.5338, 0.0041, 0.3529, 0.0063],\n",
      "        [0.6043, 0.0150, 0.4874, 0.0121],\n",
      "        [0.5434, 0.0096, 0.3533, 0.0064],\n",
      "        [0.7909, 0.0078, 0.2512, 0.0016],\n",
      "        [0.2848, 0.0235, 0.7008, 0.0104],\n",
      "        [0.2859, 0.0068, 0.5816, 0.0086],\n",
      "        [0.5009, 0.0015, 0.5274, 0.0039],\n",
      "        [0.8435, 0.0040, 0.5619, 0.0065],\n",
      "        [0.6169, 0.0092, 0.6848, 0.0058],\n",
      "        [0.4249, 0.0086, 0.3657, 0.0155],\n",
      "        [0.7655, 0.0191, 0.5879, 0.0140],\n",
      "        [0.7523, 0.0067, 0.6520, 0.0059],\n",
      "        [0.8830, 0.0047, 0.6385, 0.0119],\n",
      "        [0.5120, 0.0070, 0.6642, 0.0070],\n",
      "        [0.4210, 0.0091, 0.1710, 0.0067],\n",
      "        [0.2872, 0.0026, 0.1696, 0.0015],\n",
      "        [0.6914, 0.0223, 0.6549, 0.0079],\n",
      "        [0.3444, 0.0092, 0.5881, 0.0121],\n",
      "        [0.5197, 0.0117, 0.5425, 0.0081],\n",
      "        [0.5099, 0.0133, 0.5654, 0.0117],\n",
      "        [0.6126, 0.0160, 0.3816, 0.0074],\n",
      "        [0.3312, 0.0044, 0.1667, 0.0039],\n",
      "        [0.4428, 0.0249, 0.4518, 0.0205],\n",
      "        [0.5254, 0.0065, 0.6886, 0.0067],\n",
      "        [0.7378, 0.0057, 0.4393, 0.0028],\n",
      "        [0.5425, 0.0044, 0.6733, 0.0060],\n",
      "        [0.5102, 0.0046, 0.3739, 0.0090],\n",
      "        [0.2488, 0.0055, 0.5011, 0.0094]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0581, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -3.9181228805662895\n",
      "Epoch 2, Loss: -4.201948575004675\n",
      "Epoch 2, Loss: -4.4401483210670225\n",
      "Epoch 2, Loss: -4.277525832089179\n",
      "Epoch 2, Loss: -4.338408491236967\n",
      "tensor([[0.6352, 0.0219, 0.4624, 0.0090],\n",
      "        [0.2594, 0.0113, 0.6030, 0.0176],\n",
      "        [0.3481, 0.0088, 0.5213, 0.0098],\n",
      "        [0.5407, 0.0092, 0.8082, 0.0047],\n",
      "        [0.8126, 0.0033, 0.2774, 0.0024],\n",
      "        [0.4662, 0.0075, 0.6574, 0.0025],\n",
      "        [0.2421, 0.0148, 0.4709, 0.0198],\n",
      "        [0.4282, 0.0013, 0.4992, 0.0019],\n",
      "        [0.3256, 0.0061, 0.5505, 0.0118],\n",
      "        [0.3464, 0.0076, 0.4809, 0.0228],\n",
      "        [0.5340, 0.0105, 0.2281, 0.0062],\n",
      "        [0.3923, 0.0215, 0.5167, 0.0223],\n",
      "        [0.4700, 0.0257, 0.2958, 0.0220],\n",
      "        [0.2624, 0.0056, 0.6730, 0.0082],\n",
      "        [0.7859, 0.0083, 0.3167, 0.0080],\n",
      "        [0.6293, 0.0045, 0.8350, 0.0040],\n",
      "        [0.3009, 0.0043, 0.8209, 0.0022],\n",
      "        [0.4102, 0.0054, 0.5752, 0.0036],\n",
      "        [0.3862, 0.0063, 0.4988, 0.0160],\n",
      "        [0.5937, 0.0054, 0.7004, 0.0015],\n",
      "        [0.5645, 0.0185, 0.2400, 0.0173],\n",
      "        [0.5617, 0.0072, 0.2797, 0.0041],\n",
      "        [0.6625, 0.0036, 0.5444, 0.0016],\n",
      "        [0.5009, 0.0187, 0.3019, 0.0109],\n",
      "        [0.4649, 0.0092, 0.1567, 0.0069],\n",
      "        [0.8793, 0.0070, 0.3005, 0.0058],\n",
      "        [0.4744, 0.0129, 0.2001, 0.0090],\n",
      "        [0.7140, 0.0132, 0.4793, 0.0054],\n",
      "        [0.2423, 0.0114, 0.4520, 0.0146],\n",
      "        [0.8130, 0.0044, 0.6886, 0.0065],\n",
      "        [0.4578, 0.0049, 0.6546, 0.0045],\n",
      "        [0.2020, 0.0019, 0.5509, 0.0064]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0484, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.172810172758049\n",
      "Epoch 2, Loss: -4.653683014480864\n",
      "Epoch 2, Loss: -4.3821072330893855\n",
      "Epoch 2, Loss: -4.264569270603195\n",
      "Epoch 2, Loss: -4.1541819653087995\n",
      "tensor([[4.0740e-01, 7.7526e-03, 1.3767e-01, 3.8852e-03],\n",
      "        [1.4557e-01, 2.0454e-03, 5.2418e-01, 1.1263e-02],\n",
      "        [7.0220e-01, 4.3689e-03, 7.5794e-01, 6.6782e-03],\n",
      "        [3.8495e-01, 2.0492e-03, 5.1646e-01, 3.6959e-03],\n",
      "        [7.9692e-01, 8.6836e-03, 5.4708e-01, 4.1598e-03],\n",
      "        [5.9391e-01, 1.9215e-02, 3.5970e-01, 6.6370e-03],\n",
      "        [5.1586e-01, 4.4843e-03, 4.2802e-01, 3.9682e-03],\n",
      "        [6.9120e-01, 7.3920e-03, 6.7147e-01, 5.1159e-03],\n",
      "        [4.4287e-01, 4.8119e-03, 6.2056e-01, 6.9115e-03],\n",
      "        [4.3059e-01, 1.8813e-02, 2.8137e-01, 1.7730e-02],\n",
      "        [4.4437e-01, 1.1451e-02, 5.5657e-01, 1.3755e-02],\n",
      "        [5.4157e-01, 2.3134e-03, 1.4651e-01, 7.9812e-04],\n",
      "        [3.4886e-01, 2.6832e-02, 7.2627e-01, 1.4004e-02],\n",
      "        [3.9862e-01, 2.1849e-03, 6.6152e-01, 2.8359e-03],\n",
      "        [7.6008e-01, 7.3050e-03, 4.5923e-01, 2.1625e-03],\n",
      "        [2.8652e-01, 4.9363e-03, 4.5138e-01, 9.9852e-03],\n",
      "        [5.6651e-01, 1.2939e-02, 3.8293e-01, 5.8275e-03],\n",
      "        [7.9355e-01, 1.3249e-02, 7.6063e-01, 3.0404e-03],\n",
      "        [6.9537e-01, 8.3549e-03, 4.9335e-01, 5.3022e-03],\n",
      "        [6.2650e-01, 1.2440e-02, 4.0632e-01, 7.7859e-03],\n",
      "        [5.5861e-01, 2.2996e-02, 4.6855e-01, 2.1201e-02],\n",
      "        [2.0525e-01, 3.1263e-02, 4.3061e-01, 2.5802e-02],\n",
      "        [1.6768e-01, 6.2550e-03, 4.1023e-01, 2.6465e-02],\n",
      "        [3.6007e-01, 8.3611e-03, 4.5397e-01, 6.3105e-03],\n",
      "        [4.1159e-01, 2.3867e-03, 7.1706e-01, 1.0751e-03],\n",
      "        [2.2490e-01, 8.4582e-03, 5.1432e-01, 1.8226e-02],\n",
      "        [8.2869e-01, 1.5969e-03, 1.9712e-01, 8.2748e-04],\n",
      "        [7.8370e-01, 1.0956e-02, 7.0563e-01, 1.0097e-02],\n",
      "        [2.3947e-01, 6.6493e-03, 6.4923e-01, 9.9101e-03],\n",
      "        [6.1625e-01, 9.8516e-03, 4.1224e-01, 5.1146e-03],\n",
      "        [5.9029e-01, 1.3499e-02, 7.0817e-01, 6.0573e-03],\n",
      "        [3.5096e-01, 1.3979e-02, 5.7891e-01, 2.9981e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0506, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.244907367634484\n",
      "Epoch 2, Loss: -4.008318949116578\n",
      "Epoch 2, Loss: -4.562536086624766\n",
      "Epoch 2, Loss: -2.964347788889194\n",
      "Epoch 2, Loss: -2.8952659340489824\n",
      "tensor([[5.8479e-01, 4.1510e-02, 5.5265e-01, 2.2039e-02],\n",
      "        [5.7319e-01, 1.5716e-03, 6.4650e-01, 1.7740e-03],\n",
      "        [6.5463e-01, 3.1514e-02, 6.7446e-01, 2.0180e-02],\n",
      "        [8.4243e-01, 5.6415e-03, 6.3048e-01, 4.2890e-03],\n",
      "        [6.0153e-01, 9.0543e-04, 2.9484e-01, 3.5187e-04],\n",
      "        [2.9183e-01, 4.2884e-03, 4.5395e-01, 9.1169e-03],\n",
      "        [4.6251e-01, 1.2129e-02, 4.5338e-01, 1.1984e-02],\n",
      "        [4.9426e-01, 4.4431e-03, 3.5198e-01, 6.5131e-03],\n",
      "        [8.1131e-01, 9.6742e-03, 6.9843e-01, 4.7872e-03],\n",
      "        [5.1651e-01, 7.2706e-03, 4.8074e-01, 8.5000e-03],\n",
      "        [5.2240e-01, 8.5502e-03, 5.7039e-01, 9.7532e-03],\n",
      "        [7.8126e-01, 9.5851e-03, 6.7497e-01, 2.6827e-03],\n",
      "        [3.0169e-01, 4.5067e-03, 6.5631e-01, 4.3245e-03],\n",
      "        [4.7361e-01, 1.7694e-02, 6.7713e-01, 9.9851e-03],\n",
      "        [6.4457e-01, 1.9483e-02, 5.1851e-01, 1.3514e-02],\n",
      "        [6.1753e-01, 1.1023e-02, 6.3591e-01, 9.8406e-03],\n",
      "        [3.8079e-01, 9.8433e-03, 2.0575e-01, 2.3339e-03],\n",
      "        [3.3419e-01, 1.5574e-02, 4.4495e-01, 7.5818e-03],\n",
      "        [8.3353e-01, 1.7879e-03, 4.7452e-01, 4.0570e-04],\n",
      "        [3.7090e-01, 6.3876e-03, 2.2716e-01, 8.4091e-03],\n",
      "        [7.7377e-01, 1.0108e-03, 1.0820e-01, 5.1058e-04],\n",
      "        [3.0173e-01, 1.2331e-02, 5.4992e-01, 1.8463e-02],\n",
      "        [7.7788e-01, 5.4483e-03, 8.0505e-01, 7.1940e-04],\n",
      "        [5.2367e-01, 8.5846e-03, 6.1609e-01, 6.7846e-03],\n",
      "        [4.0870e-01, 9.8032e-03, 4.9548e-01, 1.1873e-02],\n",
      "        [5.3463e-01, 1.2202e-02, 6.0246e-01, 9.0091e-03],\n",
      "        [6.2979e-01, 2.3364e-02, 6.2433e-01, 1.2400e-02],\n",
      "        [2.9747e-01, 9.6517e-03, 6.7040e-01, 1.5275e-02],\n",
      "        [6.4920e-01, 4.7278e-03, 1.5914e-01, 7.9320e-04],\n",
      "        [5.5825e-01, 1.6117e-03, 4.7725e-01, 2.4684e-03],\n",
      "        [7.0499e-01, 1.4670e-03, 2.4521e-01, 9.2943e-04],\n",
      "        [2.8365e-01, 1.7672e-02, 4.5633e-01, 2.1513e-02]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0697, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.377430901001732\n",
      "Epoch 2, Loss: -4.198278140248316\n",
      "Epoch 2, Loss: -4.264035427673319\n",
      "Epoch 2, Loss: -4.097717576017235\n",
      "Epoch 2, Loss: -3.907256939504001\n",
      "tensor([[0.3631, 0.0233, 0.5067, 0.0131],\n",
      "        [0.5749, 0.0063, 0.5056, 0.0024],\n",
      "        [0.6206, 0.0104, 0.4452, 0.0040],\n",
      "        [0.5258, 0.0060, 0.7478, 0.0027],\n",
      "        [0.7884, 0.0036, 0.7638, 0.0015],\n",
      "        [0.3011, 0.0065, 0.3144, 0.0063],\n",
      "        [0.5212, 0.0076, 0.5980, 0.0070],\n",
      "        [0.4665, 0.0342, 0.6925, 0.0257],\n",
      "        [0.3051, 0.0023, 0.3622, 0.0041],\n",
      "        [0.4863, 0.0058, 0.6275, 0.0023],\n",
      "        [0.1879, 0.0015, 0.3683, 0.0024],\n",
      "        [0.4311, 0.0660, 0.6416, 0.0362],\n",
      "        [0.8327, 0.0025, 0.2918, 0.0015],\n",
      "        [0.2708, 0.0059, 0.3933, 0.0052],\n",
      "        [0.7100, 0.0055, 0.3364, 0.0046],\n",
      "        [0.6989, 0.0024, 0.5560, 0.0015],\n",
      "        [0.4481, 0.0083, 0.4652, 0.0083],\n",
      "        [0.5567, 0.0094, 0.8034, 0.0022],\n",
      "        [0.6827, 0.0134, 0.3590, 0.0123],\n",
      "        [0.4640, 0.0065, 0.4396, 0.0047],\n",
      "        [0.6006, 0.0038, 0.5600, 0.0017],\n",
      "        [0.5094, 0.0158, 0.5969, 0.0050],\n",
      "        [0.2540, 0.0187, 0.7419, 0.0085],\n",
      "        [0.7931, 0.0072, 0.7160, 0.0035],\n",
      "        [0.7393, 0.0060, 0.2952, 0.0040],\n",
      "        [0.4409, 0.0209, 0.5710, 0.0143],\n",
      "        [0.2967, 0.0108, 0.7437, 0.0059],\n",
      "        [0.4620, 0.0067, 0.6057, 0.0070],\n",
      "        [0.3808, 0.0201, 0.7087, 0.0151],\n",
      "        [0.4112, 0.0157, 0.4574, 0.0118],\n",
      "        [0.5585, 0.0046, 0.5530, 0.0026],\n",
      "        [0.8165, 0.0012, 0.4694, 0.0023]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0693, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "Epoch 2, Loss: -4.182284506799784\n",
      "Epoch 2, Loss: -4.012653480610062\n",
      "Epoch 2, Loss: -3.93538591650886\n",
      "Epoch 2, Loss: -4.204736173007987\n",
      "Epoch 2, Loss: -4.355129653573507\n",
      "tensor([[0.3095, 0.0074, 0.7424, 0.0030],\n",
      "        [0.3946, 0.0074, 0.7550, 0.0038],\n",
      "        [0.3601, 0.0135, 0.4655, 0.0069],\n",
      "        [0.5675, 0.0043, 0.5138, 0.0044],\n",
      "        [0.5144, 0.0082, 0.6043, 0.0021],\n",
      "        [0.7054, 0.0128, 0.5082, 0.0141],\n",
      "        [0.3164, 0.0057, 0.3773, 0.0041],\n",
      "        [0.7540, 0.0062, 0.4595, 0.0039],\n",
      "        [0.7880, 0.0018, 0.5104, 0.0047],\n",
      "        [0.2911, 0.0091, 0.3699, 0.0056],\n",
      "        [0.3874, 0.0166, 0.6252, 0.0110],\n",
      "        [0.3803, 0.0011, 0.2044, 0.0034],\n",
      "        [0.5924, 0.0046, 0.5128, 0.0026],\n",
      "        [0.4607, 0.0087, 0.2963, 0.0082],\n",
      "        [0.3966, 0.0063, 0.6699, 0.0038],\n",
      "        [0.5190, 0.0043, 0.3884, 0.0041],\n",
      "        [0.4409, 0.0025, 0.3944, 0.0039],\n",
      "        [0.3888, 0.0293, 0.5207, 0.0134],\n",
      "        [0.2337, 0.0084, 0.4557, 0.0069],\n",
      "        [0.4669, 0.0137, 0.5254, 0.0117],\n",
      "        [0.7316, 0.0215, 0.4871, 0.0172],\n",
      "        [0.8006, 0.0053, 0.3888, 0.0060],\n",
      "        [0.5986, 0.0062, 0.6507, 0.0033],\n",
      "        [0.3058, 0.0188, 0.5229, 0.0065],\n",
      "        [0.1876, 0.0236, 0.6672, 0.0121],\n",
      "        [0.5251, 0.0097, 0.5485, 0.0057],\n",
      "        [0.5223, 0.0115, 0.3049, 0.0211],\n",
      "        [0.8100, 0.0052, 0.4259, 0.0190],\n",
      "        [0.6959, 0.0050, 0.6741, 0.0028],\n",
      "        [0.5218, 0.0056, 0.2471, 0.0077],\n",
      "        [0.3682, 0.0112, 0.7758, 0.0032],\n",
      "        [0.2932, 0.0144, 0.4256, 0.0087]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.0476, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     13\u001b[0m     count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m, output \u001b[38;5;129;01min\u001b[39;00m data_generator():\n\u001b[1;32m     15\u001b[0m         count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;66;03m# Reset the gradients\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 23\u001b[0m, in \u001b[0;36mdata_generator\u001b[0;34m(folder_paths, batch_size, image_size)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Load and preprocess the image\u001b[39;00m\n\u001b[1;32m     22\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\n\u001b[0;32m---> 23\u001b[0m tensor_image \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_catalog.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     26\u001b[0m     info \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:166\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[1;32m    165\u001b[0m mode_to_nptype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint32, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI;16\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mint16, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m--> 166\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_to_nptype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    169\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/PIL/Image.py:701\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 701\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n",
      "File \u001b[0;32m~/bliss/.venv/lib/python3.10/site-packages/PIL/Image.py:779\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    776\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder error \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in tobytes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m--> 779\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 20001\n",
    "losses = []\n",
    "loss_function = torch.nn.GaussianNLLLoss(eps=1e-06, # Epsilon for numerical stability\n",
    "                                full=False, # Computes the necessary terms AND the constants\n",
    "                                reduction=\"mean\" # Alternative is 'sum' or 'none'\n",
    "                                )\n",
    "\n",
    "model.train()  # Set the model to training mode\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    count = 0\n",
    "    for input, output in data_generator():\n",
    "        count += 1\n",
    "        # Reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        # Compute and print loss\n",
    "        nn_output = model(input)\n",
    "        raw_mu_hat_mu, raw_sigma_hat_sigma = nn_output[:, 0], nn_output[:, 1]\n",
    "        raw_mu_hat_mu2, raw_sigma_hat_sigma2 = nn_output[:, 2], nn_output[:, 3]\n",
    "        target_x = np.array(output)[:][:, 0]\n",
    "        target_y = np.array(output)[:][:, 1]\n",
    "        loss1 = loss_function(input = raw_mu_hat_mu, var = raw_sigma_hat_sigma, target = torch.tensor(target_x))\n",
    "        loss2 = loss_function(input = raw_mu_hat_mu2, var = raw_sigma_hat_sigma2, target = torch.tensor(target_y))\n",
    "        loss = loss1+loss2\n",
    "        print(f\"Epoch { +1}, Loss: {loss.item()}\")\n",
    "        if count % 5 == 0:\n",
    "            print(nn_output) \n",
    "            compare = torch.nn.L1Loss()\n",
    "            coordinates = [torch.stack((x, y)) for x, y in zip(nn_output[:,0], nn_output[:,2])]\n",
    "            print(compare(torch.stack(coordinates), torch.tensor(output)))\n",
    "            # visual(input, output, nn_output.detach().numpy())\n",
    "        # Perform a backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "            # Update the parameters\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visual(input, output, nn_output.detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
