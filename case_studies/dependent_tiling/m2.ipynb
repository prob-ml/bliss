{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SDSS image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "import numpy as np\n",
    "\n",
    "f = fits.open('/home/regier/bliss/data/sdss/2583/2/136/frame-r-002583-2-0136.fits')\n",
    "w = WCS(f[0].header)\n",
    "\n",
    "# lower-left corner of the 100x100-pixel study area is at pixel (310, 630)\n",
    "w.pixel_to_world(310, 630)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(f[0].data, origin='lower', cmap='Greys_r')\n",
    "print(\"Behold, the M2 globular cluster!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logimage = np.log(f[0].data - f[0].data.min() + 1)\n",
    "plt.imshow(logimage, origin='lower', cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "plt.imshow(logimage, origin='lower', cmap='Greys_r')\n",
    "rect = Rectangle((310, 630), 100, 100, linewidth=2, edgecolor='r', facecolor='none')\n",
    "_ = plt.gca().add_patch(rect)\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading/viewing HST predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bliss.catalog import FullCatalog\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "hubble_cat_file = \"/home/regier/hlsp_acsggct_hst_acs-wfc_ngc7089_r.rdviq.cal.adj.zpt\"\n",
    "hubble_cat = np.loadtxt(hubble_cat_file, skiprows=3, usecols=(9,21,22))\n",
    "\n",
    "hst_r_mag_all = torch.from_numpy(hubble_cat[:, 0])\n",
    "ra = torch.from_numpy(hubble_cat[:, 1])\n",
    "dec = torch.from_numpy(hubble_cat[:, 2])\n",
    "\n",
    "plocs_all = FullCatalog.plocs_from_ra_dec(ra, dec, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = f[0].data[630:730, 310:410]\n",
    "\n",
    "arcsinh_median = np.arcsinh((original - np.median(original)))\n",
    "\n",
    "clipped = original.clip(max=np.quantile(original, 0.98))\n",
    "arcsinh_clipped = np.arcsinh((clipped - np.median(clipped)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "images = [original, arcsinh_median, arcsinh_clipped]\n",
    "titles = ['original', 'arcsinc', 'arcsinc with clipping']\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    ax = axs[i]\n",
    "    ax.imshow(img, origin='lower', cmap='Greys_r')\n",
    "    ax.set_title(titles[i])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_bounds = (plocs_all[:, 1] > 310) & (plocs_all[:, 1] < 410)\n",
    "in_bounds &= (plocs_all[:, 0] > 630) & (plocs_all[:, 0] < 730)\n",
    "in_bounds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hst_r_mag = hst_r_mag_all[in_bounds]\n",
    "plocs = plocs_all[in_bounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plocs_square = plocs - torch.tensor([630, 310])\n",
    "\n",
    "from bliss.catalog import convert_mag_to_nmgy, convert_nmgy_to_mag\n",
    "hst_r_nmgy = convert_mag_to_nmgy(hst_r_mag)\n",
    "\n",
    "# these magnitudes are about 15% off: the hubble fw606 band filter curve\n",
    "#  isn't exactly the sdss r band filter curve\n",
    "sdss_r_nmgy = hst_r_nmgy * 1.15\n",
    "sdss_r_mag = convert_nmgy_to_mag(sdss_r_nmgy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"plocs\": plocs_square.unsqueeze(0),\n",
    "    \"star_fluxes\": sdss_r_nmgy.unsqueeze(0).unsqueeze(2).expand([-1, -1, 5]),\n",
    "    \"galaxy_fluxes\": sdss_r_nmgy.unsqueeze(0).unsqueeze(2).expand([-1, -1, 5]) * 0.0,\n",
    "    \"n_sources\": torch.tensor(plocs.shape[0]).unsqueeze(0),\n",
    "    \"source_type\": torch.zeros(plocs.shape[0]).unsqueeze(0).unsqueeze(2).long(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cat_all = FullCatalog(100, 100, d)\n",
    "true_cat_all["n_sources"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tile_cat_all = true_cat_all.to_tile_catalog(2, 11)\n",
    "true_tile_cat_all["n_sources"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_bright = sdss_r_mag < 22.565\n",
    "is_bright.sum(), convert_mag_to_nmgy(22.565)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"plocs\": plocs_square[is_bright].unsqueeze(0),\n",
    "    \"star_fluxes\": sdss_r_nmgy[is_bright].unsqueeze(0).unsqueeze(2).expand([-1, -1, 5]),\n",
    "    \"galaxy_fluxes\": sdss_r_nmgy[is_bright].unsqueeze(0).unsqueeze(2).expand([-1, -1, 5]) * 0.0,\n",
    "    \"n_sources\": torch.tensor(plocs[is_bright].shape[0]).unsqueeze(0),\n",
    "    \"source_type\": torch.zeros(plocs[is_bright].shape[0]).unsqueeze(0).unsqueeze(2).long(),\n",
    "}\n",
    "true_cat = FullCatalog(100, 100, d)\n",
    "true_cat["n_sources"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tile_cat = true_cat.to_tile_catalog(2, 5)\n",
    "true_tile_cat["n_sources"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "cutoffs = [20, 22.065, 24]\n",
    "\n",
    "for i, cutoff in enumerate(cutoffs):\n",
    "    is_bright = sdss_r_mag < cutoff\n",
    "    plocs_square_bright = plocs_square[is_bright]\n",
    "    ax = axs[i]\n",
    "    ax.imshow(arcsinh_clipped, origin='lower', cmap='Greys_r')\n",
    "    ax.scatter(plocs_square_bright[:, 1], plocs_square_bright[:, 0], s=5, c='r')\n",
    "    ax.set_title(f\"magnitude < {cutoff}\")\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on M2 with BLISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "from pathlib import Path\n",
    "from hydra import initialize, compose\n",
    "from bliss.main import predict\n",
    "\n",
    "environ[\"BLISS_HOME\"] = str(Path().resolve().parents[1])\n",
    "with initialize(config_path=\"../../case_studies/dependent_tiling/\", version_base=None):\n",
    "    cfg = compose(\"m2_config\", {\n",
    "        \"encoder.tiles_to_crop=3\",\n",
    "        \"predict.weight_save_path=/home/regier/bliss/output/new_log_transforms/version_0/checkpoints/best_encoder.ckpt\",\n",
    " #       \"encoder.double_detect=false\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_cats = predict(cfg.predict)\n",
    "bliss_cat_pair, = bliss_cats.values()\n",
    "bliss_cat = bliss_cat_pair[\"mode_cat\"].to_full_catalog()\n",
    "true_cat["n_sources"].sum(), bliss_cat["n_sources"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra.utils import instantiate\n",
    "\n",
    "matcher = instantiate(cfg.encoder.matcher)\n",
    "metrics = instantiate(cfg.encoder.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = matcher.match_catalogs(true_cat, bliss_cat)\n",
    "metric = metrics(true_cat, bliss_cat, matching)\n",
    "metric[\"detection_recall\"], metric[\"detection_precision\"], metric[\"detection_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, metric in metrics.items():\n",
    "    metric.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = metrics[\"DetectionPerformance\"]\n",
    "recall = (m.n_true_matches / m.n_true_sources)[:-1]\n",
    "precision = (m.n_est_matches / m.n_est_sources)[:-1]\n",
    "real = {\"recall\": recall, \"precision\": precision}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "counts = []\n",
    "\n",
    "for i in range(15):\n",
    "    bliss_cats = predict(cfg.predict)\n",
    "    bliss_cat_pair, = bliss_cats.values()\n",
    "    bliss_cat = bliss_cat_pair[\"sample_cat\"].to_full_catalog()\n",
    "    counts.append(bliss_cat["n_sources"].sum())\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = torch.tensor([c.item() for c in counts]).float()\n",
    "cs.mean(), cs.quantile(0.05), cs.quantile(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent tiling (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "cfg2 = deepcopy(cfg)\n",
    "cfg2.encoder.use_checkerboard = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_cats = predict(cfg2.predict)\n",
    "bliss_cat_pair, = bliss_cats.values()\n",
    "bliss_cat_marginal = bliss_cat_pair[\"mode_cat\"].to_full_catalog()\n",
    "matching = matcher.match_catalogs(true_cat, bliss_cat_marginal)\n",
    "metric = metrics(true_cat, bliss_cat_marginal, matching)\n",
    "\n",
    "m = metrics[\"DetectionPerformance\"]\n",
    "m.plot()\n",
    "\n",
    "metric[\"detection_recall\"], metric[\"detection_precision\"], metric[\"detection_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "counts = []\n",
    "\n",
    "for i in range(15):\n",
    "    bliss_cats = predict(cfg2.predict)\n",
    "    bliss_cat_pair, = bliss_cats.values()\n",
    "    bliss_cat = bliss_cat_pair[\"sample_cat\"].to_full_catalog()\n",
    "    counts.append(bliss_cat["n_sources"].sum())\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLISS performance on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\"../../case_studies/dependent_tiling/\", version_base=None):\n",
    "    cfg3 = compose(\"m2_config\", {\n",
    "        \"train.trainer.logger=null\",\n",
    "        \"train.trainer.max_epochs=0\",\n",
    "        \"train.pretrained_weights=/home/regier/bliss/output/new_log_transforms/version_0/checkpoints/best_encoder.ckpt\",\n",
    "        \"cached_simulator.cached_data_path=/data/scratch/regier/toy_m2\",\n",
    "        \"+train.trainer.num_sanity_val_steps=0\",\n",
    "#        \"encoder.double_detect=false\"\n",
    "    })\n",
    "\n",
    "train_cfg = cfg3.train\n",
    "dataset = instantiate(train_cfg.data_source)\n",
    "encoder = instantiate(train_cfg.encoder)\n",
    "trainer = instantiate(train_cfg.trainer)\n",
    "\n",
    "enc_state_dict = torch.load(train_cfg.pretrained_weights)\n",
    "if train_cfg.pretrained_weights.endswith(\".ckpt\"):\n",
    "    enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "encoder.load_state_dict(enc_state_dict)\n",
    "\n",
    "trainer.test(encoder, datamodule=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to disable metric_reset in encoder for this to work!\n",
    "m = encoder.mode_metrics[\"DetectionPerformance\"]\n",
    "recall = (m.n_true_matches / m.n_true_sources)[:-1]\n",
    "precision = (m.n_est_matches / m.n_est_sources)[:-1]\n",
    "fully_synthetic = {\"recall\": recall, \"precision\": precision}\n",
    "fully_synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.use_checkerboard = False\n",
    "trainer.test(encoder, datamodule=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess the model and BLISS fit visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "dataset = instantiate(cfg.predict.dataset)\n",
    "dataset.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_image = torch.from_numpy(dataset[0][\"image\"][2][6:-6, 6:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = instantiate(cfg.simulator)\n",
    "truth_images, _, _, _ = simulator.image_decoder.render_images(true_tile_cat_all, [(2583, 2, 136)])\n",
    "true_recon_all = truth_images[0][2] + dataset[0][\"background\"][2][6:-6, 6:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_tile_cat = bliss_cat.to_tile_catalog(2, 5)\n",
    "bliss_images, _, _, _ = simulator.image_decoder.render_images(bliss_tile_cat, [(2583, 2, 136)])\n",
    "bliss_recon = bliss_images[0, 2] + dataset[0][\"background\"][2][6:-6, 6:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['SDSS image', 'HST reconstruction', 'BLISS reconstruction']\n",
    "\n",
    "images = [obs_image, true_recon_all, bliss_recon]\n",
    "images = [img.clip(max=obs_image.quantile(0.99)) for img in images]\n",
    "images = [np.arcsinh((img - np.median(obs_image))) for img in images]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "vmin = min(img.min() for img in images)\n",
    "vmax = max(img.max() for img in images)\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    ax = axs[i]\n",
    "    ax.imshow(arcsinh_median, origin='lower', vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(titles[i])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux Prior Elicitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob = (plocs_all[:, 1] > 210) & (plocs_all[:, 1] < 510)\n",
    "oob &= (plocs_all[:, 0] > 530) & (plocs_all[:, 0] < 830)\n",
    "oob &= ~in_bounds\n",
    "oob.sum() # some of this region (about half) is outside of our HST cat coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hst_oob = hst_r_mag_all[oob]\n",
    "hst_oob_nmgy = convert_mag_to_nmgy(hst_oob) * 1.15\n",
    "hst_oob_mag = convert_nmgy_to_mag(hst_oob_nmgy)\n",
    "training_data = hst_oob_nmgy[hst_oob_mag < 24]\n",
    "training_data.shape[0], training_data.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncpareto\n",
    "alpha, trunc, loc, scale = truncpareto.fit(training_data)\n",
    "alpha, trunc, loc, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncpareto\n",
    "\n",
    "x = np.logspace(hst_oob_nmgy.log10().min(), hst_oob_nmgy.log10().max(), num=100)\n",
    "\n",
    "_ = plt.plot(x, truncpareto.pdf(x, alpha, trunc, loc, scale), 'r-', lw=3, alpha=0.7, label='new prior')\n",
    "_ = plt.plot(x, truncpareto.pdf(x, 0.5, 1014, 0, 0.63), 'g-', lw=3, alpha=0.7, label='old prior')\n",
    "_ = plt.hist(hst_oob_nmgy, log=True, bins=100, label='star_fluxes histogram', density=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(x, truncpareto.pdf(x, alpha, trunc, loc, scale), 'r-', lw=3, alpha=0.7, label='new prior')\n",
    "_ = plt.plot(x, truncpareto.pdf(x, 0.5, 1014, 0, 0.63), 'g-', lw=3, alpha=0.7, label='old prior')\n",
    "plt.legend()\n",
    "plt.loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = truncpareto.rvs(alpha, trunc, loc, scale, size=1500)\n",
    "sorted(samples, reverse=True)[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = instantiate(cfg.prior)\n",
    "prior.sample().on_fluxes[0, :, :, :, 2].view(-1).topk(100)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate rate with oob data\n",
    "(hst_oob_mag < 24).sum() / (4 * 1e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess the two-point correlation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "from bliss.main import train\n",
    "\n",
    "with initialize(config_path=\"../../case_studies/dependent_tiling/\", version_base=None):\n",
    "    cfg5 = compose(\"m2_config\", {\n",
    "        \"train.trainer.logger=null\",\n",
    "        \"train.trainer.max_epochs=0\",\n",
    "        \"train.pretrained_weights=/home/regier/bliss/output/new_log_transforms/version_0/checkpoints/best_encoder.ckpt\",\n",
    "        \"cached_simulator.cached_data_path=/data/scratch/regier/toy_m2\",\n",
    "        \"+train.trainer.num_sanity_val_steps=0\",\n",
    "        \"cached_simulator.splits=0:10/10:20/0:100\",\n",
    "#        \"encoder.double_detect=false\",\n",
    "    })\n",
    "\n",
    "# setup dataset, encoder, and trainer\n",
    "cfg5.train.encoder.metrics.metrics = [{'_target_': 'case_studies.dependent_tiling.two_point_metric.TwoPointMetric'}]\n",
    "train_cfg = cfg5.train\n",
    "\n",
    "dataset = instantiate(train_cfg.data_source)\n",
    "encoder = instantiate(train_cfg.encoder)\n",
    "trainer = instantiate(train_cfg.trainer)\n",
    "\n",
    "# load pretrained weights\n",
    "enc_state_dict = torch.load(train_cfg.pretrained_weights)\n",
    "if train_cfg.pretrained_weights.endswith(\".ckpt\"):\n",
    "    enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "encoder.load_state_dict(enc_state_dict)\n",
    "\n",
    "# test\n",
    "trainer.test(encoder, datamodule=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = encoder.sample_metrics[\"TwoPointMetric\"]\n",
    "two_pt_checkerboard = m.compute().values()\n",
    "m.reset()\n",
    "two_pt_checkerboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings from spotchecking sources of nonzero two-point correlation above:\n",
    "* two pairs of sources with modes within 1e-4: catty corner, need 4 color checkerboard\n",
    "* one pair of sources with modes within 1e-2: consecutive columns in a row, near a corner; one source a second detect; need conditioning info to second detect\n",
    "* one pair of sources with sampled modes within 0.1: a double detect solidly within a tile; high uncertainty about whether second exists (it doesn't); first correctly identified; second detected source hovers around the pixel (of 4) containing the source; need conditioning info for the second detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.use_checkerboard = False\n",
    "trainer.test(encoder, datamodule=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = encoder.sample_metrics[\"TwoPointMetric\"]\n",
    "two_pt_ind = m.compute().values()\n",
    "two_pt_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = [0.01, 0.03, 0.1, 0.3, 1, 3, 10]\n",
    "\n",
    "plt.figure(figsize=(8, 6))  # Create a new figure with a specific size\n",
    "plt.plot(radius, two_pt_ind, marker=\"s\", label=\"independent\")\n",
    "plt.plot(radius, two_pt_checkerboard, label=\"checkerboard\", marker=\"s\")\n",
    "plt.legend()\n",
    "plt.xscale(\"log\")  # Set the x-axis scale to logarithmic\n",
    "plt.xlabel(\"Radius\")\n",
    "plt.ylabel(\"Two-point correlation\")\n",
    "\n",
    "plt.tight_layout()\n",
    "two_pt_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-synthetic M2 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\"../../case_studies/dependent_tiling/\", version_base=None):\n",
    "    cfg = compose(\"m2_config\", {\n",
    "        \"encoder.tiles_to_crop=3\",\n",
    "        \"predict.weight_save_path=/home/regier/bliss/output/new_log_transforms/version_0/checkpoints/best_encoder.ckpt\",\n",
    " #       \"encoder.double_detect=false\"\n",
    "        })\n",
    "\n",
    "d2 = deepcopy(true_cat_all)\n",
    "d2[\"plocs\"] += 6\n",
    "true_cat_pad = FullCatalog(112, 112, d2)\n",
    "\n",
    "truth_images, _, _, _ = simulator.image_decoder.render_images(\n",
    "    true_cat_pad.to_tile_catalog(2, 11), [(2583, 2, 136)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "\n",
    "true_recon_all = truth_images[0] + dataset[0][\"background\"]\n",
    "true_recon_all = Normal(true_recon_all, true_recon_all.sqrt()).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = instantiate(cfg.encoder)\n",
    "enc_state_dict = torch.load(\"/home/regier/bliss/output/new_log_transforms/version_0/checkpoints/best_encoder.ckpt\")\n",
    "enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "encoder.load_state_dict(enc_state_dict)\n",
    "encoder.eval()\n",
    "\n",
    "batch = {\n",
    "    \"images\": true_recon_all.unsqueeze(0),\n",
    "    \"background\": torch.from_numpy(dataset[0][\"background\"]).unsqueeze(0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.use_checkerboard = False\n",
    "\n",
    "with torch.no_grad():\n",
    "    mode_cat, sample_cat = encoder.predict_step(batch, 0).values()\n",
    "\n",
    "mode_cat = mode_cat.to_full_catalog()\n",
    "matching = matcher.match_catalogs(true_cat_all, mode_cat)\n",
    "metric = metrics(true_cat_all, mode_cat, matching)\n",
    "metric[\"detection_recall\"], metric[\"detection_precision\"], metric[\"detection_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.use_checkerboard = True\n",
    "\n",
    "with torch.no_grad():\n",
    "    mode_cat, sample_cat = encoder.predict_step(batch, 0).values()\n",
    "\n",
    "mode_cat = mode_cat.to_full_catalog()\n",
    "matching = matcher.match_catalogs(true_cat_all, mode_cat)\n",
    "metric = metrics(true_cat_all, mode_cat, matching)\n",
    "metric[\"detection_recall\"], metric[\"detection_precision\"], metric[\"detection_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = metrics[\"DetectionPerformance\"]\n",
    "recall = (m.n_true_matches / m.n_true_sources)[:-1]\n",
    "precision = (m.n_est_matches / m.n_est_sources)[:-1]\n",
    "semisynthetic = {\"recall\": recall, \"precision\": precision}\n",
    "semisynthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"fully synthetic\", \"semi-synthetic\", \"real\"]\n",
    "scores = [fully_synthetic, semisynthetic, real]\n",
    "\n",
    "mbc = m.mag_bin_cutoffs\n",
    "xlabels = [f\"[{mbc[i]}, {mbc[i+1]}]\" for i in range(len(mbc) - 1)]\n",
    "xlabels = [\"< \" + str(mbc[0])] + xlabels + [\"> \" + str(mbc[-1])]\n",
    "xlabels = xlabels[:-1]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for i, score in enumerate(scores):\n",
    "    axs[0].plot(score[\"recall\"], marker=\"s\", label=titles[i])\n",
    "    axs[1].plot(score[\"precision\"], marker=\"s\", label=titles[i])\n",
    "\n",
    "axs[0].set_title(\"recall\")\n",
    "axs[1].set_title(\"precision\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xticks(range(len(xlabels)))\n",
    "    ax.set_xticklabels(xlabels, rotation=45)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
