{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SDSS image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "import numpy as np\n",
    "\n",
    "f = fits.open('/home/regier/bliss/data/sdss/2583/2/136/frame-r-002583-2-0136.fits')\n",
    "w = WCS(f[0].header)\n",
    "\n",
    "# lower-left corner of the 100x100-pixel study area is at pixel (310, 630)\n",
    "w.pixel_to_world(310, 630)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(f[0].data, origin='lower', cmap='gray_r')\n",
    "print(\"Behold, the M2 globular cluster!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logimage = np.log(f[0].data - f[0].data.min() + 1)\n",
    "_ = plt.imshow(logimage, origin='lower', cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading/viewing HST predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bliss.catalog import FullCatalog\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "hubble_cat_file = \"/home/regier/hlsp_acsggct_hst_acs-wfc_ngc7089_r.rdviq.cal.adj.zpt\"\n",
    "hubble_cat = np.loadtxt(hubble_cat_file, skiprows=3, usecols=(9,21,22))\n",
    "\n",
    "hst_r_mag_all = torch.from_numpy(hubble_cat[:, 0])\n",
    "ra = torch.from_numpy(hubble_cat[:, 1])\n",
    "dec = torch.from_numpy(hubble_cat[:, 2])\n",
    "\n",
    "plocs_all = FullCatalog.plocs_from_ra_dec(ra, dec, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "plt.imshow(logimage, origin='lower', cmap='gray_r')\n",
    "plt.scatter(plocs_all[:, 1], plocs_all[:, 0], s=10, c='r')\n",
    "rect = Rectangle((310, 630), 100, 100, linewidth=1, edgecolor='b', facecolor='none')\n",
    "plt.gca().add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_bounds = (plocs_all[:, 1] > 310) & (plocs_all[:, 1] < 410)\n",
    "in_bounds &= (plocs_all[:, 0] > 630) & (plocs_all[:, 0] < 730)\n",
    "in_bounds.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(logimage, origin='lower', cmap='gray_r')\n",
    "plt.scatter(plocs_all[:, 1][in_bounds], plocs_all[:, 0][in_bounds], s=10, c='r')\n",
    "rect = Rectangle((310, 630), 100, 100, linewidth=1, edgecolor='b', facecolor='none')\n",
    "_ = plt.gca().add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hst_r_mag = hst_r_mag_all[in_bounds]\n",
    "plocs = plocs_all[in_bounds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plocs_square = plocs - torch.tensor([630, 310])\n",
    "\n",
    "from bliss.catalog import convert_mag_to_nmgy, convert_nmgy_to_mag\n",
    "hst_r_nmgy = convert_mag_to_nmgy(hst_r_mag)\n",
    "\n",
    "# these magnitudes are about 15% off: the hubble fw606 band filter curve\n",
    "#  isn't exactly the sdss r band filter curve\n",
    "sdss_r_nmgy = hst_r_nmgy * 1.15\n",
    "sdss_r_mag = convert_nmgy_to_mag(sdss_r_nmgy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"plocs\": plocs_square.unsqueeze(0),\n",
    "    \"star_fluxes\": sdss_r_nmgy.unsqueeze(0).unsqueeze(2).expand([-1, -1, 5]),\n",
    "    \"galaxy_fluxes\": sdss_r_nmgy.unsqueeze(0).unsqueeze(2).expand([-1, -1, 5]) * 0.0,\n",
    "    \"n_sources\": torch.tensor(plocs.shape[0]).unsqueeze(0),\n",
    "    \"source_type\": torch.zeros(plocs.shape[0]).unsqueeze(0).unsqueeze(2).long(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cat_all = FullCatalog(100, 100, d)\n",
    "true_cat_all.n_sources.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tile_cat_all = true_cat_all.to_tile_catalog(2, 11)\n",
    "true_tile_cat_all.n_sources.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_bright = sdss_r_mag < 22.565\n",
    "is_bright.sum(), convert_mag_to_nmgy(22.565)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    \"plocs\": plocs_square[is_bright].unsqueeze(0),\n",
    "    \"star_fluxes\": sdss_r_nmgy[is_bright].unsqueeze(0).unsqueeze(2).expand([-1, -1, 5]),\n",
    "    \"galaxy_fluxes\": sdss_r_nmgy[is_bright].unsqueeze(0).unsqueeze(2).expand([-1, -1, 5]) * 0.0,\n",
    "    \"n_sources\": torch.tensor(plocs[is_bright].shape[0]).unsqueeze(0),\n",
    "    \"source_type\": torch.zeros(plocs[is_bright].shape[0]).unsqueeze(0).unsqueeze(2).long(),\n",
    "}\n",
    "true_cat = FullCatalog(100, 100, d)\n",
    "true_cat.n_sources.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tile_cat = true_cat.to_tile_catalog(2, 5)\n",
    "true_tile_cat.n_sources.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on M2 with BLISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "from pathlib import Path\n",
    "from hydra import initialize, compose\n",
    "from bliss.main import predict\n",
    "\n",
    "environ[\"BLISS_HOME\"] = str(Path().resolve().parents[1])\n",
    "with initialize(config_path=\"../../case_studies/dependent_tiling/\", version_base=None):\n",
    "    cfg = compose(\"m2_config\", {\n",
    "        \"encoder.tiles_to_crop=3\",\n",
    "        \"predict.weight_save_path=/home/regier/bliss/output/m2_80offset/version_0/checkpoints/best_encoder.ckpt\",\n",
    " #       \"encoder.double_detect=false\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_cats = predict(cfg.predict)\n",
    "bliss_cat_pair, = bliss_cats.values()\n",
    "bliss_cat = bliss_cat_pair[\"mode_cat\"].to_full_catalog()\n",
    "true_cat.n_sources.sum(), bliss_cat.n_sources.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra.utils import instantiate\n",
    "\n",
    "matcher = instantiate(cfg.encoder.matcher)\n",
    "metrics = instantiate(cfg.encoder.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching = matcher.match_catalogs(true_cat, bliss_cat)\n",
    "metric = metrics(true_cat, bliss_cat, matching)\n",
    "metric[\"detection_recall\"], metric[\"detection_precision\"], metric[\"detection_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, metric in metrics.items():\n",
    "    metric.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "cfg2 = deepcopy(cfg)\n",
    "cfg2.encoder.use_checkerboard = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_cats = predict(cfg2.predict)\n",
    "bliss_cat_pair, = bliss_cats.values()\n",
    "bliss_cat_marginal = bliss_cat_pair[\"mode_cat\"].to_full_catalog()\n",
    "matching = matcher.match_catalogs(true_cat, bliss_cat_marginal)\n",
    "metric = metrics(true_cat, bliss_cat_marginal, matching)\n",
    "for name, m in metrics.items():\n",
    "    m.plot()\n",
    "\n",
    "metric[\"detection_recall\"], metric[\"detection_precision\"], metric[\"detection_f1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLISS performance on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\"../../case_studies/dependent_tiling/\", version_base=None):\n",
    "    cfg3 = compose(\"m2_config\", {\n",
    "        \"train.trainer.logger=null\",\n",
    "        \"train.trainer.max_epochs=0\",\n",
    "        \"train.pretrained_weights=/home/regier/bliss/output/m2_80offset/version_0/checkpoints/x.pt\",\n",
    "        \"cached_simulator.cached_data_path=/data/scratch/regier/toy_m2\",\n",
    "        \"+train.trainer.num_sanity_val_steps=0\",\n",
    "        \"encoder.double_detect=false\"\n",
    "    })\n",
    "\n",
    "from bliss.main import train\n",
    "train(cfg3.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "cfg4 = deepcopy(cfg3)\n",
    "cfg4.train.encoder.use_checkerboard = False\n",
    "train(cfg4.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess the model and BLISS fit visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "dataset = instantiate(cfg.predict.dataset)\n",
    "dataset.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_image = torch.from_numpy(dataset[0][\"image\"][2][6:-6, 6:-6])\n",
    "plt.imshow(obs_image)\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = instantiate(cfg.simulator)\n",
    "truth_images, _, _, _ = simulator.image_decoder.render_images(true_tile_cat_all, [(2583, 2, 136)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_recon_all = truth_images[0][2] + dataset[0][\"background\"][2][6:-6, 6:-6]\n",
    "plt.imshow(true_recon_all)\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = instantiate(cfg.simulator)\n",
    "truth_images, _, _, _ = simulator.image_decoder.render_images(true_tile_cat, [(2583, 2, 136)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_recon = truth_images[0][2] + dataset[0][\"background\"][2][6:-6, 6:-6]\n",
    "plt.imshow(true_recon)\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_tile_cat = bliss_cat.to_tile_catalog(2, 5)\n",
    "bliss_images, _, _, _ = simulator.image_decoder.render_images(bliss_tile_cat, [(2583, 2, 136)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bliss_recon = bliss_images[0, 2] + dataset[0][\"background\"][2][6:-6, 6:-6]\n",
    "plt.imshow(bliss_recon)\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux Prior Elicitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob = (plocs_all[:, 1] > 210) & (plocs_all[:, 1] < 510)\n",
    "oob &= (plocs_all[:, 0] > 530) & (plocs_all[:, 0] < 830)\n",
    "oob &= ~in_bounds\n",
    "oob.sum() # some of this region (about half) is outside of our HST cat coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hst_oob = hst_r_mag_all[oob]\n",
    "hst_oob_nmgy = convert_mag_to_nmgy(hst_oob) * 1.15\n",
    "hst_oob_mag = convert_nmgy_to_mag(hst_oob_nmgy)\n",
    "training_data = hst_oob_nmgy[hst_oob_mag < 24]\n",
    "training_data.shape[0], training_data.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncpareto\n",
    "alpha, trunc, loc, scale = truncpareto.fit(training_data)\n",
    "alpha, trunc, loc, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncpareto\n",
    "\n",
    "x = np.logspace(hst_oob_nmgy.log10().min(), hst_oob_nmgy.log10().max(), num=100)\n",
    "\n",
    "_ = plt.plot(x, truncpareto.pdf(x, alpha, trunc, loc, scale), 'r-', lw=3, alpha=0.7, label='new prior')\n",
    "_ = plt.plot(x, truncpareto.pdf(x, 0.5, 1014, 0, 0.63), 'g-', lw=3, alpha=0.7, label='old prior')\n",
    "_ = plt.hist(hst_oob_nmgy, log=True, bins=100, label='star_fluxes histogram', density=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(x, truncpareto.pdf(x, alpha, trunc, loc, scale), 'r-', lw=3, alpha=0.7, label='new prior')\n",
    "_ = plt.plot(x, truncpareto.pdf(x, 0.5, 1014, 0, 0.63), 'g-', lw=3, alpha=0.7, label='old prior')\n",
    "plt.legend()\n",
    "plt.loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = truncpareto.rvs(alpha, trunc, loc, scale, size=1500)\n",
    "sorted(samples, reverse=True)[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = instantiate(cfg.prior)\n",
    "prior.sample().on_fluxes[0, :, :, :, 2].view(-1).topk(10)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate rate with oob data\n",
    "(hst_oob_mag < 24).sum() / (4 * 1e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess the two-point correlation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, compose\n",
    "from bliss.main import train\n",
    "\n",
    "with initialize(config_path=\"../../case_studies/dependent_tiling/\", version_base=None):\n",
    "    cfg5 = compose(\"m2_config\", {\n",
    "        \"train.trainer.logger=null\",\n",
    "        \"train.trainer.max_epochs=0\",\n",
    "        \"train.pretrained_weights=/home/regier/bliss/output/m2_80offset/version_0/checkpoints/best_encoder.ckpt\",\n",
    "        \"cached_simulator.cached_data_path=/data/scratch/regier/toy_m2\",\n",
    "        \"+train.trainer.num_sanity_val_steps=0\",\n",
    "        \"cached_simulator.splits=0:10/10:20/0:100\",\n",
    "#        \"encoder.double_detect=false\",\n",
    "    })\n",
    "\n",
    "cfg5.train.encoder.metrics.metrics = [{'_target_': 'case_studies.dependent_tiling.two_point_metric.TwoPointMetric'}]\n",
    "train(cfg5.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "cfg6 = deepcopy(cfg5)\n",
    "cfg6.train.encoder.use_checkerboard = False\n",
    "train(cfg6.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-synthetic M2 inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\"../../case_studies/dependent_tiling/\", version_base=None):\n",
    "    cfg = compose(\"m2_config\", {\n",
    "        \"encoder.tiles_to_crop=3\",\n",
    "        \"predict.weight_save_path=/home/regier/bliss/output/m2_80offset/version_0/checkpoints/best_encoder.ckpt\",\n",
    " #       \"encoder.double_detect=false\"\n",
    "        })\n",
    "\n",
    "d2 = deepcopy(true_cat_all.to_dict())\n",
    "d2[\"plocs\"] += 6\n",
    "true_cat_pad = FullCatalog(112, 112, d2)\n",
    "\n",
    "truth_images, _, _, _ = simulator.image_decoder.render_images(\n",
    "    true_cat_pad.to_tile_catalog(2, 11), [(2583, 2, 136)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "\n",
    "true_recon_all = truth_images[0] + dataset[0][\"background\"]\n",
    "true_recon_all = Normal(true_recon_all, true_recon_all.sqrt()).sample()\n",
    "plt.imshow(true_recon_all[2])\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = instantiate(cfg.encoder)\n",
    "enc_state_dict = torch.load(\"/home/regier/bliss/output/m2_80offset/version_0/checkpoints/best_encoder.ckpt\")\n",
    "enc_state_dict = enc_state_dict[\"state_dict\"]\n",
    "encoder.load_state_dict(enc_state_dict)\n",
    "encoder.eval()\n",
    "\n",
    "batch = {\n",
    "    \"images\": true_recon_all.unsqueeze(0),\n",
    "    \"background\": torch.from_numpy(dataset[0][\"background\"]).unsqueeze(0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mode_cat, sample_cat = encoder.predict_step(batch, 0).values()\n",
    "\n",
    "mode_cat = mode_cat.to_full_catalog()\n",
    "matching = matcher.match_catalogs(true_cat_all, mode_cat)\n",
    "metric = metrics(true_cat_all, mode_cat, matching)\n",
    "metric[\"detection_recall\"], metric[\"detection_precision\"], metric[\"detection_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_images, _, _, _ = simulator.image_decoder.render_images(\n",
    "    mode_cat.to_tile_catalog(2, 2), [(2583, 2, 136)]\n",
    ")\n",
    "plt.imshow(mode_images[0, 2])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.use_checkerboard = False\n",
    "\n",
    "with torch.no_grad():\n",
    "    mode_cat, sample_cat = encoder.predict_step(batch, 0).values()\n",
    "\n",
    "mode_cat = mode_cat.to_full_catalog()\n",
    "matching = matcher.match_catalogs(true_cat_all, mode_cat)\n",
    "metric = metrics(true_cat_all, mode_cat, matching)\n",
    "metric[\"detection_recall\"], metric[\"detection_precision\"], metric[\"detection_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### filtered true catalog\n",
    "\n",
    "true_tile_cat_pad = true_cat_pad.to_tile_catalog(2, 11)\n",
    "true_tile_cat_pad = true_tile_cat_pad.filter_tile_catalog_by_flux(0.63)\n",
    "true_tile_cat_pad = true_tile_cat_pad.get_brightest_sources_per_tile(band=2, top_k=2, exclude_num=0)\n",
    "\n",
    "truth_images, _, _, _ = simulator.image_decoder.render_images(\n",
    "    true_tile_cat_pad, [(2583, 2, 136)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal\n",
    "\n",
    "true_recon_all = truth_images[0] + dataset[0][\"background\"]\n",
    "true_recon_all = Normal(true_recon_all, true_recon_all.sqrt()).sample()\n",
    "plt.imshow(true_recon_all[2])\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = {\n",
    "    \"images\": true_recon_all.unsqueeze(0),\n",
    "    \"background\": torch.from_numpy(dataset[0][\"background\"]).unsqueeze(0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.use_checkerboard = True\n",
    "\n",
    "with torch.no_grad():\n",
    "    mode_cat, sample_cat = encoder.predict_step(batch, 0).values()\n",
    "\n",
    "# target_cat = true_tile_cat_pad.symmetric_crop(3).to_full_catalog()\n",
    "\n",
    "mode_cat = mode_cat.to_full_catalog()\n",
    "matching = matcher.match_catalogs(true_cat_all, mode_cat)\n",
    "metric = metrics(true_cat_all, mode_cat, matching)\n",
    "metric[\"detection_recall\"], metric[\"detection_precision\"], metric[\"detection_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.use_checkerboard = False\n",
    "\n",
    "with torch.no_grad():\n",
    "    mode_cat, sample_cat = encoder.predict_step(batch, 0).values()\n",
    "\n",
    "mode_cat = mode_cat.to_full_catalog()\n",
    "matching = matcher.match_catalogs(true_cat_all, mode_cat)\n",
    "metric = metrics(true_cat_all, mode_cat, matching)\n",
    "metric[\"detection_recall\"], metric[\"detection_precision\"], metric[\"detection_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
