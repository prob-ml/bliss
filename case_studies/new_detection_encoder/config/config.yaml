defaults:
    - _self_
    - training:
    - override hydra/job_logging: stdout

# completely disable hydra logging
# https://github.com/facebookresearch/hydra/issues/910
hydra:
    output_subdir: null
    run:
        dir: .

mode: train

paths:
    root: ${oc.env:BLISS_HOME}
    sdss: ${paths.root}/data/sdss
    data: ${paths.root}/data
    project: ${paths.root}/case_studies/new_detection_encoder
    output: ${paths.project}/output

datasets:
    simulated:
        _target_: bliss.datasets.simulated.SimulatedDataset
        prior: ${models.prior}
        decoder:
            _target_: bliss.models.decoder.ImageDecoder
            n_bands: ${models.decoder.n_bands}
            tile_slen: ${models.decoder.tile_slen}
            ptile_slen: ${models.decoder.ptile_slen}
            border_padding: ${models.decoder.border_padding}
            psf_slen: ${models.decoder.psf_slen}
            sdss_bands:
                - 2
            psf_params_file: ${models.decoder.psf_params_file}
            galaxy_model:
        background:
            _target_: bliss.datasets.simulated.SimulatedSDSSBackground
            sdss_dir: ${paths.sdss}
            run: 94
            camcol: 1
            field: 12
            bands:
                - 2
        n_tiles_h: 8
        n_tiles_w: 8
        n_batches: 128
        batch_size: 64
        valid_n_batches: 5
        generate_device: "cpu"
        num_workers: 5
        fix_validation_set: true

# this architecture is based on yolov5l.yaml, see
# https://github.com/ultralytics/yolov5/blob/master/models/yolov5l.yaml
like_yolov5l:
    nc: 3  # number of classes (a hack to get the right output size)
    depth_multiple: 1.0  # model depth multiple
    width_multiple: 1.0  # layer channel multiple
    anchors:
        - [4, 4]  # P3/8

    backbone: [
        # [from, number, module, args]
        [-1, 1, Conv, [64, 5, 1]],
        [-1, 3, Conv, [64, 1, 1]],
        [-1, 1, Conv, [128, 3, 2]],
        [-1, 1, Conv, [128, 3, 1]],
        [-1, 1, Conv, [256, 3, 2]],
        [-1, 6, C3, [256]],
        [-1, 1, Conv, [512, 3, 2]],
        [-1, 9, C3, [512]],
        [-1, 1, Conv, [1024, 3, 2]],
        [-1, 3, C3, [1024]],
        [-1, 1, SPPF, [1024, 5]],
    ]

    head: [
        [-1, 1, Conv, [512, 1, 1]],
        [-1, 1, nn.Upsample, [None, 2, 'nearest']],
        [[-1, 6], 1, Concat, [1]],
        [-1, 3, C3, [512, false]],

        [-1, 1, Conv, [256, 1, 1]],
        [-1, 1, nn.Upsample, [None, 2, 'nearest']],
        [[-1, 4, 5], 1, Concat, [1]],
        [-1, 3, C3, [256, false]],

        [[17], 1, Detect, [nc, anchors]],
    ]

models:
    decoder:
        _target_: bliss.models.decoder.ImageDecoder
        n_bands: 1
        tile_slen: 4
        ptile_slen: 52
        border_padding: 24  # is this redundant, given tile_slen and ptile_slen??
        psf_slen: 25
        sdss_bands:
            - 2
        psf_params_file: ${paths.data}/sdss/94/1/12/psField-000094-1-0012.fits

    detection_encoder:
        _target_: case_studies.new_detection_encoder.main.NewDetectionEncoder
        #  _target_: bliss.models.detection_encoder.DetectionEncoder
        input_transform:
            _target_: bliss.models.detection_encoder.ConcatBackgroundTransform
        n_bands: ${models.decoder.n_bands}
        tile_slen: ${models.decoder.tile_slen}
        ptile_slen: 52
        max_detections: ${models.prior.max_sources}
        channel: 8
        spatial_dropout: 0.0
        dropout: 0.0
        hidden: 128
        annotate_probs: true
        slack: 1.

        optimizer_params:
            lr: 1e-3
        scheduler_params:
            milestones: [32]
            gamma: 0.1
        architecture: ${like_yolov5l}
    prior:
        _target_: bliss.models.prior.ImagePrior
        n_bands: 1
        max_sources: 1
        mean_sources: 0.6931471805599453  # 50% no source, 50% one source
        min_sources: 0
        f_min: 1e3
        f_max: 1e4
        alpha: 0.43
        prob_galaxy: 0.0

training:
    experiment: default
    version: null
    save_top_k: 1
    trainer:
        _target_: pytorch_lightning.Trainer
        logger: true
        enable_checkpointing: false
        profiler: null
        reload_dataloaders_every_n_epochs: 0
        max_epochs: ${training.n_epochs}
        min_epochs: ${training.n_epochs}
        accelerator: "gpu"
        devices: 1
        limit_train_batches: 1.0
        limit_val_batches: 5
        check_val_every_n_epoch: 1
        log_every_n_steps: 32  # correspond to n_batches
    testing:
        file: null
        batch_size: 32
        num_workers: 0
    weight_save_path: ${paths.project}/models/${training.name}.pt
    seed: null
    name: "sdss_detection_encoder"
    model: ${models.detection_encoder}
    dataset: ${datasets.simulated}
    n_epochs: 1000
