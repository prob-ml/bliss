{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules to reload:\n",
      "all-except-skipped\n",
      "\n",
      "Modules to skip:\n",
      "\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "from typing import Union, Dict, Optional\n",
    "from torch import Tensor, nn\n",
    "from torch.distributions import Categorical, Normal\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from bliss.catalog import TileCatalog, get_images_in_tiles, get_is_on_from_n_sources\n",
    "from bliss.reporting import DetectionMetrics\n",
    "from case_studies.psf_homogenization.psf_decoder import PsfSampler, GalsimBlendswithPSF\n",
    "from bliss.models.detection_encoder import (\n",
    "    DetectionEncoder,\n",
    "    LogBackgroundTransform,\n",
    "    ConcatBackgroundTransform,\n",
    "    EncoderCNN,\n",
    "    make_enc_final,\n",
    ")\n",
    "\n",
    "\n",
    "# check GPU is configured correctly\n",
    "device = torch.device('cuda:0')\n",
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "from hydra import compose, initialize\n",
    "from hydra.utils import instantiate\n",
    "from bliss.encoder import Encoder\n",
    "\n",
    "with initialize(config_path=\"../config\"):\n",
    "    cfg = compose(\"config\", overrides=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up test data\n",
    "prior = instantiate(cfg.datasets.galsim_blended_galaxies_psf.prior) \n",
    "decoder = instantiate(cfg.datasets.galsim_blended_galaxies_psf.decoder)\n",
    "background = instantiate(cfg.datasets.galsim_blended_galaxies.background)\n",
    "tile_slen = 4\n",
    "max_tile_n_sources = 1\n",
    "num_workers = 5\n",
    "batch_size = 10000\n",
    "n_batches = 1\n",
    "psf_sampler = PsfSampler(0.8, 0.8)\n",
    "\n",
    "ds_psf = GalsimBlendswithPSF(prior, decoder, background, tile_slen, max_tile_n_sources, num_workers=0, batch_size=1000, n_batches=1, psf_sampler=psf_sampler, std_psf_fwhm=1.0, valid_n_batches=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_step(self, batch, image_str):\n",
    "    catalog_dict = {\n",
    "        \"locs\": batch[\"locs\"][:, :, :, 0 : self.max_detections],\n",
    "        \"log_fluxes\": batch[\"log_fluxes\"][:, :, :, 0 : self.max_detections],\n",
    "        \"galaxy_bools\": batch[\"galaxy_bools\"][:, :, :, 0 : self.max_detections],\n",
    "        \"n_sources\": batch[\"n_sources\"].clamp(max=self.max_detections),\n",
    "    }\n",
    "    true_tile_catalog = TileCatalog(self.tile_slen, catalog_dict)\n",
    "    true_full_catalog = true_tile_catalog.to_full_params()\n",
    "    image_ptiles = get_images_in_tiles(\n",
    "        torch.cat((batch[image_str], batch[\"background\"]), dim=1),\n",
    "        self.tile_slen,\n",
    "        self.ptile_slen,\n",
    "    )\n",
    "    image_ptiles = rearrange(image_ptiles, \"n nth ntw b h w -> (n nth ntw) b h w\")\n",
    "    dist_params = self.encode(image_ptiles)\n",
    "    est_catalog_dict = self.variational_mode(dist_params)\n",
    "    est_tile_catalog = TileCatalog.from_flat_dict(\n",
    "        true_tile_catalog.tile_slen,\n",
    "        true_tile_catalog.n_tiles_h,\n",
    "        true_tile_catalog.n_tiles_w,\n",
    "        est_catalog_dict,\n",
    "    )\n",
    "    est_full_catalog = est_tile_catalog.to_full_params()\n",
    "\n",
    "    metrics = self.val_detection_metrics(true_full_catalog, est_full_catalog)\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "PATH = \"/home/wangchv/bliss/case_studies/psf_homogenization/output/sdss_detection_encoder_full_decoder_homo/std=1.0/checkpoints/epoch=989-val_loss=-0.015.ckpt\"\n",
    "detection_encoder_homo = instantiate(cfg.models.detection_encoder).eval()\n",
    "model_checkpoint = torch.load(PATH, map_location=DEVICE)\n",
    "model_state_dict = model_checkpoint[\"state_dict\"]\n",
    "detection_encoder_homo.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "PATH = \"/home/wangchv/bliss/case_studies/psf_homogenization/output/sdss_detection_encoder_full_decoder_unhomo/1.0~1.0/checkpoints/epoch=829-val_loss=-0.006.ckpt\"\n",
    "detection_encoder_unhomo = instantiate(cfg.models.detection_encoder).eval()\n",
    "model_checkpoint = torch.load(PATH, map_location=DEVICE)\n",
    "model_state_dict = model_checkpoint[\"state_dict\"]\n",
    "detection_encoder_unhomo.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': tensor(2387), 'fp': tensor(166), 'precision': tensor(0.9350), 'recall': tensor(0.6921), 'f1': tensor(0.7954), 'avg_distance': tensor(0.4657, grad_fn=<DivBackward0>), 'n_galaxies_detected': tensor(2387)}\n",
      "{'tp': tensor(2315), 'fp': tensor(160), 'precision': tensor(0.9354), 'recall': tensor(0.6724), 'f1': tensor(0.7824), 'avg_distance': tensor(0.5780, grad_fn=<DivBackward0>), 'n_galaxies_detected': tensor(2315)}\n"
     ]
    }
   ],
   "source": [
    "for x in ds_psf.val_dataloader():\n",
    "    print(validation_step(detection_encoder_homo, x, \"images\"))\n",
    "    print(validation_step(detection_encoder_unhomo, x, \"noisy_image\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from case_studies.psf_homogenization.galsim_blends_sg import GalsimBlendsSGwithPSF\n",
    "prior = instantiate(cfg.datasets.galsim_blended_std_psf.prior) \n",
    "decoder = instantiate(cfg.datasets.galsim_blended_std_psf.decoder)\n",
    "background = instantiate(cfg.datasets.galsim_blended_std_psf.background)\n",
    "tile_slen = 4\n",
    "max_tile_n_sources = 1\n",
    "num_workers = 5\n",
    "batch_size = 10000\n",
    "n_batches = 1\n",
    "psf_sampler = PsfSampler(1.0, 1.0)\n",
    "\n",
    "ds_psf = GalsimBlendsSGwithPSF(prior, decoder, background, tile_slen, max_tile_n_sources, num_workers=0, batch_size=1000, n_batches=1, psf_sampler=psf_sampler, std_psf_fwhm=1.0, valid_n_batches=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "PATH = \"/home/wangchv/bliss/case_studies/psf_homogenization/output/sdss_detection_encoder_full_decoder_SG_std/version_0/checkpoints/epoch=859-val_loss=0.028.ckpt\"\n",
    "detection_encoder_homo = instantiate(cfg.models.detection_encoder).eval()\n",
    "model_checkpoint = torch.load(PATH, map_location=DEVICE)\n",
    "model_state_dict = model_checkpoint[\"state_dict\"]\n",
    "detection_encoder_homo.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "PATH = \"/home/wangchv/bliss/case_studies/psf_homogenization/output/sdss_detection_encoder_full_decoder_SG_rand/version_0/checkpoints/epoch=999-val_loss=0.029.ckpt\"\n",
    "detection_encoder_unhomo = instantiate(cfg.models.detection_encoder).eval()\n",
    "model_checkpoint = torch.load(PATH, map_location=DEVICE)\n",
    "model_state_dict = model_checkpoint[\"state_dict\"]\n",
    "detection_encoder_unhomo.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tp': tensor(245), 'fp': tensor(17), 'precision': tensor(0.9351), 'recall': tensor(0.9919), 'f1': tensor(0.9627), 'avg_distance': tensor(0.0994, grad_fn=<DivBackward0>), 'n_galaxies_detected': tensor(159)}\n",
      "{'tp': tensor(247), 'fp': tensor(16), 'precision': tensor(0.9392), 'recall': tensor(0.9960), 'f1': tensor(0.9667), 'avg_distance': tensor(0.1035, grad_fn=<DivBackward0>), 'n_galaxies_detected': tensor(161)}\n"
     ]
    }
   ],
   "source": [
    "for x in ds_psf.val_dataloader():\n",
    "    print(validation_step(detection_encoder_homo, x, \"images\"))\n",
    "    print(validation_step(detection_encoder_unhomo, x, \"noisy_image\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('bliss-RsWe_rnr-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3309a6ecd3377f6a1529af62e353e3043fd63bfc216a9859761222bf0aaf8da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
