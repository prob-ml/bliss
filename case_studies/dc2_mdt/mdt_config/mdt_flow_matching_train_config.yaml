---
defaults:
    - ../../../bliss/conf@_here_: base_config
    - _self_
    - override hydra/job_logging: stdout

mode: train

dc2_min_flux: 0.0
dc2_min_log_flux: 0.0
# dc2_max_log_flux: 23.43
dc2_max_log_flux: 10.0
# dc2_max_flux: inf
dc2_max_flux: 22025.0

surveys:
  dc2:
    batch_size: 64

my_diffusion_factors:
  - _target_: case_studies.dc2_mdt.utils.catalog_parser.OneBitFactor
    n_params: 1
    name: n_sources
    bit_value: 1.0
    threshold: 0.0
    sample_rearrange: b ht wt 1 -> b ht wt
    loss_gating: null
  - _target_: case_studies.dc2_mdt.utils.catalog_parser.NormalizedFactor
    n_params: 2
    name: locs
    data_min: 0.0
    data_max: 1.0
    scale: 1.0
    latent_zero_point: -1.0
    sample_rearrange: b ht wt d -> b ht wt 1 d
    loss_gating:
      _target_: case_studies.dc2_mdt.utils.catalog_parser.SourcesGating
  - _target_: case_studies.dc2_mdt.utils.catalog_parser.LogNormalizedFactor
    n_params: 6
    name: fluxes
    data_min: ${dc2_min_flux}
    log_data_min: ${dc2_min_log_flux}
    log_data_max: ${dc2_max_log_flux}
    scale: 1.0
    latent_zero_point: -1.0
    sample_rearrange: b ht wt d -> b ht wt 1 d
    loss_gating:
      _target_: case_studies.dc2_mdt.utils.catalog_parser.SourcesGating

my_metrics:
  detection_performance:
    _target_: case_studies.dc2_mdt.utils.metrics.DetectionPerformance
  flux_error:
    _target_: bliss.encoder.metrics.FluxError
    survey_bands: ${encoder.survey_bands}
    base_flux_bin_cutoffs: [200, 400, 600, 800, 1000]
    mag_zero_point: 3631e9  # for DC2
    report_bin_unit: mag

my_image_normalizers:
  asinh:
    _target_: bliss.encoder.image_normalizer.AsinhQuantileNormalizer
    q: [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99, 0.999, 0.9999, 0.99999]

encoder:
    _target_: case_studies.dc2_mdt.utils.flow_matching_encoder.DC2FMEncoder
    survey_bands: [u, g, r, i, z, y]
    reference_band: 2
    d_flow_matching_type: vanilla
    acc_grad_batches: 1
    max_fluxes: ${dc2_max_flux}
    optimizer_params:
        lr: 3e-4
        amsgrad: true  # to make adam more stable
    scheduler_params:
        milestones: [350, 390]
        gamma: 0.1
    image_normalizers: ${my_image_normalizers}
    catalog_parser:
        _target_: case_studies.dc2_mdt.utils.catalog_parser.CatalogParser
        factors: ${my_diffusion_factors}
    image_size: [80, 80]
    matcher:
        _target_: bliss.encoder.metrics.CatalogMatcher
        dist_slack: 1.0
        mag_slack: null
        mag_band: 2  # SDSS r-band
    mode_metrics:
        _target_: torchmetrics.MetricCollection
        _convert_: partial
        compute_groups: false
        metrics: ${my_metrics}

train:
    trainer:
        logger:
            name: DC2_mdt_flow_matching_exp
            version: null  # change it before running the code
        devices: null  # change it before running the code
        use_distributed_sampler: false  # disable this because we use the self-defined distributed sampler
        precision: 32-true
        max_epochs: 400
        # detect_anomaly: false
        # gradient_clip_val: 0.0
    data_source: ${surveys.dc2}
    pretrained_weights: null
    seed: 7272
    callbacks:
        early_stopping:
            _target_: pytorch_lightning.callbacks.early_stopping.EarlyStopping
            monitor: val/_loss
            mode: min
            patience: 400
        schedule_checkpointing:
            _target_: pytorch_lightning.callbacks.ModelCheckpoint
            filename: "schedule_saved_encoder_{epoch:03d}"
            save_top_k: -1
            every_n_epochs: 50
            verbose: true
            save_on_train_epoch_end: true
            auto_insert_metric_name: false