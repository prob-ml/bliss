{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3578c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from hydra.utils import instantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33c107e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "from pathlib import Path\n",
    "from hydra import initialize, compose\n",
    "from bliss.main import predict\n",
    "\n",
    "environ[\"BLISS_HOME\"] = str(\"/home/declan/current/bliss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d390d81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/declan/current/bliss'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"BLISS_HOME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e9e36fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yolandz/bliss/case_studies/redshift_estimation'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "449342fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path=\".\", version_base=None):\n",
    "    cfg = compose(\"redshift\", {\n",
    "        \"predict.weight_save_path=/home/declan/current/bliss/redshift_output/version_4/checkpoints/best_encoder.ckpt\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0ca8c",
   "metadata": {},
   "source": [
    "We'd really like to call the `predict` function from `bliss.main` here. Still working on getting that going. In the meantime, we can \"initialize\" an encoder using the config `redshift.yaml` and load the weights manually like so. The cell below will take a while as I still have it loading all of the data, which probably overkill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d6cdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(cfg.train.seed)\n",
    "\n",
    "# setup dataset and encoder\n",
    "# taken from train in main.py\n",
    "dataset = instantiate(cfg.train.data_source)\n",
    "encoder = instantiate(cfg.train.encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c518fbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bliss.simulator.simulated_dataset.CachedSimulatedDataset"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e81013e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bliss.encoder.encoder.Encoder"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6248e808",
   "metadata": {},
   "source": [
    "We'll access the test Dataloader that CachedSimulatedDataset can construct for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be126110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader = dataset.test_dataloader()\n",
    "type(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e37761",
   "metadata": {},
   "source": [
    "Let's access some observations from the test dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c76e0cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5534a7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['images', 'background', 'deconvolution', 'psf_params', 'tile_catalog'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eadca65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5, 80, 80])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation['images'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec4326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['locs', 'n_sources', 'source_type', 'galaxy_fluxes', 'galaxy_params', 'star_fluxes', 'redshifts'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation['tile_catalog'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161e25e",
   "metadata": {},
   "source": [
    "Let's use the untrained encoder for prediction (it should perform very badly). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5d44a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_cat = encoder.sample(observation, use_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75206f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['locs', 'n_sources', 'star_fluxes', 'source_type', 'galaxy_params', 'galaxy_fluxes', 'redshifts'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_cat = est_cat.to_dict()\n",
    "est_cat.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5db8cc",
   "metadata": {},
   "source": [
    "When `observation` is passed to `encoder`, the encoder ignores the ground truth `observation['tile_catalog']` to make the prediction obviously. But now we can compare the prediction to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3d20670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0200, -0.0500, -0.0300, -0.0900,  0.0300,  0.1700, -0.3000,  0.2500,\n",
       "          0.0400, -0.0200,  0.0800,  0.0000,  0.0400, -0.1400, -0.1800, -0.0900,\n",
       "          0.0100, -0.1600],\n",
       "        [-0.0300, -0.0200,  0.0500,  0.0100, -0.0600,  0.0300, -0.1800, -1.0200,\n",
       "          0.4100,  0.1600, -0.0100,  0.1900,  0.1600,  0.2200, -0.0300, -0.4300,\n",
       "          0.2100,  0.2200],\n",
       "        [-0.0300, -0.0500, -0.0800, -0.0200, -0.0500,  0.2100, -0.1500,  0.0200,\n",
       "          0.1400,  0.3500,  0.0900,  0.4000,  0.1000,  0.0700,  0.1900,  0.1200,\n",
       "          0.1900, -0.1800],\n",
       "        [-0.0300, -0.0300,  0.0300,  0.2100,  0.6000, -1.5300, -0.1200,  0.2800,\n",
       "         -0.5500, -0.3900, -0.0900, -0.0000,  0.1200,  0.1100, -0.1700,  0.1700,\n",
       "         -0.0400,  0.0400],\n",
       "        [-0.0200, -0.0200,  0.0500, -0.0700,  0.0900, -0.4200, -0.2400, -0.4900,\n",
       "         -0.5500,  0.0300, -0.1300, -0.1500, -0.4700, -0.3700,  0.1900,  0.0300,\n",
       "         -0.1400,  0.1300],\n",
       "        [-0.0000, -0.0200, -0.1100, -0.0200, -0.1400,  0.0300,  0.2700,  0.1600,\n",
       "         -0.5400, -0.2600, -0.1900, -0.1400, -0.1900, -0.0200,  0.2300, -0.1000,\n",
       "         -0.2500,  0.2500],\n",
       "        [-0.0600,  0.0100, -0.0500,  0.1100,  0.1000, -0.0900, -0.0600, -0.0700,\n",
       "         -0.1400, -0.1800, -0.2000, -0.1300, -0.0800,  0.2100,  0.2000,  0.0900,\n",
       "          0.3200,  0.1500],\n",
       "        [-0.0900, -0.0400, -0.1000,  0.0300,  0.0500,  0.0400,  0.2600,  0.1600,\n",
       "          0.0100,  0.1000,  0.0200,  0.0700, -0.0200,  0.0900, -0.1900,  0.1000,\n",
       "         -0.0300,  0.0100],\n",
       "        [ 0.0600, -0.0500,  0.1000,  0.1700,  0.2200,  0.0500,  0.1400,  0.2300,\n",
       "          0.1800,  0.1100,  0.0300,  0.1100,  0.0100, -0.0900,  0.2900,  0.5100,\n",
       "         -0.9700, -1.7700],\n",
       "        [ 0.3300,  0.0200, -0.5800, -0.6800,  0.5900,  0.0400, -0.2000,  0.0200,\n",
       "          0.1500,  0.1900,  0.0800, -0.0400,  0.0200, -0.1400, -0.0700, -0.8300,\n",
       "         -0.2900,  0.1500],\n",
       "        [-1.2300, -1.2000, -1.5100, -0.7400,  1.2100,  0.5400,  0.0700, -0.0500,\n",
       "         -0.1900,  0.0900,  0.2000, -0.0000, -0.1000, -0.3100,  0.1300,  0.0700,\n",
       "         -1.8300,  1.5800],\n",
       "        [-1.8400,  1.6000, -1.9500, -1.9600,  1.4200,  0.8600, -0.0700,  0.1800,\n",
       "          0.1100,  0.0200,  0.0700,  0.1400,  0.0100, -0.2100, -0.1000, -0.4500,\n",
       "         -0.2400,  0.2800],\n",
       "        [ 0.2600, -0.9600, -0.6300,  1.2100, -1.0600,  0.3700, -0.0700,  0.0800,\n",
       "         -0.6100,  0.2100,  0.2500,  0.0200, -0.0400,  0.3500, -0.4800, -0.7400,\n",
       "          0.2700, -0.1400],\n",
       "        [ 0.3000, -0.9700,  1.4500, -6.7300, -1.4900,  1.7200,  0.4700, -0.5400,\n",
       "          0.5700,  0.2500, -0.0300, -0.0200, -0.3000, -0.2000, -0.4300, -0.7900,\n",
       "          0.4700,  0.1200],\n",
       "        [ 2.4400, -0.3900, -1.7800, -3.4900, -1.5600, -1.0000, -1.0300,  0.0600,\n",
       "         -0.0400,  0.2400,  0.0500,  0.0300,  0.1500, -0.0700, -0.5500, -1.1000,\n",
       "         -0.4700, -0.5000],\n",
       "        [ 0.3300,  1.0000,  1.0500, -0.3500, -0.7600,  1.0300, -0.8200,  0.2300,\n",
       "         -0.1100,  0.5000,  0.1400, -0.0600, -0.0500,  0.0400, -0.0500, -0.3100,\n",
       "          0.6500, -0.0500],\n",
       "        [-0.5800, -0.7400,  0.1200, -1.9400, -3.4400, -0.3100,  0.0300, -0.3200,\n",
       "         -0.2000,  0.2900, -0.0600,  0.0500,  0.0500,  0.1400,  0.0200,  0.3100,\n",
       "         -0.2300, -0.0100],\n",
       "        [ 0.4300, -0.1100,  0.5700,  0.1200, -0.4100,  0.7800,  0.1100,  0.0500,\n",
       "          0.4500,  0.1300,  0.0300,  0.0100, -0.0400, -0.1400, -0.0300, -0.0100,\n",
       "         -0.1200, -0.0400]], grad_fn=<RoundBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_cat['redshifts'].shape # 32 x 18 x 18 x1\n",
    "torch.round(est_cat['redshifts'][0].reshape(18,18), decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4e84a4",
   "metadata": {},
   "source": [
    "So it does terribly as expected. But we can load the weights and it should perform much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4d481d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/home/declan/current/bliss/redshift_output/version_4/checkpoints/best_encoder.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m PATH \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/declan/current/bliss/redshift_output/version_4/checkpoints/best_encoder.ckpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(PATH)\n\u001b[1;32m      3\u001b[0m encoder\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/bliss-toolkit-CJUeDhKp-py3.10/lib/python3.10/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/bliss-toolkit-CJUeDhKp-py3.10/lib/python3.10/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    272\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/bliss-toolkit-CJUeDhKp-py3.10/lib/python3.10/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/home/declan/current/bliss/redshift_output/version_4/checkpoints/best_encoder.ckpt'"
     ]
    }
   ],
   "source": [
    "PATH = \"/home/declan/current/bliss/redshift_output/version_4/checkpoints/best_encoder.ckpt\"\n",
    "checkpoint = torch.load(PATH)\n",
    "encoder.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd208e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9982, 0.9962, 0.9970, 0.9988, 0.9977, 0.9975, 0.9971, 0.9983, 0.9974,\n",
       "         0.9973, 0.9973, 0.9974, 0.9984, 0.9986, 0.9977, 0.9977, 0.9970, 0.9980],\n",
       "        [0.9979, 0.9983, 0.9976, 0.9972, 0.9979, 0.9978, 0.9978, 0.9989, 0.9975,\n",
       "         0.9980, 0.9979, 0.9969, 0.9979, 0.9986, 0.9974, 0.9984, 0.9970, 0.9981],\n",
       "        [0.9979, 0.9978, 0.9983, 0.9990, 0.9984, 0.9973, 0.9957, 0.9974, 0.9980,\n",
       "         0.9982, 0.9978, 0.9969, 0.9972, 0.9970, 0.9978, 0.9979, 0.9971, 0.9978],\n",
       "        [0.9989, 0.9989, 0.9980, 0.9976, 0.9974, 0.9964, 0.9979, 0.9972, 0.9977,\n",
       "         0.9989, 0.9977, 0.9978, 0.9993, 0.9972, 0.9973, 0.9965, 0.9977, 0.9979],\n",
       "        [0.9985, 0.9983, 0.9980, 0.9985, 0.9977, 0.9982, 0.9981, 0.9974, 0.9977,\n",
       "         0.9983, 0.9983, 0.9978, 0.9972, 0.9980, 0.9989, 0.9967, 0.9975, 0.9988],\n",
       "        [0.9972, 0.9976, 0.9976, 0.9987, 0.9972, 0.9974, 0.9970, 0.9974, 0.9981,\n",
       "         0.9997, 0.9981, 0.9978, 0.9972, 0.9978, 0.9985, 0.9972, 0.9974, 0.9972],\n",
       "        [0.9973, 0.9978, 0.9976, 0.9968, 0.9966, 0.9964, 0.9993, 0.9981, 0.9982,\n",
       "         0.9979, 0.9984, 0.9978, 0.9973, 0.9973, 0.9972, 1.0003, 0.9970, 0.9987],\n",
       "        [0.9964, 0.9973, 0.9974, 0.9982, 0.9973, 0.9981, 0.9982, 0.9994, 0.9977,\n",
       "         0.9983, 0.9978, 0.9980, 0.9981, 0.9985, 0.9991, 0.9984, 0.9995, 0.9987],\n",
       "        [0.9964, 0.9981, 0.9972, 0.9973, 0.9968, 0.9979, 0.9975, 0.9961, 0.9971,\n",
       "         0.9983, 0.9975, 0.9973, 0.9983, 0.9990, 0.9978, 0.9986, 0.9984, 0.9983],\n",
       "        [0.9982, 0.9990, 0.9974, 0.9999, 0.9982, 0.9990, 0.9987, 0.9986, 0.9994,\n",
       "         0.9988, 0.9980, 0.9984, 1.0002, 1.0003, 0.9991, 0.9988, 0.9982, 0.9965],\n",
       "        [0.9983, 0.9980, 0.9981, 0.9982, 0.9986, 0.9982, 0.9981, 0.9983, 1.0002,\n",
       "         0.9996, 0.9987, 0.9992, 0.9999, 0.9997, 0.9998, 0.9979, 0.9997, 0.9986],\n",
       "        [1.0001, 0.9981, 0.9975, 0.9992, 0.9992, 0.9986, 0.9997, 0.9989, 0.9999,\n",
       "         0.9990, 0.9991, 0.9998, 0.9987, 0.9985, 0.9991, 0.9986, 0.9981, 0.9988],\n",
       "        [0.9977, 0.9986, 0.9986, 1.0004, 0.9982, 0.9980, 0.9995, 0.9991, 1.0005,\n",
       "         1.0010, 0.9991, 0.9986, 0.9990, 0.9986, 0.9982, 0.9987, 0.9988, 0.9990],\n",
       "        [0.9992, 0.9958, 0.9978, 0.9975, 0.9984, 0.9997, 0.9986, 0.9986, 0.9989,\n",
       "         0.9984, 0.9987, 0.9982, 0.9980, 0.9977, 0.9989, 0.9981, 0.9991, 0.9988],\n",
       "        [0.9989, 0.9982, 0.9983, 0.9985, 0.9984, 0.9989, 0.9989, 0.9989, 0.9989,\n",
       "         0.9988, 0.9983, 0.9988, 0.9980, 0.9983, 0.9985, 0.9986, 0.9986, 0.9984],\n",
       "        [0.9983, 0.9978, 0.9976, 0.9974, 0.9979, 0.9981, 0.9978, 0.9986, 0.9981,\n",
       "         0.9983, 0.9980, 0.9976, 0.9977, 0.9979, 0.9985, 0.9974, 0.9975, 0.9986],\n",
       "        [0.9987, 0.9994, 0.9975, 0.9978, 1.0003, 0.9980, 0.9976, 0.9979, 0.9980,\n",
       "         1.0004, 0.9982, 0.9979, 0.9978, 0.9981, 0.9972, 0.9974, 0.9977, 0.9986],\n",
       "        [0.9986, 0.9972, 0.9985, 1.0002, 0.9991, 0.9983, 0.9977, 0.9975, 0.9975,\n",
       "         0.9983, 0.9979, 0.9966, 0.9969, 0.9968, 0.9970, 0.9980, 0.9976, 0.9987]],\n",
       "       grad_fn=<RoundBackward1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_cat = encoder.sample(observation, use_mode=True)\n",
    "est_cat = est_cat.to_dict()\n",
    "torch.round(est_cat['redshifts'][0].reshape(18,18), decimals=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efabe286",
   "metadata": {},
   "source": [
    "Looking pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e9640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bliss-toolkit-CJUeDhKp-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "74faa6c8bf11e8d878eea2e3809df0e4ec9259726236bf969c63713d4776b734"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
