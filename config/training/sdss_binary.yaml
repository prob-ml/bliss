model: ${models.binary}
dataset: ${datasets.simulated}
optimizer:
    name: Adam
    kwargs:
        lr: 1e-4
        weight_decay: 0

n_epochs: 501
save_top_k: 5
experiment: default
version: null
trainer:
  _target_: pytorch_lightning.Trainer
  logger: True
  checkpoint_callback: True
  profiler: null
  reload_dataloaders_every_epoch: False
  max_epochs: ${training.n_epochs}
  min_epochs: ${training.n_epochs}
  gpus: ${gpus}
  limit_train_batches: 1.0
  limit_val_batches: 1.0
  check_val_every_n_epoch: 10
  log_every_n_steps: 10 # correspond to n_batches
  deterministic: False
