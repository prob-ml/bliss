{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import simulated_datasets_lib\n",
    "import sdss_dataset_lib\n",
    "import sdss_psf\n",
    "import image_utils \n",
    "\n",
    "import starnet_vae_lib\n",
    "import inv_kl_objective_lib as inv_kl_lib\n",
    "import kl_objective_lib as kl_lib\n",
    "import plotting_utils\n",
    "import wake_sleep_lib\n",
    "\n",
    "import psf_transform_lib\n",
    "import image_statistics_lib\n",
    "\n",
    "np.random.seed(34534)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_hubble_data = sdss_dataset_lib.SDSSHubbleData(x0 = 650, x1 = 120)\n",
    "\n",
    "# psf file \n",
    "psf_fit_file = str(sdss_hubble_data.psf_file)\n",
    "\n",
    "# image \n",
    "full_image = sdss_hubble_data.sdss_image.squeeze()\n",
    "full_background = sdss_hubble_data.sdss_background.squeeze()\n",
    "\n",
    "# true parameters\n",
    "which_bright = (sdss_hubble_data.fluxes > 1000.)\n",
    "true_locs = sdss_hubble_data.locs[which_bright]\n",
    "true_fluxes = sdss_hubble_data.fluxes[which_bright]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(full_image.squeeze())\n",
    "plt.colorbar()\n",
    "\n",
    "# plt.scatter(true_locs[:, 1] * 100, \n",
    "#            true_locs[:, 0] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "psf_og = sdss_psf.psf_at_points(0, 0, psf_fit_file = str(sdss_hubble_data.psf_file))\n",
    "\n",
    "psf_init = torch.Tensor(simulated_datasets_lib._expand_psf(psf_og, full_image.shape[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_encoder = starnet_vae_lib.StarEncoder(full_slen = full_image.shape[-1],\n",
    "                                           stamp_slen = 9,\n",
    "                                           step = 2,\n",
    "                                           edge_padding = 3,\n",
    "                                           n_bands = 1,\n",
    "                                           max_detections = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_encoder.load_state_dict(torch.load('../fits/starnet-10172019-no_reweighting', \n",
    "                                       map_location=lambda storage, loc: storage))\n",
    "star_encoder.eval(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_transform = psf_transform_lib.PsfLocalTransform(torch.Tensor(psf_og),\n",
    "                                    full_image.shape[-1], \n",
    "                                    kernel_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf = psf_transform.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out map estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_locs_full_image, map_fluxes_full_image, map_n_stars_full, _, _, _ = \\\n",
    "    wake_sleep_lib.sample_star_encoder(star_encoder, \n",
    "                                       full_image.unsqueeze(0).unsqueeze(0), \n",
    "                                       full_background.unsqueeze(0).unsqueeze(0),\n",
    "                                       n_samples = 1, return_map = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert this matches an earlier implementation\n",
    "map_locs_full_image_test, map_fluxes_full_image_test, map_n_stars_full_test = \\\n",
    "    star_encoder.get_results_on_full_image(full_image.unsqueeze(0).unsqueeze(0), \n",
    "                                           full_background.unsqueeze(0).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.all(map_fluxes_full_image_test == map_fluxes_full_image)\n",
    "assert torch.all(map_locs_full_image_test == map_locs_full_image)\n",
    "assert torch.all(map_n_stars_full_test == map_n_stars_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check reconstruction\n",
    "map_recon_mean, map_loss = psf_transform_lib.get_psf_loss(full_image.squeeze(), full_background.squeeze(),\n",
    "                                        map_locs_full_image,\n",
    "                                        map_fluxes_full_image,\n",
    "                                        n_stars = map_n_stars_full,\n",
    "                                        psf = psf_init,\n",
    "                                        pad = 5, grid = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_resid = map_recon_mean.squeeze().detach() - full_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "axarr[0].matshow(full_image.squeeze())\n",
    "\n",
    "axarr[1].matshow(map_recon_mean.squeeze().detach())\n",
    "\n",
    "_resid = map_resid / full_image\n",
    "vmax = _resid.abs().max()\n",
    "im2 = axarr[2].matshow(_resid, vmax = vmax, vmin = -vmax, \n",
    "                       cmap=plt.get_cmap('bwr'))\n",
    "fig.colorbar(im2, ax=axarr[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check sampling of variational parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_locs_full_image, sampled_fluxes_full_image, sampled_n_stars_full, _, _, _ = \\\n",
    "    wake_sleep_lib.sample_star_encoder(star_encoder, \n",
    "                                       full_image.unsqueeze(0).unsqueeze(0), \n",
    "                                       full_background.unsqueeze(0).unsqueeze(0),\n",
    "                                       n_samples = n_samples, return_map = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_means, loss = psf_transform_lib.get_psf_loss(full_image.squeeze(), full_background.squeeze(),\n",
    "                                        sampled_locs_full_image,\n",
    "                                        sampled_fluxes_full_image,\n",
    "                                        n_stars = sampled_n_stars_full,\n",
    "                                        psf = psf,\n",
    "                                        pad = 5, grid = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(loss.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "axarr[0].matshow(full_image.squeeze())\n",
    "\n",
    "axarr[1].matshow(map_recon_mean.squeeze().detach())\n",
    "axarr[1].set_title('map reconstruction')\n",
    "\n",
    "_resid = (map_recon_mean.squeeze().detach() - full_image.squeeze())\n",
    "vmax = _resid.abs().max()\n",
    "im2 = axarr[2].matshow(_resid, vmax = vmax, vmin = -vmax, \n",
    "                       cmap=plt.get_cmap('bwr'))\n",
    "fig.colorbar(im2, ax=axarr[2])\n",
    "axarr[2].set_title('map residual')\n",
    "\n",
    "for i in range(n_samples): \n",
    "    fig, axarr = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "    axarr[0].matshow(full_image.squeeze())\n",
    "\n",
    "    axarr[1].matshow(recon_means[i].squeeze().detach())\n",
    "    axarr[1].set_title('sample reconstruction '+ str(i))\n",
    "\n",
    "\n",
    "    _resid = recon_means[i].squeeze().detach() - full_image.squeeze()\n",
    "    vmax = _resid.abs().max()\n",
    "    im2 = axarr[2].matshow(_resid, vmax = vmax, vmin = -vmax, \n",
    "                           cmap=plt.get_cmap('bwr'))\n",
    "    fig.colorbar(im2, ax=axarr[2])\n",
    "    axarr[2].set_title('sample residual ' + str(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 40\n",
    "x1 = 40\n",
    "subimage_slen = 10\n",
    "\n",
    "fig, axarr = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "plotting_utils.plot_subimage(axarr[0], full_image.squeeze(), \n",
    "                            map_locs_full_image.squeeze(), \n",
    "                            true_locs.squeeze(), \n",
    "                            x0, x1, subimage_slen, \n",
    "                            add_colorbar = True, \n",
    "                            global_fig = fig)\n",
    "\n",
    "plotting_utils.plot_subimage(axarr[1], map_recon_mean.squeeze(), \n",
    "                            map_locs_full_image.squeeze(), \n",
    "                            None, \n",
    "                            x0, x1, subimage_slen, \n",
    "                            add_colorbar = True, \n",
    "                            global_fig = fig)\n",
    "axarr[1].set_title('map reconstruction')\n",
    "\n",
    "_resid = (map_recon_mean.squeeze().detach() - full_image.squeeze())\n",
    "plotting_utils.plot_subimage(axarr[2], _resid.squeeze(), \n",
    "                            map_locs_full_image.squeeze(), \n",
    "                            None, \n",
    "                            x0, x1, subimage_slen, \n",
    "                            add_colorbar = True, \n",
    "                            global_fig = fig, \n",
    "                            diverging_cmap = True)\n",
    "axarr[1].set_title('map residual')\n",
    "\n",
    "for i in range(n_samples): \n",
    "    fig, axarr = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "    plotting_utils.plot_subimage(axarr[0], full_image.squeeze(), \n",
    "                                sampled_locs_full_image[i].squeeze(), \n",
    "                                true_locs.squeeze(), \n",
    "                                x0, x1, subimage_slen, \n",
    "                                add_colorbar = True, \n",
    "                                global_fig = fig)\n",
    "\n",
    "    plotting_utils.plot_subimage(axarr[1], recon_means[i].squeeze().detach(), \n",
    "                                sampled_locs_full_image[i].squeeze(), \n",
    "                                None, \n",
    "                                x0, x1, subimage_slen, \n",
    "                                add_colorbar = True, \n",
    "                                global_fig = fig)\n",
    "    axarr[1].set_title('sampled reconstruction')\n",
    "\n",
    "    _resid = (recon_means[i].squeeze().detach() - full_image.squeeze())\n",
    "    plotting_utils.plot_subimage(axarr[2], _resid.squeeze(), \n",
    "                                sampled_locs_full_image[i].squeeze(), \n",
    "                                None, \n",
    "                                x0, x1, subimage_slen, \n",
    "                                add_colorbar = True, \n",
    "                                global_fig = fig, \n",
    "                                diverging_cmap = True)\n",
    "    axarr[1].set_title('sampled residual')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "axarr[0].matshow(full_image.squeeze()[40:60, 40:60])\n",
    "\n",
    "axarr[1].matshow(map_recon_mean.squeeze().detach()[40:60, 40:60])\n",
    "axarr[1].set_title('map reconstruction')\n",
    "\n",
    "_resid = (map_recon_mean.squeeze().detach() - full_image.squeeze())[40:60, 40:60]\n",
    "vmax = _resid.abs().max()\n",
    "im2 = axarr[2].matshow(_resid, vmax = vmax, vmin = -vmax, \n",
    "                       cmap=plt.get_cmap('bwr'))\n",
    "fig.colorbar(im2, ax=axarr[2])\n",
    "axarr[2].set_title('map residual')\n",
    "\n",
    "\n",
    "for i in range(n_samples): \n",
    "    fig, axarr = plt.subplots(1, 3, figsize=(15, 6))\n",
    "\n",
    "    axarr[0].matshow(full_image.squeeze()[40:60, 40:60])\n",
    "\n",
    "    axarr[1].matshow(recon_means[i].squeeze().detach()[40:60, 40:60])\n",
    "\n",
    "    _resid = (recon_means[i].squeeze().detach() - full_image.squeeze())[40:60, 40:60]\n",
    "    vmax = _resid.abs().max()\n",
    "    im2 = axarr[2].matshow(_resid, vmax = vmax, vmin = -vmax, \n",
    "                           cmap=plt.get_cmap('bwr'))\n",
    "    fig.colorbar(im2, ax=axarr[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(loss)): \n",
    "    _full_image = full_image[5:96, 5:96]\n",
    "    _recon_mean = recon_means[i].squeeze()[5:96, 5:96]\n",
    "    loss_i = inv_kl_lib.eval_normal_logprob(_full_image, _recon_mean, torch.log(_recon_mean)).sum()\n",
    "    \n",
    "    assert loss[i] == - loss_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check my _get_params_from_hidden ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we condition on a given set of n_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stamps = star_encoder.get_image_stamps(full_image.unsqueeze(0).unsqueeze(0),\n",
    "                        locs = None, fluxes = None, trim_images = False)[0]\n",
    "background_stamps = star_encoder.get_image_stamps(full_background.unsqueeze(0).unsqueeze(0),\n",
    "                    locs = None, fluxes = None, trim_images = False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = star_encoder._forward_to_last_hidden(image_stamps, background_stamps).detach()\n",
    "# get log probs\n",
    "log_probs = star_encoder._get_logprobs_from_last_hidden_layer(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample number of stars\n",
    "from kl_objective_lib import sample_class_weights\n",
    "n_stars_sampled = sample_class_weights(torch.exp(log_probs), n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_on_array = wake_sleep_lib.get_is_on_from_n_stars_2d(n_stars_sampled,\n",
    "                            star_encoder.max_detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_loc_mean, logit_loc_logvar, \\\n",
    "    log_flux_mean, log_flux_logvar = \\\n",
    "        wake_sleep_lib._get_params_from_last_hidden_layer_2dn_stars(star_encoder, h, n_stars_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_loc_mean[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK THAT THIS MATCHES MY OLD PARAMETERS\n",
    "for i in range(n_samples): \n",
    "    logit_loc_mean_i, logit_loc_logvar_i, \\\n",
    "        log_flux_mean_i, log_flux_logvar_i = \\\n",
    "            star_encoder._get_params_from_last_hidden_layer(h, n_stars_sampled[i])\n",
    "            \n",
    "    assert torch.all(logit_loc_mean_i == logit_loc_mean[i])\n",
    "    assert torch.all(logit_loc_logvar_i == logit_loc_logvar[i])\n",
    "    assert torch.all(log_flux_mean_i == log_flux_mean[i])\n",
    "    assert torch.all(log_flux_logvar_i == log_flux_logvar[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_loc_sd = torch.exp(0.5 * logit_loc_logvar)\n",
    "log_flux_sd = torch.exp(0.5 * log_flux_logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample locations\n",
    "locs_randn = torch.randn(logit_loc_mean.shape).to(device)\n",
    "\n",
    "logit_locs_sampled = logit_loc_mean + locs_randn * logit_loc_sd\n",
    "subimage_locs_sampled = \\\n",
    "    torch.sigmoid(logit_locs_sampled) * is_on_array.unsqueeze(3).float()\n",
    "\n",
    "# sample fluxes\n",
    "fluxes_randn = torch.randn(log_flux_mean.shape).to(device)\n",
    "log_flux_sampled = log_flux_mean + fluxes_randn * log_flux_sd\n",
    "subimage_fluxes_sampled = \\\n",
    "    torch.exp(log_flux_sampled) * is_on_array.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inv_kl_objective_lib import eval_normal_logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_q_locs = eval_normal_logprob(logit_locs_sampled, logit_loc_mean,\n",
    "                                            logit_loc_logvar).view(n_samples, -1).sum(1)\n",
    "log_q_fluxes = eval_normal_logprob(log_flux_sampled, log_flux_mean,\n",
    "                                    log_flux_logvar).view(n_samples, -1).sum(1)\n",
    "log_q_n_stars = torch.gather(log_probs, 1, n_stars_sampled.transpose(0, 1)).transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkout my IWAE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_locs_full_image, sampled_fluxes_full_image, sampled_n_stars_full, \\\n",
    "    log_q_locs, log_q_fluxes, log_q_n_stars = \\\n",
    "        wake_sleep_lib.sample_star_encoder(star_encoder, \n",
    "                                           full_image.unsqueeze(0).unsqueeze(0), \n",
    "                                           full_background.unsqueeze(0).unsqueeze(0),\n",
    "                                            n_samples, return_map = False,\n",
    "                                            return_log_q = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_means, neg_logprob = psf_transform_lib.get_psf_loss(full_image.squeeze(), full_background.squeeze(),\n",
    "                                        sampled_locs_full_image,\n",
    "                                        sampled_fluxes_full_image,\n",
    "                                        n_stars = sampled_n_stars_full,\n",
    "                                        psf = psf,\n",
    "                                        pad = 5, grid = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " - neg_logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_q_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_q_fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_q_n_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pq = - neg_logprob - log_q_locs - log_q_fluxes - log_q_n_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pq - np.log(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.logsumexp(log_pq - np.log(n_samples), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_04)",
   "language": "python",
   "name": "pytorch_update"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
