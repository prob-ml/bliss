{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "path = os.path.abspath('../..')\n",
    "if path not in sys.path: \n",
    "    sys.path.insert(0, path)\n",
    "sys.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import fitsio \n",
    "\n",
    "import json\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('torch version: ', torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from celeste import psf_transform, utils\n",
    "from celeste.datasets import simulated_datasets\n",
    "from celeste.models import sourcenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the PSF I fitted using ground truth Hubble locations/fluxes. \n",
    "init_psf_params = torch.tensor(np.load('../../data/fitted_powerlaw_psf_params.npy'), device=device)\n",
    "power_law_psf = psf_transform.PowerLawPSF(init_psf_params)\n",
    "psf = power_law_psf.forward().detach()\n",
    "\n",
    "# number of bands. Here, there are two. \n",
    "n_bands = psf.shape[0]\n",
    "print(n_bands)\n",
    "print(psf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parameters\n",
    "with open('../../config/dataset_params/default_star_parameters.json', 'r') as fp:\n",
    "    data_params = json.load(fp)\n",
    "data_params['max_stars'] = 10\n",
    "data_params['mean_stars'] = 5\n",
    "data_params['slen']= 20\n",
    "data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set background \n",
    "background = torch.zeros(n_bands, data_params['slen'], data_params['slen'], device=device)\n",
    "background[0] = 686.\n",
    "background[1] = 1123."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw data \n",
    "n_images = 32\n",
    "\n",
    "simulated_dataset = \\\n",
    "    simulated_datasets.StarDataset.load_dataset_from_params(n_images,\n",
    "                    data_params, psf,\n",
    "                    background,\n",
    "                    transpose_psf = False, \n",
    "                    add_noise = True, draw_poisson=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a nice batch \n",
    "images = simulated_dataset.get_batch(2)['images']\n",
    "locs = simulated_dataset.get_batch(2)['locs']\n",
    "log_fluxes =  simulated_dataset.get_batch(2)['log_fluxes']\n",
    "images.shape\n",
    "locs.shape\n",
    "log_fluxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0,0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrices from encoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slen = data_params['slen'] \n",
    "patch_slen = 8 \n",
    "step = 2\n",
    "edge_padding = 3 \n",
    "n_bands = 2 \n",
    "max_detections = 2\n",
    "n_source_params = 2\n",
    "\n",
    "star_encoder = sourcenet.SourceEncoder(slen, patch_slen, step, edge_padding, n_bands, \n",
    "                                       max_detections, n_source_params).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image ptiles and the corresponding h matrix. \n",
    "image_ptiles, true_tile_locs , _ , true_tile_n_sources, true_tile_is_on_array = star_encoder.get_image_ptiles(images, locs, log_fluxes, clip_max_sources=True)\n",
    "h = star_encoder._get_var_params_all(image_ptiles)\n",
    "image_ptiles.shape\n",
    "\n",
    "# take a note!  the tiles are not separated into batches, they are just added to the first shape here. \n",
    "# This makes sense, because for the encoder all tiles across all batches should be on the same footing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_tile_is_on_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## investigate shapes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_ptiles.shape  )\n",
    "print(h.shape)  # the first shape[0] corresponds to number of ptiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape[0] correponds to (max_detections + 1)\n",
    "# shape[1] corresponds to (max_detections * len(x,y))\n",
    "star_encoder.locs_mean_indx_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices for probably of there being 0 , 1 or 2 objects. (over-parametrized)\n",
    "star_encoder.prob_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what happens when we apply softmax \n",
    "print(h[:, star_encoder.prob_indx].shape)\n",
    "star_encoder._get_logprob_n_from_var_params(h).shape\n",
    "\n",
    "## => retains the tile shape and the other one too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs_n = star_encoder._get_logprob_n_from_var_params(h)\n",
    "n_sources = torch.argmax(log_probs_n, dim=1)\n",
    "n_sources.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(loc_mean, loc_logvar, source_param_mean, source_param_logvar) = star_encoder._get_var_params_for_n_sources(h, n_sources)\n",
    "print(loc_mean.shape)\n",
    "print(source_param_mean.shape)\n",
    "# shape is n_ptiles x max_detections x len(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(loc_mean,\n",
    "loc_logvar,\n",
    "source_param_mean,\n",
    "source_param_logvar,\n",
    "bernoulli_param,\n",
    "log_probs_n_sources_per_tile) = star_encoder.forward(image_ptiles, n_sources=true_tile_n_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bernoulli_param.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding indexing in sleep phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deblend] *",
   "language": "python",
   "name": "conda-env-deblend-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
