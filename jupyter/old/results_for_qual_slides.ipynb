{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import simulated_datasets_lib\n",
    "import sdss_dataset_lib\n",
    "import sdss_psf\n",
    "import image_utils \n",
    "import starnet_vae_lib\n",
    "import inv_kl_objective_lib as inv_kl_lib\n",
    "import image_statistics_lib\n",
    "\n",
    "import plotting_utils\n",
    "\n",
    "np.random.seed(34534)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_hubble_data = sdss_dataset_lib.SDSSHubbleData(bands = bands)\n",
    "\n",
    "# image \n",
    "full_image = sdss_hubble_data.sdss_image\n",
    "full_background = sdss_hubble_data.sdss_background \n",
    "\n",
    "# true parameters\n",
    "which_bright = (sdss_hubble_data.fluxes[:, 0] > fmin)\n",
    "true_locs = sdss_hubble_data.locs[which_bright]\n",
    "true_fluxes = sdss_hubble_data.fluxes[which_bright]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs_sorted = torch.sort(true_locs[:, 1])[0]\n",
    "\n",
    "x = locs_sorted[1:len(locs_sorted)] - locs_sorted[0:-1]\n",
    "\n",
    "bins = plt.hist(x, density=True)[1]\n",
    "\n",
    "# lambd = 1000 # 1 / x.numpy().mean() \n",
    "# pdf = lambd * np.exp(-lambd * bins)\n",
    "\n",
    "# plt.plot(bins, pdf, 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_locs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image = torch.Tensor(full_image)\n",
    "print(full_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(full_image[0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get simulator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitsio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_dir = '../data/'\n",
    "psf_r = fitsio.FITS(psf_dir + 'sdss-002583-2-0136-psf-r.fits')[0].read()\n",
    "psf_i = fitsio.FITS(psf_dir + 'sdss-002583-2-0136-psf-i.fits')[0].read()\n",
    "\n",
    "if len(bands) == 2: \n",
    "    psf_og = np.array([psf_r, psf_i])\n",
    "elif len(bands) == 1: \n",
    "    psf_og = np.array([psf_r])\n",
    "else: \n",
    "    assert 1 == 2, 'not implemented error'\n",
    "    \n",
    "sky_intensity = full_background.reshape(full_background.shape[0], -1).mean(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator1 = simulated_datasets_lib.StarSimulator(psf=psf_og[0:1], \n",
    "                                                slen = full_image.shape[-1], \n",
    "                                                  transpose_psf = False,\n",
    "                                                sky_intensity = sky_intensity[0:1])\n",
    "\n",
    "\n",
    "simulator = simulated_datasets_lib.StarSimulator(psf=psf_og, \n",
    "                                                slen = full_image.shape[-1], \n",
    "                                                transpose_psf = False,\n",
    "                                                sky_intensity = sky_intensity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulator.psf = torch.Tensor(psf_trained)\n",
    "# simulator1.psf = torch.Tensor(psf_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_recon = simulator.draw_image_from_params(locs = sdss_hubble_data.locs.unsqueeze(0), \n",
    "                            fluxes = sdss_hubble_data.fluxes.unsqueeze(0),\n",
    "                            n_stars = torch.Tensor([len(sdss_hubble_data.fluxes)]).type(torch.LongTensor), \n",
    "                            add_noise = False).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sdss_hubble_data.bands)): \n",
    "    foo = (truth_recon[i] - full_image[i]) / full_image[i]\n",
    "    plt.matshow(foo, vmax = foo.abs().max(), vmin = - foo.abs().max(), cmap = plt.get_cmap('bwr')) \n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(foo[5:15, 55:65], vmax = foo.abs().max(), vmin = - foo.abs().max(), cmap = plt.get_cmap('bwr')) \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Portillos results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '../../multiband_pcat/pcat-lion-results/20191107-115253/'\n",
    "\n",
    "chain_results = np.load(results_dir + 'chain.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n bands \n",
    "chain_results['f'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fudge_factor = 1 / (1 - 0.83)\n",
    "fudge_factor = sdss_hubble_data.sdss_data[0]['gain'][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_classical_catalogue = True\n",
    "\n",
    "if include_classical_catalogue: \n",
    "    pcat_catalog = np.loadtxt(results_dir + 'classical_catalog.txt')\n",
    "    \n",
    "    x1_loc = pcat_catalog[:, 0]\n",
    "    x0_loc = pcat_catalog[:, 2]\n",
    "        \n",
    "    fluxes = pcat_catalog[:, 4] * fudge_factor\n",
    "    \n",
    "    # remove na\n",
    "    is_na = (fluxes < fmin) | np.isnan(fluxes)\n",
    "    \n",
    "    x1_loc = x1_loc[~is_na]\n",
    "    x0_loc = x0_loc[~is_na]\n",
    "    fluxes = fluxes[~is_na]\n",
    "    \n",
    "    portillos_est_locs = torch.Tensor([x0_loc, x1_loc]).transpose(0,1) / (full_image.shape[-1] - 1)\n",
    "    portillos_est_fluxes = torch.Tensor(fluxes).unsqueeze(-1)\n",
    "    \n",
    "else: \n",
    "    # just take one sample \n",
    "    fluxes = chain_results['f'][:, -1, ].transpose() * fudge_factor\n",
    "    \n",
    "    x1_loc = chain_results['x'][-1, ].flatten()[fluxes[:, 0] > fmin]\n",
    "    x0_loc = chain_results['y'][-1, ].flatten()[fluxes[:, 0] > fmin]\n",
    "    \n",
    "    fluxes = fluxes[fluxes[:, 0] > fmin]\n",
    "        \n",
    "    portillos_est_locs = torch.Tensor([x0_loc, x1_loc]).transpose(0,1) / (full_image.shape[-1] - 1)\n",
    "    portillos_est_fluxes = torch.Tensor(fluxes) \n",
    "    \n",
    "\n",
    "# x1_loc_samples = chain_results['x'][-300:, ].flatten()\n",
    "# x0_loc_samples = chain_results['y'][-300:, ].flatten()\n",
    "\n",
    "# portillos_est_fluxes_sampled = torch.Tensor(chain_results['f'][0, -300:, ].flatten()) * fudge_factor\n",
    "# portillos_est_locs_sampled = torch.Tensor([x0_loc_samples, x1_loc_samples]).transpose(0,1) \\\n",
    "#                                 / (full_image.shape[-1] - 1)\n",
    "    \n",
    "# # filter by fmin\n",
    "# port_which_bright = portillos_est_fluxes_sampled > fmin\n",
    "# portillos_est_fluxes_sampled = portillos_est_fluxes_sampled[port_which_bright]\n",
    "# portillos_est_locs_sampled = portillos_est_locs_sampled[port_which_bright]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_results['n'][-300:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_results['n'][-300:].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portillos_est_fluxes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get reconstruction mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_locs = portillos_est_locs.unsqueeze(0) \n",
    "_fluxes = portillos_est_fluxes.unsqueeze(0)\n",
    "_n_stars = torch.Tensor([len(x0_loc)]).type(torch.LongTensor)\n",
    "\n",
    "if _fluxes.shape[-1] == 1:\n",
    "    portillos_recon_mean = simulator1.draw_image_from_params(locs = _locs, \n",
    "                                            fluxes = _fluxes,\n",
    "                                             n_stars = _n_stars,  \n",
    "                                             add_noise = False).squeeze(0)\n",
    "else: \n",
    "    portillos_recon_mean = simulator.draw_image_from_params(locs = _locs, \n",
    "                                                fluxes = _fluxes,\n",
    "                                                 n_stars = _n_stars,  \n",
    "                                                 add_noise = False).squeeze()\n",
    "\n",
    "plt.matshow(portillos_recon_mean[0]); \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portillos_recon_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portillos_residuals = portillos_recon_mean - full_image\n",
    "\n",
    "for i in range(portillos_recon_mean.shape[0]): \n",
    "    foo = (portillos_residuals[i] / full_image[i])[5:95, 5:95]\n",
    "    plt.matshow(foo, vmax = foo.abs().max(), vmin = -foo.abs().max(), cmap = plt.get_cmap('bwr'))\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(foo[15:35, 50:70], vmax = foo.abs().max(), vmin = - foo.abs().max(), cmap = plt.get_cmap('bwr')) \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My starnet result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_encoder1 = starnet_vae_lib.StarEncoder(full_slen = 101,\n",
    "                                            stamp_slen = 7,\n",
    "                                            step = 2,\n",
    "                                            edge_padding = 2, \n",
    "                                            n_bands = len(bands),\n",
    "                                            max_detections = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_encoder1.load_state_dict(torch.load('../fits/results_11202019/starnet_r', \n",
    "                               map_location=lambda storage, loc: storage))\n",
    "\n",
    "\n",
    "star_encoder1.eval(); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get parameters on the full image \n",
    "# map_locs_full_image, map_fluxes_full_image, map_n_stars_full = \\\n",
    "#     star_encoder.get_results_on_full_image(full_image.unsqueeze(0).unsqueeze(0), \n",
    "#                                            full_background.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "t0 = time.time()\n",
    "map_locs_full_image, map_fluxes_full_image, map_n_stars_full = \\\n",
    "    star_encoder1.sample_star_encoder(full_image.unsqueeze(0), \n",
    "                                    full_background.unsqueeze(0), \n",
    "                                    return_map = True)[0:3]\n",
    "    \n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_recon_mean = simulator.draw_image_from_params(locs = map_locs_full_image, \n",
    "                                                fluxes = map_fluxes_full_image,\n",
    "                                                 n_stars = map_n_stars_full, \n",
    "                                                 add_noise = False).squeeze(0)\n",
    "\n",
    "vae_residuals = vae_recon_mean - full_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(vae_residuals.shape[0]): \n",
    "    foo = (vae_residuals[i] / full_image[i])[5:95, 5:95]\n",
    "    plt.matshow(foo, vmax = foo.abs().max(), vmin = -foo.abs().max(), cmap = plt.get_cmap('bwr'))\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results after wake sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_encoder2 = starnet_vae_lib.StarEncoder(full_slen = 101,\n",
    "                                            stamp_slen = 7,\n",
    "                                            step = 2,\n",
    "                                            edge_padding = 2, \n",
    "                                            n_bands = len(bands),\n",
    "                                            max_detections = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_encoder2.load_state_dict(torch.load('../fits/results_11202019/wake-sleep_630x310_r-encoder-iter6', \n",
    "                               map_location=lambda storage, loc: storage))\n",
    "\n",
    "\n",
    "star_encoder2.eval(); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get parameters on the full image \n",
    "# map_locs_full_image, map_fluxes_full_image, map_n_stars_full = \\\n",
    "#     star_encoder.get_results_on_full_image(full_image.unsqueeze(0).unsqueeze(0), \n",
    "#                                            full_background.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "map_locs_full_image2, map_fluxes_full_image2, map_n_stars_full2 = \\\n",
    "    star_encoder2.sample_star_encoder(full_image.unsqueeze(0), \n",
    "                                    full_background.unsqueeze(0), \n",
    "                                    return_map = True)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_recon_mean2 = simulator.draw_image_from_params(locs = map_locs_full_image2, \n",
    "                                                fluxes = map_fluxes_full_image2,\n",
    "                                                 n_stars = map_n_stars_full2, \n",
    "                                                 add_noise = False).squeeze(0)\n",
    "\n",
    "vae_residuals2 = vae_recon_mean2 - full_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(vae_residuals2.shape[0]): \n",
    "    foo = (vae_residuals2[i] / full_image[i])[5:95, 5:95]\n",
    "    plt.matshow(foo, vmax = foo.abs().max(), vmin = -foo.abs().max(), cmap = plt.get_cmap('bwr'))\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_n_stars_full2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkout some summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_n_stars_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_n_stars_full2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(portillos_est_fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(true_fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_completeness1, my_tpr1, my_complete_bool1, my_tpr_bool = \\\n",
    "    image_statistics_lib.get_summary_stats(map_locs_full_image.squeeze(0), \n",
    "                                           true_locs, \n",
    "                                           full_image.shape[-1], \n",
    "                                           map_fluxes_full_image.squeeze(0)[:, 0], \n",
    "                                           true_fluxes[:, 0])\n",
    "\n",
    "my_completeness2, my_tpr2, my_complete_bool2, my_tpr_bool = \\\n",
    "    image_statistics_lib.get_summary_stats(map_locs_full_image2.squeeze(0), \n",
    "                                           true_locs, \n",
    "                                           full_image.shape[-1], \n",
    "                                           map_fluxes_full_image2.squeeze(0)[:, 0], \n",
    "                                           true_fluxes[:, 0])\n",
    "    \n",
    "\n",
    "portillos_completeness, portillos_tpr, portillos_complete_bool, portillos_tpr_bool = \\\n",
    "    image_statistics_lib.get_summary_stats(portillos_est_locs, true_locs, \n",
    "                                           full_image.shape[-1], \n",
    "                                           portillos_est_fluxes[:, 0], \n",
    "                                           true_fluxes[:, 0])\n",
    "\n",
    "    \n",
    "print('my completeness 1: {:0.3f}'.format(my_completeness1))\n",
    "print('my completeness 2: {:0.3f}'.format(my_completeness2))\n",
    "print('portillos completeness: {:0.3f}\\n'.format(portillos_completeness))\n",
    "\n",
    "print('my true positive rate 1: {:0.3f}'.format(my_tpr1))\n",
    "print('my true positive rate 2: {:0.3f}'.format(my_tpr2))\n",
    "print('portillos true positive rate: {:0.3f}'.format(portillos_tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portillos_locs_error, portillos_fluxes_error = image_statistics_lib.get_l1_error(portillos_est_locs, true_locs, \n",
    "                                       full_image.shape[-1], \n",
    "                                       portillos_est_fluxes[:, 0], \n",
    "                                       true_fluxes[:, 0])\n",
    "\n",
    "my_locs_error1, my_fluxes_error1 = image_statistics_lib.get_l1_error(map_locs_full_image.squeeze(0), \n",
    "                                           true_locs, \n",
    "                                           full_image.shape[-1], \n",
    "                                           map_fluxes_full_image.squeeze(0)[:, 0], \n",
    "                                           true_fluxes[:, 0])\n",
    "\n",
    "my_locs_error2, my_fluxes_error2 = image_statistics_lib.get_l1_error(map_locs_full_image2.squeeze(0), \n",
    "                                           true_locs, \n",
    "                                           full_image.shape[-1], \n",
    "                                           map_fluxes_full_image2.squeeze(0)[:, 0], \n",
    "                                           true_fluxes[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### loc errors \n",
    "print((my_locs_error1.mean(), my_locs_error1.std() / np.sqrt(len(my_locs_error1))))\n",
    "print((my_locs_error2.mean(), my_locs_error2.std() / np.sqrt(len(my_locs_error1))))\n",
    "print((portillos_locs_error.mean(), portillos_locs_error.std() / np.sqrt(len(portillos_locs_error))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flux errors \n",
    "print((my_fluxes_error1.mean(), my_fluxes_error1.std() / np.sqrt(len(my_fluxes_error1))))\n",
    "print((my_fluxes_error2.mean(), my_fluxes_error2.std() / np.sqrt(len(my_fluxes_error1))))\n",
    "print((portillos_fluxes_error.mean(), portillos_fluxes_error.std() / np.sqrt(len(portillos_fluxes_error))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare sleep vs portillos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_completeness_vec1, my_comp_mag_vec1 = \\\n",
    "    image_statistics_lib.get_completeness_vec(map_locs_full_image.squeeze(0), \n",
    "                                           true_locs, \n",
    "                                           full_image.shape[-1], \n",
    "                                           map_fluxes_full_image.squeeze(0)[:, 0], \n",
    "                                           true_fluxes[:, 0], \n",
    "                                             mag_vec = None)[0:2]\n",
    "\n",
    "portillos_completeness, portillos_comp_mag_vec = \\\n",
    "    image_statistics_lib.get_completeness_vec(portillos_est_locs.squeeze(0), \n",
    "                                           true_locs, \n",
    "                                           full_image.shape[-1], \n",
    "                                           portillos_est_fluxes.squeeze(0)[:, 0], \n",
    "                                           true_fluxes[:, 0], \n",
    "                                             mag_vec = None)[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tpr_vec1, my_tpr_mag_vec1 = \\\n",
    "    image_statistics_lib.get_tpr_vec(map_locs_full_image.squeeze(0), \n",
    "                                           true_locs, \n",
    "                                           full_image.shape[-1], \n",
    "                                           map_fluxes_full_image.squeeze(0)[:, 0], \n",
    "                                           true_fluxes[:, 0], \n",
    "                                             mag_vec = None)[0:2]\n",
    "\n",
    "portillos_tpr, portillos_tpr_mag_vec = \\\n",
    "    image_statistics_lib.get_tpr_vec(portillos_est_locs.squeeze(0), \n",
    "                                           true_locs, \n",
    "                                           full_image.shape[-1], \n",
    "                                           portillos_est_fluxes.squeeze(0)[:, 0], \n",
    "                                           true_fluxes[:, 0], \n",
    "                                             mag_vec = None)[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axarr[0].plot(my_comp_mag_vec1[0:-1], my_completeness_vec1, 'r--x', label = 'VI sleep-phase')\n",
    "axarr[0].plot(portillos_comp_mag_vec[0:-1], portillos_completeness, 'b--x', label = 'Portillos')\n",
    "\n",
    "# axarr[0].legend()\n",
    "axarr[0].set_xlabel('true log flux', size = 16)\n",
    "axarr[0].set_ylabel('TPR', size = 16)\n",
    "\n",
    "\n",
    "axarr[1].plot(my_tpr_mag_vec1[0:-1], my_tpr_vec1, 'r--x', label = 'VI sleep-phase')\n",
    "axarr[1].plot(portillos_tpr_mag_vec[0:-1], portillos_tpr, 'b--x', label = 'Portillos')\n",
    "\n",
    "axarr[1].legend(fontsize = 16)\n",
    "axarr[1].set_xlabel('estimated log flux', size = 16)\n",
    "axarr[1].set_ylabel('PPV', size = 16)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if save_figs: \n",
    "    plt.savefig('../../qualifying_exam_slides/figures/sleep_vs_portillos.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare sleep vs wake-sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mags = torch.log10(true_fluxes[:, 0]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_vec = np.percentile(true_mags, np.arange(0, 110, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_completeness_vec1, my_comp_mag_vec1 = \\\n",
    "    image_statistics_lib.get_completeness_vec(map_locs_full_image.squeeze(0), \n",
    "                                           true_locs, \n",
    "                                           full_image.shape[-1], \n",
    "                                           map_fluxes_full_image.squeeze(0)[:, 0], \n",
    "                                           true_fluxes[:, 0], \n",
    "                                             mag_vec = None)[0:2]\n",
    "\n",
    "my_completeness_vec2, my_comp_mag_vec2 = \\\n",
    "    image_statistics_lib.get_completeness_vec(map_locs_full_image2.squeeze(0), \n",
    "                                           true_locs, \n",
    "                                           full_image.shape[-1], \n",
    "                                           map_fluxes_full_image2.squeeze(0)[:, 0], \n",
    "                                           true_fluxes[:, 0], \n",
    "                                             mag_vec = None)[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags = torch.log10(map_fluxes_full_image.squeeze(0)[:, 0]).numpy()\n",
    "mag_vec = np.percentile(mags, np.arange(0, 110, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tpr_vec1, my_tpr_mag_vec1, counts_vec  = \\\n",
    "    image_statistics_lib.get_tpr_vec(map_locs_full_image.squeeze(0), \n",
    "                                           true_locs, \n",
    "                                           full_image.shape[-1], \n",
    "                                           map_fluxes_full_image.squeeze(0)[:, 0], \n",
    "                                           true_fluxes[:, 0], mag_vec = None)\n",
    "\n",
    "my_tpr_vec2, my_tpr_mag_vec2, counts_vec2 = \\\n",
    "    image_statistics_lib.get_tpr_vec(map_locs_full_image2.squeeze(0), \n",
    "                                       true_locs, \n",
    "                                       full_image.shape[-1], \n",
    "                                       map_fluxes_full_image2.squeeze(0)[:, 0], \n",
    "                                       true_fluxes[:, 0], mag_vec = None)\n",
    "\n",
    "# plt.plot(my_mag_vec1[0:-1], my_tpr_vec1, '--x', label = 'starnet-iter0')\n",
    "# plt.plot(my_mag_vec2[0:-1], my_tpr_vec2, '--x', label = 'starnet-iter6')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel('true log flux')\n",
    "# plt.ylabel('tpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# TPR\n",
    "axarr[0].plot(my_comp_mag_vec1[0:-1], my_completeness_vec1, 'r--x', label = 'sleep-phase only')\n",
    "axarr[0].plot(my_comp_mag_vec2[0:-1], my_completeness_vec2, '--x', color = 'orange', label = 'wake-sleep')\n",
    "\n",
    "axarr[0].legend(fontsize = 14)\n",
    "axarr[0].set_xlabel('true log flux', size = 16)\n",
    "axarr[0].set_ylabel('TPR', size = 16)\n",
    "\n",
    "# PPV\n",
    "axarr[1].plot(my_tpr_mag_vec1[0:-1], my_tpr_vec1, 'r--x', label = 'VI sleep-phase only ')\n",
    "axarr[1].plot(my_tpr_mag_vec2[0:-1], my_tpr_vec2, '--x', color = 'orange', label = 'VI wake-sleep')\n",
    "\n",
    "# axarr[0].legend()\n",
    "axarr[1].set_xlabel('true log flux', size = 16)\n",
    "axarr[1].set_ylabel('PPV', size = 16)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if save_figs: \n",
    "    plt.savefig('../../qualifying_exam_slides/figures/wake_sleep_curves.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_complete_bool1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_complete_bool2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_true_locs, _true_fluxes = image_statistics_lib.filter_params(true_locs, true_fluxes[:, 0], 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which_bool = (torch.log10(_true_fluxes).flatten() > 4.0) & \\\n",
    "#                 (my_complete_bool1 == 0) & \\\n",
    "#                 (my_complete_bool2 == 1)\n",
    "        \n",
    "\n",
    "which_bool = (torch.log10(_true_fluxes).flatten() > 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_indx = torch.nonzero(which_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_true_locs[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "\n",
    "x0 = 85\n",
    "x1 = 15\n",
    "plotting_utils.plot_subimage(axarr[0], full_image[0], \n",
    "                             map_locs_full_image.squeeze(), \n",
    "                             true_locs, \n",
    "                             x0, \n",
    "                             x1, subimage_slen = 10, \n",
    "                            add_colorbar = True, \n",
    "                             global_fig = fig)\n",
    "\n",
    "  \n",
    "plotting_utils.plot_subimage(axarr[1], full_image[0], \n",
    "                             map_locs_full_image2.squeeze(), \n",
    "                             true_locs, \n",
    "                             x0, \n",
    "                             x1, subimage_slen = 10, \n",
    "                            add_colorbar = True, \n",
    "                             global_fig = fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets take a closer look at sleep vs wake-sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psf_transform_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_transform = psf_transform_lib.PsfLocalTransform(torch.Tensor(psf_og),\n",
    "                                    full_image.shape[-1], \n",
    "                                    kernel_size = 3)\n",
    "\n",
    "psf_transform.load_state_dict(torch.load('../fits/results_11202019/wake-sleep_630x310_r-psf_transform-iter5', \n",
    "                                             map_location=lambda storage, loc: storage))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator_psf_trained = simulated_datasets_lib.StarSimulator(psf=psf_og, \n",
    "                                                slen = full_image.shape[-1], \n",
    "                                                transpose_psf = False,\n",
    "                                                sky_intensity = sky_intensity)\n",
    "\n",
    "simulator_psf_trained.psf = psf_transform.forward().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = ((truth_recon - full_image) / full_image)[band, 5:95, 5:95]\n",
    "plt.matshow(foo, vmax = foo.abs().max(), vmin = -foo.abs().max(), cmap = plt.get_cmap('bwr'))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(foo).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_recon_trained = simulator_psf_trained.draw_image_from_params(locs = sdss_hubble_data.locs.unsqueeze(0), \n",
    "                            fluxes = sdss_hubble_data.fluxes.unsqueeze(0),\n",
    "                            n_stars = torch.Tensor([len(sdss_hubble_data.fluxes)]).type(torch.LongTensor), \n",
    "                            add_noise = False).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = ((truth_recon_trained - full_image) / full_image)[band, 5:95, 5:95]\n",
    "plt.matshow(foo, vmax = foo.abs().max(), vmin = -foo.abs().max(), cmap = plt.get_cmap('bwr'))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(foo).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_fluxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,1, figsize=(5, 4))\n",
    "\n",
    "foo = ((truth_recon - full_image) / truth_recon)\n",
    "plotting_utils.plot_subimage(axarr, foo[band] - foo[band].mean(), \n",
    "                             true_locs[true_fluxes[:, 0] > 10**(4.3)],\n",
    "                             None, \n",
    "                             x0 = 55, \n",
    "                            x1 = 5, \n",
    "                            subimage_slen = 25, \n",
    "                            diverging_cmap = True, \n",
    "                            color = 'navy', marker = 'o', \n",
    "                            add_colorbar = True, \n",
    "                             vmax = 0.21, vmin = -0.21, \n",
    "                            global_fig = fig)\n",
    "\n",
    "axarr.set_title('residuals \\n', size = 16)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if save_figs: \n",
    "    plt.savefig('../../qualifying_exam_slides/figures/psf_misfit_ex_patch.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "foo = ((truth_recon - full_image) / full_image)\n",
    "plotting_utils.plot_subimage(axarr[0], foo[band] - foo[band].mean(), \n",
    "                             true_locs[true_fluxes[:, 0] > 10**(4.3)],\n",
    "                             None, \n",
    "                             x0 = 55, \n",
    "                            x1 = 5, \n",
    "                            subimage_slen = 25, \n",
    "                            diverging_cmap = True, \n",
    "                            color = 'navy', marker = 'o', \n",
    "                            add_colorbar = True, \n",
    "                             vmax = 0.21, vmin = -0.21, \n",
    "                            global_fig = fig)\n",
    "\n",
    "foo1 = ((truth_recon_trained - full_image) / full_image)\n",
    "plotting_utils.plot_subimage(axarr[1], foo1[band] - foo1[band].mean(), \n",
    "                             true_locs[true_fluxes[:, 0] > 10**(4.3)],\n",
    "                             None, \n",
    "                             x0 = 55, \n",
    "                            x1 = 5, \n",
    "                            subimage_slen = 25, \n",
    "                            diverging_cmap = True, \n",
    "                            color = 'navy', marker = 'o', \n",
    "                            add_colorbar = True, \n",
    "                             vmax = 0.21, vmin = -0.21, \n",
    "                            global_fig = fig)\n",
    "\n",
    "\n",
    "axarr[0].set_title('residuals: SDSS psf \\n', size = 16)\n",
    "axarr[1].set_title('residuals: wake-sleep psf \\n', size = 16)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if save_figs: \n",
    "    plt.savefig('../../qualifying_exam_slides/figures/residuals_psf_training.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show reverse KL does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_encoder_kl = starnet_vae_lib.StarEncoder(full_slen = 101,\n",
    "                                            stamp_slen = 7,\n",
    "                                            step = 2,\n",
    "                                            edge_padding = 2, \n",
    "                                            n_bands = psf_og.shape[0],\n",
    "                                            max_detections = 2, \n",
    "                                            fmin = 1000.)\n",
    "\n",
    "star_encoder_kl.load_state_dict(torch.load('../fits/results_11202019/kl_starnet2', \n",
    "                               map_location=lambda storage, loc: storage))\n",
    "star_encoder_kl.eval(); \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get parameters on the full image \n",
    "map_locs_full_imagekl, map_fluxes_full_imagekl, map_n_stars_fullkl = \\\n",
    "    star_encoder_kl.sample_star_encoder(full_image.unsqueeze(0), \n",
    "                                    full_background.unsqueeze(0), \n",
    "                                    return_map = True)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "x0_vec = [55, 56, 23]\n",
    "x1_vec = [19, 71, 32]\n",
    "for i in range(3): \n",
    "    x0 = x0_vec[i]\n",
    "    x1 = x1_vec[i]\n",
    "    \n",
    "    plotting_utils.plot_subimage(axarr[i], full_image[0], \n",
    "                                     map_locs_full_imagekl.squeeze(), \n",
    "                                     true_locs, \n",
    "                                     x0, x1, subimage_slen = 10, \n",
    "                                    add_colorbar = True, \n",
    "                                     global_fig = fig)\n",
    "\n",
    "fig.tight_layout()\n",
    "if save_figs: \n",
    "    plt.savefig('../../qualifying_exam_slides/figures/reverse_kl_fails.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "x0_vec = [55, 56, 23]\n",
    "x1_vec = [19, 71, 32]\n",
    "for i in range(3): \n",
    "    x0 = x0_vec[i]\n",
    "    x1 = x1_vec[i]\n",
    "    \n",
    "    plotting_utils.plot_subimage(axarr[i], full_image[0], \n",
    "                                     map_locs_full_image.squeeze(), \n",
    "                                     true_locs, \n",
    "                                     x0, x1, subimage_slen = 10, \n",
    "                                    add_colorbar = True, \n",
    "                                     global_fig = fig)\n",
    "fig.tight_layout()\n",
    "if save_figs: \n",
    "    plt.savefig('../../qualifying_exam_slides/figures/forward_kl_better.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "plotting_utils.plot_subimage(axarr[0], full_image[0], \n",
    "                                     map_locs_full_imagekl.squeeze(), \n",
    "                                     true_locs, \n",
    "                                     x0, x1, subimage_slen = 10, \n",
    "                                    add_colorbar = True, \n",
    "                                     global_fig = fig)\n",
    "\n",
    "plotting_utils.plot_subimage(axarr[1], full_image[0], \n",
    "                                     map_locs_full_image.squeeze(), \n",
    "                                     true_locs, \n",
    "                                     x0, x1, subimage_slen = 10, \n",
    "                                    add_colorbar = True, \n",
    "                                     global_fig = fig)\n",
    "\n",
    "axarr[0].set_title('E-step inferred locations\\n', size = 16)\n",
    "axarr[1].set_title('Sleep phase inferred locations\\n', size = 16)\n",
    "fig.tight_layout()\n",
    "\n",
    "if save_figs: \n",
    "    fig.savefig('../../qualifying_exam_slides/figures/kl_vs_invkl.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(2, 2, figsize=(8, 6.5))\n",
    "\n",
    "x0_vec = [53, 31, 41, 32]\n",
    "x1_vec = [70, 83, 23, 64]\n",
    "\n",
    "\n",
    "for i in range(4): \n",
    "    x0 = x0_vec[i]\n",
    "    x1 = x1_vec[i]\n",
    "    subimage_slen = 10\n",
    "    \n",
    "    plotting_utils.plot_subimage(axarr[i // 2, i % 2], full_image[0], \n",
    "                                         None, \n",
    "                                         true_locs, \n",
    "                                         x0_vec[i], \n",
    "                                         x1_vec[i], subimage_slen = 10, \n",
    "                                        add_colorbar = True, \n",
    "                                         global_fig = fig)\n",
    "    \n",
    "    \n",
    "#     axarr[i // 2, i % 2].set_title('observed; coords: {}\\n'.format([x0, x1]));\n",
    "\n",
    "    # portillos catalogue\n",
    "#     _portillos_est_locs = portillos_est_locs * (full_image.shape[-1] - 1)\n",
    "#     which_locs = (_portillos_est_locs[:, 0] > x0) & \\\n",
    "#                     (_portillos_est_locs[:, 0] < (x0 + subimage_slen - 1)) & \\\n",
    "#                     (_portillos_est_locs[:, 1] > x1) & \\\n",
    "#                     (_portillos_est_locs[:, 1] < (x1 + subimage_slen - 1))\n",
    "#     portillos_locs = (_portillos_est_locs[which_locs, :] - torch.Tensor([[x0, x1]])) \n",
    "#     axarr[i // 2, i % 2].scatter(portillos_locs[:, 1], portillos_locs[:, 0], color = 'c', marker = 'x')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figs: \n",
    "    plt.savefig('../../qualifying_exam_slides/figures/portillos_m2_image_subpatches.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(2, 2, figsize=(8, 6.5))\n",
    "\n",
    "x0_vec = [53, 31, 41, 32]\n",
    "x1_vec = [70, 83, 23, 64]\n",
    "\n",
    "\n",
    "for i in range(4): \n",
    "    x0 = x0_vec[i]\n",
    "    x1 = x1_vec[i]\n",
    "    subimage_slen = 10\n",
    "    \n",
    "    plotting_utils.plot_subimage(axarr[i // 2, i % 2], full_image[0], \n",
    "                                         map_locs_full_image2.squeeze(), \n",
    "                                         true_locs, \n",
    "                                         x0_vec[i], \n",
    "                                         x1_vec[i], subimage_slen = 10, \n",
    "                                        add_colorbar = True, \n",
    "                                         global_fig = fig)\n",
    "    \n",
    "    \n",
    "#     axarr[i // 2, i % 2].set_title('observed; coords: {}\\n'.format([x0, x1]));\n",
    "\n",
    "    # portillos catalogue\n",
    "    _portillos_est_locs = portillos_est_locs * (full_image.shape[-1] - 1)\n",
    "    which_locs = (_portillos_est_locs[:, 0] > x0) & \\\n",
    "                    (_portillos_est_locs[:, 0] < (x0 + subimage_slen - 1)) & \\\n",
    "                    (_portillos_est_locs[:, 1] > x1) & \\\n",
    "                    (_portillos_est_locs[:, 1] < (x1 + subimage_slen - 1))\n",
    "    portillos_locs = (_portillos_est_locs[which_locs, :] - torch.Tensor([[x0, x1]])) \n",
    "    axarr[i // 2, i % 2].scatter(portillos_locs[:, 1], portillos_locs[:, 0], color = 'c', marker = 'x')\n",
    "\n",
    "plt.tight_layout()\n",
    "if save_figs: \n",
    "    plt.savefig('../../qualifying_exam_slides/sample_figures.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stamps, _, _, \\\n",
    "    subimage_n_stars, _ = \\\n",
    "        star_encoder1.get_image_stamps(full_image.unsqueeze(0), \n",
    "                                       true_locs.unsqueeze(0), \n",
    "                                       true_fluxes.unsqueeze(0))\n",
    "        \n",
    "background_stamps = star_encoder1.get_image_stamps(full_background.unsqueeze(0),\n",
    "                            locs = None, fluxes = None, trim_images = False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "indx = int(np.random.choice(image_stamps.shape[0], 1))\n",
    "# indx = int(np.random.choice(torch.where(true_subimage_n_stars == 2)[0].numpy(), 1))\n",
    "\n",
    "plotting_utils.plot_subimage(axarr[0], full_image[band],\n",
    "                            map_locs_full_image2.squeeze(), \n",
    "                            true_locs, \n",
    "                            int(star_encoder2.tile_coords[indx, 0]), \n",
    "                            int(star_encoder2.tile_coords[indx, 1]), \n",
    "                            subimage_slen = star_encoder2.stamp_slen, \n",
    "                            add_colorbar = True, \n",
    "                            global_fig = f)\n",
    "\n",
    "# plotting_utils.plot_subimage(axarr[1], [0, band],\n",
    "#                             map_locs_full_image.squeeze(), \n",
    "#                             None, \n",
    "#                             int(star_encoder.tile_coords[indx, 0]), \n",
    "#                             int(star_encoder.tile_coords[indx, 1]), \n",
    "#                             subimage_slen = star_encoder.stamp_slen, \n",
    "#                             add_colorbar = True, \n",
    "#                             global_fig = f)\n",
    "\n",
    "# foo = vae_recon_mean[0, band] - images_full[0, band]\n",
    "# plotting_utils.plot_subimage(axarr[2], foo, \n",
    "#                             map_locs_full_image.squeeze(), \n",
    "#                             None, \n",
    "#                             int(star_encoder.tile_coords[indx, 0]), \n",
    "#                             int(star_encoder.tile_coords[indx, 1]), \n",
    "#                             subimage_slen = star_encoder.stamp_slen, \n",
    "#                             add_colorbar = True, \n",
    "#                             global_fig = f, \n",
    "#                             diverging_cmap = True)\n",
    "\n",
    "axarr[0].axvline(x=2, color = 'r')\n",
    "axarr[0].axvline(x=4, color = 'r')\n",
    "axarr[0].axhline(y=2, color = 'r')\n",
    "axarr[0].axhline(y=4, color = 'r')\n",
    "\n",
    "axarr[1].axvline(x=2, color = 'r')\n",
    "axarr[1].axvline(x=4, color = 'r')\n",
    "axarr[1].axhline(y=2, color = 'r')\n",
    "axarr[1].axhline(y=4, color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainties?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_locs_full_image, sampled_fluxes_full_image, sampled_n_stars_full = \\\n",
    "    star_encoder2.sample_star_encoder(full_image.unsqueeze(0), \n",
    "                                    full_background.unsqueeze(0), \n",
    "                                    return_map = False, \n",
    "                                    n_samples = 100)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(2, 2, figsize=(8, 6.5))\n",
    "\n",
    "x0_vec = [53, 31, 41, 32]\n",
    "x1_vec = [70, 83, 23, 64]\n",
    "\n",
    "\n",
    "for i in range(4): \n",
    "    x0 = x0_vec[i]\n",
    "    x1 = x1_vec[i]\n",
    "    subimage_slen = 10\n",
    "    \n",
    "    # posterior samples\n",
    "    _sampled_locs = sampled_locs_full_image * (full_image.shape[-1] - 1)\n",
    "    which_locs = (_sampled_locs[:, :, 0] > x0) & \\\n",
    "                    (_sampled_locs[:, :, 0] < (x0 + subimage_slen - 1)) & \\\n",
    "                    (_sampled_locs[:, :, 1] > x1) & \\\n",
    "                    (_sampled_locs[:, :, 1] < (x1 + subimage_slen - 1))\n",
    "    sampled_locs = (_sampled_locs[which_locs, :] - torch.Tensor([[[x0, x1]]])) \n",
    "    axarr[i // 2, i % 2].scatter(sampled_locs[:, :, 1].flatten(), \n",
    "                                 sampled_locs[:, :, 0].flatten(), \n",
    "                                 color = 'r', marker = 'x', alpha = 0.1)\n",
    "\n",
    "    # map estimates\n",
    "    plotting_utils.plot_subimage(axarr[i // 2, i % 2], full_image[0], \n",
    "                                         map_locs_full_image2.squeeze(), \n",
    "                                         true_locs, \n",
    "                                         x0_vec[i], \n",
    "                                         x1_vec[i], subimage_slen = 10, \n",
    "                                        add_colorbar = True, \n",
    "                                         global_fig = fig, color = 'green')\n",
    "    \n",
    "    \n",
    "#     axarr[i // 2, i % 2].set_title('observed; coords: {}\\n'.format([x0, x1]));\n",
    "        \n",
    "    # axarr[i // 2, i % 2].set_title();\n",
    "\n",
    "plt.tight_layout()\n",
    "if save_figs: \n",
    "    plt.savefig('../../qualifying_exam_slides/figures/sample_figures_my_posterior_samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now CONDITION on the true number of stars. \n",
    "# quantify uncertainties\n",
    "# get image stamps\n",
    "\n",
    "image_stamps, true_subimage_locs, true_subimage_fluxes, \\\n",
    "    true_subimage_n_stars, true_is_on_array = \\\n",
    "        star_encoder1.get_image_stamps(full_image.unsqueeze(0), \n",
    "                                       true_locs.unsqueeze(0), \n",
    "                                       true_fluxes.unsqueeze(0), \n",
    "                                      trim_images = False, clip_max_stars = True)\n",
    "    \n",
    "background_stamps = star_encoder1.get_image_stamps(full_background.unsqueeze(0), None, None, \n",
    "                                      trim_images = False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that these variational parameters are estimated using the true number of stars!\n",
    "stamp_logit_loc_mean, stamp_logit_loc_log_var, \\\n",
    "    stamp_log_flux_mean, stamp_log_flux_log_var, stamp_log_probs = \\\n",
    "        star_encoder1(image_stamps, background_stamps, true_subimage_n_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we really just want the permutation\n",
    "loss, counter_loss, locs_loss, fluxes_loss, perm_indx = \\\n",
    "    inv_kl_lib.get_encoder_loss(star_encoder2, full_image.unsqueeze(0), \n",
    "                                full_background.unsqueeze(0),\n",
    "                                true_locs.unsqueeze(0), \n",
    "                                true_fluxes.unsqueeze(0))[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "perm_list = []\n",
    "for perm in permutations(range(star_encoder1.max_detections)):\n",
    "    perm_list.append(perm)\n",
    "    \n",
    "perm = np.zeros((image_stamps.shape[0], star_encoder1.max_detections))\n",
    "for i in range(image_stamps.shape[0]): \n",
    "    perm[i, :] = perm_list[perm_indx[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permute true parameters \n",
    "def permute_params(locs, fluxes, perm): \n",
    "    batchsize = perm.shape[0]\n",
    "    max_stars = perm.shape[1]\n",
    "    \n",
    "    n_bands = fluxes.shape[-1]\n",
    "\n",
    "    locs_perm = torch.zeros((batchsize, max_stars, 2))\n",
    "    fluxes_perm = torch.zeros((batchsize, max_stars, n_bands))\n",
    "    seq_tensor = torch.LongTensor([i for i in range(batchsize)])\n",
    "\n",
    "    for i in range(max_stars):\n",
    "        locs_perm[:, i, :] = locs[seq_tensor, perm[:, i], :]\n",
    "        fluxes_perm[:, i, :] = fluxes[seq_tensor, perm[:, i], :]\n",
    "        \n",
    "    return locs_perm, fluxes_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stamp_logit_loc_mean, stamp_log_flux_mean = permute_params(stamp_logit_loc_mean, stamp_log_flux_mean, perm)\n",
    "stamp_logit_loc_log_var, stamp_log_flux_log_var = \\\n",
    "    permute_params(stamp_logit_loc_log_var, stamp_log_flux_log_var, perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check same patterning of nonzero entries: true because we conditioned on the true number of stars\n",
    "assert ((stamp_logit_loc_mean != 0).float() == (true_subimage_locs != 0).float()).all()\n",
    "assert ((stamp_log_flux_mean != 0).float() == (true_subimage_fluxes != 0).float()).all()\n",
    "\n",
    "true_subimage_logit_locs = utils._logit(true_subimage_locs) * (true_subimage_locs != 0).float()\n",
    "true_subimage_log_fluxes = torch.log(true_subimage_fluxes + 1e-16) * (true_subimage_fluxes != 0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stamp_logit_loc_mean.flatten()[stamp_logit_loc_mean.flatten() != 0].detach().numpy(), \n",
    "         true_subimage_logit_locs.flatten()[true_subimage_logit_locs.flatten() != 0].numpy(), '+')\n",
    "\n",
    "plt.plot(true_subimage_logit_locs.flatten()[stamp_logit_loc_mean.flatten() != 0].detach().numpy(), \n",
    "         true_subimage_logit_locs.flatten()[true_subimage_logit_locs.flatten() != 0].numpy(), '-')\n",
    "\n",
    "plt.xlabel('estimated')\n",
    "plt.ylabel('truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stamp_log_flux_mean.flatten()[stamp_log_flux_mean.flatten() != 0].detach().numpy(), \n",
    "         true_subimage_log_fluxes.flatten()[stamp_log_flux_mean.flatten() != 0].numpy(), '+')\n",
    "\n",
    "plt.plot(true_subimage_log_fluxes.flatten()[stamp_log_flux_mean.flatten() != 0].detach().numpy(), \n",
    "         true_subimage_log_fluxes.flatten()[stamp_log_flux_mean.flatten() != 0].numpy(), '-')\n",
    "\n",
    "plt.xlabel('estimated')\n",
    "plt.ylabel('truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore_locs = (stamp_logit_loc_mean.flatten()[stamp_logit_loc_mean.flatten() != 0] - \\\n",
    "            true_subimage_logit_locs.flatten()[true_subimage_logit_locs.flatten() != 0]) / \\\n",
    "            torch.exp(0.5 * stamp_logit_loc_log_var.flatten()[true_subimage_logit_locs.flatten() != 0])\n",
    "    \n",
    "zscore_fluxes = (stamp_log_flux_mean.flatten()[stamp_log_flux_mean.flatten() != 0] - \\\n",
    "            true_subimage_log_fluxes.flatten()[true_subimage_log_fluxes.flatten() != 0]) / \\\n",
    "            torch.exp(0.5 * stamp_log_flux_log_var.flatten()[stamp_log_flux_log_var.flatten() != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# zscores for logit locations\n",
    "n, bins, patches = axarr[0].hist(zscore_locs.detach().clamp(max = 10), bins = 100, density = True); \n",
    "\n",
    "normal = torch.distributions.normal.Normal(loc=0, scale = 1)\n",
    "normal_pdf = torch.exp(normal.log_prob(torch.Tensor(bins)))\n",
    "\n",
    "axarr[0].plot(bins, normal_pdf.numpy(), color = 'red', linewidth = 2)\n",
    "\n",
    "axarr[0].set_xlabel('z-score', size = 16)\n",
    "axarr[0].set_ylabel('density', size = 16)\n",
    "axarr[0].set_title('z-score for logit-locations', size = 16)\n",
    "\n",
    "# zscore for log fluxes\n",
    "n, bins, patches = axarr[1].hist(zscore_fluxes.detach(), bins = 100, density = True); \n",
    "\n",
    "normal = torch.distributions.normal.Normal(loc=0, scale = 1)\n",
    "normal_pdf = torch.exp(normal.log_prob(torch.Tensor(bins)))\n",
    "\n",
    "axarr[1].plot(bins, normal_pdf.numpy(), color = 'red', linewidth = 2)\n",
    "\n",
    "axarr[1].set_xlabel('z-score', size = 16)\n",
    "axarr[1].set_ylabel('density', size = 16)\n",
    "axarr[1].set_title('z-score for log-fluxes', size = 16)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if save_figs: \n",
    "    fig.savefig('../../qualifying_exam_slides/figures/zscores.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_locs_full_image, sampled_fluxes_full_image, sampled_n_stars_full = \\\n",
    "    star_encoder2.sample_star_encoder(full_image.unsqueeze(0), \n",
    "                                    full_background.unsqueeze(0), \n",
    "                                    return_map = Fa, \n",
    "                                    n_samples = 300)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_n_stars_full2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = sampled_locs_full_image.shape[0]\n",
    "completeness_sampled = torch.zeros(n_samples)\n",
    "tpr_sampled = torch.zeros(n_samples)\n",
    "\n",
    "for i in range(300): \n",
    "    my_completeness1, my_tpr1, my_complete_bool1, my_tpr_bool = \\\n",
    "        image_statistics_lib.get_summary_stats(sampled_locs_full_image[i], \n",
    "                                               true_locs, \n",
    "                                               full_image.shape[-1], \n",
    "                                               sampled_fluxes_full_image[i][:, 0], \n",
    "                                               true_fluxes[:, 0])\n",
    "\n",
    "    completeness_sampled[i] = my_completeness1\n",
    "    tpr_sampled[i] = my_tpr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness_sampled.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_sampled.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portillos posterior samples \n",
    "\n",
    "fluxes = chain_results['f'][0, -300:, ] * fudge_factor\n",
    "\n",
    "x1_loc = chain_results['x'][-300:, ]\n",
    "x0_loc = chain_results['y'][-300:, ]\n",
    "\n",
    "\n",
    "fluxes = fluxes * (fluxes > fmin)\n",
    "\n",
    "x0_loc = x0_loc * (fluxes[:, :] > fmin)\n",
    "x1_loc = x1_loc * (fluxes[:, :] > fmin)\n",
    "\n",
    "portillos_est_locs = torch.Tensor([x0_loc, x1_loc]).transpose(0, 2).transpose(0, 1) / (full_image.shape[-1] - 1)\n",
    "portillos_est_fluxes = torch.Tensor(fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stars = (portillos_est_fluxes > 0).sum(1)\n",
    "\n",
    "portillos_recon_mean = simulator1.draw_image_from_params(locs = portillos_est_locs[0:2], \n",
    "                                                            fluxes = portillos_est_fluxes[0:2].unsqueeze(2),\n",
    "                                                             n_stars = n_stars[0:2],  \n",
    "                                                             add_noise = False).squeeze(0)\n",
    "\n",
    "plt.matshow(portillos_recon_mean[1, 0]); \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(2, 2, figsize=(8, 6.5))\n",
    "\n",
    "x0_vec = [53, 31, 41, 32]\n",
    "x1_vec = [70, 83, 23, 64]\n",
    "\n",
    "\n",
    "for i in range(4): \n",
    "    x0 = x0_vec[i]\n",
    "    x1 = x1_vec[i]\n",
    "    subimage_slen = 10\n",
    "    \n",
    "    # posterior samples\n",
    "    _sampled_locs = portillos_est_locs * (full_image.shape[-1] - 1)\n",
    "    which_locs = (_sampled_locs[:, :, 0] > x0) & \\\n",
    "                    (_sampled_locs[:, :, 0] < (x0 + subimage_slen - 1)) & \\\n",
    "                    (_sampled_locs[:, :, 1] > x1) & \\\n",
    "                    (_sampled_locs[:, :, 1] < (x1 + subimage_slen - 1))\n",
    "    sampled_locs = (_sampled_locs[which_locs, :] - torch.Tensor([[[x0, x1]]])) \n",
    "    axarr[i // 2, i % 2].scatter(sampled_locs[:, :, 1].flatten(), \n",
    "                                 sampled_locs[:, :, 0].flatten(), \n",
    "                                 color = 'r', marker = 'x', alpha = 0.1)\n",
    "\n",
    "    # map estimates\n",
    "    plotting_utils.plot_subimage(axarr[i // 2, i % 2], full_image[0], \n",
    "                                         None, \n",
    "                                         true_locs, \n",
    "                                         x0_vec[i], \n",
    "                                         x1_vec[i], subimage_slen = 10, \n",
    "                                        add_colorbar = True, \n",
    "                                         global_fig = fig, color = 'green')\n",
    "    \n",
    "    \n",
    "#     axarr[i // 2, i % 2].set_title('observed; coords: {}\\n'.format([x0, x1]));\n",
    "        \n",
    "    # axarr[i // 2, i % 2].set_title();\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../../qualifying_exam_slides/figures/sample_figures_port_posterior_samples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = portillos_est_fluxes.shape[0]\n",
    "completeness_sampled = torch.zeros(n_samples)\n",
    "tpr_sampled = torch.zeros(n_samples)\n",
    "\n",
    "for i in range(n_samples): \n",
    "    my_completeness1, my_tpr1, my_complete_bool1, my_tpr_bool = \\\n",
    "        image_statistics_lib.get_summary_stats(portillos_est_locs[i], \n",
    "                                               true_locs, \n",
    "                                               full_image.shape[-1], \n",
    "                                               portillos_est_fluxes[i], \n",
    "                                               true_fluxes[:, 0])\n",
    "\n",
    "    completeness_sampled[i] = my_completeness1\n",
    "    tpr_sampled[i] = my_tpr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness_sampled.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_sampled.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(portillos_est_fluxes > 0).sum(1).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results at center of cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(sdss_hubble_data.sdss_image_full[0][870:970, 160:260])\n",
    "plt.savefig('../../qualifying_exam_slides/figures/sdss_image_center.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_hubble_data_center = sdss_dataset_lib.SDSSHubbleData(bands = bands, x0 = 870, x1 = 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sdss_hubble_data_center.fluxes > 1000.).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(sdss_hubble_data_center.sdss_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_locs, map_fluxes, map_n_stars = \\\n",
    "    star_encoder2.sample_star_encoder(full_image=sdss_hubble_data_center.sdss_image.unsqueeze(0), \n",
    "                                 full_background=sdss_hubble_data_center.sdss_background.unsqueeze(0), \n",
    "                                     return_map = True)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_mean = simulator.draw_image_from_params(locs = map_locs, \n",
    "                                                fluxes = map_fluxes,\n",
    "                                                 n_stars = map_n_stars, \n",
    "                                                 add_noise = False).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = recon_mean - sdss_hubble_data_center.sdss_image\n",
    "plt.matshow(foo[0], vmax = foo.abs().max(), vmin = foo.abs().max() * -1, cmap = plt.get_cmap('bwr'))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(2, 2, figsize=(8, 6.5))\n",
    "\n",
    "for i in range(4): \n",
    "    x0 = int(np.random.choice(90, 1))\n",
    "    x1 = int(np.random.choice(90, 1))\n",
    "    subimage_slen = 10\n",
    "    \n",
    "    plotting_utils.plot_subimage(axarr[i // 2, i % 2], full_image[0], \n",
    "                             None, # map_locs.squeeze(), \n",
    "                             sdss_hubble_data_center.locs[sdss_hubble_data_center.fluxes[:, 0] > 10000.], \n",
    "                             x0, \n",
    "                             x1, subimage_slen = 10, \n",
    "                            add_colorbar = True, \n",
    "                             global_fig = fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ROC curves on image stamps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stamps, _, _, \\\n",
    "    subimage_n_stars, _ = \\\n",
    "        star_encoder1.get_image_stamps(full_image.unsqueeze(0), \n",
    "                                       true_locs.unsqueeze(0), \n",
    "                                       true_fluxes.unsqueeze(0))\n",
    "        \n",
    "background_stamps = star_encoder1.get_image_stamps(full_background.unsqueeze(0),\n",
    "                            locs = None, fluxes = None, trim_images = False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(subimage_n_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs1 = star_encoder1(image_stamps, background_stamps)[4]\n",
    "probs1 = torch.exp(log_probs1)\n",
    "\n",
    "is_on_probs1 = 1 - probs1[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_curve(is_on_probs, true_n_stars, seq): \n",
    "    tpr_vec = torch.zeros(seq.shape)\n",
    "    fpr_vec = torch.zeros(seq.shape)\n",
    "    for i in range(len(seq)): \n",
    "        true_positives = (is_on_probs >= seq[i]) & (true_n_stars > 0)\n",
    "        tpr_vec[i] = true_positives.float().sum() / (true_n_stars > 0).float().sum()\n",
    "        \n",
    "        false_positives = (is_on_probs >= seq[i]) & (true_n_stars == 0)\n",
    "        fpr_vec[i] = false_positives.float().sum() / (true_n_stars == 0).float().sum()\n",
    "        \n",
    "    return tpr_vec, fpr_vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_vec1, fpr_vec1 = get_roc_curve(is_on_probs1, subimage_n_stars, torch.arange(0, 1.05, step = 0.05))\n",
    "\n",
    "log_probs2 = star_encoder2(image_stamps, background_stamps)[4]\n",
    "probs2 = torch.exp(log_probs2)\n",
    "\n",
    "is_on_probs2 = 1 - probs2[:, 0]\n",
    "\n",
    "tpr_vec2, fpr_vec2 = get_roc_curve(is_on_probs2, subimage_n_stars, torch.arange(0, 1.05, step = 0.05))\n",
    "plt.plot(fpr_vec1.numpy(), tpr_vec1.numpy(), '-x', color = 'orange')\n",
    "plt.plot(fpr_vec2.numpy(), tpr_vec2.numpy(), '-x', color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities for portillos ... \n",
    "# we need to full chain here\n",
    "\n",
    "port_flux_samples = chain_results['f'][0, -500:, :] * fudge_factor\n",
    "\n",
    "x1_loc = chain_results['x'][-500:, ] * (port_flux_samples > fmin)\n",
    "x0_loc = chain_results['y'][-500:, ] * (port_flux_samples > fmin)\n",
    "    \n",
    "        \n",
    "port_locs_samples = torch.Tensor(np.stack([x0_loc, x1_loc], 2)) / (full_image.shape[-1] - 1)\n",
    "port_flux_samples = torch.Tensor(port_flux_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check one sample, make sure I loaded this correctly \n",
    "portillos_recon_mean = simulator.draw_image_from_params(locs = port_locs_samples[0:1], \n",
    "                                                fluxes = port_flux_samples[0:1].unsqueeze(2),\n",
    "                                                 n_stars = (port_flux_samples > 0).sum(1)[0:1],  \n",
    "                                                 add_noise = False).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = ((portillos_recon_mean - full_image[0]) / full_image[0])[5:95, 5:95]\n",
    "plt.matshow(foo, vmax = foo.abs().max(), vmin = -foo.abs().max(), cmap = plt.get_cmap('bwr'))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_n_stars_sampled = torch.zeros(port_locs_samples.shape[0], star_encoder1.tile_coords.shape[0])\n",
    "\n",
    "# doing it all at once freezes my laptop ... \n",
    "for i in range(port_sampled_locs.shape[0]): \n",
    "    port_n_stars_sampled[i] = image_utils.get_params_in_patches(star_encoder1.tile_coords,\n",
    "                                          port_locs_samples[i:(i+1)],\n",
    "                                          port_flux_samples[i:(i+1)].unsqueeze(2),\n",
    "                                          star_encoder1.full_slen,\n",
    "                                          star_encoder1.stamp_slen,\n",
    "                                          star_encoder1.edge_padding)[2]\n",
    "    \n",
    "    if(i % 50 == 0): \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(port_n_stars_sampled.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_on_probs_port = (port_n_stars_sampled > 0).float().mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_on_probs_port[is_on_probs_port > 0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_vec_port, fpr_vec_port = get_roc_curve(is_on_probs_port, n_stars, \n",
    "                                           # torch.arange(0, 1 + 2 / 300, step = 1/300))\n",
    "                                           torch.arange(0, 1.06, step = 1/500))\n",
    "\n",
    "plt.plot(fpr_vec_port.numpy(), tpr_vec_port.numpy(), '-x')\n",
    "plt.plot(fpr_vec1.numpy(), tpr_vec1.numpy(), '-x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fpr_vec1.numpy(), tpr_vec1.numpy(), '-x', color = 'orange', label = 'sleep only')\n",
    "plt.plot(fpr_vec2.numpy(), tpr_vec2.numpy(), '-x', color = 'red', label = 'wake-sleep')\n",
    "plt.plot(fpr_vec_port.numpy(), tpr_vec_port.numpy(), '-x', color = 'blue', label = 'Portillos')\n",
    "\n",
    "plt.xlabel('False positive rate', size = 16)\n",
    "plt.ylabel('True positive rate', size = 16)\n",
    "plt.legend()\n",
    "\n",
    "if save_fig: \n",
    "    plt.savefig('../../qualifying_exam_slides/figures/roc_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Band misalignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_hubble_data_bands = sdss_dataset_lib.SDSSHubbleData(bands = [2, 3], align_bands = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "im0 = axarr[0].matshow(sdss_hubble_data_bands.sdss_image[0])\n",
    "fig.colorbar(im0, ax = axarr[0])\n",
    "axarr[0].set_title('r band image \\n', size = 16)\n",
    "\n",
    "im1 = axarr[1].matshow(sdss_hubble_data_bands.sdss_image[1])\n",
    "fig.colorbar(im1, ax = axarr[1])\n",
    "axarr[1].set_title('i band image \\n', size = 16)\n",
    "\n",
    "\n",
    "diff = sdss_hubble_data_bands.sdss_image[0] - sdss_hubble_data_bands.sdss_image[1]\n",
    "im2 = axarr[2].matshow(diff, vmax = diff.abs().max(), vmin = -diff.abs().max(), cmap = plt.get_cmap('bwr'))\n",
    "fig.colorbar(im2, ax = axarr[2])\n",
    "axarr[2].set_title('r - i \\n', size = 16)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('../../qualifying_exam_slides/figures/misaligned_bands.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_hubble_data_center = sdss_dataset_lib.SDSSHubbleData(x0 = 870, x1 = 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(sdss_hubble_data_center.sdss_image[0])\n",
    "plt.colorbar()\n",
    "plt.savefig('../../qualifying_exam_slides/figures/sdss_image_center.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(sdss_hubble_data.sdss_image_full[0, 900:950, 180:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "for i in range(3): \n",
    "    x0 = int(np.random.choice(90))\n",
    "    x1 = int(np.random.choice(90))\n",
    "    \n",
    "    plotting_utils.plot_subimage(axarr[i], sdss_hubble_data_center.sdss_image[0], \n",
    "                                     None, \n",
    "                                     None, \n",
    "                                     x0, x1, \n",
    "                                     subimage_slen = 10, \n",
    "                                    add_colorbar = True, \n",
    "                                     global_fig = fig)\n",
    "fig.tight_layout()\n",
    "# if save_figs: \n",
    "#     plt.savefig('../../qualifying_exam_slides/figures/forward_kl_better.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdss_hubble_data_bands"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_star_patches(full_image, true_locs, which_stars, subimage_slen):\n",
    "    \n",
    "    assert len(full_image.shape) == 4\n",
    "    assert (true_locs >= 0).all() & (true_locs <= 1).all()\n",
    "    assert len(true_locs.shape) == 2\n",
    "    \n",
    "    slen0 = full_image.shape[-2]\n",
    "    slen1 = full_image.shape[-1]\n",
    "    \n",
    "    which_locs = true_locs[which_stars]\n",
    "    \n",
    "    star_patches = torch.zeros(which_locs.shape[0], subimage_slen, subimage_slen)\n",
    "    patch_coords = torch.zeros(which_locs.shape[0], 2)\n",
    "    \n",
    "    is_blended = torch.zeros(which_locs.shape[0])\n",
    "    \n",
    "    for i in range(which_stars.shape[0]):\n",
    "        loc_i = which_locs[i] * torch.Tensor([slen0 - 1., slen1 - 1.])\n",
    "\n",
    "        which_pix = loc_i.round().type(torch.long)\n",
    "\n",
    "        x0 = int(which_pix[0] - (subimage_slen - 1) / 2)\n",
    "        x1 = int(which_pix[1] - (subimage_slen - 1) / 2)\n",
    "        \n",
    "        assert x0 > 0\n",
    "        assert x1 > 0\n",
    "        assert (x0 + subimage_slen) < slen0\n",
    "        assert (x1 + subimage_slen) < slen1\n",
    "        \n",
    "        star_patches[i] = full_image[0, 0, x0:(x0 + subimage_slen), x1:(x1 + subimage_slen)]\n",
    "        patch_coords[i] = torch.Tensor([x0, x1])\n",
    "        \n",
    "        if (star_patches[i, int((subimage_slen - 1) / 2), \n",
    "                            int((subimage_slen - 1) / 2)]) < star_patches[i].max(): \n",
    "            is_blended[i] = 1\n",
    "        \n",
    "        \n",
    "    return star_patches, patch_coords, is_blended"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.hist(torch.log10(true_fluxes.squeeze()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "which_stars = torch.nonzero((torch.log10(true_fluxes.squeeze()) > 5.0) & \n",
    "                           (true_locs[:, 0] < 0.95) & (true_locs[:, 1] < 0.95) & \n",
    "                           (true_locs[:, 0] > 0.05) & (true_locs[:, 1] > 0.05)).squeeze()\n",
    "\n",
    "canon_slen = 7"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "star_patches, patch_coords, is_blended = \\\n",
    "    get_star_patches(full_image.unsqueeze(0), true_locs, which_stars, canon_slen)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "star_patches = star_patches[is_blended == 0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "star_patches_normed = star_patches / \\\n",
    "    star_patches.view(star_patches.shape[0], -1).sum(1).unsqueeze(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(star_patches.shape[0]): \n",
    "    plt.matshow(star_patches_normed[i])\n",
    "    plt.colorbar()\n",
    "    \n",
    "    if i > 10: \n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "canonical_star = star_patches_normed.mean(0).numpy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.matshow(canonical_star); plt.colorbar()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "psf0 = simulated_datasets_lib._trim_psf(psf_r[None], 7)[0]\n",
    "psf0 = psf0 / psf0.sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.matshow(psf1 - psf0); plt.colorbar()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "foo = torch.Tensor(psf0 - canonical_star)\n",
    "plt.matshow(foo, vmax = foo.abs().max(), vmin = -foo.abs().max(), cmap = plt.get_cmap('bwr')); \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import psf_transform_lib"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "psf_transform = psf_transform_lib.PsfLocalTransform(torch.Tensor(psf_og),\n",
    "                                    full_image.shape[-1], \n",
    "                                    kernel_size = 3)\n",
    "\n",
    "psf_transform.load_state_dict(torch.load('../fits/results_11202019/wake-sleep_630x310_r-psf_transform-iter5', \n",
    "                                             map_location=lambda storage, loc: storage))\n",
    "    \n",
    "psf1 = psf_transform.forward().detach().numpy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "psf1 = simulated_datasets_lib._trim_psf(psf1, canon_slen)[0]\n",
    "psf1 = psf1 / psf1.sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "foo = torch.Tensor(psf1 - canonical_star)\n",
    "plt.matshow(foo, vmax = foo.abs().max(), vmin = -foo.abs().max(), cmap = plt.get_cmap('bwr')); \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "profilex_canon = canonical_star.sum(0)\n",
    "profilex_og = psf0.sum(0)\n",
    "profilex_train = psf1.sum(0)\n",
    "\n",
    "profiley_canon = canonical_star.sum(1)\n",
    "profiley_og = psf0.sum(1)\n",
    "profiley_train = psf1.sum(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_x = np.arange(- (canon_slen - 1) / 2, (canon_slen + 1) / 2)\n",
    "fx_canon = interp1d(_x, profilex_canon, kind = 'cubic')\n",
    "fx_og = interp1d(_x, profilex_og, kind = 'cubic')\n",
    "fx_train = interp1d(_x, profilex_train, kind = 'cubic')\n",
    "\n",
    "fy_canon = interp1d(_x, profiley_canon, kind = 'cubic')\n",
    "fy_og = interp1d(_x, profiley_og, kind = 'cubic')\n",
    "fy_train = interp1d(_x, profiley_train, kind = 'cubic')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = np.linspace(- (canon_slen - 1) / 2, (canon_slen - 1) / 2, 100)\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axarr[0].scatter(_x, profilex_canon, color = 'b', marker = 'x', label = 'canonical')\n",
    "axarr[0].scatter(_x, profilex_og, color = 'r', marker = 'x', label = 'sdss psf')\n",
    "axarr[0].scatter(_x, profilex_train, color = 'g', marker = 'x', label = 'trans psf')\n",
    "\n",
    "axarr[0].plot(x, fx_canon(x), color = 'b', alpha = 0.5)\n",
    "axarr[0].plot(x, fx_og(x), color = 'r', alpha = 0.5)\n",
    "axarr[0].plot(x, fx_train(x), color = 'g', alpha = 0.5)\n",
    "\n",
    "axarr[0].legend()\n",
    "axarr[0].set_title('x-coordinate star profile', fontsize = 16)\n",
    "\n",
    "axarr[1].scatter(_x, profiley_canon, color = 'b', marker = 'x', label = 'canonical')\n",
    "axarr[1].scatter(_x, profiley_og, color = 'r', marker = 'x', label = 'sdss psf')\n",
    "axarr[1].scatter(_x, profiley_train, color = 'g', marker = 'x', label = 'trans psf')\n",
    "\n",
    "axarr[1].plot(x, fy_canon(x), color = 'b', alpha = 0.5)\n",
    "axarr[1].plot(x, fy_og(x), color = 'r', alpha = 0.5)\n",
    "axarr[1].plot(x, fy_train(x), color = 'g', alpha = 0.5)\n",
    "\n",
    "axarr[1].legend()\n",
    "axarr[1].set_title('x-coordinate star profile', fontsize = 16)\n",
    "\n",
    "\n",
    "for i in range(2): \n",
    "    axarr[i].set_xlabel('pixel coordinate', fontsize = 14)\n",
    "    axarr[i].set_ylabel('normalized brightness', fontsize = 14)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_04)",
   "language": "python",
   "name": "pytorch_update"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
