---
defaults:
    - _self_

# completely disable hydra logging
# https://github.com/facebookresearch/hydra/issues/910
hydra:
    output_subdir: null
    run:
        dir: .

mode: train

paths:
    root: ${oc.env:BLISS_HOME}
    data: ${paths.root}/data
    sdss: ${paths.data}/sdss
    decals: ${paths.data}/decals
    output: ${paths.root}/output
    pretrained_models: ${paths.data}/pretrained_models

simulator:
    _target_: bliss.simulator.simulated_dataset.SimulatedDataset
    n_batches: 128
    valid_n_batches: 10  # 256
    fix_validation_set: true
    num_workers: 32
    sdss_fields:  # Used in simulator for sampling backgrounds and PSFs for decoder
        dir: ${paths.sdss}
        bands: [2]
        field_list:  # list of dictionaries, each with run, camcol, and list of fields
          - run: 94
            camcol: 1
            fields: [12]
    prior:
        _target_: bliss.simulator.prior.ImagePrior
        sdss_fields: ${simulator.sdss_fields}
        n_tiles_h: 20
        n_tiles_w: 20
        tile_slen: 4
        batch_size: 64
        max_sources: 1
        mean_sources: 0.2
        min_sources: 0
        prob_galaxy: 0.72
        star_flux_min: 622
        star_flux_max: 1e6
        star_flux_alpha: 0.43
        galaxy_flux_min: 622.0
        galaxy_flux_max: 1e6
        galaxy_alpha: 0.47
        galaxy_a_concentration: 0.39330758068481686
        galaxy_a_loc: 0.8371888967872619
        galaxy_a_scale: 4.432725319432478
        galaxy_a_bd_ratio: 2.0
    decoder:
        _target_: bliss.simulator.decoder.ImageDecoder
        pixel_scale: 0.396
        psf_slen: 25
        sdss_fields: ${simulator.sdss_fields}
    background:
        _target_: bliss.simulator.background.SimulatedSDSSBackground
        sdss_fields: ${simulator.sdss_fields}

cached_simulator:
    _target_: bliss.simulator.simulated_dataset.CachedSimulatedDataset
    batch_size: ${generate.batch_size} # 128 for large cached
    num_workers: 0
    cached_data_path: ${generate.cached_data_path}
    file_prefix: ${generate.file_prefix}
    val_split_file_idxs: null # inclusive range
    test_split_file_idxs: null # inclusive range

encoder:
    _target_: bliss.encoder.Encoder
    bands: [2]
    tile_slen: ${simulator.prior.tile_slen}
    tiles_to_crop: 1
    slack: 1.0
    optimizer_params:
        lr: 1e-3
    scheduler_params:
        milestones: [32]
        gamma: 0.1
    input_transform_params:
        use_deconv_channel: false
        concat_psf_params: false
    architecture:
        # this architecture is based on yolov5l.yaml, see
        # https://github.com/ultralytics/yolov5/blob/master/models/yolov5l.yaml
        depth_multiple: 1.0  # model depth multiple
        width_multiple: 1.0  # layer channel multiple
        anchors:
            - [4, 4]  # P3/8
        backbone: [
            # [from, number, module, args]
            [-1, 1, Conv, [64, 5, 1]],
            [-1, 3, Conv, [64, 1, 1]],
            [-1, 1, Conv, [128, 3, 2]],
            [-1, 1, Conv, [128, 3, 1]],
            [-1, 1, Conv, [256, 3, 2]],
            [-1, 6, C3, [256]],
            [-1, 1, Conv, [512, 3, 2]],
            [-1, 9, C3, [512]],
            [-1, 1, Conv, [1024, 3, 2]],
            [-1, 3, C3, [1024]],
            [-1, 1, SPPF, [1024, 5]],
        ]
        head: [
            [-1, 1, Conv, [512, 1, 1]],
            [-1, 1, nn.Upsample, [None, 2, 'nearest']],
            [[-1, 6], 1, Concat, [1]],
            [-1, 3, C3, [512, false]],
            [-1, 1, Conv, [256, 1, 1]],
            [-1, 1, nn.Upsample, [None, 2, 'nearest']],
            [[-1, 4, 5], 1, Concat, [1]],
            [-1, 3, C3, [256, false]],
            [[17], 1, Detect, [nc, anchors]],
        ]

generate:
    n_workers_per_process: 0
    n_batches: ${simulator.n_batches}
    batch_size: ${simulator.prior.batch_size}
    max_images_per_file: 5000
    cached_data_path: ${paths.data}/cached_dataset
    file_prefix: dataset
    files_start_idx: 0

training:
    name: null
    version: null
    n_epochs: 50
    save_top_k: 1
    enable_early_stopping: true
    patience: 3
    pretrained_weights: null
    trainer:
        _target_: pytorch_lightning.Trainer
        logger: true
        enable_checkpointing: true
        profiler: null
        reload_dataloaders_every_n_epochs: 0
        check_val_every_n_epoch: 10
        log_every_n_steps: 10  # corresponds to n_batches
        max_epochs: ${training.n_epochs}
        min_epochs: 1
        accelerator: "gpu"
        devices: 1
    testing:
        file: null
        batch_size: 32
        num_workers: 0
    seed: 42
    weight_save_path: null
    use_cached_simulator: false

predict:
    dataset:
        _target_: bliss.surveys.sdss.SloanDigitalSkySurvey
        sdss_dir: ${paths.sdss}
        run: 94
        camcol: 1
        fields: [12]
        bands: [2]
        predict_device: ${predict.device}
        predict_crop: ${predict.crop}
    photo_catalog:
        _target_: bliss.surveys.sdss.PhotoFullCatalog
        sdss_dir: ${paths.sdss}
        run: ${predict.dataset.run}
        camcol: ${predict.dataset.camcol}
        fields: ${predict.dataset.fields}
        bands: ${predict.dataset.bands}
    trainer: ${training.trainer}
    encoder: ${encoder}
    weight_save_path: ${paths.pretrained_models}/sdss.pt
    device: "cuda:0"
    crop:
        do_crop: true
        left_upper_corner: [160, 160]
        width: 640
        height: 640
    plot:
        show_plot: true
        width: 1000
        height: 1000
        out_file_name: ${paths.output}/predict.html
    is_simulated: false
