---
defaults:
    - _self_
    - override /hydra/job_logging: stdout

# completely disable hydra logging
# https://github.com/facebookresearch/hydra/issues/910
hydra:
    output_subdir: null
    run:
        dir: .

mode: train

paths:
    root: ${oc.env:BLISS_HOME}
    data: ${paths.root}/data
    sdss: ${paths.data}/sdss
    decals: ${paths.data}/decals
    output: ${paths.root}/output
    pretrained_models: ${paths.data}/pretrained_models

simulator:
    _target_: bliss.simulator.simulated_dataset.SimulatedDataset
    survey: ${surveys.sdss}
    n_batches: 128
    num_workers: 32
    valid_n_batches: 10  # 256
    fix_validation_set: true
    prior:
        _target_: bliss.simulator.prior.CatalogPrior
        reference_band: 2  # r-band
        n_bands: ${simulator.survey.n_bands}
        star_color_model_path: ${simulator.survey.dir_path}/color_models/star_gmm_nmgy.pkl
        gal_color_model_path: ${simulator.survey.dir_path}/color_models/gal_gmm_nmgy.pkl
        n_tiles_h: 20
        n_tiles_w: 20
        tile_slen: 4
        batch_size: 64
        max_sources: 1
        mean_sources: 0.2
        min_sources: 0
        prob_galaxy: 0.72
        star_flux_min: 0.63094948
        star_flux_max: 1014
        star_flux_alpha: 0.43
        galaxy_flux_min: 0.6301037
        galaxy_flux_max: 1013
        galaxy_alpha: 0.47
        galaxy_a_concentration: 0.39330758068481686
        galaxy_a_loc: 0.8371888967872619
        galaxy_a_scale: 4.432725319432478
        galaxy_a_bd_ratio: 2.0

cached_simulator:
    _target_: bliss.simulator.simulated_dataset.CachedSimulatedDataset
    batch_size: ${generate.batch_size} # 128 for large cached
    splits: 0:80/80:90/90:100
    num_workers: 0
    cached_data_path: ${generate.cached_data_path}
    file_prefix: ${generate.file_prefix}
    bands: [0, 1, 2, 3, 4]

encoder:
    _target_: bliss.encoder.Encoder
    bands: [0, 1, 2, 3, 4]
    tile_slen: ${simulator.prior.tile_slen}
    tiles_to_crop: 1
    slack: 1.0
    min_flux_threshold: 0  # default 0 to take all sources
    optimizer_params:
        lr: 1e-3
    scheduler_params:
        milestones: [32]
        gamma: 0.1
    input_transform_params:
        use_deconv_channel: false
        concat_psf_params: false
        z_score: true
    architecture:
        # this architecture is based on yolov5l.yaml, see
        # https://github.com/ultralytics/yolov5/blob/master/models/yolov5l.yaml
        depth_multiple: 1.0  # model depth multiple
        width_multiple: 1.0  # layer channel multiple
        anchors:
            - [4, 4]  # P3/8
        backbone: [
            # [from, number, module, args]
            [-1, 1, Conv, [64, 5, 1]],
            [-1, 3, Conv, [64, 1, 1]],
            [-1, 1, Conv, [128, 3, 2]],
            [-1, 1, Conv, [128, 3, 1]],
            [-1, 1, Conv, [256, 3, 2]],
            [-1, 6, C3, [256]],
            [-1, 1, Conv, [512, 3, 2]],
            [-1, 9, C3, [512]],
            [-1, 1, Conv, [1024, 3, 2]],
            [-1, 3, C3, [1024]],
            [-1, 1, SPPF, [1024, 5]],
        ]
        head: [
            [-1, 1, Conv, [512, 1, 1]],
            [-1, 1, nn.Upsample, [None, 2, 'nearest']],
            [[-1, 6], 1, Concat, [1]],
            [-1, 3, C3, [512, false]],
            [-1, 1, Conv, [256, 1, 1]],
            [-1, 1, nn.Upsample, [None, 2, 'nearest']],
            [[-1, 4, 5], 1, Concat, [1]],
            [-1, 3, C3, [256, false]],
            [[17], 1, Detect, [nc, anchors]],
        ]

generate:
    n_workers_per_process: 0
    n_batches: ${simulator.n_batches}
    batch_size: ${simulator.prior.batch_size}
    max_images_per_file: 4096
    cached_data_path: ${paths.data}/cached_dataset
    file_prefix: dataset

training:
    name: null
    version: null
    n_epochs: 50
    save_top_k: 1
    enable_early_stopping: true
    patience: 3
    pretrained_weights: null
    trainer:
        _target_: pytorch_lightning.Trainer
        logger: true
        enable_checkpointing: true
        profiler: null
        reload_dataloaders_every_n_epochs: 0
        check_val_every_n_epoch: 10
        log_every_n_steps: 10  # corresponds to n_batches
        max_epochs: ${training.n_epochs}
        min_epochs: 1
        accelerator: "gpu"
        devices: 1
    testing: true
    seed: 42
    weight_save_path: null
    use_cached_simulator: false

predict:
    dataset: ${surveys.sdss}
    trainer: ${training.trainer}
    encoder: ${encoder}
    weight_save_path: ${paths.pretrained_models}/zscore_five_band.pt
    device: "cuda:0"
    crop:
        do_crop: true
        left_upper_corner: [160, 160]
        width: 640
        height: 640
    plot:
        show_plot: true
        width: 1000
        height: 1000
        out_file_name: ${paths.output}/predict.html
    is_simulated: false

surveys:
    sdss:
        _target_: bliss.surveys.sdss.SloanDigitalSkySurvey
        dir_path: ${paths.sdss}
        fields:  # TODO: better arbitary name for fields/bricks?
            - run: 94
              camcol: 1
              fields: [12]
        psf_config:
            pixel_scale: 0.396
            psf_slen: 25
        n_bands: 5
    decals:
        _target_: bliss.surveys.decals.DarkEnergyCameraLegacySurvey
        decals_dir: ${paths.decals}
        sky_coords: # in degrees
            # brick '3366m010' corresponds to SDSS RCF 94-1-12
            - ra: 336.6643042496718
              dec: -0.9316385797930247
        bands: ${encoder.bands}
        reference_band: 1 # DECaLS r-band, DECaLS-indexed (via header)
