---
defaults:
    - _self_
    - override /hydra/job_logging: stdout

# completely disable hydra logging
# https://github.com/facebookresearch/hydra/issues/910
hydra:
    output_subdir: null
    run:
        dir: .

paths:
    sdss: /data/scratch/sdss
    des: /data/scratch/des
    dc2: /data/scratch/dc2local
    cached_data: /data/scratch/regier/sdss_like
    output: ${oc.env:HOME}/bliss_output

# this prior is sdss-like; the flux parameters were fit using SDSS catalogs
prior:
    _target_: bliss.simulator.prior.CatalogPrior
    survey_bands: ["u", "g", "r", "i", "z"]  # SDSS available band filters
    reference_band: 2  # SDSS r-band
    star_color_model_path: ${simulator.decoder.survey.dir_path}/color_models/star_gmm_nmgy.pkl
    gal_color_model_path: ${simulator.decoder.survey.dir_path}/color_models/gal_gmm_nmgy.pkl
    n_tiles_h: 20
    n_tiles_w: 20
    batch_size: 64
    max_sources: 1
    mean_sources: 0.01  # 0.0025 is more realistic for SDSS but training takes more iterations
    min_sources: 0
    prob_galaxy: 0.5144
    star_flux_exponent: 0.4689157382430609
    star_flux_truncation: 613313.768995269
    star_flux_loc: -0.5534648001193676
    star_flux_scale: 1.1846035501201129
    galaxy_flux_exponent: 1.5609458661807678
    galaxy_flux_truncation: 28790.449063519092
    galaxy_flux_loc: -3.29383532288203
    galaxy_flux_scale: 3.924799999613338
    galaxy_a_concentration: 0.39330758068481686
    galaxy_a_loc: 0.8371888967872619
    galaxy_a_scale: 4.432725319432478
    galaxy_a_bd_ratio: 2.0

decoder:
    _target_: bliss.simulator.decoder.Decoder
    tile_slen: 4
    survey: ${surveys.sdss}
    with_dither: true
    with_noise: true

simulator:
    _target_: bliss.simulator.simulated_dataset.SimulatedDataset
    prior: ${prior}
    decoder: ${decoder}
    n_batches: 128
    num_workers: 32
    valid_n_batches: 10  # 256
    fix_validation_set: true

cached_simulator:
    _target_: bliss.cached_dataset.CachedSimulatedDataModule
    batch_size: 64
    splits: 0:80/80:90/90:100  # train/val/test splits as percent ranges
    num_workers: 8
    cached_data_path: ${paths.cached_data}
    train_transforms:
        - _target_: bliss.data_augmentation.RotateFlipTransform
    nontrain_transforms: []

variational_factors:
    - _target_: bliss.encoder.variational_dist.BernoulliFactor
      name: n_sources
      sample_rearrange: null
      nll_rearrange: null
      nll_gating: null
    - _target_: bliss.encoder.variational_dist.TDBNFactor
      name: locs
      sample_rearrange: "b ht wt d -> b ht wt 1 d"
      nll_rearrange: "b ht wt 1 d -> b ht wt d"
      nll_gating: n_sources
    - _target_: bliss.encoder.variational_dist.BernoulliFactor
      name: source_type
      sample_rearrange: "b ht wt -> b ht wt 1 1"
      nll_rearrange: "b ht wt 1 1 -> b ht wt"
      nll_gating: n_sources
    - _target_: bliss.encoder.variational_dist.LogNormalFactor
      name: star_fluxes
      dim: 5
      sample_rearrange: "b ht wt d -> b ht wt 1 d"
      nll_rearrange: "b ht wt 1 d -> b ht wt d"
      nll_gating: is_star
    - _target_: bliss.encoder.variational_dist.LogNormalFactor
      name: galaxy_fluxes
      dim: 5
      sample_rearrange: "b ht wt d -> b ht wt 1 d"
      nll_rearrange: "b ht wt 1 d -> b ht wt d"
      nll_gating: is_galaxy
    - _target_: bliss.encoder.variational_dist.LogitNormalFactor
      name: galaxy_disk_frac
      sample_rearrange: "b ht wt d -> b ht wt 1 d"
      nll_rearrange: "b ht wt 1 1 -> b ht wt 1"
      nll_gating: is_galaxy
    - _target_: bliss.encoder.variational_dist.LogitNormalFactor
      name: galaxy_beta_radians
      high: 3.1415926
      sample_rearrange: "b ht wt d -> b ht wt 1 d"
      nll_rearrange: "b ht wt 1 1 -> b ht wt 1"
      nll_gating: is_galaxy
    - _target_: bliss.encoder.variational_dist.LogitNormalFactor
      name: galaxy_disk_q
      sample_rearrange: "b ht wt d -> b ht wt 1 d"
      nll_rearrange: "b ht wt 1 1 -> b ht wt 1"
      nll_gating: is_galaxy
    - _target_: bliss.encoder.variational_dist.LogNormalFactor
      name: galaxy_a_d
      sample_rearrange: "b ht wt d -> b ht wt 1 d"
      nll_rearrange: "b ht wt 1 1 -> b ht wt 1"
      nll_gating: is_galaxy
    - _target_: bliss.encoder.variational_dist.LogitNormalFactor
      name: galaxy_bulge_q
      sample_rearrange: "b ht wt d -> b ht wt 1 d"
      nll_rearrange: "b ht wt 1 1 -> b ht wt 1"
      nll_gating: is_galaxy
    - _target_: bliss.encoder.variational_dist.LogNormalFactor
      name: galaxy_a_b
      sample_rearrange: "b ht wt d -> b ht wt 1 d"
      nll_rearrange: "b ht wt 1 1 -> b ht wt 1"
      nll_gating: is_galaxy

metrics:
    detection_performance:
        _target_: bliss.encoder.metrics.DetectionPerformance
        mag_bin_cutoffs: [19, 19.4, 19.8, 20.2, 20.6, 21, 21.4, 21.8]
        mag_band: 2
    source_type_accuracy:
        _target_: bliss.encoder.metrics.SourceTypeAccuracy
        flux_bin_cutoffs: [200, 400, 600, 800, 1000]
    flux_error:
        _target_: bliss.encoder.metrics.FluxError
        survey_bands: ${encoder.survey_bands}

image_normalizers:
    psf:
        _target_: bliss.encoder.image_normalizer.PsfAsImage
        num_psf_params: 6  # 6 for SDSS, 4 for DC2, 10 for DES
    clahe:
        _target_: bliss.encoder.image_normalizer.ClaheNormalizer
        min_stdev: 200
    asinh:
        _target_: bliss.encoder.image_normalizer.AsinhQuantileNormalizer
        q: [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99, 0.999, 0.9999, 0.99999]

encoder:
    _target_: bliss.encoder.encoder.Encoder
    survey_bands: ["u", "g", "r", "i", "z"]
    reference_band: 2  # SDSS r-band
    tile_slen: ${simulator.decoder.tile_slen}
    optimizer_params:
        lr: 1e-3
    scheduler_params:
        milestones: [32]
        gamma: 0.1
    image_normalizers: ${image_normalizers}
    var_dist:
        _target_: bliss.encoder.variational_dist.VariationalDist
        tile_slen: ${encoder.tile_slen}
        factors: ${variational_factors}
    matcher:
        _target_: bliss.encoder.metrics.CatalogMatcher
        dist_slack: 1.0
        mag_slack: null
        mag_band: 2  # SDSS r-band
    mode_metrics:
        _target_: torchmetrics.MetricCollection
        _convert_: "partial"
        metrics: ${metrics}
    sample_metrics: null
    sample_image_renders:
        _target_: torchmetrics.MetricCollection
        metrics:
            - _target_: bliss.encoder.sample_image_renders.PlotSampleImages
              frequency: 1
              restrict_batch: 0
              tiles_to_crop: 0
              tile_slen: ${simulator.decoder.tile_slen}
    use_double_detect: false
    use_checkerboard: false

surveys:
    sdss:
        _target_: bliss.surveys.sdss.SloanDigitalSkySurvey
        dir_path: ${paths.sdss}
        fields:  # TODO: better arbitary name for fields/bricks?
            - run: 94
              camcol: 1
              fields: [12]
        psf_config:
            pixel_scale: 0.396
            psf_slen: 25
        load_image_data: false
        # options below only apply to prediction
        align_to_band: null  # should be 2 but it's slower then
        crop_to_bands: null
        crop_to_hw: null

    des:
        _target_: bliss.surveys.des.DarkEnergySurvey
        dir_path: ${paths.des}
        image_ids:
            - sky_coord:
                  ra: 336.6643042496718
                  dec: -0.9316385797930247
              decals_brickname: "3366m010"
              ccdname: "S28"
              g: "decam/CP/V4.8.2a/CP20171108/c4d_171109_002003_ooi_g_ls9"
              r: "decam/CP/V4.8.2a/CP20170926/c4d_170927_025457_ooi_r_ls9"
              i: ""
              z: "decam/CP/V4.8.2a/CP20170926/c4d_170927_025655_ooi_z_ls9"
        psf_config:
            pixel_scale: 0.262
            psf_slen: 63
    dc2:
        _target_: bliss.surveys.dc2.DC2DataModule
        dc2_image_dir: ${paths.dc2}/run2.2i-dr6-v4/coadd-t3828-t3829/deepCoadd-results/
        dc2_cat_path: ${paths.dc2}/merged_catalog_with_flux_over_50.pkl
        image_lim: [4000, 4000]
        n_image_split: 50
        tile_slen: 4
        max_sources_per_tile: 5
        min_flux: 0.0
        prepare_data_processes_num: 4
        data_in_one_cached_file: 1250
        splits: 0:80/80:90/90:100
        batch_size: 1
        num_workers: 1
        cached_data_path: ${paths.output}/dc2_cached_data
        train_transforms:
            - _target_: bliss.data_augmentation.RotateFlipTransform
            - _target_: bliss.data_augmentation.RandomShiftTransform
              tile_slen: ${surveys.dc2.tile_slen}
              max_sources_per_tile: ${surveys.dc2.tile_slen}
        nontrain_transforms: []

#######################################################################
# things above matter only if they are referenced below

mode: train

generate:
    n_image_files: 128
    n_batches_per_file: 16
    simulator: ${simulator}
    cached_data_path: ${paths.cached_data}
    file_prefix: dataset
    store_full_catalog: false

train:
    trainer:
        _target_: pytorch_lightning.Trainer
        logger:
            _target_: pytorch_lightning.loggers.TensorBoardLogger
            save_dir: ${paths.output}
            name: null
            version: null
            default_hp_metric: false
        reload_dataloaders_every_n_epochs: 0
        check_val_every_n_epoch: 1
        log_every_n_steps: 10  # corresponds to n_batches
        min_epochs: 1
        max_epochs: 50
        accelerator: "gpu"
        devices: 1
        precision: 32-true
    callbacks:
        checkpointing:
            _target_: pytorch_lightning.callbacks.ModelCheckpoint
            filename: best_encoder
            save_top_k: 1
            verbose: True
            monitor: val/_loss
            mode: min
            save_on_train_epoch_end: False
            auto_insert_metric_name: False
        early_stopping:
            _target_: pytorch_lightning.callbacks.early_stopping.EarlyStopping
            monitor: val/_loss
            mode: min
            patience: 10
    data_source: ${cached_simulator}
    encoder: ${encoder}
    seed: null
    pretrained_weights: null
    ckpt_path: null
    matmul_precision: high

predict:
    dataset: ${surveys.dc2}
    trainer:
        _target_: pytorch_lightning.Trainer
        accelerator: "gpu"
        precision: ${train.trainer.precision}
    encoder: ${encoder}
    weight_save_path: null
    device: "cuda:0"
